{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We train Resnet models with different number of layers (18, 20, 32, 44, 56) each with 3 different GPU types (K80, P100, V100). \n",
        "\n",
        "We download Resnet model from github repo\n",
        "\n",
        "Data: CIFAR10."
      ],
      "metadata": {
        "id": "TS1TDkFc7hEN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeq1q5hokeR7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDNAHRWEn1Ma",
        "outputId": "3acf58b3-7082-4bae-88a6-005f209f05ac"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 20 21:17:02 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKrSnNNgknj2",
        "outputId": "27c9b130-3e0d-4f3e-c7b6-caccfb8e74eb"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30dTV3kNlOk_",
        "outputId": "28c7ed64-2c6a-49e2-9a84-09bd569638a0"
      },
      "source": [
        "!git clone --recursive https://github.com/eladhoffer/convNet.pytorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'convNet.pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2Dh_HsYlYLS",
        "outputId": "3584ede9-29b2-433c-e6bc-6d74dee32ec1"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/convNet.pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/convNet.pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFm5kD4Nlyt_",
        "outputId": "832d9903-49cf-45db-9e0b-bb406fcbf14e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autoaugment.py\t\tLICENSE        probe.py\t\t results\n",
            "compare_experiments.py\tmain.py        __pycache__\t trainer.py\n",
            "data.py\t\t\tmodels\t       README.md\t utils\n",
            "evaluate.py\t\tpreprocess.py  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9gksl8E91QK",
        "outputId": "83e72be4-03d7-4b14-bc19-277fc62f2199"
      },
      "source": [
        "!python main.py --dataset cifar10 --model resnet --workers 4 --model-config \"{'depth': 50}\" -b 128 --epochs 70 --save resnet50-p100-v2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving to ./results/resnet50-p100-v2\n",
            "creating model resnet\n",
            "created model with configuration: {'dataset': 'cifar10', 'depth': 50}\n",
            "number of parameters: 758554\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/Datasets/cifar10/cifar-10-python.tar.gz\n",
            "170499072it [00:06, 26310669.33it/s]                   \n",
            "Extracting /root/Datasets/cifar10/cifar-10-python.tar.gz to /root/Datasets/cifar10\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Files already downloaded and verified\n",
            "optimization regime: [{'epoch': 0, 'optimizer': 'SGD', 'lr': 0.1, 'momentum': 0.9, 'regularizer': {'name': 'WeightDecay', 'value': 0.0001, 'log': False, 'filter': {'parameter_name': <function weight_decay_config.<locals>.<lambda> at 0x7f8ab0b335f0>, 'module': <function weight_decay_config.<locals>.<lambda> at 0x7f8ab0b33680>}}}, {'epoch': 81, 'lr': 0.01}, {'epoch': 122, 'lr': 0.001}, {'epoch': 164, 'lr': 0.0001}]\n",
            "data regime: Current: {'datasets_path': '~/Datasets', 'name': 'cifar10', 'split': 'train', 'augment': True, 'input_size': None, 'batch_size': 128, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': True, 'distributed': False, 'duplicates': 1, 'autoaugment': False, 'cutout': None}\n",
            " Regime:None\n",
            "\n",
            "Starting Epoch: 1\n",
            "\n",
            "TRAINING - Epoch: [0][0/390]\tTime 0.957 (0.957)\tData 0.343 (0.343)\tLoss 2.3018 (2.3018)\tPrec@1 10.938 (10.938)\tPrec@5 50.000 (50.000)\t\n",
            "TRAINING - Epoch: [0][10/390]\tTime 0.053 (0.139)\tData 0.000 (0.035)\tLoss 2.2336 (2.2725)\tPrec@1 12.500 (11.151)\tPrec@5 60.938 (55.682)\t\n",
            "TRAINING - Epoch: [0][20/390]\tTime 0.065 (0.102)\tData 0.000 (0.019)\tLoss 2.0485 (2.2158)\tPrec@1 24.219 (14.509)\tPrec@5 72.656 (62.426)\t\n",
            "TRAINING - Epoch: [0][30/390]\tTime 0.059 (0.088)\tData 0.007 (0.014)\tLoss 1.9629 (2.1722)\tPrec@1 25.000 (16.961)\tPrec@5 83.594 (66.835)\t\n",
            "TRAINING - Epoch: [0][40/390]\tTime 0.057 (0.080)\tData 0.005 (0.012)\tLoss 1.9962 (2.1292)\tPrec@1 22.656 (17.950)\tPrec@5 80.469 (70.103)\t\n",
            "TRAINING - Epoch: [0][50/390]\tTime 0.052 (0.076)\tData 0.000 (0.011)\tLoss 1.9369 (2.0936)\tPrec@1 19.531 (19.332)\tPrec@5 86.719 (72.273)\t\n",
            "TRAINING - Epoch: [0][60/390]\tTime 0.055 (0.072)\tData 0.000 (0.009)\tLoss 1.9656 (2.0740)\tPrec@1 27.344 (20.248)\tPrec@5 78.906 (73.540)\t\n",
            "TRAINING - Epoch: [0][70/390]\tTime 0.047 (0.070)\tData 0.000 (0.008)\tLoss 1.9838 (2.0474)\tPrec@1 26.562 (21.578)\tPrec@5 82.031 (74.945)\t\n",
            "TRAINING - Epoch: [0][80/390]\tTime 0.049 (0.069)\tData 0.000 (0.008)\tLoss 1.7905 (2.0260)\tPrec@1 32.031 (22.377)\tPrec@5 88.281 (76.148)\t\n",
            "TRAINING - Epoch: [0][90/390]\tTime 0.047 (0.067)\tData 0.000 (0.008)\tLoss 1.7197 (2.0059)\tPrec@1 39.844 (23.000)\tPrec@5 89.062 (77.198)\t\n",
            "TRAINING - Epoch: [0][100/390]\tTime 0.048 (0.066)\tData 0.000 (0.007)\tLoss 1.8029 (1.9870)\tPrec@1 28.125 (23.670)\tPrec@5 85.938 (78.094)\t\n",
            "TRAINING - Epoch: [0][110/390]\tTime 0.051 (0.065)\tData 0.000 (0.007)\tLoss 1.7196 (1.9641)\tPrec@1 22.656 (24.528)\tPrec@5 87.500 (78.927)\t\n",
            "TRAINING - Epoch: [0][120/390]\tTime 0.048 (0.065)\tData 0.000 (0.007)\tLoss 1.7158 (1.9470)\tPrec@1 40.625 (25.323)\tPrec@5 92.969 (79.604)\t\n",
            "TRAINING - Epoch: [0][130/390]\tTime 0.049 (0.064)\tData 0.000 (0.007)\tLoss 1.7056 (1.9325)\tPrec@1 32.031 (25.781)\tPrec@5 87.500 (80.147)\t\n",
            "TRAINING - Epoch: [0][140/390]\tTime 0.061 (0.064)\tData 0.000 (0.006)\tLoss 1.6493 (1.9174)\tPrec@1 39.062 (26.241)\tPrec@5 89.062 (80.657)\t\n",
            "TRAINING - Epoch: [0][150/390]\tTime 0.052 (0.063)\tData 0.004 (0.006)\tLoss 1.6918 (1.9047)\tPrec@1 34.375 (26.635)\tPrec@5 88.281 (81.084)\t\n",
            "TRAINING - Epoch: [0][160/390]\tTime 0.052 (0.063)\tData 0.000 (0.006)\tLoss 1.6515 (1.8903)\tPrec@1 38.281 (27.150)\tPrec@5 87.500 (81.590)\t\n",
            "TRAINING - Epoch: [0][170/390]\tTime 0.050 (0.062)\tData 0.000 (0.006)\tLoss 1.6402 (1.8790)\tPrec@1 38.281 (27.531)\tPrec@5 90.625 (81.990)\t\n",
            "TRAINING - Epoch: [0][180/390]\tTime 0.094 (0.062)\tData 0.007 (0.006)\tLoss 1.6071 (1.8653)\tPrec@1 38.281 (28.017)\tPrec@5 89.844 (82.472)\t\n",
            "TRAINING - Epoch: [0][190/390]\tTime 0.064 (0.062)\tData 0.007 (0.006)\tLoss 1.5019 (1.8509)\tPrec@1 40.625 (28.534)\tPrec@5 87.500 (82.878)\t\n",
            "TRAINING - Epoch: [0][200/390]\tTime 0.048 (0.062)\tData 0.000 (0.006)\tLoss 1.5074 (1.8400)\tPrec@1 42.188 (29.031)\tPrec@5 91.406 (83.228)\t\n",
            "TRAINING - Epoch: [0][210/390]\tTime 0.048 (0.062)\tData 0.000 (0.006)\tLoss 1.6228 (1.8297)\tPrec@1 40.625 (29.462)\tPrec@5 88.281 (83.538)\t\n",
            "TRAINING - Epoch: [0][220/390]\tTime 0.060 (0.062)\tData 0.007 (0.005)\tLoss 1.5959 (1.8210)\tPrec@1 42.188 (29.864)\tPrec@5 88.281 (83.806)\t\n",
            "TRAINING - Epoch: [0][230/390]\tTime 0.060 (0.061)\tData 0.006 (0.005)\tLoss 1.5342 (1.8097)\tPrec@1 45.312 (30.374)\tPrec@5 91.406 (84.098)\t\n",
            "TRAINING - Epoch: [0][240/390]\tTime 0.058 (0.061)\tData 0.007 (0.005)\tLoss 1.4512 (1.7981)\tPrec@1 41.406 (30.916)\tPrec@5 94.531 (84.433)\t\n",
            "TRAINING - Epoch: [0][250/390]\tTime 0.053 (0.061)\tData 0.000 (0.005)\tLoss 1.6473 (1.7876)\tPrec@1 35.938 (31.350)\tPrec@5 89.844 (84.736)\t\n",
            "TRAINING - Epoch: [0][260/390]\tTime 0.047 (0.061)\tData 0.000 (0.005)\tLoss 1.5805 (1.7782)\tPrec@1 41.406 (31.729)\tPrec@5 89.062 (85.007)\t\n",
            "TRAINING - Epoch: [0][270/390]\tTime 0.053 (0.061)\tData 0.000 (0.005)\tLoss 1.2800 (1.7691)\tPrec@1 48.438 (32.135)\tPrec@5 96.094 (85.240)\t\n",
            "TRAINING - Epoch: [0][280/390]\tTime 0.071 (0.061)\tData 0.007 (0.005)\tLoss 1.5933 (1.7577)\tPrec@1 45.312 (32.629)\tPrec@5 91.406 (85.512)\t\n",
            "TRAINING - Epoch: [0][290/390]\tTime 0.052 (0.061)\tData 0.000 (0.005)\tLoss 1.5321 (1.7477)\tPrec@1 39.844 (33.059)\tPrec@5 89.844 (85.742)\t\n",
            "TRAINING - Epoch: [0][300/390]\tTime 0.059 (0.061)\tData 0.007 (0.005)\tLoss 1.3822 (1.7384)\tPrec@1 46.094 (33.490)\tPrec@5 94.531 (85.969)\t\n",
            "TRAINING - Epoch: [0][310/390]\tTime 0.050 (0.060)\tData 0.000 (0.005)\tLoss 1.6669 (1.7295)\tPrec@1 33.594 (33.832)\tPrec@5 87.500 (86.186)\t\n",
            "TRAINING - Epoch: [0][320/390]\tTime 0.069 (0.060)\tData 0.000 (0.005)\tLoss 1.3542 (1.7213)\tPrec@1 47.656 (34.119)\tPrec@5 92.188 (86.376)\t\n",
            "TRAINING - Epoch: [0][330/390]\tTime 0.053 (0.060)\tData 0.000 (0.005)\tLoss 1.3340 (1.7126)\tPrec@1 53.125 (34.491)\tPrec@5 93.750 (86.589)\t\n",
            "TRAINING - Epoch: [0][340/390]\tTime 0.048 (0.060)\tData 0.000 (0.005)\tLoss 1.4582 (1.7052)\tPrec@1 46.094 (34.819)\tPrec@5 95.312 (86.735)\t\n",
            "TRAINING - Epoch: [0][350/390]\tTime 0.054 (0.060)\tData 0.000 (0.005)\tLoss 1.4447 (1.6963)\tPrec@1 46.875 (35.192)\tPrec@5 92.969 (86.932)\t\n",
            "TRAINING - Epoch: [0][360/390]\tTime 0.049 (0.060)\tData 0.000 (0.005)\tLoss 1.5427 (1.6875)\tPrec@1 41.406 (35.561)\tPrec@5 93.750 (87.115)\t\n",
            "TRAINING - Epoch: [0][370/390]\tTime 0.066 (0.060)\tData 0.007 (0.005)\tLoss 1.3077 (1.6783)\tPrec@1 62.500 (35.942)\tPrec@5 93.750 (87.279)\t\n",
            "TRAINING - Epoch: [0][380/390]\tTime 0.061 (0.060)\tData 0.007 (0.005)\tLoss 1.5741 (1.6692)\tPrec@1 44.531 (36.339)\tPrec@5 90.625 (87.482)\t\n",
            "TRAINING - Epoch: [0][389/390]\tTime 0.040 (0.059)\tData 0.000 (0.005)\tLoss 1.3600 (1.6615)\tPrec@1 49.219 (36.641)\tPrec@5 93.750 (87.650)\t\n",
            "EVALUATING - Epoch: [0][0/79]\tTime 0.220 (0.220)\tData 0.175 (0.175)\tLoss 1.4822 (1.4822)\tPrec@1 49.219 (49.219)\tPrec@5 91.406 (91.406)\t\n",
            "EVALUATING - Epoch: [0][10/79]\tTime 0.014 (0.054)\tData 0.000 (0.026)\tLoss 1.4713 (1.4883)\tPrec@1 51.562 (48.580)\tPrec@5 91.406 (91.193)\t\n",
            "EVALUATING - Epoch: [0][20/79]\tTime 0.034 (0.045)\tData 0.009 (0.017)\tLoss 1.5026 (1.5121)\tPrec@1 44.531 (48.810)\tPrec@5 91.406 (91.629)\t\n",
            "EVALUATING - Epoch: [0][30/79]\tTime 0.021 (0.039)\tData 0.000 (0.013)\tLoss 1.4975 (1.5091)\tPrec@1 49.219 (49.294)\tPrec@5 93.750 (91.759)\t\n",
            "EVALUATING - Epoch: [0][40/79]\tTime 0.038 (0.037)\tData 0.007 (0.011)\tLoss 1.5542 (1.5023)\tPrec@1 46.875 (49.181)\tPrec@5 89.844 (91.711)\t\n",
            "EVALUATING - Epoch: [0][50/79]\tTime 0.036 (0.036)\tData 0.006 (0.010)\tLoss 1.4907 (1.5147)\tPrec@1 46.875 (49.035)\tPrec@5 89.844 (91.330)\t\n",
            "EVALUATING - Epoch: [0][60/79]\tTime 0.027 (0.035)\tData 0.000 (0.009)\tLoss 1.5893 (1.5164)\tPrec@1 49.219 (48.937)\tPrec@5 89.844 (91.419)\t\n",
            "EVALUATING - Epoch: [0][70/79]\tTime 0.038 (0.034)\tData 0.007 (0.009)\tLoss 1.4257 (1.5211)\tPrec@1 50.781 (48.933)\tPrec@5 94.531 (91.406)\t\n",
            "EVALUATING - Epoch: [0][78/79]\tTime 0.037 (0.032)\tData 0.000 (0.008)\tLoss 1.0572 (1.5208)\tPrec@1 50.000 (48.830)\tPrec@5 100.000 (91.400)\t\n",
            "\n",
            "Results - Epoch: 1\n",
            "Training Loss 1.6615 \tTraining Prec@1 36.641 \tTraining Prec@5 87.650 \tValidation Loss 1.5208 \tValidation Prec@1 48.830 \tValidation Prec@5 91.400 \t\n",
            "\n",
            "Plot file saved at: /content/drive/My Drive/Colab Notebooks/convNet.pytorch/results/resnet50-p100-v2/results.html\n",
            "\n",
            "Starting Epoch: 2\n",
            "\n",
            "TRAINING - Epoch: [1][0/390]\tTime 0.437 (0.437)\tData 0.278 (0.278)\tLoss 1.2509 (1.2509)\tPrec@1 56.250 (56.250)\tPrec@5 92.188 (92.188)\t\n",
            "TRAINING - Epoch: [1][10/390]\tTime 0.048 (0.091)\tData 0.000 (0.028)\tLoss 1.3765 (1.2808)\tPrec@1 50.000 (52.202)\tPrec@5 92.969 (94.318)\t\n",
            "TRAINING - Epoch: [1][20/390]\tTime 0.050 (0.075)\tData 0.000 (0.015)\tLoss 1.2748 (1.2849)\tPrec@1 53.906 (52.716)\tPrec@5 96.094 (94.308)\t\n",
            "TRAINING - Epoch: [1][30/390]\tTime 0.049 (0.069)\tData 0.000 (0.011)\tLoss 1.2777 (1.2725)\tPrec@1 57.812 (53.377)\tPrec@5 97.656 (94.682)\t\n",
            "TRAINING - Epoch: [1][40/390]\tTime 0.054 (0.066)\tData 0.000 (0.009)\tLoss 1.3106 (1.2786)\tPrec@1 46.094 (53.030)\tPrec@5 94.531 (94.646)\t\n",
            "TRAINING - Epoch: [1][50/390]\tTime 0.070 (0.064)\tData 0.007 (0.008)\tLoss 1.3080 (1.2827)\tPrec@1 51.562 (52.926)\tPrec@5 95.312 (94.516)\t\n",
            "TRAINING - Epoch: [1][60/390]\tTime 0.055 (0.063)\tData 0.000 (0.007)\tLoss 1.2980 (1.2827)\tPrec@1 54.688 (52.741)\tPrec@5 93.750 (94.570)\t\n",
            "TRAINING - Epoch: [1][70/390]\tTime 0.048 (0.062)\tData 0.000 (0.007)\tLoss 1.2230 (1.2827)\tPrec@1 63.281 (52.927)\tPrec@5 87.500 (94.311)\t\n",
            "TRAINING - Epoch: [1][80/390]\tTime 0.062 (0.061)\tData 0.006 (0.006)\tLoss 1.0917 (1.2747)\tPrec@1 58.594 (53.009)\tPrec@5 96.875 (94.531)\t\n",
            "TRAINING - Epoch: [1][90/390]\tTime 0.058 (0.061)\tData 0.011 (0.006)\tLoss 1.3406 (1.2706)\tPrec@1 53.125 (53.168)\tPrec@5 96.094 (94.660)\t\n",
            "TRAINING - Epoch: [1][100/390]\tTime 0.060 (0.061)\tData 0.007 (0.006)\tLoss 1.3978 (1.2695)\tPrec@1 47.656 (53.117)\tPrec@5 96.094 (94.616)\t\n",
            "TRAINING - Epoch: [1][110/390]\tTime 0.049 (0.060)\tData 0.000 (0.006)\tLoss 1.0077 (1.2638)\tPrec@1 66.406 (53.477)\tPrec@5 99.219 (94.665)\t\n",
            "TRAINING - Epoch: [1][120/390]\tTime 0.066 (0.060)\tData 0.007 (0.006)\tLoss 1.0483 (1.2546)\tPrec@1 58.594 (53.900)\tPrec@5 95.312 (94.725)\t\n",
            "TRAINING - Epoch: [1][130/390]\tTime 0.049 (0.060)\tData 0.000 (0.005)\tLoss 1.2758 (1.2455)\tPrec@1 55.469 (54.216)\tPrec@5 91.406 (94.770)\t\n",
            "TRAINING - Epoch: [1][140/390]\tTime 0.072 (0.060)\tData 0.007 (0.005)\tLoss 1.1842 (1.2366)\tPrec@1 58.594 (54.599)\tPrec@5 96.094 (94.886)\t\n",
            "TRAINING - Epoch: [1][150/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 1.1338 (1.2296)\tPrec@1 56.250 (54.775)\tPrec@5 99.219 (95.002)\t\n",
            "TRAINING - Epoch: [1][160/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 1.1320 (1.2268)\tPrec@1 57.812 (54.886)\tPrec@5 96.094 (95.050)\t\n",
            "TRAINING - Epoch: [1][170/390]\tTime 0.067 (0.059)\tData 0.000 (0.005)\tLoss 1.1028 (1.2231)\tPrec@1 60.938 (55.035)\tPrec@5 92.969 (95.070)\t\n",
            "TRAINING - Epoch: [1][180/390]\tTime 0.051 (0.059)\tData 0.001 (0.005)\tLoss 1.2991 (1.2206)\tPrec@1 49.219 (55.098)\tPrec@5 93.750 (95.092)\t\n",
            "TRAINING - Epoch: [1][190/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 1.2123 (1.2161)\tPrec@1 60.938 (55.346)\tPrec@5 95.312 (95.137)\t\n",
            "TRAINING - Epoch: [1][200/390]\tTime 0.050 (0.059)\tData 0.000 (0.005)\tLoss 1.0185 (1.2122)\tPrec@1 61.719 (55.473)\tPrec@5 95.312 (95.176)\t\n",
            "TRAINING - Epoch: [1][210/390]\tTime 0.055 (0.059)\tData 0.007 (0.005)\tLoss 1.1384 (1.2071)\tPrec@1 59.375 (55.702)\tPrec@5 96.875 (95.205)\t\n",
            "TRAINING - Epoch: [1][220/390]\tTime 0.067 (0.058)\tData 0.007 (0.005)\tLoss 1.2674 (1.2029)\tPrec@1 50.781 (55.882)\tPrec@5 93.750 (95.210)\t\n",
            "TRAINING - Epoch: [1][230/390]\tTime 0.058 (0.058)\tData 0.006 (0.005)\tLoss 1.3019 (1.1995)\tPrec@1 55.469 (55.996)\tPrec@5 94.531 (95.228)\t\n",
            "TRAINING - Epoch: [1][240/390]\tTime 0.056 (0.058)\tData 0.007 (0.005)\tLoss 0.9938 (1.1954)\tPrec@1 65.625 (56.091)\tPrec@5 96.875 (95.254)\t\n",
            "TRAINING - Epoch: [1][250/390]\tTime 0.056 (0.058)\tData 0.000 (0.005)\tLoss 1.0012 (1.1886)\tPrec@1 60.938 (56.368)\tPrec@5 97.656 (95.291)\t\n",
            "TRAINING - Epoch: [1][260/390]\tTime 0.060 (0.058)\tData 0.012 (0.005)\tLoss 1.1339 (1.1832)\tPrec@1 59.375 (56.618)\tPrec@5 97.656 (95.342)\t\n",
            "TRAINING - Epoch: [1][270/390]\tTime 0.054 (0.058)\tData 0.000 (0.005)\tLoss 1.0366 (1.1766)\tPrec@1 60.938 (56.873)\tPrec@5 96.875 (95.411)\t\n",
            "TRAINING - Epoch: [1][280/390]\tTime 0.078 (0.058)\tData 0.007 (0.005)\tLoss 0.9826 (1.1743)\tPrec@1 68.750 (57.023)\tPrec@5 98.438 (95.446)\t\n",
            "TRAINING - Epoch: [1][290/390]\tTime 0.055 (0.058)\tData 0.006 (0.005)\tLoss 1.0233 (1.1716)\tPrec@1 64.062 (57.144)\tPrec@5 95.312 (95.441)\t\n",
            "TRAINING - Epoch: [1][300/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 1.1010 (1.1681)\tPrec@1 57.812 (57.257)\tPrec@5 94.531 (95.466)\t\n",
            "TRAINING - Epoch: [1][310/390]\tTime 0.056 (0.058)\tData 0.009 (0.005)\tLoss 1.1578 (1.1651)\tPrec@1 57.812 (57.330)\tPrec@5 96.094 (95.524)\t\n",
            "TRAINING - Epoch: [1][320/390]\tTime 0.055 (0.058)\tData 0.007 (0.004)\tLoss 1.0786 (1.1621)\tPrec@1 64.062 (57.457)\tPrec@5 94.531 (95.534)\t\n",
            "TRAINING - Epoch: [1][330/390]\tTime 0.048 (0.058)\tData 0.000 (0.004)\tLoss 1.0517 (1.1590)\tPrec@1 59.375 (57.588)\tPrec@5 96.875 (95.551)\t\n",
            "TRAINING - Epoch: [1][340/390]\tTime 0.057 (0.058)\tData 0.009 (0.004)\tLoss 0.6924 (1.1544)\tPrec@1 76.562 (57.762)\tPrec@5 99.219 (95.576)\t\n",
            "TRAINING - Epoch: [1][350/390]\tTime 0.056 (0.058)\tData 0.000 (0.004)\tLoss 1.1265 (1.1516)\tPrec@1 60.156 (57.850)\tPrec@5 93.750 (95.593)\t\n",
            "TRAINING - Epoch: [1][360/390]\tTime 0.049 (0.058)\tData 0.003 (0.004)\tLoss 0.9474 (1.1477)\tPrec@1 70.312 (58.005)\tPrec@5 96.094 (95.628)\t\n",
            "TRAINING - Epoch: [1][370/390]\tTime 0.054 (0.058)\tData 0.007 (0.004)\tLoss 0.9867 (1.1429)\tPrec@1 68.750 (58.210)\tPrec@5 96.094 (95.654)\t\n",
            "TRAINING - Epoch: [1][380/390]\tTime 0.058 (0.058)\tData 0.007 (0.004)\tLoss 0.9678 (1.1389)\tPrec@1 67.969 (58.378)\tPrec@5 97.656 (95.675)\t\n",
            "TRAINING - Epoch: [1][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 1.1934 (1.1365)\tPrec@1 62.500 (58.506)\tPrec@5 96.094 (95.685)\t\n",
            "EVALUATING - Epoch: [1][0/79]\tTime 0.274 (0.274)\tData 0.239 (0.239)\tLoss 1.0124 (1.0124)\tPrec@1 63.281 (63.281)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [1][10/79]\tTime 0.012 (0.053)\tData 0.000 (0.026)\tLoss 0.9949 (1.0369)\tPrec@1 62.500 (63.849)\tPrec@5 97.656 (97.088)\t\n",
            "EVALUATING - Epoch: [1][20/79]\tTime 0.029 (0.043)\tData 0.008 (0.016)\tLoss 1.1988 (1.0848)\tPrec@1 62.500 (63.095)\tPrec@5 96.094 (96.838)\t\n",
            "EVALUATING - Epoch: [1][30/79]\tTime 0.025 (0.038)\tData 0.010 (0.013)\tLoss 0.9465 (1.0880)\tPrec@1 67.188 (63.407)\tPrec@5 100.000 (96.799)\t\n",
            "EVALUATING - Epoch: [1][40/79]\tTime 0.037 (0.037)\tData 0.010 (0.011)\tLoss 0.9916 (1.0720)\tPrec@1 65.625 (63.605)\tPrec@5 96.875 (96.780)\t\n",
            "EVALUATING - Epoch: [1][50/79]\tTime 0.014 (0.036)\tData 0.000 (0.010)\tLoss 1.2128 (1.0849)\tPrec@1 58.594 (63.051)\tPrec@5 94.531 (96.691)\t\n",
            "EVALUATING - Epoch: [1][60/79]\tTime 0.046 (0.036)\tData 0.007 (0.008)\tLoss 1.1704 (1.0898)\tPrec@1 62.500 (62.999)\tPrec@5 95.312 (96.657)\t\n",
            "EVALUATING - Epoch: [1][70/79]\tTime 0.023 (0.034)\tData 0.000 (0.008)\tLoss 0.9158 (1.0986)\tPrec@1 69.531 (62.555)\tPrec@5 99.219 (96.688)\t\n",
            "EVALUATING - Epoch: [1][78/79]\tTime 0.006 (0.032)\tData 0.000 (0.007)\tLoss 0.7778 (1.0913)\tPrec@1 75.000 (62.860)\tPrec@5 100.000 (96.690)\t\n",
            "\n",
            "Results - Epoch: 2\n",
            "Training Loss 1.1365 \tTraining Prec@1 58.506 \tTraining Prec@5 95.685 \tValidation Loss 1.0913 \tValidation Prec@1 62.860 \tValidation Prec@5 96.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 3\n",
            "\n",
            "TRAINING - Epoch: [2][0/390]\tTime 0.372 (0.372)\tData 0.284 (0.284)\tLoss 0.8365 (0.8365)\tPrec@1 71.094 (71.094)\tPrec@5 98.438 (98.438)\t\n",
            "TRAINING - Epoch: [2][10/390]\tTime 0.057 (0.088)\tData 0.000 (0.030)\tLoss 0.9905 (0.9945)\tPrec@1 59.375 (63.778)\tPrec@5 100.000 (96.733)\t\n",
            "TRAINING - Epoch: [2][20/390]\tTime 0.064 (0.073)\tData 0.000 (0.016)\tLoss 0.8222 (0.9913)\tPrec@1 72.656 (64.509)\tPrec@5 96.875 (96.726)\t\n",
            "TRAINING - Epoch: [2][30/390]\tTime 0.046 (0.067)\tData 0.000 (0.013)\tLoss 1.0139 (0.9965)\tPrec@1 61.719 (64.390)\tPrec@5 98.438 (96.623)\t\n",
            "TRAINING - Epoch: [2][40/390]\tTime 0.047 (0.065)\tData 0.000 (0.010)\tLoss 0.9298 (0.9806)\tPrec@1 70.312 (65.206)\tPrec@5 97.656 (96.799)\t\n",
            "TRAINING - Epoch: [2][50/390]\tTime 0.053 (0.063)\tData 0.005 (0.009)\tLoss 1.0049 (0.9745)\tPrec@1 63.281 (65.135)\tPrec@5 96.094 (96.921)\t\n",
            "TRAINING - Epoch: [2][60/390]\tTime 0.050 (0.062)\tData 0.001 (0.008)\tLoss 1.0931 (0.9656)\tPrec@1 66.406 (65.343)\tPrec@5 94.531 (96.888)\t\n",
            "TRAINING - Epoch: [2][70/390]\tTime 0.047 (0.061)\tData 0.000 (0.007)\tLoss 0.8695 (0.9648)\tPrec@1 71.094 (65.317)\tPrec@5 96.875 (96.930)\t\n",
            "TRAINING - Epoch: [2][80/390]\tTime 0.048 (0.060)\tData 0.000 (0.007)\tLoss 0.8882 (0.9598)\tPrec@1 67.969 (65.365)\tPrec@5 97.656 (96.943)\t\n",
            "TRAINING - Epoch: [2][90/390]\tTime 0.048 (0.060)\tData 0.000 (0.007)\tLoss 1.0269 (0.9526)\tPrec@1 62.500 (65.539)\tPrec@5 98.438 (97.030)\t\n",
            "TRAINING - Epoch: [2][100/390]\tTime 0.059 (0.060)\tData 0.007 (0.006)\tLoss 0.8841 (0.9504)\tPrec@1 68.750 (65.571)\tPrec@5 96.875 (97.146)\t\n",
            "TRAINING - Epoch: [2][110/390]\tTime 0.054 (0.060)\tData 0.006 (0.006)\tLoss 1.1107 (0.9565)\tPrec@1 59.375 (65.308)\tPrec@5 93.750 (97.128)\t\n",
            "TRAINING - Epoch: [2][120/390]\tTime 0.064 (0.059)\tData 0.006 (0.006)\tLoss 0.8409 (0.9587)\tPrec@1 67.969 (65.347)\tPrec@5 98.438 (97.114)\t\n",
            "TRAINING - Epoch: [2][130/390]\tTime 0.061 (0.059)\tData 0.012 (0.006)\tLoss 1.0775 (0.9642)\tPrec@1 58.594 (65.154)\tPrec@5 95.312 (97.000)\t\n",
            "TRAINING - Epoch: [2][140/390]\tTime 0.056 (0.059)\tData 0.000 (0.006)\tLoss 0.8055 (0.9641)\tPrec@1 71.875 (65.171)\tPrec@5 97.656 (97.047)\t\n",
            "TRAINING - Epoch: [2][150/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.9303 (0.9602)\tPrec@1 64.844 (65.387)\tPrec@5 98.438 (97.061)\t\n",
            "TRAINING - Epoch: [2][160/390]\tTime 0.050 (0.059)\tData 0.000 (0.005)\tLoss 1.0532 (0.9579)\tPrec@1 61.719 (65.523)\tPrec@5 96.094 (97.098)\t\n",
            "TRAINING - Epoch: [2][170/390]\tTime 0.054 (0.059)\tData 0.000 (0.005)\tLoss 1.0625 (0.9566)\tPrec@1 64.844 (65.511)\tPrec@5 96.094 (97.103)\t\n",
            "TRAINING - Epoch: [2][180/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.7288 (0.9539)\tPrec@1 76.562 (65.582)\tPrec@5 99.219 (97.121)\t\n",
            "TRAINING - Epoch: [2][190/390]\tTime 0.057 (0.058)\tData 0.004 (0.005)\tLoss 0.9308 (0.9509)\tPrec@1 64.844 (65.629)\tPrec@5 96.875 (97.174)\t\n",
            "TRAINING - Epoch: [2][200/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.7547 (0.9489)\tPrec@1 70.312 (65.703)\tPrec@5 98.438 (97.213)\t\n",
            "TRAINING - Epoch: [2][210/390]\tTime 0.055 (0.058)\tData 0.000 (0.005)\tLoss 0.9384 (0.9462)\tPrec@1 66.406 (65.788)\tPrec@5 96.094 (97.227)\t\n",
            "TRAINING - Epoch: [2][220/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.9078 (0.9461)\tPrec@1 68.750 (65.826)\tPrec@5 96.875 (97.204)\t\n",
            "TRAINING - Epoch: [2][230/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.9903 (0.9436)\tPrec@1 59.375 (65.963)\tPrec@5 99.219 (97.250)\t\n",
            "TRAINING - Epoch: [2][240/390]\tTime 0.056 (0.058)\tData 0.000 (0.005)\tLoss 0.9625 (0.9454)\tPrec@1 67.188 (65.907)\tPrec@5 97.656 (97.238)\t\n",
            "TRAINING - Epoch: [2][250/390]\tTime 0.062 (0.058)\tData 0.000 (0.005)\tLoss 1.0248 (0.9451)\tPrec@1 59.375 (65.924)\tPrec@5 96.875 (97.214)\t\n",
            "TRAINING - Epoch: [2][260/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.7800 (0.9432)\tPrec@1 72.656 (66.020)\tPrec@5 99.219 (97.222)\t\n",
            "TRAINING - Epoch: [2][270/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.9259 (0.9410)\tPrec@1 60.938 (66.095)\tPrec@5 98.438 (97.227)\t\n",
            "TRAINING - Epoch: [2][280/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.8243 (0.9394)\tPrec@1 73.438 (66.170)\tPrec@5 97.656 (97.256)\t\n",
            "TRAINING - Epoch: [2][290/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.8934 (0.9384)\tPrec@1 71.094 (66.267)\tPrec@5 95.312 (97.259)\t\n",
            "TRAINING - Epoch: [2][300/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.8346 (0.9370)\tPrec@1 71.094 (66.349)\tPrec@5 99.219 (97.270)\t\n",
            "TRAINING - Epoch: [2][310/390]\tTime 0.064 (0.058)\tData 0.000 (0.005)\tLoss 1.0160 (0.9359)\tPrec@1 62.500 (66.381)\tPrec@5 98.438 (97.277)\t\n",
            "TRAINING - Epoch: [2][320/390]\tTime 0.048 (0.058)\tData 0.000 (0.004)\tLoss 0.7180 (0.9347)\tPrec@1 75.000 (66.377)\tPrec@5 96.094 (97.294)\t\n",
            "TRAINING - Epoch: [2][330/390]\tTime 0.059 (0.058)\tData 0.012 (0.004)\tLoss 1.0374 (0.9329)\tPrec@1 65.625 (66.468)\tPrec@5 96.875 (97.295)\t\n",
            "TRAINING - Epoch: [2][340/390]\tTime 0.053 (0.058)\tData 0.000 (0.004)\tLoss 1.0106 (0.9321)\tPrec@1 62.500 (66.489)\tPrec@5 96.875 (97.283)\t\n",
            "TRAINING - Epoch: [2][350/390]\tTime 0.054 (0.058)\tData 0.007 (0.004)\tLoss 0.7547 (0.9293)\tPrec@1 74.219 (66.540)\tPrec@5 97.656 (97.311)\t\n",
            "TRAINING - Epoch: [2][360/390]\tTime 0.059 (0.058)\tData 0.000 (0.004)\tLoss 0.8265 (0.9265)\tPrec@1 69.531 (66.620)\tPrec@5 99.219 (97.342)\t\n",
            "TRAINING - Epoch: [2][370/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.8530 (0.9242)\tPrec@1 68.750 (66.684)\tPrec@5 96.875 (97.349)\t\n",
            "TRAINING - Epoch: [2][380/390]\tTime 0.055 (0.058)\tData 0.007 (0.004)\tLoss 0.8718 (0.9208)\tPrec@1 75.000 (66.800)\tPrec@5 97.656 (97.367)\t\n",
            "TRAINING - Epoch: [2][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.8334 (0.9199)\tPrec@1 75.000 (66.865)\tPrec@5 99.219 (97.362)\t\n",
            "EVALUATING - Epoch: [2][0/79]\tTime 0.206 (0.206)\tData 0.176 (0.176)\tLoss 1.0623 (1.0623)\tPrec@1 64.844 (64.844)\tPrec@5 95.312 (95.312)\t\n",
            "EVALUATING - Epoch: [2][10/79]\tTime 0.033 (0.055)\tData 0.019 (0.028)\tLoss 1.1878 (1.2358)\tPrec@1 58.594 (59.091)\tPrec@5 95.312 (96.449)\t\n",
            "EVALUATING - Epoch: [2][20/79]\tTime 0.013 (0.041)\tData 0.000 (0.017)\tLoss 1.6106 (1.3052)\tPrec@1 50.781 (57.589)\tPrec@5 94.531 (96.094)\t\n",
            "EVALUATING - Epoch: [2][30/79]\tTime 0.026 (0.038)\tData 0.007 (0.013)\tLoss 1.1607 (1.3146)\tPrec@1 57.812 (57.031)\tPrec@5 98.438 (95.993)\t\n",
            "EVALUATING - Epoch: [2][40/79]\tTime 0.028 (0.036)\tData 0.001 (0.011)\tLoss 1.3353 (1.3091)\tPrec@1 57.812 (57.393)\tPrec@5 95.312 (95.979)\t\n",
            "EVALUATING - Epoch: [2][50/79]\tTime 0.012 (0.034)\tData 0.000 (0.009)\tLoss 1.4909 (1.3257)\tPrec@1 50.000 (56.939)\tPrec@5 96.875 (95.787)\t\n",
            "EVALUATING - Epoch: [2][60/79]\tTime 0.024 (0.034)\tData 0.004 (0.009)\tLoss 1.3663 (1.3100)\tPrec@1 60.938 (57.223)\tPrec@5 96.875 (95.889)\t\n",
            "EVALUATING - Epoch: [2][70/79]\tTime 0.022 (0.034)\tData 0.010 (0.008)\tLoss 1.1786 (1.3058)\tPrec@1 53.906 (57.405)\tPrec@5 97.656 (95.863)\t\n",
            "EVALUATING - Epoch: [2][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.9788 (1.3040)\tPrec@1 56.250 (57.360)\tPrec@5 100.000 (95.950)\t\n",
            "\n",
            "Results - Epoch: 3\n",
            "Training Loss 0.9199 \tTraining Prec@1 66.865 \tTraining Prec@5 97.362 \tValidation Loss 1.3040 \tValidation Prec@1 57.360 \tValidation Prec@5 95.950 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 4\n",
            "\n",
            "TRAINING - Epoch: [3][0/390]\tTime 0.394 (0.394)\tData 0.281 (0.281)\tLoss 0.7014 (0.7014)\tPrec@1 75.000 (75.000)\tPrec@5 97.656 (97.656)\t\n",
            "TRAINING - Epoch: [3][10/390]\tTime 0.056 (0.091)\tData 0.000 (0.028)\tLoss 0.7626 (0.8559)\tPrec@1 73.438 (69.957)\tPrec@5 98.438 (97.514)\t\n",
            "TRAINING - Epoch: [3][20/390]\tTime 0.055 (0.075)\tData 0.007 (0.017)\tLoss 0.9238 (0.8745)\tPrec@1 66.406 (68.973)\tPrec@5 95.312 (97.359)\t\n",
            "TRAINING - Epoch: [3][30/390]\tTime 0.066 (0.069)\tData 0.010 (0.012)\tLoss 0.7247 (0.8395)\tPrec@1 67.188 (70.086)\tPrec@5 99.219 (97.732)\t\n",
            "TRAINING - Epoch: [3][40/390]\tTime 0.057 (0.066)\tData 0.006 (0.010)\tLoss 0.8728 (0.8355)\tPrec@1 67.969 (70.084)\tPrec@5 97.656 (97.847)\t\n",
            "TRAINING - Epoch: [3][50/390]\tTime 0.062 (0.064)\tData 0.012 (0.009)\tLoss 0.8713 (0.8322)\tPrec@1 67.969 (70.236)\tPrec@5 96.875 (97.886)\t\n",
            "TRAINING - Epoch: [3][60/390]\tTime 0.047 (0.062)\tData 0.000 (0.008)\tLoss 0.9116 (0.8385)\tPrec@1 64.844 (69.928)\tPrec@5 96.875 (97.836)\t\n",
            "TRAINING - Epoch: [3][70/390]\tTime 0.055 (0.061)\tData 0.006 (0.008)\tLoss 0.7248 (0.8388)\tPrec@1 73.438 (70.004)\tPrec@5 99.219 (97.854)\t\n",
            "TRAINING - Epoch: [3][80/390]\tTime 0.056 (0.061)\tData 0.008 (0.007)\tLoss 0.7571 (0.8327)\tPrec@1 75.000 (70.467)\tPrec@5 98.438 (97.868)\t\n",
            "TRAINING - Epoch: [3][90/390]\tTime 0.062 (0.060)\tData 0.006 (0.007)\tLoss 0.8774 (0.8297)\tPrec@1 68.750 (70.501)\tPrec@5 96.094 (97.871)\t\n",
            "TRAINING - Epoch: [3][100/390]\tTime 0.049 (0.060)\tData 0.000 (0.006)\tLoss 0.8213 (0.8259)\tPrec@1 71.094 (70.684)\tPrec@5 96.875 (97.873)\t\n",
            "TRAINING - Epoch: [3][110/390]\tTime 0.051 (0.060)\tData 0.000 (0.006)\tLoss 0.8871 (0.8213)\tPrec@1 68.750 (70.904)\tPrec@5 99.219 (97.903)\t\n",
            "TRAINING - Epoch: [3][120/390]\tTime 0.056 (0.060)\tData 0.008 (0.006)\tLoss 0.8870 (0.8253)\tPrec@1 72.656 (70.861)\tPrec@5 96.094 (97.837)\t\n",
            "TRAINING - Epoch: [3][130/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.5755 (0.8249)\tPrec@1 76.562 (70.939)\tPrec@5 99.219 (97.859)\t\n",
            "TRAINING - Epoch: [3][140/390]\tTime 0.058 (0.060)\tData 0.000 (0.006)\tLoss 0.7415 (0.8246)\tPrec@1 71.094 (70.855)\tPrec@5 99.219 (97.878)\t\n",
            "TRAINING - Epoch: [3][150/390]\tTime 0.061 (0.060)\tData 0.008 (0.006)\tLoss 0.7786 (0.8248)\tPrec@1 73.438 (70.809)\tPrec@5 98.438 (97.889)\t\n",
            "TRAINING - Epoch: [3][160/390]\tTime 0.050 (0.059)\tData 0.001 (0.005)\tLoss 0.8061 (0.8219)\tPrec@1 71.094 (70.919)\tPrec@5 96.875 (97.918)\t\n",
            "TRAINING - Epoch: [3][170/390]\tTime 0.060 (0.059)\tData 0.011 (0.005)\tLoss 0.6826 (0.8203)\tPrec@1 76.562 (71.034)\tPrec@5 99.219 (97.926)\t\n",
            "TRAINING - Epoch: [3][180/390]\tTime 0.063 (0.059)\tData 0.007 (0.005)\tLoss 0.9405 (0.8203)\tPrec@1 67.188 (71.025)\tPrec@5 98.438 (97.937)\t\n",
            "TRAINING - Epoch: [3][190/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.9063 (0.8186)\tPrec@1 71.875 (71.090)\tPrec@5 96.875 (97.947)\t\n",
            "TRAINING - Epoch: [3][200/390]\tTime 0.065 (0.059)\tData 0.000 (0.005)\tLoss 0.8620 (0.8160)\tPrec@1 68.750 (71.195)\tPrec@5 99.219 (97.959)\t\n",
            "TRAINING - Epoch: [3][210/390]\tTime 0.049 (0.059)\tData 0.000 (0.005)\tLoss 0.7139 (0.8141)\tPrec@1 70.312 (71.209)\tPrec@5 98.438 (97.986)\t\n",
            "TRAINING - Epoch: [3][220/390]\tTime 0.078 (0.058)\tData 0.009 (0.005)\tLoss 1.0064 (0.8130)\tPrec@1 63.281 (71.242)\tPrec@5 96.875 (97.992)\t\n",
            "TRAINING - Epoch: [3][230/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.8461 (0.8126)\tPrec@1 69.531 (71.232)\tPrec@5 98.438 (98.018)\t\n",
            "TRAINING - Epoch: [3][240/390]\tTime 0.053 (0.058)\tData 0.000 (0.005)\tLoss 0.7570 (0.8105)\tPrec@1 75.000 (71.308)\tPrec@5 97.656 (98.036)\t\n",
            "TRAINING - Epoch: [3][250/390]\tTime 0.061 (0.058)\tData 0.007 (0.005)\tLoss 0.8505 (0.8108)\tPrec@1 67.969 (71.333)\tPrec@5 96.094 (98.020)\t\n",
            "TRAINING - Epoch: [3][260/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.8210 (0.8090)\tPrec@1 71.094 (71.378)\tPrec@5 96.875 (98.030)\t\n",
            "TRAINING - Epoch: [3][270/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.7707 (0.8080)\tPrec@1 74.219 (71.376)\tPrec@5 98.438 (98.025)\t\n",
            "TRAINING - Epoch: [3][280/390]\tTime 0.078 (0.058)\tData 0.000 (0.005)\tLoss 0.8090 (0.8068)\tPrec@1 67.188 (71.377)\tPrec@5 96.875 (98.029)\t\n",
            "TRAINING - Epoch: [3][290/390]\tTime 0.058 (0.058)\tData 0.006 (0.005)\tLoss 0.7030 (0.8052)\tPrec@1 75.000 (71.448)\tPrec@5 96.094 (98.035)\t\n",
            "TRAINING - Epoch: [3][300/390]\tTime 0.052 (0.058)\tData 0.004 (0.005)\tLoss 0.7598 (0.8029)\tPrec@1 64.844 (71.491)\tPrec@5 99.219 (98.043)\t\n",
            "TRAINING - Epoch: [3][310/390]\tTime 0.067 (0.058)\tData 0.006 (0.005)\tLoss 0.7651 (0.8002)\tPrec@1 75.781 (71.619)\tPrec@5 99.219 (98.071)\t\n",
            "TRAINING - Epoch: [3][320/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.7651 (0.7998)\tPrec@1 75.781 (71.590)\tPrec@5 97.656 (98.060)\t\n",
            "TRAINING - Epoch: [3][330/390]\tTime 0.076 (0.058)\tData 0.008 (0.005)\tLoss 0.6555 (0.7987)\tPrec@1 73.438 (71.637)\tPrec@5 100.000 (98.053)\t\n",
            "TRAINING - Epoch: [3][340/390]\tTime 0.060 (0.058)\tData 0.000 (0.004)\tLoss 0.8157 (0.7992)\tPrec@1 71.875 (71.628)\tPrec@5 99.219 (98.046)\t\n",
            "TRAINING - Epoch: [3][350/390]\tTime 0.047 (0.058)\tData 0.000 (0.004)\tLoss 0.7313 (0.7979)\tPrec@1 74.219 (71.657)\tPrec@5 99.219 (98.064)\t\n",
            "TRAINING - Epoch: [3][360/390]\tTime 0.048 (0.058)\tData 0.000 (0.004)\tLoss 0.7905 (0.7971)\tPrec@1 67.188 (71.687)\tPrec@5 97.656 (98.070)\t\n",
            "TRAINING - Epoch: [3][370/390]\tTime 0.070 (0.058)\tData 0.006 (0.004)\tLoss 0.8043 (0.7959)\tPrec@1 71.094 (71.728)\tPrec@5 98.438 (98.086)\t\n",
            "TRAINING - Epoch: [3][380/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.8272 (0.7954)\tPrec@1 72.656 (71.748)\tPrec@5 98.438 (98.089)\t\n",
            "TRAINING - Epoch: [3][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.6897 (0.7956)\tPrec@1 75.781 (71.743)\tPrec@5 98.438 (98.077)\t\n",
            "EVALUATING - Epoch: [3][0/79]\tTime 0.282 (0.282)\tData 0.246 (0.246)\tLoss 1.2394 (1.2394)\tPrec@1 65.625 (65.625)\tPrec@5 96.875 (96.875)\t\n",
            "EVALUATING - Epoch: [3][10/79]\tTime 0.039 (0.056)\tData 0.001 (0.026)\tLoss 1.2982 (1.3112)\tPrec@1 60.938 (59.730)\tPrec@5 93.750 (94.815)\t\n",
            "EVALUATING - Epoch: [3][20/79]\tTime 0.037 (0.045)\tData 0.002 (0.016)\tLoss 1.2029 (1.3264)\tPrec@1 63.281 (59.635)\tPrec@5 95.312 (94.159)\t\n",
            "EVALUATING - Epoch: [3][30/79]\tTime 0.032 (0.040)\tData 0.009 (0.012)\tLoss 1.2800 (1.3282)\tPrec@1 56.250 (59.577)\tPrec@5 96.094 (93.851)\t\n",
            "EVALUATING - Epoch: [3][40/79]\tTime 0.036 (0.038)\tData 0.010 (0.011)\tLoss 1.4271 (1.3256)\tPrec@1 60.156 (59.527)\tPrec@5 90.625 (93.864)\t\n",
            "EVALUATING - Epoch: [3][50/79]\tTime 0.013 (0.036)\tData 0.000 (0.010)\tLoss 1.1919 (1.3309)\tPrec@1 63.281 (59.375)\tPrec@5 96.094 (93.903)\t\n",
            "EVALUATING - Epoch: [3][60/79]\tTime 0.020 (0.035)\tData 0.000 (0.009)\tLoss 1.5098 (1.3224)\tPrec@1 57.031 (59.477)\tPrec@5 91.406 (93.904)\t\n",
            "EVALUATING - Epoch: [3][70/79]\tTime 0.034 (0.034)\tData 0.010 (0.008)\tLoss 1.3040 (1.3217)\tPrec@1 58.594 (59.221)\tPrec@5 96.094 (93.915)\t\n",
            "EVALUATING - Epoch: [3][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 1.3781 (1.3189)\tPrec@1 68.750 (59.340)\tPrec@5 93.750 (93.970)\t\n",
            "\n",
            "Results - Epoch: 4\n",
            "Training Loss 0.7956 \tTraining Prec@1 71.743 \tTraining Prec@5 98.077 \tValidation Loss 1.3189 \tValidation Prec@1 59.340 \tValidation Prec@5 93.970 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 5\n",
            "\n",
            "TRAINING - Epoch: [4][0/390]\tTime 0.415 (0.415)\tData 0.313 (0.313)\tLoss 0.8271 (0.8271)\tPrec@1 72.656 (72.656)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [4][10/390]\tTime 0.049 (0.092)\tData 0.000 (0.032)\tLoss 0.6868 (0.7187)\tPrec@1 75.000 (74.787)\tPrec@5 98.438 (98.651)\t\n",
            "TRAINING - Epoch: [4][20/390]\tTime 0.047 (0.073)\tData 0.000 (0.018)\tLoss 0.5549 (0.7111)\tPrec@1 82.812 (75.112)\tPrec@5 99.219 (98.772)\t\n",
            "TRAINING - Epoch: [4][30/390]\tTime 0.076 (0.069)\tData 0.014 (0.014)\tLoss 0.6560 (0.6994)\tPrec@1 74.219 (75.277)\tPrec@5 97.656 (98.664)\t\n",
            "TRAINING - Epoch: [4][40/390]\tTime 0.062 (0.065)\tData 0.000 (0.011)\tLoss 0.6619 (0.6995)\tPrec@1 77.344 (75.210)\tPrec@5 99.219 (98.666)\t\n",
            "TRAINING - Epoch: [4][50/390]\tTime 0.079 (0.064)\tData 0.006 (0.009)\tLoss 0.7129 (0.7128)\tPrec@1 72.656 (74.724)\tPrec@5 100.000 (98.606)\t\n",
            "TRAINING - Epoch: [4][60/390]\tTime 0.048 (0.063)\tData 0.000 (0.009)\tLoss 0.7177 (0.7126)\tPrec@1 75.781 (74.962)\tPrec@5 98.438 (98.604)\t\n",
            "TRAINING - Epoch: [4][70/390]\tTime 0.055 (0.062)\tData 0.007 (0.008)\tLoss 0.8162 (0.7213)\tPrec@1 75.000 (74.637)\tPrec@5 97.656 (98.537)\t\n",
            "TRAINING - Epoch: [4][80/390]\tTime 0.054 (0.061)\tData 0.000 (0.007)\tLoss 0.5358 (0.7235)\tPrec@1 81.250 (74.662)\tPrec@5 99.219 (98.476)\t\n",
            "TRAINING - Epoch: [4][90/390]\tTime 0.067 (0.061)\tData 0.007 (0.007)\tLoss 0.7141 (0.7217)\tPrec@1 76.562 (74.674)\tPrec@5 96.875 (98.455)\t\n",
            "TRAINING - Epoch: [4][100/390]\tTime 0.068 (0.060)\tData 0.013 (0.007)\tLoss 0.6909 (0.7258)\tPrec@1 75.781 (74.613)\tPrec@5 98.438 (98.461)\t\n",
            "TRAINING - Epoch: [4][110/390]\tTime 0.050 (0.060)\tData 0.000 (0.006)\tLoss 0.4900 (0.7235)\tPrec@1 84.375 (74.676)\tPrec@5 98.438 (98.494)\t\n",
            "TRAINING - Epoch: [4][120/390]\tTime 0.056 (0.060)\tData 0.000 (0.006)\tLoss 0.7963 (0.7215)\tPrec@1 71.875 (74.780)\tPrec@5 97.656 (98.502)\t\n",
            "TRAINING - Epoch: [4][130/390]\tTime 0.055 (0.059)\tData 0.000 (0.006)\tLoss 0.7140 (0.7160)\tPrec@1 72.656 (74.964)\tPrec@5 98.438 (98.491)\t\n",
            "TRAINING - Epoch: [4][140/390]\tTime 0.049 (0.059)\tData 0.000 (0.006)\tLoss 0.7907 (0.7169)\tPrec@1 73.438 (74.889)\tPrec@5 99.219 (98.498)\t\n",
            "TRAINING - Epoch: [4][150/390]\tTime 0.056 (0.059)\tData 0.007 (0.006)\tLoss 0.7281 (0.7215)\tPrec@1 74.219 (74.715)\tPrec@5 96.875 (98.474)\t\n",
            "TRAINING - Epoch: [4][160/390]\tTime 0.049 (0.059)\tData 0.000 (0.005)\tLoss 0.7837 (0.7249)\tPrec@1 71.094 (74.476)\tPrec@5 98.438 (98.471)\t\n",
            "TRAINING - Epoch: [4][170/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 0.7210 (0.7286)\tPrec@1 79.688 (74.406)\tPrec@5 96.875 (98.451)\t\n",
            "TRAINING - Epoch: [4][180/390]\tTime 0.054 (0.059)\tData 0.004 (0.005)\tLoss 0.8102 (0.7293)\tPrec@1 69.531 (74.396)\tPrec@5 99.219 (98.463)\t\n",
            "TRAINING - Epoch: [4][190/390]\tTime 0.066 (0.058)\tData 0.013 (0.005)\tLoss 0.6682 (0.7304)\tPrec@1 73.438 (74.350)\tPrec@5 97.656 (98.470)\t\n",
            "TRAINING - Epoch: [4][200/390]\tTime 0.055 (0.058)\tData 0.006 (0.005)\tLoss 0.6524 (0.7271)\tPrec@1 77.344 (74.483)\tPrec@5 98.438 (98.480)\t\n",
            "TRAINING - Epoch: [4][210/390]\tTime 0.056 (0.058)\tData 0.000 (0.005)\tLoss 0.5525 (0.7238)\tPrec@1 83.594 (74.574)\tPrec@5 99.219 (98.497)\t\n",
            "TRAINING - Epoch: [4][220/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.6125 (0.7210)\tPrec@1 80.469 (74.668)\tPrec@5 99.219 (98.529)\t\n",
            "TRAINING - Epoch: [4][230/390]\tTime 0.053 (0.058)\tData 0.005 (0.005)\tLoss 0.6520 (0.7201)\tPrec@1 77.344 (74.716)\tPrec@5 98.438 (98.525)\t\n",
            "TRAINING - Epoch: [4][240/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.6876 (0.7196)\tPrec@1 79.688 (74.776)\tPrec@5 98.438 (98.525)\t\n",
            "TRAINING - Epoch: [4][250/390]\tTime 0.054 (0.058)\tData 0.000 (0.005)\tLoss 0.6003 (0.7189)\tPrec@1 78.906 (74.813)\tPrec@5 99.219 (98.522)\t\n",
            "TRAINING - Epoch: [4][260/390]\tTime 0.056 (0.058)\tData 0.007 (0.005)\tLoss 0.7204 (0.7189)\tPrec@1 71.875 (74.799)\tPrec@5 98.438 (98.518)\t\n",
            "TRAINING - Epoch: [4][270/390]\tTime 0.057 (0.058)\tData 0.007 (0.005)\tLoss 0.6169 (0.7161)\tPrec@1 78.906 (74.841)\tPrec@5 98.438 (98.553)\t\n",
            "TRAINING - Epoch: [4][280/390]\tTime 0.069 (0.058)\tData 0.007 (0.005)\tLoss 0.5655 (0.7140)\tPrec@1 82.812 (74.930)\tPrec@5 97.656 (98.546)\t\n",
            "TRAINING - Epoch: [4][290/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.6540 (0.7137)\tPrec@1 79.688 (74.984)\tPrec@5 98.438 (98.556)\t\n",
            "TRAINING - Epoch: [4][300/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.5680 (0.7120)\tPrec@1 79.688 (75.070)\tPrec@5 98.438 (98.547)\t\n",
            "TRAINING - Epoch: [4][310/390]\tTime 0.061 (0.058)\tData 0.012 (0.005)\tLoss 0.6887 (0.7108)\tPrec@1 75.781 (75.085)\tPrec@5 95.312 (98.543)\t\n",
            "TRAINING - Epoch: [4][320/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.7166 (0.7092)\tPrec@1 72.656 (75.175)\tPrec@5 98.438 (98.549)\t\n",
            "TRAINING - Epoch: [4][330/390]\tTime 0.066 (0.058)\tData 0.006 (0.005)\tLoss 0.7538 (0.7087)\tPrec@1 75.000 (75.234)\tPrec@5 97.656 (98.539)\t\n",
            "TRAINING - Epoch: [4][340/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.6204 (0.7091)\tPrec@1 78.906 (75.220)\tPrec@5 97.656 (98.531)\t\n",
            "TRAINING - Epoch: [4][350/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.7725 (0.7073)\tPrec@1 70.312 (75.280)\tPrec@5 99.219 (98.549)\t\n",
            "TRAINING - Epoch: [4][360/390]\tTime 0.057 (0.058)\tData 0.008 (0.005)\tLoss 0.6465 (0.7039)\tPrec@1 77.344 (75.387)\tPrec@5 96.875 (98.563)\t\n",
            "TRAINING - Epoch: [4][370/390]\tTime 0.067 (0.058)\tData 0.002 (0.005)\tLoss 0.6906 (0.7033)\tPrec@1 78.906 (75.419)\tPrec@5 98.438 (98.572)\t\n",
            "TRAINING - Epoch: [4][380/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.6304 (0.7035)\tPrec@1 76.562 (75.424)\tPrec@5 99.219 (98.561)\t\n",
            "TRAINING - Epoch: [4][389/390]\tTime 0.040 (0.058)\tData 0.000 (0.005)\tLoss 0.5882 (0.7029)\tPrec@1 79.688 (75.461)\tPrec@5 99.219 (98.552)\t\n",
            "EVALUATING - Epoch: [4][0/79]\tTime 0.203 (0.203)\tData 0.161 (0.161)\tLoss 0.7147 (0.7147)\tPrec@1 75.000 (75.000)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [4][10/79]\tTime 0.028 (0.051)\tData 0.001 (0.022)\tLoss 0.7435 (0.8771)\tPrec@1 75.781 (71.946)\tPrec@5 97.656 (98.509)\t\n",
            "EVALUATING - Epoch: [4][20/79]\tTime 0.047 (0.043)\tData 0.011 (0.014)\tLoss 1.0333 (0.9156)\tPrec@1 68.750 (71.763)\tPrec@5 96.094 (97.954)\t\n",
            "EVALUATING - Epoch: [4][30/79]\tTime 0.047 (0.039)\tData 0.014 (0.011)\tLoss 0.7385 (0.9091)\tPrec@1 72.656 (71.673)\tPrec@5 98.438 (97.807)\t\n",
            "EVALUATING - Epoch: [4][40/79]\tTime 0.034 (0.037)\tData 0.000 (0.010)\tLoss 0.8119 (0.8956)\tPrec@1 71.875 (71.932)\tPrec@5 98.438 (97.732)\t\n",
            "EVALUATING - Epoch: [4][50/79]\tTime 0.038 (0.036)\tData 0.000 (0.008)\tLoss 0.9249 (0.8955)\tPrec@1 72.656 (71.875)\tPrec@5 96.094 (97.855)\t\n",
            "EVALUATING - Epoch: [4][60/79]\tTime 0.019 (0.035)\tData 0.000 (0.008)\tLoss 1.2225 (0.8893)\tPrec@1 70.312 (72.016)\tPrec@5 96.094 (97.938)\t\n",
            "EVALUATING - Epoch: [4][70/79]\tTime 0.026 (0.034)\tData 0.000 (0.008)\tLoss 0.8470 (0.8969)\tPrec@1 72.656 (71.622)\tPrec@5 99.219 (98.008)\t\n",
            "EVALUATING - Epoch: [4][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.8945 (0.8905)\tPrec@1 75.000 (71.630)\tPrec@5 100.000 (98.040)\t\n",
            "\n",
            "Results - Epoch: 5\n",
            "Training Loss 0.7029 \tTraining Prec@1 75.461 \tTraining Prec@5 98.552 \tValidation Loss 0.8905 \tValidation Prec@1 71.630 \tValidation Prec@5 98.040 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 6\n",
            "\n",
            "TRAINING - Epoch: [5][0/390]\tTime 0.370 (0.370)\tData 0.274 (0.274)\tLoss 0.6065 (0.6065)\tPrec@1 78.906 (78.906)\tPrec@5 97.656 (97.656)\t\n",
            "TRAINING - Epoch: [5][10/390]\tTime 0.054 (0.090)\tData 0.007 (0.028)\tLoss 0.5683 (0.6448)\tPrec@1 81.250 (77.202)\tPrec@5 99.219 (98.295)\t\n",
            "TRAINING - Epoch: [5][20/390]\tTime 0.055 (0.074)\tData 0.007 (0.018)\tLoss 0.6247 (0.6670)\tPrec@1 75.781 (76.265)\tPrec@5 97.656 (98.549)\t\n",
            "TRAINING - Epoch: [5][30/390]\tTime 0.055 (0.068)\tData 0.007 (0.013)\tLoss 0.4973 (0.6454)\tPrec@1 84.375 (77.167)\tPrec@5 98.438 (98.538)\t\n",
            "TRAINING - Epoch: [5][40/390]\tTime 0.062 (0.065)\tData 0.000 (0.011)\tLoss 0.6400 (0.6374)\tPrec@1 76.562 (77.572)\tPrec@5 100.000 (98.742)\t\n",
            "TRAINING - Epoch: [5][50/390]\tTime 0.076 (0.064)\tData 0.010 (0.010)\tLoss 0.6423 (0.6264)\tPrec@1 75.781 (77.757)\tPrec@5 100.000 (98.912)\t\n",
            "TRAINING - Epoch: [5][60/390]\tTime 0.052 (0.062)\tData 0.000 (0.008)\tLoss 0.5026 (0.6336)\tPrec@1 82.812 (77.433)\tPrec@5 99.219 (98.847)\t\n",
            "TRAINING - Epoch: [5][70/390]\tTime 0.049 (0.061)\tData 0.000 (0.008)\tLoss 0.6099 (0.6280)\tPrec@1 77.344 (77.553)\tPrec@5 98.438 (98.834)\t\n",
            "TRAINING - Epoch: [5][80/390]\tTime 0.051 (0.061)\tData 0.000 (0.007)\tLoss 0.6355 (0.6282)\tPrec@1 80.469 (77.662)\tPrec@5 98.438 (98.765)\t\n",
            "TRAINING - Epoch: [5][90/390]\tTime 0.047 (0.060)\tData 0.000 (0.007)\tLoss 0.7311 (0.6298)\tPrec@1 78.125 (77.576)\tPrec@5 96.875 (98.747)\t\n",
            "TRAINING - Epoch: [5][100/390]\tTime 0.077 (0.059)\tData 0.000 (0.006)\tLoss 0.7332 (0.6297)\tPrec@1 75.000 (77.638)\tPrec@5 97.656 (98.747)\t\n",
            "TRAINING - Epoch: [5][110/390]\tTime 0.054 (0.059)\tData 0.000 (0.006)\tLoss 0.9056 (0.6314)\tPrec@1 67.969 (77.534)\tPrec@5 97.656 (98.796)\t\n",
            "TRAINING - Epoch: [5][120/390]\tTime 0.051 (0.059)\tData 0.002 (0.006)\tLoss 0.4848 (0.6282)\tPrec@1 84.375 (77.686)\tPrec@5 100.000 (98.799)\t\n",
            "TRAINING - Epoch: [5][130/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.5710 (0.6304)\tPrec@1 80.469 (77.678)\tPrec@5 98.438 (98.813)\t\n",
            "TRAINING - Epoch: [5][140/390]\tTime 0.049 (0.058)\tData 0.000 (0.006)\tLoss 0.7170 (0.6302)\tPrec@1 73.438 (77.682)\tPrec@5 97.656 (98.842)\t\n",
            "TRAINING - Epoch: [5][150/390]\tTime 0.055 (0.058)\tData 0.007 (0.006)\tLoss 0.7393 (0.6319)\tPrec@1 77.344 (77.665)\tPrec@5 97.656 (98.851)\t\n",
            "TRAINING - Epoch: [5][160/390]\tTime 0.049 (0.058)\tData 0.000 (0.006)\tLoss 0.4957 (0.6341)\tPrec@1 85.938 (77.630)\tPrec@5 99.219 (98.831)\t\n",
            "TRAINING - Epoch: [5][170/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.6264 (0.6342)\tPrec@1 78.125 (77.609)\tPrec@5 100.000 (98.830)\t\n",
            "TRAINING - Epoch: [5][180/390]\tTime 0.053 (0.059)\tData 0.007 (0.005)\tLoss 0.6085 (0.6364)\tPrec@1 79.688 (77.538)\tPrec@5 99.219 (98.822)\t\n",
            "TRAINING - Epoch: [5][190/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.6561 (0.6374)\tPrec@1 78.906 (77.491)\tPrec@5 95.312 (98.802)\t\n",
            "TRAINING - Epoch: [5][200/390]\tTime 0.071 (0.058)\tData 0.000 (0.005)\tLoss 0.5712 (0.6369)\tPrec@1 78.906 (77.503)\tPrec@5 97.656 (98.787)\t\n",
            "TRAINING - Epoch: [5][210/390]\tTime 0.059 (0.058)\tData 0.009 (0.005)\tLoss 0.6384 (0.6372)\tPrec@1 78.125 (77.514)\tPrec@5 96.094 (98.760)\t\n",
            "TRAINING - Epoch: [5][220/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.6731 (0.6359)\tPrec@1 73.438 (77.524)\tPrec@5 99.219 (98.773)\t\n",
            "TRAINING - Epoch: [5][230/390]\tTime 0.069 (0.058)\tData 0.007 (0.005)\tLoss 0.6036 (0.6357)\tPrec@1 78.125 (77.560)\tPrec@5 99.219 (98.772)\t\n",
            "TRAINING - Epoch: [5][240/390]\tTime 0.057 (0.058)\tData 0.011 (0.005)\tLoss 0.6275 (0.6332)\tPrec@1 76.562 (77.619)\tPrec@5 98.438 (98.797)\t\n",
            "TRAINING - Epoch: [5][250/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.7212 (0.6332)\tPrec@1 76.562 (77.587)\tPrec@5 98.438 (98.808)\t\n",
            "TRAINING - Epoch: [5][260/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.7228 (0.6356)\tPrec@1 79.688 (77.562)\tPrec@5 97.656 (98.797)\t\n",
            "TRAINING - Epoch: [5][270/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.6267 (0.6350)\tPrec@1 75.000 (77.606)\tPrec@5 99.219 (98.798)\t\n",
            "TRAINING - Epoch: [5][280/390]\tTime 0.054 (0.058)\tData 0.000 (0.005)\tLoss 0.5857 (0.6352)\tPrec@1 79.688 (77.655)\tPrec@5 100.000 (98.785)\t\n",
            "TRAINING - Epoch: [5][290/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.4848 (0.6336)\tPrec@1 87.500 (77.749)\tPrec@5 98.438 (98.784)\t\n",
            "TRAINING - Epoch: [5][300/390]\tTime 0.062 (0.058)\tData 0.012 (0.005)\tLoss 0.5712 (0.6337)\tPrec@1 78.906 (77.756)\tPrec@5 99.219 (98.772)\t\n",
            "TRAINING - Epoch: [5][310/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.6542 (0.6312)\tPrec@1 78.125 (77.866)\tPrec@5 98.438 (98.792)\t\n",
            "TRAINING - Epoch: [5][320/390]\tTime 0.068 (0.058)\tData 0.007 (0.005)\tLoss 0.5419 (0.6312)\tPrec@1 82.812 (77.899)\tPrec@5 99.219 (98.788)\t\n",
            "TRAINING - Epoch: [5][330/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.5538 (0.6288)\tPrec@1 79.688 (77.974)\tPrec@5 98.438 (98.803)\t\n",
            "TRAINING - Epoch: [5][340/390]\tTime 0.060 (0.057)\tData 0.000 (0.005)\tLoss 0.6740 (0.6273)\tPrec@1 77.344 (78.068)\tPrec@5 100.000 (98.816)\t\n",
            "TRAINING - Epoch: [5][350/390]\tTime 0.047 (0.057)\tData 0.000 (0.005)\tLoss 0.6730 (0.6269)\tPrec@1 76.562 (78.078)\tPrec@5 97.656 (98.818)\t\n",
            "TRAINING - Epoch: [5][360/390]\tTime 0.068 (0.057)\tData 0.000 (0.005)\tLoss 0.6513 (0.6264)\tPrec@1 76.562 (78.093)\tPrec@5 99.219 (98.816)\t\n",
            "TRAINING - Epoch: [5][370/390]\tTime 0.052 (0.057)\tData 0.006 (0.005)\tLoss 0.7319 (0.6262)\tPrec@1 76.562 (78.133)\tPrec@5 98.438 (98.808)\t\n",
            "TRAINING - Epoch: [5][380/390]\tTime 0.060 (0.057)\tData 0.007 (0.005)\tLoss 0.5719 (0.6246)\tPrec@1 82.031 (78.189)\tPrec@5 99.219 (98.819)\t\n",
            "TRAINING - Epoch: [5][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.005)\tLoss 0.5717 (0.6239)\tPrec@1 80.469 (78.211)\tPrec@5 98.438 (98.816)\t\n",
            "EVALUATING - Epoch: [5][0/79]\tTime 0.191 (0.191)\tData 0.159 (0.159)\tLoss 0.5303 (0.5303)\tPrec@1 80.469 (80.469)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [5][10/79]\tTime 0.028 (0.054)\tData 0.000 (0.028)\tLoss 0.6241 (0.6666)\tPrec@1 76.562 (76.918)\tPrec@5 98.438 (98.935)\t\n",
            "EVALUATING - Epoch: [5][20/79]\tTime 0.033 (0.043)\tData 0.000 (0.016)\tLoss 0.6501 (0.6841)\tPrec@1 78.125 (76.897)\tPrec@5 97.656 (98.586)\t\n",
            "EVALUATING - Epoch: [5][30/79]\tTime 0.027 (0.038)\tData 0.004 (0.012)\tLoss 0.5014 (0.6907)\tPrec@1 79.688 (76.613)\tPrec@5 99.219 (98.513)\t\n",
            "EVALUATING - Epoch: [5][40/79]\tTime 0.038 (0.036)\tData 0.007 (0.011)\tLoss 0.7175 (0.6765)\tPrec@1 75.781 (77.306)\tPrec@5 99.219 (98.495)\t\n",
            "EVALUATING - Epoch: [5][50/79]\tTime 0.024 (0.035)\tData 0.005 (0.010)\tLoss 0.6817 (0.6833)\tPrec@1 75.000 (77.114)\tPrec@5 97.656 (98.606)\t\n",
            "EVALUATING - Epoch: [5][60/79]\tTime 0.014 (0.034)\tData 0.000 (0.009)\tLoss 0.8097 (0.6802)\tPrec@1 73.438 (77.408)\tPrec@5 96.875 (98.668)\t\n",
            "EVALUATING - Epoch: [5][70/79]\tTime 0.020 (0.033)\tData 0.000 (0.008)\tLoss 0.5738 (0.6773)\tPrec@1 81.250 (77.597)\tPrec@5 99.219 (98.724)\t\n",
            "EVALUATING - Epoch: [5][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.008)\tLoss 0.5112 (0.6743)\tPrec@1 81.250 (77.640)\tPrec@5 100.000 (98.790)\t\n",
            "\n",
            "Results - Epoch: 6\n",
            "Training Loss 0.6239 \tTraining Prec@1 78.211 \tTraining Prec@5 98.816 \tValidation Loss 0.6743 \tValidation Prec@1 77.640 \tValidation Prec@5 98.790 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 7\n",
            "\n",
            "TRAINING - Epoch: [6][0/390]\tTime 0.393 (0.393)\tData 0.281 (0.281)\tLoss 0.5736 (0.5736)\tPrec@1 78.906 (78.906)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [6][10/390]\tTime 0.049 (0.087)\tData 0.000 (0.028)\tLoss 0.4779 (0.5124)\tPrec@1 84.375 (82.315)\tPrec@5 100.000 (99.645)\t\n",
            "TRAINING - Epoch: [6][20/390]\tTime 0.058 (0.072)\tData 0.010 (0.016)\tLoss 0.6533 (0.5368)\tPrec@1 77.344 (81.436)\tPrec@5 99.219 (99.405)\t\n",
            "TRAINING - Epoch: [6][30/390]\tTime 0.054 (0.067)\tData 0.007 (0.012)\tLoss 0.6401 (0.5551)\tPrec@1 77.344 (80.721)\tPrec@5 98.438 (99.320)\t\n",
            "TRAINING - Epoch: [6][40/390]\tTime 0.047 (0.064)\tData 0.000 (0.010)\tLoss 0.5972 (0.5582)\tPrec@1 79.688 (80.659)\tPrec@5 99.219 (99.257)\t\n",
            "TRAINING - Epoch: [6][50/390]\tTime 0.051 (0.062)\tData 0.000 (0.009)\tLoss 0.5105 (0.5544)\tPrec@1 79.688 (80.744)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [6][60/390]\tTime 0.064 (0.061)\tData 0.007 (0.008)\tLoss 0.6534 (0.5533)\tPrec@1 79.688 (80.879)\tPrec@5 97.656 (99.219)\t\n",
            "TRAINING - Epoch: [6][70/390]\tTime 0.056 (0.061)\tData 0.007 (0.007)\tLoss 0.4861 (0.5519)\tPrec@1 83.594 (80.964)\tPrec@5 100.000 (99.208)\t\n",
            "TRAINING - Epoch: [6][80/390]\tTime 0.049 (0.060)\tData 0.000 (0.007)\tLoss 0.4435 (0.5503)\tPrec@1 87.500 (80.990)\tPrec@5 99.219 (99.228)\t\n",
            "TRAINING - Epoch: [6][90/390]\tTime 0.047 (0.060)\tData 0.000 (0.007)\tLoss 0.5673 (0.5552)\tPrec@1 82.031 (80.795)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [6][100/390]\tTime 0.050 (0.059)\tData 0.000 (0.006)\tLoss 0.4830 (0.5522)\tPrec@1 82.031 (80.863)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [6][110/390]\tTime 0.060 (0.059)\tData 0.007 (0.006)\tLoss 0.4179 (0.5553)\tPrec@1 85.938 (80.814)\tPrec@5 99.219 (99.205)\t\n",
            "TRAINING - Epoch: [6][120/390]\tTime 0.052 (0.059)\tData 0.000 (0.006)\tLoss 0.5818 (0.5501)\tPrec@1 82.031 (80.901)\tPrec@5 97.656 (99.212)\t\n",
            "TRAINING - Epoch: [6][130/390]\tTime 0.051 (0.059)\tData 0.002 (0.006)\tLoss 0.6285 (0.5516)\tPrec@1 78.125 (80.868)\tPrec@5 98.438 (99.195)\t\n",
            "TRAINING - Epoch: [6][140/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.5858 (0.5566)\tPrec@1 78.906 (80.740)\tPrec@5 97.656 (99.186)\t\n",
            "TRAINING - Epoch: [6][150/390]\tTime 0.065 (0.058)\tData 0.008 (0.005)\tLoss 0.4886 (0.5551)\tPrec@1 82.812 (80.738)\tPrec@5 99.219 (99.157)\t\n",
            "TRAINING - Epoch: [6][160/390]\tTime 0.061 (0.058)\tData 0.007 (0.005)\tLoss 0.6352 (0.5545)\tPrec@1 78.125 (80.799)\tPrec@5 98.438 (99.141)\t\n",
            "TRAINING - Epoch: [6][170/390]\tTime 0.078 (0.058)\tData 0.013 (0.005)\tLoss 0.5176 (0.5547)\tPrec@1 83.594 (80.766)\tPrec@5 100.000 (99.114)\t\n",
            "TRAINING - Epoch: [6][180/390]\tTime 0.067 (0.058)\tData 0.013 (0.005)\tLoss 0.6344 (0.5568)\tPrec@1 76.562 (80.663)\tPrec@5 100.000 (99.141)\t\n",
            "TRAINING - Epoch: [6][190/390]\tTime 0.048 (0.058)\tData 0.001 (0.005)\tLoss 0.6195 (0.5603)\tPrec@1 81.250 (80.534)\tPrec@5 100.000 (99.129)\t\n",
            "TRAINING - Epoch: [6][200/390]\tTime 0.065 (0.058)\tData 0.007 (0.005)\tLoss 0.7936 (0.5614)\tPrec@1 76.562 (80.488)\tPrec@5 96.875 (99.122)\t\n",
            "TRAINING - Epoch: [6][210/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.6974 (0.5628)\tPrec@1 76.562 (80.406)\tPrec@5 97.656 (99.108)\t\n",
            "TRAINING - Epoch: [6][220/390]\tTime 0.058 (0.058)\tData 0.007 (0.005)\tLoss 0.4749 (0.5644)\tPrec@1 89.062 (80.384)\tPrec@5 100.000 (99.095)\t\n",
            "TRAINING - Epoch: [6][230/390]\tTime 0.056 (0.057)\tData 0.007 (0.005)\tLoss 0.4948 (0.5625)\tPrec@1 82.031 (80.411)\tPrec@5 100.000 (99.097)\t\n",
            "TRAINING - Epoch: [6][240/390]\tTime 0.062 (0.057)\tData 0.007 (0.005)\tLoss 0.4551 (0.5613)\tPrec@1 80.469 (80.472)\tPrec@5 100.000 (99.105)\t\n",
            "TRAINING - Epoch: [6][250/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.5760 (0.5619)\tPrec@1 79.688 (80.428)\tPrec@5 98.438 (99.116)\t\n",
            "TRAINING - Epoch: [6][260/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.4556 (0.5617)\tPrec@1 80.469 (80.397)\tPrec@5 99.219 (99.126)\t\n",
            "TRAINING - Epoch: [6][270/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.5326 (0.5605)\tPrec@1 83.594 (80.469)\tPrec@5 99.219 (99.135)\t\n",
            "TRAINING - Epoch: [6][280/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.6263 (0.5622)\tPrec@1 78.125 (80.399)\tPrec@5 98.438 (99.124)\t\n",
            "TRAINING - Epoch: [6][290/390]\tTime 0.064 (0.057)\tData 0.011 (0.004)\tLoss 0.5720 (0.5641)\tPrec@1 79.688 (80.340)\tPrec@5 100.000 (99.114)\t\n",
            "TRAINING - Epoch: [6][300/390]\tTime 0.054 (0.057)\tData 0.006 (0.004)\tLoss 0.5592 (0.5655)\tPrec@1 83.594 (80.269)\tPrec@5 99.219 (99.105)\t\n",
            "TRAINING - Epoch: [6][310/390]\tTime 0.052 (0.057)\tData 0.006 (0.004)\tLoss 0.6452 (0.5645)\tPrec@1 78.125 (80.285)\tPrec@5 99.219 (99.113)\t\n",
            "TRAINING - Epoch: [6][320/390]\tTime 0.050 (0.057)\tData 0.003 (0.004)\tLoss 0.6864 (0.5648)\tPrec@1 76.562 (80.291)\tPrec@5 99.219 (99.107)\t\n",
            "TRAINING - Epoch: [6][330/390]\tTime 0.056 (0.057)\tData 0.000 (0.005)\tLoss 0.5790 (0.5635)\tPrec@1 77.344 (80.339)\tPrec@5 99.219 (99.087)\t\n",
            "TRAINING - Epoch: [6][340/390]\tTime 0.062 (0.057)\tData 0.007 (0.004)\tLoss 0.5647 (0.5634)\tPrec@1 78.125 (80.324)\tPrec@5 99.219 (99.088)\t\n",
            "TRAINING - Epoch: [6][350/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.6539 (0.5630)\tPrec@1 79.688 (80.362)\tPrec@5 98.438 (99.074)\t\n",
            "TRAINING - Epoch: [6][360/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.6473 (0.5626)\tPrec@1 79.688 (80.348)\tPrec@5 99.219 (99.080)\t\n",
            "TRAINING - Epoch: [6][370/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.5601 (0.5628)\tPrec@1 80.469 (80.351)\tPrec@5 99.219 (99.065)\t\n",
            "TRAINING - Epoch: [6][380/390]\tTime 0.061 (0.057)\tData 0.007 (0.004)\tLoss 0.3827 (0.5625)\tPrec@1 83.594 (80.368)\tPrec@5 100.000 (99.057)\t\n",
            "TRAINING - Epoch: [6][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.5617 (0.5628)\tPrec@1 81.250 (80.391)\tPrec@5 96.875 (99.042)\t\n",
            "EVALUATING - Epoch: [6][0/79]\tTime 0.207 (0.207)\tData 0.162 (0.162)\tLoss 0.5888 (0.5888)\tPrec@1 79.688 (79.688)\tPrec@5 97.656 (97.656)\t\n",
            "EVALUATING - Epoch: [6][10/79]\tTime 0.030 (0.053)\tData 0.000 (0.023)\tLoss 0.6153 (0.7155)\tPrec@1 75.000 (76.065)\tPrec@5 99.219 (98.438)\t\n",
            "EVALUATING - Epoch: [6][20/79]\tTime 0.038 (0.042)\tData 0.000 (0.014)\tLoss 0.8745 (0.7709)\tPrec@1 68.750 (74.888)\tPrec@5 97.656 (98.140)\t\n",
            "EVALUATING - Epoch: [6][30/79]\tTime 0.046 (0.038)\tData 0.008 (0.011)\tLoss 0.5280 (0.7737)\tPrec@1 82.812 (74.924)\tPrec@5 100.000 (97.933)\t\n",
            "EVALUATING - Epoch: [6][40/79]\tTime 0.035 (0.036)\tData 0.010 (0.009)\tLoss 0.8173 (0.7577)\tPrec@1 72.656 (75.286)\tPrec@5 98.438 (98.114)\t\n",
            "EVALUATING - Epoch: [6][50/79]\tTime 0.035 (0.034)\tData 0.000 (0.008)\tLoss 0.8834 (0.7630)\tPrec@1 72.656 (75.322)\tPrec@5 96.094 (98.009)\t\n",
            "EVALUATING - Epoch: [6][60/79]\tTime 0.036 (0.034)\tData 0.001 (0.008)\tLoss 0.8467 (0.7588)\tPrec@1 74.219 (75.333)\tPrec@5 97.656 (98.143)\t\n",
            "EVALUATING - Epoch: [6][70/79]\tTime 0.053 (0.033)\tData 0.005 (0.007)\tLoss 0.5939 (0.7610)\tPrec@1 76.562 (75.220)\tPrec@5 97.656 (98.096)\t\n",
            "EVALUATING - Epoch: [6][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.006)\tLoss 0.3759 (0.7572)\tPrec@1 81.250 (75.240)\tPrec@5 100.000 (98.130)\t\n",
            "\n",
            "Results - Epoch: 7\n",
            "Training Loss 0.5628 \tTraining Prec@1 80.391 \tTraining Prec@5 99.042 \tValidation Loss 0.7572 \tValidation Prec@1 75.240 \tValidation Prec@5 98.130 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 8\n",
            "\n",
            "TRAINING - Epoch: [7][0/390]\tTime 0.342 (0.342)\tData 0.214 (0.214)\tLoss 0.4980 (0.4980)\tPrec@1 82.812 (82.812)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [7][10/390]\tTime 0.055 (0.089)\tData 0.007 (0.024)\tLoss 0.4793 (0.5066)\tPrec@1 82.812 (82.244)\tPrec@5 100.000 (99.361)\t\n",
            "TRAINING - Epoch: [7][20/390]\tTime 0.058 (0.072)\tData 0.007 (0.015)\tLoss 0.4915 (0.5216)\tPrec@1 83.594 (81.845)\tPrec@5 98.438 (99.256)\t\n",
            "TRAINING - Epoch: [7][30/390]\tTime 0.056 (0.067)\tData 0.008 (0.011)\tLoss 0.6085 (0.5364)\tPrec@1 80.469 (81.401)\tPrec@5 99.219 (99.244)\t\n",
            "TRAINING - Epoch: [7][40/390]\tTime 0.049 (0.064)\tData 0.000 (0.009)\tLoss 0.5217 (0.5337)\tPrec@1 83.594 (81.764)\tPrec@5 99.219 (99.200)\t\n",
            "TRAINING - Epoch: [7][50/390]\tTime 0.055 (0.062)\tData 0.006 (0.008)\tLoss 0.5901 (0.5291)\tPrec@1 78.906 (81.847)\tPrec@5 99.219 (99.203)\t\n",
            "TRAINING - Epoch: [7][60/390]\tTime 0.056 (0.061)\tData 0.006 (0.007)\tLoss 0.3927 (0.5260)\tPrec@1 85.938 (81.980)\tPrec@5 100.000 (99.232)\t\n",
            "TRAINING - Epoch: [7][70/390]\tTime 0.069 (0.060)\tData 0.007 (0.006)\tLoss 0.5313 (0.5287)\tPrec@1 84.375 (81.921)\tPrec@5 97.656 (99.252)\t\n",
            "TRAINING - Epoch: [7][80/390]\tTime 0.055 (0.060)\tData 0.005 (0.006)\tLoss 0.4535 (0.5251)\tPrec@1 84.375 (82.070)\tPrec@5 100.000 (99.257)\t\n",
            "TRAINING - Epoch: [7][90/390]\tTime 0.049 (0.060)\tData 0.000 (0.006)\tLoss 0.5603 (0.5259)\tPrec@1 80.469 (81.954)\tPrec@5 98.438 (99.236)\t\n",
            "TRAINING - Epoch: [7][100/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.4994 (0.5230)\tPrec@1 79.688 (82.031)\tPrec@5 99.219 (99.288)\t\n",
            "TRAINING - Epoch: [7][110/390]\tTime 0.051 (0.059)\tData 0.000 (0.005)\tLoss 0.3980 (0.5178)\tPrec@1 85.938 (82.256)\tPrec@5 99.219 (99.275)\t\n",
            "TRAINING - Epoch: [7][120/390]\tTime 0.064 (0.059)\tData 0.005 (0.005)\tLoss 0.5347 (0.5141)\tPrec@1 80.469 (82.315)\tPrec@5 100.000 (99.296)\t\n",
            "TRAINING - Epoch: [7][130/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.5952 (0.5168)\tPrec@1 82.031 (82.133)\tPrec@5 97.656 (99.249)\t\n",
            "TRAINING - Epoch: [7][140/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.4469 (0.5160)\tPrec@1 86.719 (82.153)\tPrec@5 99.219 (99.246)\t\n",
            "TRAINING - Epoch: [7][150/390]\tTime 0.063 (0.058)\tData 0.007 (0.005)\tLoss 0.5942 (0.5198)\tPrec@1 76.562 (82.062)\tPrec@5 99.219 (99.203)\t\n",
            "TRAINING - Epoch: [7][160/390]\tTime 0.061 (0.058)\tData 0.012 (0.005)\tLoss 0.6559 (0.5193)\tPrec@1 78.125 (82.085)\tPrec@5 100.000 (99.194)\t\n",
            "TRAINING - Epoch: [7][170/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.4722 (0.5195)\tPrec@1 83.594 (82.136)\tPrec@5 99.219 (99.191)\t\n",
            "TRAINING - Epoch: [7][180/390]\tTime 0.059 (0.058)\tData 0.007 (0.005)\tLoss 0.4557 (0.5228)\tPrec@1 85.156 (81.984)\tPrec@5 100.000 (99.176)\t\n",
            "TRAINING - Epoch: [7][190/390]\tTime 0.065 (0.058)\tData 0.006 (0.005)\tLoss 0.4935 (0.5225)\tPrec@1 82.812 (82.064)\tPrec@5 100.000 (99.170)\t\n",
            "TRAINING - Epoch: [7][200/390]\tTime 0.056 (0.057)\tData 0.008 (0.005)\tLoss 0.5239 (0.5244)\tPrec@1 82.812 (81.977)\tPrec@5 100.000 (99.164)\t\n",
            "TRAINING - Epoch: [7][210/390]\tTime 0.055 (0.057)\tData 0.001 (0.005)\tLoss 0.5224 (0.5253)\tPrec@1 83.594 (81.946)\tPrec@5 97.656 (99.160)\t\n",
            "TRAINING - Epoch: [7][220/390]\tTime 0.056 (0.057)\tData 0.006 (0.005)\tLoss 0.4851 (0.5244)\tPrec@1 81.250 (81.953)\tPrec@5 98.438 (99.159)\t\n",
            "TRAINING - Epoch: [7][230/390]\tTime 0.060 (0.057)\tData 0.000 (0.005)\tLoss 0.5256 (0.5246)\tPrec@1 76.562 (81.889)\tPrec@5 100.000 (99.168)\t\n",
            "TRAINING - Epoch: [7][240/390]\tTime 0.047 (0.057)\tData 0.000 (0.005)\tLoss 0.5057 (0.5238)\tPrec@1 81.250 (81.872)\tPrec@5 98.438 (99.157)\t\n",
            "TRAINING - Epoch: [7][250/390]\tTime 0.067 (0.057)\tData 0.009 (0.005)\tLoss 0.3902 (0.5217)\tPrec@1 85.938 (81.953)\tPrec@5 99.219 (99.147)\t\n",
            "TRAINING - Epoch: [7][260/390]\tTime 0.053 (0.057)\tData 0.007 (0.005)\tLoss 0.4317 (0.5194)\tPrec@1 87.500 (82.055)\tPrec@5 97.656 (99.144)\t\n",
            "TRAINING - Epoch: [7][270/390]\tTime 0.053 (0.057)\tData 0.007 (0.005)\tLoss 0.3582 (0.5187)\tPrec@1 88.281 (82.089)\tPrec@5 100.000 (99.147)\t\n",
            "TRAINING - Epoch: [7][280/390]\tTime 0.066 (0.057)\tData 0.000 (0.005)\tLoss 0.5367 (0.5205)\tPrec@1 82.812 (82.012)\tPrec@5 98.438 (99.155)\t\n",
            "TRAINING - Epoch: [7][290/390]\tTime 0.047 (0.057)\tData 0.000 (0.005)\tLoss 0.5791 (0.5201)\tPrec@1 80.469 (81.986)\tPrec@5 97.656 (99.154)\t\n",
            "TRAINING - Epoch: [7][300/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.3457 (0.5194)\tPrec@1 87.500 (82.000)\tPrec@5 100.000 (99.156)\t\n",
            "TRAINING - Epoch: [7][310/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.4207 (0.5190)\tPrec@1 85.938 (82.014)\tPrec@5 99.219 (99.156)\t\n",
            "TRAINING - Epoch: [7][320/390]\tTime 0.057 (0.057)\tData 0.008 (0.004)\tLoss 0.4998 (0.5183)\tPrec@1 82.031 (82.031)\tPrec@5 100.000 (99.165)\t\n",
            "TRAINING - Epoch: [7][330/390]\tTime 0.051 (0.057)\tData 0.004 (0.004)\tLoss 0.4178 (0.5183)\tPrec@1 82.031 (82.022)\tPrec@5 100.000 (99.160)\t\n",
            "TRAINING - Epoch: [7][340/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.4562 (0.5191)\tPrec@1 85.156 (81.981)\tPrec@5 100.000 (99.164)\t\n",
            "TRAINING - Epoch: [7][350/390]\tTime 0.073 (0.057)\tData 0.007 (0.004)\tLoss 0.6260 (0.5209)\tPrec@1 78.906 (81.927)\tPrec@5 98.438 (99.150)\t\n",
            "TRAINING - Epoch: [7][360/390]\tTime 0.067 (0.057)\tData 0.007 (0.004)\tLoss 0.3619 (0.5190)\tPrec@1 89.062 (82.016)\tPrec@5 100.000 (99.154)\t\n",
            "TRAINING - Epoch: [7][370/390]\tTime 0.061 (0.057)\tData 0.006 (0.004)\tLoss 0.5659 (0.5196)\tPrec@1 78.906 (82.000)\tPrec@5 100.000 (99.147)\t\n",
            "TRAINING - Epoch: [7][380/390]\tTime 0.062 (0.057)\tData 0.000 (0.004)\tLoss 0.4569 (0.5191)\tPrec@1 81.250 (81.998)\tPrec@5 99.219 (99.149)\t\n",
            "TRAINING - Epoch: [7][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.4857 (0.5183)\tPrec@1 83.594 (82.051)\tPrec@5 100.000 (99.141)\t\n",
            "EVALUATING - Epoch: [7][0/79]\tTime 0.195 (0.195)\tData 0.165 (0.165)\tLoss 0.5464 (0.5464)\tPrec@1 81.250 (81.250)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [7][10/79]\tTime 0.017 (0.051)\tData 0.003 (0.023)\tLoss 0.6361 (0.6433)\tPrec@1 76.562 (77.344)\tPrec@5 99.219 (99.006)\t\n",
            "EVALUATING - Epoch: [7][20/79]\tTime 0.036 (0.041)\tData 0.010 (0.013)\tLoss 0.6773 (0.6693)\tPrec@1 78.906 (77.307)\tPrec@5 96.875 (98.624)\t\n",
            "EVALUATING - Epoch: [7][30/79]\tTime 0.017 (0.038)\tData 0.000 (0.011)\tLoss 0.5271 (0.6700)\tPrec@1 78.125 (77.394)\tPrec@5 100.000 (98.438)\t\n",
            "EVALUATING - Epoch: [7][40/79]\tTime 0.015 (0.035)\tData 0.000 (0.009)\tLoss 0.7893 (0.6692)\tPrec@1 72.656 (77.382)\tPrec@5 98.438 (98.438)\t\n",
            "EVALUATING - Epoch: [7][50/79]\tTime 0.030 (0.035)\tData 0.000 (0.008)\tLoss 0.6808 (0.6658)\tPrec@1 78.906 (77.191)\tPrec@5 99.219 (98.560)\t\n",
            "EVALUATING - Epoch: [7][60/79]\tTime 0.013 (0.034)\tData 0.000 (0.008)\tLoss 0.6827 (0.6616)\tPrec@1 78.125 (77.536)\tPrec@5 98.438 (98.476)\t\n",
            "EVALUATING - Epoch: [7][70/79]\tTime 0.021 (0.033)\tData 0.003 (0.007)\tLoss 0.5766 (0.6611)\tPrec@1 80.469 (77.498)\tPrec@5 100.000 (98.449)\t\n",
            "EVALUATING - Epoch: [7][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.5459 (0.6594)\tPrec@1 75.000 (77.430)\tPrec@5 100.000 (98.440)\t\n",
            "\n",
            "Results - Epoch: 8\n",
            "Training Loss 0.5183 \tTraining Prec@1 82.051 \tTraining Prec@5 99.141 \tValidation Loss 0.6594 \tValidation Prec@1 77.430 \tValidation Prec@5 98.440 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 9\n",
            "\n",
            "TRAINING - Epoch: [8][0/390]\tTime 0.374 (0.374)\tData 0.236 (0.236)\tLoss 0.4970 (0.4970)\tPrec@1 82.031 (82.031)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [8][10/390]\tTime 0.047 (0.087)\tData 0.000 (0.025)\tLoss 0.5536 (0.4479)\tPrec@1 80.469 (83.736)\tPrec@5 99.219 (99.787)\t\n",
            "TRAINING - Epoch: [8][20/390]\tTime 0.059 (0.072)\tData 0.010 (0.016)\tLoss 0.4443 (0.4723)\tPrec@1 82.812 (83.557)\tPrec@5 98.438 (99.256)\t\n",
            "TRAINING - Epoch: [8][30/390]\tTime 0.049 (0.066)\tData 0.000 (0.011)\tLoss 0.5644 (0.4783)\tPrec@1 81.250 (83.417)\tPrec@5 100.000 (99.269)\t\n",
            "TRAINING - Epoch: [8][40/390]\tTime 0.051 (0.064)\tData 0.004 (0.009)\tLoss 0.5413 (0.4853)\tPrec@1 82.031 (83.365)\tPrec@5 100.000 (99.371)\t\n",
            "TRAINING - Epoch: [8][50/390]\tTime 0.058 (0.063)\tData 0.006 (0.008)\tLoss 0.6417 (0.4893)\tPrec@1 82.031 (83.211)\tPrec@5 99.219 (99.372)\t\n",
            "TRAINING - Epoch: [8][60/390]\tTime 0.054 (0.062)\tData 0.006 (0.008)\tLoss 0.5159 (0.4845)\tPrec@1 83.594 (83.402)\tPrec@5 98.438 (99.347)\t\n",
            "TRAINING - Epoch: [8][70/390]\tTime 0.063 (0.061)\tData 0.009 (0.007)\tLoss 0.5121 (0.4840)\tPrec@1 82.031 (83.572)\tPrec@5 98.438 (99.318)\t\n",
            "TRAINING - Epoch: [8][80/390]\tTime 0.052 (0.060)\tData 0.000 (0.007)\tLoss 0.4534 (0.4852)\tPrec@1 84.375 (83.565)\tPrec@5 100.000 (99.296)\t\n",
            "TRAINING - Epoch: [8][90/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.3978 (0.4834)\tPrec@1 83.594 (83.413)\tPrec@5 100.000 (99.270)\t\n",
            "TRAINING - Epoch: [8][100/390]\tTime 0.052 (0.059)\tData 0.000 (0.006)\tLoss 0.4422 (0.4834)\tPrec@1 85.938 (83.385)\tPrec@5 98.438 (99.273)\t\n",
            "TRAINING - Epoch: [8][110/390]\tTime 0.054 (0.059)\tData 0.006 (0.006)\tLoss 0.5637 (0.4896)\tPrec@1 78.125 (83.242)\tPrec@5 99.219 (99.233)\t\n",
            "TRAINING - Epoch: [8][120/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.5265 (0.4907)\tPrec@1 82.812 (83.206)\tPrec@5 99.219 (99.212)\t\n",
            "TRAINING - Epoch: [8][130/390]\tTime 0.047 (0.058)\tData 0.001 (0.005)\tLoss 0.4472 (0.4923)\tPrec@1 85.156 (83.188)\tPrec@5 99.219 (99.189)\t\n",
            "TRAINING - Epoch: [8][140/390]\tTime 0.055 (0.058)\tData 0.006 (0.005)\tLoss 0.5501 (0.4938)\tPrec@1 78.125 (83.084)\tPrec@5 99.219 (99.163)\t\n",
            "TRAINING - Epoch: [8][150/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.6777 (0.4975)\tPrec@1 78.906 (83.025)\tPrec@5 97.656 (99.141)\t\n",
            "TRAINING - Epoch: [8][160/390]\tTime 0.060 (0.058)\tData 0.008 (0.005)\tLoss 0.4869 (0.4965)\tPrec@1 85.938 (83.128)\tPrec@5 98.438 (99.141)\t\n",
            "TRAINING - Epoch: [8][170/390]\tTime 0.061 (0.058)\tData 0.007 (0.005)\tLoss 0.6151 (0.4968)\tPrec@1 77.344 (83.064)\tPrec@5 96.875 (99.141)\t\n",
            "TRAINING - Epoch: [8][180/390]\tTime 0.052 (0.058)\tData 0.005 (0.005)\tLoss 0.4954 (0.4985)\tPrec@1 83.594 (82.981)\tPrec@5 100.000 (99.128)\t\n",
            "TRAINING - Epoch: [8][190/390]\tTime 0.067 (0.057)\tData 0.010 (0.005)\tLoss 0.4565 (0.4983)\tPrec@1 85.938 (83.017)\tPrec@5 100.000 (99.133)\t\n",
            "TRAINING - Epoch: [8][200/390]\tTime 0.067 (0.057)\tData 0.006 (0.005)\tLoss 0.5219 (0.4980)\tPrec@1 86.719 (83.034)\tPrec@5 99.219 (99.141)\t\n",
            "TRAINING - Epoch: [8][210/390]\tTime 0.054 (0.057)\tData 0.002 (0.005)\tLoss 0.4718 (0.4972)\tPrec@1 81.250 (83.035)\tPrec@5 98.438 (99.141)\t\n",
            "TRAINING - Epoch: [8][220/390]\tTime 0.058 (0.057)\tData 0.000 (0.004)\tLoss 0.5044 (0.4958)\tPrec@1 84.375 (83.081)\tPrec@5 99.219 (99.141)\t\n",
            "TRAINING - Epoch: [8][230/390]\tTime 0.057 (0.057)\tData 0.008 (0.004)\tLoss 0.5052 (0.4943)\tPrec@1 82.031 (83.124)\tPrec@5 98.438 (99.134)\t\n",
            "TRAINING - Epoch: [8][240/390]\tTime 0.060 (0.057)\tData 0.007 (0.004)\tLoss 0.5463 (0.4942)\tPrec@1 82.031 (83.124)\tPrec@5 100.000 (99.144)\t\n",
            "TRAINING - Epoch: [8][250/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.4255 (0.4933)\tPrec@1 82.031 (83.139)\tPrec@5 100.000 (99.153)\t\n",
            "TRAINING - Epoch: [8][260/390]\tTime 0.069 (0.057)\tData 0.011 (0.004)\tLoss 0.5170 (0.4926)\tPrec@1 82.812 (83.127)\tPrec@5 98.438 (99.156)\t\n",
            "TRAINING - Epoch: [8][270/390]\tTime 0.060 (0.057)\tData 0.000 (0.004)\tLoss 0.4803 (0.4934)\tPrec@1 83.594 (83.081)\tPrec@5 99.219 (99.158)\t\n",
            "TRAINING - Epoch: [8][280/390]\tTime 0.053 (0.057)\tData 0.006 (0.004)\tLoss 0.4797 (0.4941)\tPrec@1 82.812 (83.032)\tPrec@5 100.000 (99.166)\t\n",
            "TRAINING - Epoch: [8][290/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.4302 (0.4937)\tPrec@1 86.719 (83.041)\tPrec@5 99.219 (99.173)\t\n",
            "TRAINING - Epoch: [8][300/390]\tTime 0.051 (0.057)\tData 0.003 (0.004)\tLoss 0.4945 (0.4925)\tPrec@1 79.688 (83.093)\tPrec@5 100.000 (99.190)\t\n",
            "TRAINING - Epoch: [8][310/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.3901 (0.4902)\tPrec@1 87.500 (83.177)\tPrec@5 99.219 (99.201)\t\n",
            "TRAINING - Epoch: [8][320/390]\tTime 0.065 (0.057)\tData 0.007 (0.004)\tLoss 0.5467 (0.4899)\tPrec@1 78.906 (83.158)\tPrec@5 100.000 (99.207)\t\n",
            "TRAINING - Epoch: [8][330/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.4805 (0.4908)\tPrec@1 82.031 (83.105)\tPrec@5 100.000 (99.209)\t\n",
            "TRAINING - Epoch: [8][340/390]\tTime 0.049 (0.057)\tData 0.001 (0.004)\tLoss 0.4854 (0.4910)\tPrec@1 81.250 (83.083)\tPrec@5 99.219 (99.205)\t\n",
            "TRAINING - Epoch: [8][350/390]\tTime 0.071 (0.057)\tData 0.000 (0.004)\tLoss 0.5815 (0.4911)\tPrec@1 82.031 (83.111)\tPrec@5 98.438 (99.208)\t\n",
            "TRAINING - Epoch: [8][360/390]\tTime 0.053 (0.057)\tData 0.007 (0.004)\tLoss 0.4083 (0.4911)\tPrec@1 85.938 (83.133)\tPrec@5 100.000 (99.197)\t\n",
            "TRAINING - Epoch: [8][370/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.5380 (0.4905)\tPrec@1 80.469 (83.170)\tPrec@5 99.219 (99.202)\t\n",
            "TRAINING - Epoch: [8][380/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.3758 (0.4899)\tPrec@1 89.062 (83.202)\tPrec@5 99.219 (99.202)\t\n",
            "TRAINING - Epoch: [8][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.3670 (0.4892)\tPrec@1 88.281 (83.203)\tPrec@5 100.000 (99.209)\t\n",
            "EVALUATING - Epoch: [8][0/79]\tTime 0.279 (0.279)\tData 0.247 (0.247)\tLoss 0.4424 (0.4424)\tPrec@1 82.812 (82.812)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [8][10/79]\tTime 0.038 (0.052)\tData 0.007 (0.026)\tLoss 0.4831 (0.5839)\tPrec@1 80.469 (79.901)\tPrec@5 97.656 (99.006)\t\n",
            "EVALUATING - Epoch: [8][20/79]\tTime 0.014 (0.043)\tData 0.000 (0.016)\tLoss 0.5670 (0.6128)\tPrec@1 79.688 (79.390)\tPrec@5 98.438 (98.996)\t\n",
            "EVALUATING - Epoch: [8][30/79]\tTime 0.017 (0.038)\tData 0.004 (0.013)\tLoss 0.4787 (0.6136)\tPrec@1 83.594 (79.561)\tPrec@5 100.000 (98.891)\t\n",
            "EVALUATING - Epoch: [8][40/79]\tTime 0.027 (0.036)\tData 0.000 (0.011)\tLoss 0.5949 (0.6035)\tPrec@1 81.250 (80.164)\tPrec@5 99.219 (98.971)\t\n",
            "EVALUATING - Epoch: [8][50/79]\tTime 0.032 (0.034)\tData 0.000 (0.009)\tLoss 0.5548 (0.5979)\tPrec@1 81.250 (79.963)\tPrec@5 100.000 (99.081)\t\n",
            "EVALUATING - Epoch: [8][60/79]\tTime 0.012 (0.033)\tData 0.000 (0.009)\tLoss 0.7260 (0.5983)\tPrec@1 73.438 (79.892)\tPrec@5 99.219 (99.116)\t\n",
            "EVALUATING - Epoch: [8][70/79]\tTime 0.036 (0.033)\tData 0.004 (0.008)\tLoss 0.5963 (0.6027)\tPrec@1 79.688 (79.776)\tPrec@5 100.000 (99.087)\t\n",
            "EVALUATING - Epoch: [8][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.008)\tLoss 0.5796 (0.5997)\tPrec@1 81.250 (79.800)\tPrec@5 100.000 (99.070)\t\n",
            "\n",
            "Results - Epoch: 9\n",
            "Training Loss 0.4892 \tTraining Prec@1 83.203 \tTraining Prec@5 99.209 \tValidation Loss 0.5997 \tValidation Prec@1 79.800 \tValidation Prec@5 99.070 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 10\n",
            "\n",
            "TRAINING - Epoch: [9][0/390]\tTime 0.384 (0.384)\tData 0.297 (0.297)\tLoss 0.3849 (0.3849)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [9][10/390]\tTime 0.046 (0.085)\tData 0.000 (0.030)\tLoss 0.4909 (0.4405)\tPrec@1 82.812 (84.943)\tPrec@5 98.438 (99.361)\t\n",
            "TRAINING - Epoch: [9][20/390]\tTime 0.051 (0.069)\tData 0.000 (0.017)\tLoss 0.3641 (0.4449)\tPrec@1 85.156 (84.970)\tPrec@5 100.000 (99.516)\t\n",
            "TRAINING - Epoch: [9][30/390]\tTime 0.048 (0.065)\tData 0.000 (0.012)\tLoss 0.3783 (0.4564)\tPrec@1 89.062 (84.551)\tPrec@5 100.000 (99.446)\t\n",
            "TRAINING - Epoch: [9][40/390]\tTime 0.048 (0.062)\tData 0.000 (0.010)\tLoss 0.3828 (0.4406)\tPrec@1 85.938 (85.156)\tPrec@5 99.219 (99.409)\t\n",
            "TRAINING - Epoch: [9][50/390]\tTime 0.056 (0.061)\tData 0.006 (0.009)\tLoss 0.5847 (0.4431)\tPrec@1 81.250 (84.988)\tPrec@5 99.219 (99.449)\t\n",
            "TRAINING - Epoch: [9][60/390]\tTime 0.059 (0.060)\tData 0.010 (0.008)\tLoss 0.5780 (0.4534)\tPrec@1 81.250 (84.670)\tPrec@5 99.219 (99.449)\t\n",
            "TRAINING - Epoch: [9][70/390]\tTime 0.064 (0.059)\tData 0.000 (0.007)\tLoss 0.5248 (0.4581)\tPrec@1 79.688 (84.419)\tPrec@5 99.219 (99.461)\t\n",
            "TRAINING - Epoch: [9][80/390]\tTime 0.067 (0.059)\tData 0.013 (0.007)\tLoss 0.4752 (0.4634)\tPrec@1 85.156 (84.259)\tPrec@5 100.000 (99.450)\t\n",
            "TRAINING - Epoch: [9][90/390]\tTime 0.048 (0.059)\tData 0.000 (0.007)\tLoss 0.4965 (0.4686)\tPrec@1 86.719 (84.075)\tPrec@5 98.438 (99.408)\t\n",
            "TRAINING - Epoch: [9][100/390]\tTime 0.077 (0.058)\tData 0.000 (0.006)\tLoss 0.4889 (0.4686)\tPrec@1 81.250 (83.996)\tPrec@5 99.219 (99.412)\t\n",
            "TRAINING - Epoch: [9][110/390]\tTime 0.048 (0.058)\tData 0.000 (0.006)\tLoss 0.6216 (0.4687)\tPrec@1 81.250 (83.918)\tPrec@5 98.438 (99.423)\t\n",
            "TRAINING - Epoch: [9][120/390]\tTime 0.060 (0.058)\tData 0.007 (0.005)\tLoss 0.4617 (0.4687)\tPrec@1 82.812 (83.865)\tPrec@5 99.219 (99.432)\t\n",
            "TRAINING - Epoch: [9][130/390]\tTime 0.063 (0.057)\tData 0.000 (0.005)\tLoss 0.3494 (0.4694)\tPrec@1 85.938 (83.791)\tPrec@5 100.000 (99.445)\t\n",
            "TRAINING - Epoch: [9][140/390]\tTime 0.077 (0.057)\tData 0.007 (0.005)\tLoss 0.4363 (0.4691)\tPrec@1 88.281 (83.804)\tPrec@5 98.438 (99.446)\t\n",
            "TRAINING - Epoch: [9][150/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.4128 (0.4676)\tPrec@1 86.719 (83.883)\tPrec@5 99.219 (99.436)\t\n",
            "TRAINING - Epoch: [9][160/390]\tTime 0.055 (0.057)\tData 0.007 (0.005)\tLoss 0.4942 (0.4672)\tPrec@1 82.031 (83.963)\tPrec@5 100.000 (99.427)\t\n",
            "TRAINING - Epoch: [9][170/390]\tTime 0.056 (0.057)\tData 0.007 (0.005)\tLoss 0.5914 (0.4703)\tPrec@1 77.344 (83.799)\tPrec@5 100.000 (99.424)\t\n",
            "TRAINING - Epoch: [9][180/390]\tTime 0.066 (0.057)\tData 0.007 (0.005)\tLoss 0.5590 (0.4703)\tPrec@1 84.375 (83.810)\tPrec@5 98.438 (99.391)\t\n",
            "TRAINING - Epoch: [9][190/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.2878 (0.4685)\tPrec@1 89.062 (83.843)\tPrec@5 100.000 (99.403)\t\n",
            "TRAINING - Epoch: [9][200/390]\tTime 0.047 (0.057)\tData 0.000 (0.005)\tLoss 0.4078 (0.4673)\tPrec@1 86.719 (83.889)\tPrec@5 99.219 (99.405)\t\n",
            "TRAINING - Epoch: [9][210/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.4659 (0.4656)\tPrec@1 84.375 (83.945)\tPrec@5 98.438 (99.415)\t\n",
            "TRAINING - Epoch: [9][220/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.5159 (0.4649)\tPrec@1 86.719 (84.004)\tPrec@5 96.875 (99.399)\t\n",
            "TRAINING - Epoch: [9][230/390]\tTime 0.057 (0.056)\tData 0.009 (0.004)\tLoss 0.4022 (0.4655)\tPrec@1 85.156 (83.966)\tPrec@5 98.438 (99.381)\t\n",
            "TRAINING - Epoch: [9][240/390]\tTime 0.068 (0.056)\tData 0.010 (0.004)\tLoss 0.5788 (0.4675)\tPrec@1 78.906 (83.902)\tPrec@5 100.000 (99.368)\t\n",
            "TRAINING - Epoch: [9][250/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.6445 (0.4666)\tPrec@1 78.125 (83.967)\tPrec@5 100.000 (99.371)\t\n",
            "TRAINING - Epoch: [9][260/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.4752 (0.4649)\tPrec@1 82.812 (83.989)\tPrec@5 99.219 (99.377)\t\n",
            "TRAINING - Epoch: [9][270/390]\tTime 0.057 (0.056)\tData 0.009 (0.004)\tLoss 0.4976 (0.4643)\tPrec@1 81.250 (84.006)\tPrec@5 100.000 (99.380)\t\n",
            "TRAINING - Epoch: [9][280/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.4052 (0.4631)\tPrec@1 85.938 (84.047)\tPrec@5 99.219 (99.383)\t\n",
            "TRAINING - Epoch: [9][290/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.4517 (0.4622)\tPrec@1 82.031 (84.064)\tPrec@5 100.000 (99.391)\t\n",
            "TRAINING - Epoch: [9][300/390]\tTime 0.061 (0.056)\tData 0.007 (0.004)\tLoss 0.5601 (0.4617)\tPrec@1 80.469 (84.084)\tPrec@5 99.219 (99.382)\t\n",
            "TRAINING - Epoch: [9][310/390]\tTime 0.051 (0.056)\tData 0.003 (0.004)\tLoss 0.4459 (0.4620)\tPrec@1 82.031 (84.074)\tPrec@5 100.000 (99.385)\t\n",
            "TRAINING - Epoch: [9][320/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.4238 (0.4613)\tPrec@1 85.938 (84.115)\tPrec@5 98.438 (99.396)\t\n",
            "TRAINING - Epoch: [9][330/390]\tTime 0.053 (0.056)\tData 0.006 (0.004)\tLoss 0.6095 (0.4625)\tPrec@1 82.812 (84.054)\tPrec@5 98.438 (99.384)\t\n",
            "TRAINING - Epoch: [9][340/390]\tTime 0.057 (0.056)\tData 0.007 (0.004)\tLoss 0.4354 (0.4633)\tPrec@1 82.812 (84.020)\tPrec@5 100.000 (99.379)\t\n",
            "TRAINING - Epoch: [9][350/390]\tTime 0.065 (0.056)\tData 0.010 (0.004)\tLoss 0.5808 (0.4633)\tPrec@1 82.031 (84.017)\tPrec@5 100.000 (99.386)\t\n",
            "TRAINING - Epoch: [9][360/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.5750 (0.4635)\tPrec@1 78.125 (83.985)\tPrec@5 100.000 (99.392)\t\n",
            "TRAINING - Epoch: [9][370/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.4090 (0.4634)\tPrec@1 87.500 (83.985)\tPrec@5 98.438 (99.381)\t\n",
            "TRAINING - Epoch: [9][380/390]\tTime 0.052 (0.056)\tData 0.001 (0.004)\tLoss 0.3651 (0.4623)\tPrec@1 85.938 (84.041)\tPrec@5 99.219 (99.383)\t\n",
            "TRAINING - Epoch: [9][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.4125 (0.4618)\tPrec@1 82.812 (84.048)\tPrec@5 99.219 (99.375)\t\n",
            "EVALUATING - Epoch: [9][0/79]\tTime 0.208 (0.208)\tData 0.180 (0.180)\tLoss 0.4541 (0.4541)\tPrec@1 84.375 (84.375)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [9][10/79]\tTime 0.028 (0.056)\tData 0.000 (0.024)\tLoss 0.4897 (0.6063)\tPrec@1 81.250 (80.043)\tPrec@5 99.219 (99.290)\t\n",
            "EVALUATING - Epoch: [9][20/79]\tTime 0.036 (0.044)\tData 0.006 (0.015)\tLoss 0.7017 (0.6478)\tPrec@1 81.250 (79.948)\tPrec@5 97.656 (98.847)\t\n",
            "EVALUATING - Epoch: [9][30/79]\tTime 0.028 (0.040)\tData 0.006 (0.012)\tLoss 0.5575 (0.6465)\tPrec@1 81.250 (79.839)\tPrec@5 100.000 (98.916)\t\n",
            "EVALUATING - Epoch: [9][40/79]\tTime 0.040 (0.037)\tData 0.006 (0.011)\tLoss 0.8061 (0.6489)\tPrec@1 75.000 (79.573)\tPrec@5 100.000 (98.895)\t\n",
            "EVALUATING - Epoch: [9][50/79]\tTime 0.023 (0.036)\tData 0.000 (0.009)\tLoss 0.6110 (0.6493)\tPrec@1 83.594 (79.504)\tPrec@5 98.438 (98.928)\t\n",
            "EVALUATING - Epoch: [9][60/79]\tTime 0.012 (0.035)\tData 0.000 (0.009)\tLoss 0.7929 (0.6509)\tPrec@1 74.219 (79.316)\tPrec@5 98.438 (98.937)\t\n",
            "EVALUATING - Epoch: [9][70/79]\tTime 0.019 (0.034)\tData 0.003 (0.008)\tLoss 0.4243 (0.6509)\tPrec@1 85.156 (79.401)\tPrec@5 100.000 (98.933)\t\n",
            "EVALUATING - Epoch: [9][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.8730 (0.6453)\tPrec@1 68.750 (79.460)\tPrec@5 93.750 (98.950)\t\n",
            "\n",
            "Results - Epoch: 10\n",
            "Training Loss 0.4618 \tTraining Prec@1 84.048 \tTraining Prec@5 99.375 \tValidation Loss 0.6453 \tValidation Prec@1 79.460 \tValidation Prec@5 98.950 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 11\n",
            "\n",
            "TRAINING - Epoch: [10][0/390]\tTime 0.403 (0.403)\tData 0.317 (0.317)\tLoss 0.4844 (0.4844)\tPrec@1 84.375 (84.375)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [10][10/390]\tTime 0.059 (0.088)\tData 0.010 (0.031)\tLoss 0.3730 (0.4002)\tPrec@1 85.938 (86.932)\tPrec@5 100.000 (99.574)\t\n",
            "TRAINING - Epoch: [10][20/390]\tTime 0.053 (0.072)\tData 0.005 (0.018)\tLoss 0.2745 (0.3797)\tPrec@1 89.844 (86.979)\tPrec@5 99.219 (99.665)\t\n",
            "TRAINING - Epoch: [10][30/390]\tTime 0.053 (0.067)\tData 0.000 (0.014)\tLoss 0.3898 (0.3950)\tPrec@1 86.719 (86.492)\tPrec@5 98.438 (99.572)\t\n",
            "TRAINING - Epoch: [10][40/390]\tTime 0.047 (0.063)\tData 0.000 (0.011)\tLoss 0.5094 (0.4104)\tPrec@1 82.031 (85.823)\tPrec@5 100.000 (99.486)\t\n",
            "TRAINING - Epoch: [10][50/390]\tTime 0.054 (0.062)\tData 0.007 (0.010)\tLoss 0.2711 (0.4108)\tPrec@1 89.844 (85.861)\tPrec@5 99.219 (99.510)\t\n",
            "TRAINING - Epoch: [10][60/390]\tTime 0.054 (0.061)\tData 0.004 (0.009)\tLoss 0.4159 (0.4149)\tPrec@1 82.031 (85.605)\tPrec@5 100.000 (99.488)\t\n",
            "TRAINING - Epoch: [10][70/390]\tTime 0.051 (0.060)\tData 0.004 (0.008)\tLoss 0.5532 (0.4234)\tPrec@1 79.688 (85.123)\tPrec@5 99.219 (99.472)\t\n",
            "TRAINING - Epoch: [10][80/390]\tTime 0.047 (0.059)\tData 0.000 (0.008)\tLoss 0.3090 (0.4194)\tPrec@1 89.844 (85.330)\tPrec@5 99.219 (99.460)\t\n",
            "TRAINING - Epoch: [10][90/390]\tTime 0.050 (0.059)\tData 0.000 (0.007)\tLoss 0.4767 (0.4217)\tPrec@1 82.812 (85.199)\tPrec@5 99.219 (99.442)\t\n",
            "TRAINING - Epoch: [10][100/390]\tTime 0.048 (0.059)\tData 0.000 (0.007)\tLoss 0.5780 (0.4263)\tPrec@1 82.812 (85.056)\tPrec@5 99.219 (99.466)\t\n",
            "TRAINING - Epoch: [10][110/390]\tTime 0.062 (0.059)\tData 0.007 (0.007)\tLoss 0.4435 (0.4285)\tPrec@1 85.156 (84.959)\tPrec@5 99.219 (99.416)\t\n",
            "TRAINING - Epoch: [10][120/390]\tTime 0.055 (0.058)\tData 0.007 (0.007)\tLoss 0.4369 (0.4283)\tPrec@1 87.500 (85.059)\tPrec@5 100.000 (99.412)\t\n",
            "TRAINING - Epoch: [10][130/390]\tTime 0.053 (0.058)\tData 0.005 (0.007)\tLoss 0.5535 (0.4279)\tPrec@1 78.125 (85.073)\tPrec@5 100.000 (99.422)\t\n",
            "TRAINING - Epoch: [10][140/390]\tTime 0.047 (0.058)\tData 0.000 (0.006)\tLoss 0.3718 (0.4286)\tPrec@1 88.281 (85.057)\tPrec@5 100.000 (99.435)\t\n",
            "TRAINING - Epoch: [10][150/390]\tTime 0.068 (0.058)\tData 0.011 (0.006)\tLoss 0.5070 (0.4277)\tPrec@1 89.062 (85.229)\tPrec@5 99.219 (99.452)\t\n",
            "TRAINING - Epoch: [10][160/390]\tTime 0.054 (0.058)\tData 0.007 (0.006)\tLoss 0.4675 (0.4272)\tPrec@1 86.719 (85.292)\tPrec@5 99.219 (99.437)\t\n",
            "TRAINING - Epoch: [10][170/390]\tTime 0.058 (0.057)\tData 0.008 (0.006)\tLoss 0.4573 (0.4282)\tPrec@1 85.156 (85.284)\tPrec@5 100.000 (99.447)\t\n",
            "TRAINING - Epoch: [10][180/390]\tTime 0.046 (0.057)\tData 0.000 (0.006)\tLoss 0.4388 (0.4289)\tPrec@1 82.812 (85.212)\tPrec@5 98.438 (99.448)\t\n",
            "TRAINING - Epoch: [10][190/390]\tTime 0.048 (0.057)\tData 0.000 (0.006)\tLoss 0.4486 (0.4285)\tPrec@1 86.719 (85.254)\tPrec@5 97.656 (99.444)\t\n",
            "TRAINING - Epoch: [10][200/390]\tTime 0.050 (0.057)\tData 0.000 (0.006)\tLoss 0.5223 (0.4285)\tPrec@1 78.125 (85.203)\tPrec@5 100.000 (99.444)\t\n",
            "TRAINING - Epoch: [10][210/390]\tTime 0.054 (0.057)\tData 0.000 (0.005)\tLoss 0.3876 (0.4300)\tPrec@1 89.062 (85.116)\tPrec@5 99.219 (99.445)\t\n",
            "TRAINING - Epoch: [10][220/390]\tTime 0.061 (0.057)\tData 0.009 (0.005)\tLoss 0.5590 (0.4304)\tPrec@1 85.156 (85.124)\tPrec@5 98.438 (99.438)\t\n",
            "TRAINING - Epoch: [10][230/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.4243 (0.4301)\tPrec@1 82.031 (85.112)\tPrec@5 100.000 (99.442)\t\n",
            "TRAINING - Epoch: [10][240/390]\tTime 0.055 (0.057)\tData 0.006 (0.005)\tLoss 0.4896 (0.4304)\tPrec@1 84.375 (85.095)\tPrec@5 99.219 (99.423)\t\n",
            "TRAINING - Epoch: [10][250/390]\tTime 0.055 (0.057)\tData 0.007 (0.005)\tLoss 0.4959 (0.4325)\tPrec@1 79.688 (85.010)\tPrec@5 99.219 (99.415)\t\n",
            "TRAINING - Epoch: [10][260/390]\tTime 0.055 (0.057)\tData 0.000 (0.005)\tLoss 0.4257 (0.4340)\tPrec@1 81.250 (84.947)\tPrec@5 100.000 (99.425)\t\n",
            "TRAINING - Epoch: [10][270/390]\tTime 0.064 (0.057)\tData 0.010 (0.005)\tLoss 0.3833 (0.4355)\tPrec@1 84.375 (84.894)\tPrec@5 100.000 (99.421)\t\n",
            "TRAINING - Epoch: [10][280/390]\tTime 0.050 (0.056)\tData 0.000 (0.005)\tLoss 0.5061 (0.4362)\tPrec@1 83.594 (84.887)\tPrec@5 98.438 (99.413)\t\n",
            "TRAINING - Epoch: [10][290/390]\tTime 0.055 (0.056)\tData 0.000 (0.005)\tLoss 0.5344 (0.4351)\tPrec@1 80.469 (84.890)\tPrec@5 99.219 (99.423)\t\n",
            "TRAINING - Epoch: [10][300/390]\tTime 0.055 (0.056)\tData 0.007 (0.005)\tLoss 0.5102 (0.4339)\tPrec@1 83.594 (84.967)\tPrec@5 100.000 (99.421)\t\n",
            "TRAINING - Epoch: [10][310/390]\tTime 0.069 (0.056)\tData 0.001 (0.005)\tLoss 0.4312 (0.4328)\tPrec@1 85.938 (84.975)\tPrec@5 99.219 (99.425)\t\n",
            "TRAINING - Epoch: [10][320/390]\tTime 0.048 (0.056)\tData 0.000 (0.005)\tLoss 0.6416 (0.4323)\tPrec@1 79.688 (85.030)\tPrec@5 95.312 (99.423)\t\n",
            "TRAINING - Epoch: [10][330/390]\tTime 0.059 (0.056)\tData 0.009 (0.005)\tLoss 0.4025 (0.4317)\tPrec@1 84.375 (85.043)\tPrec@5 99.219 (99.429)\t\n",
            "TRAINING - Epoch: [10][340/390]\tTime 0.058 (0.056)\tData 0.009 (0.005)\tLoss 0.4799 (0.4326)\tPrec@1 85.938 (85.051)\tPrec@5 100.000 (99.423)\t\n",
            "TRAINING - Epoch: [10][350/390]\tTime 0.067 (0.056)\tData 0.007 (0.004)\tLoss 0.3992 (0.4337)\tPrec@1 85.156 (85.018)\tPrec@5 99.219 (99.421)\t\n",
            "TRAINING - Epoch: [10][360/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.4660 (0.4344)\tPrec@1 82.031 (84.990)\tPrec@5 100.000 (99.405)\t\n",
            "TRAINING - Epoch: [10][370/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.5305 (0.4359)\tPrec@1 82.031 (84.952)\tPrec@5 98.438 (99.400)\t\n",
            "TRAINING - Epoch: [10][380/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.4157 (0.4359)\tPrec@1 85.156 (84.943)\tPrec@5 100.000 (99.399)\t\n",
            "TRAINING - Epoch: [10][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.4697 (0.4373)\tPrec@1 85.938 (84.900)\tPrec@5 99.219 (99.389)\t\n",
            "EVALUATING - Epoch: [10][0/79]\tTime 0.251 (0.251)\tData 0.216 (0.216)\tLoss 0.4355 (0.4355)\tPrec@1 85.938 (85.938)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [10][10/79]\tTime 0.027 (0.053)\tData 0.000 (0.023)\tLoss 0.3840 (0.5445)\tPrec@1 83.594 (80.824)\tPrec@5 100.000 (99.432)\t\n",
            "EVALUATING - Epoch: [10][20/79]\tTime 0.028 (0.041)\tData 0.007 (0.014)\tLoss 0.5640 (0.5617)\tPrec@1 81.250 (80.580)\tPrec@5 99.219 (99.107)\t\n",
            "EVALUATING - Epoch: [10][30/79]\tTime 0.023 (0.038)\tData 0.004 (0.011)\tLoss 0.3995 (0.5623)\tPrec@1 85.938 (80.822)\tPrec@5 100.000 (99.042)\t\n",
            "EVALUATING - Epoch: [10][40/79]\tTime 0.028 (0.036)\tData 0.001 (0.010)\tLoss 0.5007 (0.5534)\tPrec@1 79.688 (80.926)\tPrec@5 100.000 (99.123)\t\n",
            "EVALUATING - Epoch: [10][50/79]\tTime 0.050 (0.035)\tData 0.013 (0.009)\tLoss 0.6393 (0.5540)\tPrec@1 78.906 (81.020)\tPrec@5 99.219 (99.157)\t\n",
            "EVALUATING - Epoch: [10][60/79]\tTime 0.028 (0.034)\tData 0.000 (0.008)\tLoss 0.4983 (0.5482)\tPrec@1 85.156 (81.263)\tPrec@5 99.219 (99.142)\t\n",
            "EVALUATING - Epoch: [10][70/79]\tTime 0.037 (0.033)\tData 0.018 (0.008)\tLoss 0.5275 (0.5515)\tPrec@1 82.812 (81.173)\tPrec@5 100.000 (99.186)\t\n",
            "EVALUATING - Epoch: [10][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.4066 (0.5462)\tPrec@1 93.750 (81.510)\tPrec@5 100.000 (99.220)\t\n",
            "\n",
            "Results - Epoch: 11\n",
            "Training Loss 0.4373 \tTraining Prec@1 84.900 \tTraining Prec@5 99.389 \tValidation Loss 0.5462 \tValidation Prec@1 81.510 \tValidation Prec@5 99.220 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 12\n",
            "\n",
            "TRAINING - Epoch: [11][0/390]\tTime 0.396 (0.396)\tData 0.306 (0.306)\tLoss 0.5393 (0.5393)\tPrec@1 78.125 (78.125)\tPrec@5 98.438 (98.438)\t\n",
            "TRAINING - Epoch: [11][10/390]\tTime 0.057 (0.089)\tData 0.009 (0.031)\tLoss 0.4058 (0.4061)\tPrec@1 87.500 (85.156)\tPrec@5 99.219 (99.574)\t\n",
            "TRAINING - Epoch: [11][20/390]\tTime 0.054 (0.073)\tData 0.000 (0.017)\tLoss 0.4651 (0.4050)\tPrec@1 83.594 (85.826)\tPrec@5 100.000 (99.554)\t\n",
            "TRAINING - Epoch: [11][30/390]\tTime 0.066 (0.067)\tData 0.010 (0.014)\tLoss 0.4413 (0.3965)\tPrec@1 85.156 (86.089)\tPrec@5 100.000 (99.572)\t\n",
            "TRAINING - Epoch: [11][40/390]\tTime 0.055 (0.063)\tData 0.000 (0.011)\tLoss 0.5009 (0.4048)\tPrec@1 84.375 (86.014)\tPrec@5 98.438 (99.505)\t\n",
            "TRAINING - Epoch: [11][50/390]\tTime 0.048 (0.062)\tData 0.000 (0.009)\tLoss 0.3445 (0.4044)\tPrec@1 89.844 (86.106)\tPrec@5 98.438 (99.464)\t\n",
            "TRAINING - Epoch: [11][60/390]\tTime 0.057 (0.061)\tData 0.000 (0.008)\tLoss 0.3958 (0.4121)\tPrec@1 87.500 (86.027)\tPrec@5 100.000 (99.488)\t\n",
            "TRAINING - Epoch: [11][70/390]\tTime 0.061 (0.061)\tData 0.010 (0.008)\tLoss 0.4820 (0.4091)\tPrec@1 85.156 (86.191)\tPrec@5 100.000 (99.538)\t\n",
            "TRAINING - Epoch: [11][80/390]\tTime 0.056 (0.060)\tData 0.006 (0.007)\tLoss 0.3601 (0.4129)\tPrec@1 88.281 (86.015)\tPrec@5 100.000 (99.556)\t\n",
            "TRAINING - Epoch: [11][90/390]\tTime 0.061 (0.059)\tData 0.011 (0.007)\tLoss 0.4471 (0.4148)\tPrec@1 81.250 (85.834)\tPrec@5 100.000 (99.528)\t\n",
            "TRAINING - Epoch: [11][100/390]\tTime 0.074 (0.060)\tData 0.000 (0.006)\tLoss 0.2957 (0.4139)\tPrec@1 89.844 (85.806)\tPrec@5 100.000 (99.520)\t\n",
            "TRAINING - Epoch: [11][110/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.4520 (0.4172)\tPrec@1 84.375 (85.663)\tPrec@5 100.000 (99.528)\t\n",
            "TRAINING - Epoch: [11][120/390]\tTime 0.081 (0.059)\tData 0.008 (0.006)\tLoss 0.3506 (0.4159)\tPrec@1 89.062 (85.666)\tPrec@5 99.219 (99.522)\t\n",
            "TRAINING - Epoch: [11][130/390]\tTime 0.053 (0.059)\tData 0.003 (0.006)\tLoss 0.3639 (0.4164)\tPrec@1 83.594 (85.663)\tPrec@5 98.438 (99.475)\t\n",
            "TRAINING - Epoch: [11][140/390]\tTime 0.049 (0.059)\tData 0.000 (0.006)\tLoss 0.4903 (0.4143)\tPrec@1 82.812 (85.744)\tPrec@5 100.000 (99.463)\t\n",
            "TRAINING - Epoch: [11][150/390]\tTime 0.049 (0.059)\tData 0.002 (0.006)\tLoss 0.2954 (0.4159)\tPrec@1 89.844 (85.679)\tPrec@5 100.000 (99.462)\t\n",
            "TRAINING - Epoch: [11][160/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.5013 (0.4171)\tPrec@1 82.812 (85.617)\tPrec@5 99.219 (99.452)\t\n",
            "TRAINING - Epoch: [11][170/390]\tTime 0.055 (0.058)\tData 0.007 (0.005)\tLoss 0.3940 (0.4190)\tPrec@1 85.156 (85.481)\tPrec@5 100.000 (99.452)\t\n",
            "TRAINING - Epoch: [11][180/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.4720 (0.4181)\tPrec@1 83.594 (85.519)\tPrec@5 100.000 (99.448)\t\n",
            "TRAINING - Epoch: [11][190/390]\tTime 0.082 (0.058)\tData 0.007 (0.005)\tLoss 0.3165 (0.4180)\tPrec@1 89.062 (85.528)\tPrec@5 100.000 (99.456)\t\n",
            "TRAINING - Epoch: [11][200/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.4107 (0.4178)\tPrec@1 81.250 (85.475)\tPrec@5 99.219 (99.452)\t\n",
            "TRAINING - Epoch: [11][210/390]\tTime 0.055 (0.057)\tData 0.002 (0.005)\tLoss 0.3091 (0.4158)\tPrec@1 90.625 (85.545)\tPrec@5 99.219 (99.463)\t\n",
            "TRAINING - Epoch: [11][220/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.4137 (0.4175)\tPrec@1 85.938 (85.499)\tPrec@5 100.000 (99.463)\t\n",
            "TRAINING - Epoch: [11][230/390]\tTime 0.073 (0.057)\tData 0.001 (0.005)\tLoss 0.3879 (0.4184)\tPrec@1 85.156 (85.461)\tPrec@5 100.000 (99.466)\t\n",
            "TRAINING - Epoch: [11][240/390]\tTime 0.056 (0.057)\tData 0.007 (0.005)\tLoss 0.3917 (0.4174)\tPrec@1 89.062 (85.539)\tPrec@5 99.219 (99.465)\t\n",
            "TRAINING - Epoch: [11][250/390]\tTime 0.054 (0.057)\tData 0.009 (0.005)\tLoss 0.5679 (0.4162)\tPrec@1 82.031 (85.604)\tPrec@5 99.219 (99.468)\t\n",
            "TRAINING - Epoch: [11][260/390]\tTime 0.072 (0.057)\tData 0.006 (0.005)\tLoss 0.2819 (0.4166)\tPrec@1 91.406 (85.611)\tPrec@5 100.000 (99.464)\t\n",
            "TRAINING - Epoch: [11][270/390]\tTime 0.059 (0.057)\tData 0.006 (0.005)\tLoss 0.5254 (0.4171)\tPrec@1 78.125 (85.583)\tPrec@5 98.438 (99.455)\t\n",
            "TRAINING - Epoch: [11][280/390]\tTime 0.051 (0.057)\tData 0.000 (0.005)\tLoss 0.3532 (0.4175)\tPrec@1 90.625 (85.573)\tPrec@5 99.219 (99.447)\t\n",
            "TRAINING - Epoch: [11][290/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.3445 (0.4169)\tPrec@1 86.719 (85.583)\tPrec@5 100.000 (99.447)\t\n",
            "TRAINING - Epoch: [11][300/390]\tTime 0.052 (0.057)\tData 0.000 (0.005)\tLoss 0.4536 (0.4164)\tPrec@1 86.719 (85.618)\tPrec@5 99.219 (99.452)\t\n",
            "TRAINING - Epoch: [11][310/390]\tTime 0.053 (0.057)\tData 0.001 (0.004)\tLoss 0.5191 (0.4186)\tPrec@1 81.250 (85.505)\tPrec@5 100.000 (99.452)\t\n",
            "TRAINING - Epoch: [11][320/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.4102 (0.4181)\tPrec@1 81.250 (85.553)\tPrec@5 99.219 (99.457)\t\n",
            "TRAINING - Epoch: [11][330/390]\tTime 0.063 (0.056)\tData 0.008 (0.004)\tLoss 0.3768 (0.4172)\tPrec@1 87.500 (85.562)\tPrec@5 98.438 (99.455)\t\n",
            "TRAINING - Epoch: [11][340/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.5513 (0.4157)\tPrec@1 82.812 (85.628)\tPrec@5 97.656 (99.455)\t\n",
            "TRAINING - Epoch: [11][350/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.3751 (0.4156)\tPrec@1 88.281 (85.619)\tPrec@5 100.000 (99.459)\t\n",
            "TRAINING - Epoch: [11][360/390]\tTime 0.062 (0.056)\tData 0.007 (0.004)\tLoss 0.5323 (0.4167)\tPrec@1 82.031 (85.600)\tPrec@5 98.438 (99.455)\t\n",
            "TRAINING - Epoch: [11][370/390]\tTime 0.053 (0.056)\tData 0.002 (0.004)\tLoss 0.3745 (0.4172)\tPrec@1 86.719 (85.592)\tPrec@5 99.219 (99.444)\t\n",
            "TRAINING - Epoch: [11][380/390]\tTime 0.063 (0.056)\tData 0.011 (0.004)\tLoss 0.4366 (0.4175)\tPrec@1 84.375 (85.595)\tPrec@5 100.000 (99.442)\t\n",
            "TRAINING - Epoch: [11][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.5747 (0.4171)\tPrec@1 78.125 (85.589)\tPrec@5 100.000 (99.453)\t\n",
            "EVALUATING - Epoch: [11][0/79]\tTime 0.252 (0.252)\tData 0.211 (0.211)\tLoss 0.4372 (0.4372)\tPrec@1 85.938 (85.938)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [11][10/79]\tTime 0.045 (0.053)\tData 0.015 (0.023)\tLoss 0.4498 (0.5172)\tPrec@1 84.375 (83.026)\tPrec@5 100.000 (99.219)\t\n",
            "EVALUATING - Epoch: [11][20/79]\tTime 0.041 (0.042)\tData 0.005 (0.014)\tLoss 0.4488 (0.5513)\tPrec@1 85.156 (82.292)\tPrec@5 100.000 (99.107)\t\n",
            "EVALUATING - Epoch: [11][30/79]\tTime 0.028 (0.038)\tData 0.000 (0.011)\tLoss 0.4443 (0.5459)\tPrec@1 86.719 (82.334)\tPrec@5 100.000 (99.068)\t\n",
            "EVALUATING - Epoch: [11][40/79]\tTime 0.028 (0.034)\tData 0.005 (0.009)\tLoss 0.5138 (0.5453)\tPrec@1 82.812 (82.374)\tPrec@5 99.219 (99.162)\t\n",
            "EVALUATING - Epoch: [11][50/79]\tTime 0.034 (0.034)\tData 0.006 (0.009)\tLoss 0.5552 (0.5406)\tPrec@1 78.125 (82.384)\tPrec@5 98.438 (99.112)\t\n",
            "EVALUATING - Epoch: [11][60/79]\tTime 0.043 (0.034)\tData 0.017 (0.008)\tLoss 0.5483 (0.5387)\tPrec@1 82.031 (82.454)\tPrec@5 99.219 (99.168)\t\n",
            "EVALUATING - Epoch: [11][70/79]\tTime 0.020 (0.033)\tData 0.008 (0.008)\tLoss 0.4257 (0.5370)\tPrec@1 85.938 (82.394)\tPrec@5 100.000 (99.175)\t\n",
            "EVALUATING - Epoch: [11][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.3324 (0.5354)\tPrec@1 93.750 (82.500)\tPrec@5 100.000 (99.220)\t\n",
            "\n",
            "Results - Epoch: 12\n",
            "Training Loss 0.4171 \tTraining Prec@1 85.589 \tTraining Prec@5 99.453 \tValidation Loss 0.5354 \tValidation Prec@1 82.500 \tValidation Prec@5 99.220 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 13\n",
            "\n",
            "TRAINING - Epoch: [12][0/390]\tTime 0.287 (0.287)\tData 0.190 (0.190)\tLoss 0.3543 (0.3543)\tPrec@1 87.500 (87.500)\tPrec@5 98.438 (98.438)\t\n",
            "TRAINING - Epoch: [12][10/390]\tTime 0.056 (0.087)\tData 0.006 (0.025)\tLoss 0.3920 (0.3804)\tPrec@1 85.156 (86.861)\tPrec@5 100.000 (99.503)\t\n",
            "TRAINING - Epoch: [12][20/390]\tTime 0.053 (0.072)\tData 0.000 (0.015)\tLoss 0.3585 (0.3799)\tPrec@1 85.938 (86.830)\tPrec@5 98.438 (99.516)\t\n",
            "TRAINING - Epoch: [12][30/390]\tTime 0.049 (0.067)\tData 0.000 (0.012)\tLoss 0.3527 (0.3778)\tPrec@1 87.500 (86.694)\tPrec@5 100.000 (99.597)\t\n",
            "TRAINING - Epoch: [12][40/390]\tTime 0.062 (0.064)\tData 0.007 (0.010)\tLoss 0.4207 (0.3915)\tPrec@1 87.500 (86.280)\tPrec@5 100.000 (99.543)\t\n",
            "TRAINING - Epoch: [12][50/390]\tTime 0.049 (0.062)\tData 0.001 (0.008)\tLoss 0.4395 (0.3927)\tPrec@1 85.156 (86.137)\tPrec@5 100.000 (99.602)\t\n",
            "TRAINING - Epoch: [12][60/390]\tTime 0.048 (0.061)\tData 0.000 (0.007)\tLoss 0.5425 (0.3975)\tPrec@1 82.031 (86.219)\tPrec@5 98.438 (99.590)\t\n",
            "TRAINING - Epoch: [12][70/390]\tTime 0.047 (0.060)\tData 0.000 (0.007)\tLoss 0.5149 (0.3989)\tPrec@1 85.156 (86.235)\tPrec@5 98.438 (99.582)\t\n",
            "TRAINING - Epoch: [12][80/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.3508 (0.3988)\tPrec@1 87.500 (86.208)\tPrec@5 100.000 (99.566)\t\n",
            "TRAINING - Epoch: [12][90/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.5205 (0.3992)\tPrec@1 82.812 (86.169)\tPrec@5 99.219 (99.571)\t\n",
            "TRAINING - Epoch: [12][100/390]\tTime 0.065 (0.059)\tData 0.000 (0.006)\tLoss 0.2876 (0.3949)\tPrec@1 88.281 (86.301)\tPrec@5 100.000 (99.567)\t\n",
            "TRAINING - Epoch: [12][110/390]\tTime 0.071 (0.059)\tData 0.009 (0.005)\tLoss 0.3462 (0.3954)\tPrec@1 85.938 (86.282)\tPrec@5 100.000 (99.535)\t\n",
            "TRAINING - Epoch: [12][120/390]\tTime 0.054 (0.059)\tData 0.006 (0.005)\tLoss 0.4755 (0.3964)\tPrec@1 84.375 (86.325)\tPrec@5 99.219 (99.535)\t\n",
            "TRAINING - Epoch: [12][130/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.4440 (0.3930)\tPrec@1 88.281 (86.528)\tPrec@5 100.000 (99.523)\t\n",
            "TRAINING - Epoch: [12][140/390]\tTime 0.063 (0.058)\tData 0.007 (0.005)\tLoss 0.3191 (0.3928)\tPrec@1 89.062 (86.553)\tPrec@5 99.219 (99.535)\t\n",
            "TRAINING - Epoch: [12][150/390]\tTime 0.053 (0.058)\tData 0.000 (0.005)\tLoss 0.3350 (0.3899)\tPrec@1 87.500 (86.595)\tPrec@5 100.000 (99.550)\t\n",
            "TRAINING - Epoch: [12][160/390]\tTime 0.061 (0.058)\tData 0.014 (0.005)\tLoss 0.3681 (0.3900)\tPrec@1 87.500 (86.597)\tPrec@5 99.219 (99.558)\t\n",
            "TRAINING - Epoch: [12][170/390]\tTime 0.054 (0.058)\tData 0.000 (0.004)\tLoss 0.3929 (0.3911)\tPrec@1 85.938 (86.605)\tPrec@5 100.000 (99.561)\t\n",
            "TRAINING - Epoch: [12][180/390]\tTime 0.059 (0.057)\tData 0.000 (0.004)\tLoss 0.3643 (0.3895)\tPrec@1 87.500 (86.650)\tPrec@5 100.000 (99.555)\t\n",
            "TRAINING - Epoch: [12][190/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.3255 (0.3887)\tPrec@1 91.406 (86.670)\tPrec@5 98.438 (99.546)\t\n",
            "TRAINING - Epoch: [12][200/390]\tTime 0.059 (0.057)\tData 0.010 (0.004)\tLoss 0.3314 (0.3899)\tPrec@1 89.844 (86.672)\tPrec@5 99.219 (99.541)\t\n",
            "TRAINING - Epoch: [12][210/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.4380 (0.3912)\tPrec@1 82.031 (86.608)\tPrec@5 100.000 (99.526)\t\n",
            "TRAINING - Epoch: [12][220/390]\tTime 0.054 (0.057)\tData 0.008 (0.004)\tLoss 0.4374 (0.3904)\tPrec@1 87.500 (86.652)\tPrec@5 99.219 (99.523)\t\n",
            "TRAINING - Epoch: [12][230/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.3947 (0.3884)\tPrec@1 85.938 (86.732)\tPrec@5 100.000 (99.530)\t\n",
            "TRAINING - Epoch: [12][240/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.3111 (0.3888)\tPrec@1 89.844 (86.667)\tPrec@5 100.000 (99.520)\t\n",
            "TRAINING - Epoch: [12][250/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2335 (0.3901)\tPrec@1 94.531 (86.622)\tPrec@5 100.000 (99.527)\t\n",
            "TRAINING - Epoch: [12][260/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.4488 (0.3922)\tPrec@1 84.375 (86.554)\tPrec@5 99.219 (99.527)\t\n",
            "TRAINING - Epoch: [12][270/390]\tTime 0.059 (0.057)\tData 0.011 (0.004)\tLoss 0.5106 (0.3919)\tPrec@1 85.156 (86.563)\tPrec@5 100.000 (99.530)\t\n",
            "TRAINING - Epoch: [12][280/390]\tTime 0.069 (0.057)\tData 0.000 (0.004)\tLoss 0.5549 (0.3926)\tPrec@1 81.250 (86.541)\tPrec@5 99.219 (99.536)\t\n",
            "TRAINING - Epoch: [12][290/390]\tTime 0.054 (0.057)\tData 0.000 (0.004)\tLoss 0.3599 (0.3920)\tPrec@1 89.844 (86.558)\tPrec@5 100.000 (99.530)\t\n",
            "TRAINING - Epoch: [12][300/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.3105 (0.3905)\tPrec@1 90.625 (86.618)\tPrec@5 99.219 (99.538)\t\n",
            "TRAINING - Epoch: [12][310/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.5124 (0.3912)\tPrec@1 82.812 (86.583)\tPrec@5 100.000 (99.543)\t\n",
            "TRAINING - Epoch: [12][320/390]\tTime 0.055 (0.057)\tData 0.000 (0.004)\tLoss 0.5272 (0.3925)\tPrec@1 82.031 (86.546)\tPrec@5 98.438 (99.528)\t\n",
            "TRAINING - Epoch: [12][330/390]\tTime 0.055 (0.057)\tData 0.005 (0.004)\tLoss 0.3998 (0.3917)\tPrec@1 83.594 (86.570)\tPrec@5 99.219 (99.528)\t\n",
            "TRAINING - Epoch: [12][340/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.4079 (0.3914)\tPrec@1 85.156 (86.570)\tPrec@5 100.000 (99.526)\t\n",
            "TRAINING - Epoch: [12][350/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2681 (0.3918)\tPrec@1 89.844 (86.565)\tPrec@5 100.000 (99.526)\t\n",
            "TRAINING - Epoch: [12][360/390]\tTime 0.055 (0.056)\tData 0.008 (0.004)\tLoss 0.3028 (0.3912)\tPrec@1 89.844 (86.578)\tPrec@5 100.000 (99.528)\t\n",
            "TRAINING - Epoch: [12][370/390]\tTime 0.056 (0.056)\tData 0.006 (0.004)\tLoss 0.4092 (0.3907)\tPrec@1 82.812 (86.538)\tPrec@5 100.000 (99.539)\t\n",
            "TRAINING - Epoch: [12][380/390]\tTime 0.055 (0.056)\tData 0.009 (0.004)\tLoss 0.3517 (0.3913)\tPrec@1 85.156 (86.542)\tPrec@5 100.000 (99.537)\t\n",
            "TRAINING - Epoch: [12][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.4677 (0.3912)\tPrec@1 85.938 (86.544)\tPrec@5 100.000 (99.539)\t\n",
            "EVALUATING - Epoch: [12][0/79]\tTime 0.178 (0.178)\tData 0.155 (0.155)\tLoss 0.4458 (0.4458)\tPrec@1 86.719 (86.719)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [12][10/79]\tTime 0.015 (0.051)\tData 0.003 (0.025)\tLoss 0.4825 (0.4995)\tPrec@1 84.375 (83.452)\tPrec@5 99.219 (99.148)\t\n",
            "EVALUATING - Epoch: [12][20/79]\tTime 0.036 (0.042)\tData 0.000 (0.016)\tLoss 0.4687 (0.5249)\tPrec@1 84.375 (82.961)\tPrec@5 99.219 (99.144)\t\n",
            "EVALUATING - Epoch: [12][30/79]\tTime 0.026 (0.037)\tData 0.005 (0.012)\tLoss 0.4252 (0.5261)\tPrec@1 85.156 (83.014)\tPrec@5 100.000 (99.042)\t\n",
            "EVALUATING - Epoch: [12][40/79]\tTime 0.048 (0.036)\tData 0.016 (0.010)\tLoss 0.5749 (0.5214)\tPrec@1 81.250 (82.984)\tPrec@5 100.000 (99.181)\t\n",
            "EVALUATING - Epoch: [12][50/79]\tTime 0.024 (0.034)\tData 0.007 (0.009)\tLoss 0.5522 (0.5161)\tPrec@1 77.344 (83.073)\tPrec@5 100.000 (99.219)\t\n",
            "EVALUATING - Epoch: [12][60/79]\tTime 0.028 (0.034)\tData 0.013 (0.009)\tLoss 0.5772 (0.5246)\tPrec@1 83.594 (82.774)\tPrec@5 98.438 (99.232)\t\n",
            "EVALUATING - Epoch: [12][70/79]\tTime 0.037 (0.033)\tData 0.000 (0.008)\tLoss 0.3947 (0.5225)\tPrec@1 87.500 (82.680)\tPrec@5 100.000 (99.252)\t\n",
            "EVALUATING - Epoch: [12][78/79]\tTime 0.006 (0.030)\tData 0.000 (0.007)\tLoss 0.3130 (0.5196)\tPrec@1 87.500 (82.800)\tPrec@5 100.000 (99.270)\t\n",
            "\n",
            "Results - Epoch: 13\n",
            "Training Loss 0.3912 \tTraining Prec@1 86.544 \tTraining Prec@5 99.539 \tValidation Loss 0.5196 \tValidation Prec@1 82.800 \tValidation Prec@5 99.270 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 14\n",
            "\n",
            "TRAINING - Epoch: [13][0/390]\tTime 0.317 (0.317)\tData 0.174 (0.174)\tLoss 0.3734 (0.3734)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [13][10/390]\tTime 0.048 (0.086)\tData 0.000 (0.019)\tLoss 0.4312 (0.3746)\tPrec@1 83.594 (86.577)\tPrec@5 99.219 (99.645)\t\n",
            "TRAINING - Epoch: [13][20/390]\tTime 0.050 (0.070)\tData 0.000 (0.011)\tLoss 0.3054 (0.3719)\tPrec@1 88.281 (86.830)\tPrec@5 100.000 (99.665)\t\n",
            "TRAINING - Epoch: [13][30/390]\tTime 0.068 (0.066)\tData 0.007 (0.009)\tLoss 0.3209 (0.3691)\tPrec@1 87.500 (86.946)\tPrec@5 98.438 (99.647)\t\n",
            "TRAINING - Epoch: [13][40/390]\tTime 0.066 (0.063)\tData 0.000 (0.007)\tLoss 0.3491 (0.3577)\tPrec@1 89.062 (87.481)\tPrec@5 99.219 (99.638)\t\n",
            "TRAINING - Epoch: [13][50/390]\tTime 0.065 (0.061)\tData 0.010 (0.007)\tLoss 0.3013 (0.3531)\tPrec@1 90.625 (87.699)\tPrec@5 100.000 (99.663)\t\n",
            "TRAINING - Epoch: [13][60/390]\tTime 0.048 (0.060)\tData 0.000 (0.006)\tLoss 0.2501 (0.3544)\tPrec@1 91.406 (87.705)\tPrec@5 100.000 (99.667)\t\n",
            "TRAINING - Epoch: [13][70/390]\tTime 0.074 (0.059)\tData 0.007 (0.006)\tLoss 0.3368 (0.3558)\tPrec@1 89.844 (87.742)\tPrec@5 98.438 (99.637)\t\n",
            "TRAINING - Epoch: [13][80/390]\tTime 0.057 (0.059)\tData 0.008 (0.005)\tLoss 0.3663 (0.3564)\tPrec@1 85.938 (87.674)\tPrec@5 99.219 (99.653)\t\n",
            "TRAINING - Epoch: [13][90/390]\tTime 0.066 (0.058)\tData 0.006 (0.005)\tLoss 0.3371 (0.3592)\tPrec@1 89.062 (87.534)\tPrec@5 100.000 (99.639)\t\n",
            "TRAINING - Epoch: [13][100/390]\tTime 0.061 (0.058)\tData 0.007 (0.005)\tLoss 0.4042 (0.3633)\tPrec@1 84.375 (87.345)\tPrec@5 100.000 (99.644)\t\n",
            "TRAINING - Epoch: [13][110/390]\tTime 0.067 (0.058)\tData 0.000 (0.005)\tLoss 0.3990 (0.3650)\tPrec@1 86.719 (87.289)\tPrec@5 100.000 (99.641)\t\n",
            "TRAINING - Epoch: [13][120/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.4722 (0.3692)\tPrec@1 85.156 (87.203)\tPrec@5 100.000 (99.626)\t\n",
            "TRAINING - Epoch: [13][130/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.4312 (0.3709)\tPrec@1 79.688 (87.077)\tPrec@5 100.000 (99.630)\t\n",
            "TRAINING - Epoch: [13][140/390]\tTime 0.059 (0.057)\tData 0.010 (0.004)\tLoss 0.2461 (0.3709)\tPrec@1 92.188 (87.051)\tPrec@5 100.000 (99.645)\t\n",
            "TRAINING - Epoch: [13][150/390]\tTime 0.063 (0.057)\tData 0.007 (0.004)\tLoss 0.3046 (0.3695)\tPrec@1 90.625 (87.153)\tPrec@5 100.000 (99.633)\t\n",
            "TRAINING - Epoch: [13][160/390]\tTime 0.057 (0.057)\tData 0.011 (0.004)\tLoss 0.3106 (0.3707)\tPrec@1 92.188 (87.151)\tPrec@5 100.000 (99.617)\t\n",
            "TRAINING - Epoch: [13][170/390]\tTime 0.060 (0.057)\tData 0.000 (0.004)\tLoss 0.3451 (0.3713)\tPrec@1 88.281 (87.139)\tPrec@5 100.000 (99.598)\t\n",
            "TRAINING - Epoch: [13][180/390]\tTime 0.055 (0.057)\tData 0.006 (0.004)\tLoss 0.4956 (0.3716)\tPrec@1 81.250 (87.090)\tPrec@5 99.219 (99.599)\t\n",
            "TRAINING - Epoch: [13][190/390]\tTime 0.068 (0.057)\tData 0.003 (0.004)\tLoss 0.3594 (0.3735)\tPrec@1 85.938 (87.030)\tPrec@5 99.219 (99.587)\t\n",
            "TRAINING - Epoch: [13][200/390]\tTime 0.050 (0.056)\tData 0.000 (0.004)\tLoss 0.3769 (0.3725)\tPrec@1 86.719 (87.049)\tPrec@5 100.000 (99.596)\t\n",
            "TRAINING - Epoch: [13][210/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.4577 (0.3722)\tPrec@1 86.719 (87.089)\tPrec@5 99.219 (99.589)\t\n",
            "TRAINING - Epoch: [13][220/390]\tTime 0.055 (0.056)\tData 0.000 (0.004)\tLoss 0.5766 (0.3722)\tPrec@1 82.031 (87.101)\tPrec@5 98.438 (99.586)\t\n",
            "TRAINING - Epoch: [13][230/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.3403 (0.3711)\tPrec@1 89.062 (87.111)\tPrec@5 99.219 (99.598)\t\n",
            "TRAINING - Epoch: [13][240/390]\tTime 0.057 (0.056)\tData 0.010 (0.004)\tLoss 0.4227 (0.3740)\tPrec@1 88.281 (87.040)\tPrec@5 100.000 (99.582)\t\n",
            "TRAINING - Epoch: [13][250/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.4238 (0.3751)\tPrec@1 83.594 (87.021)\tPrec@5 100.000 (99.577)\t\n",
            "TRAINING - Epoch: [13][260/390]\tTime 0.068 (0.056)\tData 0.007 (0.004)\tLoss 0.3233 (0.3752)\tPrec@1 87.500 (87.027)\tPrec@5 99.219 (99.566)\t\n",
            "TRAINING - Epoch: [13][270/390]\tTime 0.061 (0.056)\tData 0.006 (0.004)\tLoss 0.3529 (0.3755)\tPrec@1 88.281 (87.024)\tPrec@5 99.219 (99.556)\t\n",
            "TRAINING - Epoch: [13][280/390]\tTime 0.070 (0.056)\tData 0.009 (0.004)\tLoss 0.5014 (0.3768)\tPrec@1 81.250 (86.994)\tPrec@5 98.438 (99.544)\t\n",
            "TRAINING - Epoch: [13][290/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.3867 (0.3766)\tPrec@1 85.156 (86.966)\tPrec@5 100.000 (99.538)\t\n",
            "TRAINING - Epoch: [13][300/390]\tTime 0.060 (0.056)\tData 0.000 (0.004)\tLoss 0.2444 (0.3753)\tPrec@1 90.625 (87.030)\tPrec@5 100.000 (99.535)\t\n",
            "TRAINING - Epoch: [13][310/390]\tTime 0.048 (0.056)\tData 0.002 (0.004)\tLoss 0.3097 (0.3753)\tPrec@1 89.844 (87.023)\tPrec@5 99.219 (99.538)\t\n",
            "TRAINING - Epoch: [13][320/390]\tTime 0.075 (0.056)\tData 0.000 (0.004)\tLoss 0.3465 (0.3750)\tPrec@1 85.938 (87.030)\tPrec@5 100.000 (99.538)\t\n",
            "TRAINING - Epoch: [13][330/390]\tTime 0.055 (0.056)\tData 0.008 (0.004)\tLoss 0.3908 (0.3756)\tPrec@1 86.719 (87.016)\tPrec@5 98.438 (99.533)\t\n",
            "TRAINING - Epoch: [13][340/390]\tTime 0.050 (0.056)\tData 0.002 (0.004)\tLoss 0.2615 (0.3753)\tPrec@1 90.625 (87.012)\tPrec@5 100.000 (99.537)\t\n",
            "TRAINING - Epoch: [13][350/390]\tTime 0.065 (0.056)\tData 0.010 (0.004)\tLoss 0.4499 (0.3753)\tPrec@1 86.719 (86.986)\tPrec@5 99.219 (99.524)\t\n",
            "TRAINING - Epoch: [13][360/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.3260 (0.3752)\tPrec@1 88.281 (86.978)\tPrec@5 100.000 (99.524)\t\n",
            "TRAINING - Epoch: [13][370/390]\tTime 0.061 (0.056)\tData 0.000 (0.004)\tLoss 0.2989 (0.3761)\tPrec@1 90.625 (86.950)\tPrec@5 100.000 (99.524)\t\n",
            "TRAINING - Epoch: [13][380/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.4082 (0.3765)\tPrec@1 84.375 (86.944)\tPrec@5 99.219 (99.524)\t\n",
            "TRAINING - Epoch: [13][389/390]\tTime 0.040 (0.055)\tData 0.000 (0.004)\tLoss 0.2936 (0.3756)\tPrec@1 89.062 (86.971)\tPrec@5 99.219 (99.527)\t\n",
            "EVALUATING - Epoch: [13][0/79]\tTime 0.297 (0.297)\tData 0.271 (0.271)\tLoss 0.3914 (0.3914)\tPrec@1 85.156 (85.156)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [13][10/79]\tTime 0.039 (0.058)\tData 0.007 (0.030)\tLoss 0.4634 (0.5144)\tPrec@1 84.375 (83.381)\tPrec@5 98.438 (99.361)\t\n",
            "EVALUATING - Epoch: [13][20/79]\tTime 0.029 (0.044)\tData 0.005 (0.018)\tLoss 0.3792 (0.5239)\tPrec@1 87.500 (83.110)\tPrec@5 99.219 (99.107)\t\n",
            "EVALUATING - Epoch: [13][30/79]\tTime 0.036 (0.040)\tData 0.000 (0.013)\tLoss 0.4254 (0.5225)\tPrec@1 88.281 (83.543)\tPrec@5 100.000 (98.942)\t\n",
            "EVALUATING - Epoch: [13][40/79]\tTime 0.030 (0.038)\tData 0.006 (0.012)\tLoss 0.6406 (0.5220)\tPrec@1 82.031 (83.613)\tPrec@5 99.219 (99.028)\t\n",
            "EVALUATING - Epoch: [13][50/79]\tTime 0.041 (0.036)\tData 0.005 (0.010)\tLoss 0.5141 (0.5202)\tPrec@1 80.469 (83.563)\tPrec@5 100.000 (99.096)\t\n",
            "EVALUATING - Epoch: [13][60/79]\tTime 0.042 (0.035)\tData 0.007 (0.009)\tLoss 0.5100 (0.5141)\tPrec@1 81.250 (83.760)\tPrec@5 99.219 (99.129)\t\n",
            "EVALUATING - Epoch: [13][70/79]\tTime 0.021 (0.034)\tData 0.007 (0.009)\tLoss 0.3782 (0.5137)\tPrec@1 90.625 (83.671)\tPrec@5 99.219 (99.186)\t\n",
            "EVALUATING - Epoch: [13][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.008)\tLoss 0.6054 (0.5092)\tPrec@1 87.500 (83.750)\tPrec@5 100.000 (99.210)\t\n",
            "\n",
            "Results - Epoch: 14\n",
            "Training Loss 0.3756 \tTraining Prec@1 86.971 \tTraining Prec@5 99.527 \tValidation Loss 0.5092 \tValidation Prec@1 83.750 \tValidation Prec@5 99.210 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 15\n",
            "\n",
            "TRAINING - Epoch: [14][0/390]\tTime 0.345 (0.345)\tData 0.213 (0.213)\tLoss 0.4179 (0.4179)\tPrec@1 85.938 (85.938)\tPrec@5 98.438 (98.438)\t\n",
            "TRAINING - Epoch: [14][10/390]\tTime 0.054 (0.088)\tData 0.000 (0.021)\tLoss 0.3216 (0.3673)\tPrec@1 87.500 (87.074)\tPrec@5 100.000 (99.432)\t\n",
            "TRAINING - Epoch: [14][20/390]\tTime 0.047 (0.073)\tData 0.000 (0.013)\tLoss 0.2936 (0.3607)\tPrec@1 92.188 (87.537)\tPrec@5 99.219 (99.516)\t\n",
            "TRAINING - Epoch: [14][30/390]\tTime 0.067 (0.067)\tData 0.016 (0.011)\tLoss 0.3389 (0.3472)\tPrec@1 88.281 (87.853)\tPrec@5 99.219 (99.546)\t\n",
            "TRAINING - Epoch: [14][40/390]\tTime 0.056 (0.065)\tData 0.007 (0.009)\tLoss 0.3408 (0.3467)\tPrec@1 87.500 (88.091)\tPrec@5 99.219 (99.562)\t\n",
            "TRAINING - Epoch: [14][50/390]\tTime 0.048 (0.063)\tData 0.000 (0.008)\tLoss 0.4549 (0.3491)\tPrec@1 83.594 (87.960)\tPrec@5 98.438 (99.571)\t\n",
            "TRAINING - Epoch: [14][60/390]\tTime 0.050 (0.061)\tData 0.000 (0.007)\tLoss 0.4081 (0.3514)\tPrec@1 84.375 (87.923)\tPrec@5 100.000 (99.526)\t\n",
            "TRAINING - Epoch: [14][70/390]\tTime 0.054 (0.061)\tData 0.000 (0.007)\tLoss 0.2999 (0.3494)\tPrec@1 88.281 (87.962)\tPrec@5 100.000 (99.549)\t\n",
            "TRAINING - Epoch: [14][80/390]\tTime 0.063 (0.060)\tData 0.007 (0.006)\tLoss 0.4861 (0.3560)\tPrec@1 81.250 (87.645)\tPrec@5 99.219 (99.556)\t\n",
            "TRAINING - Epoch: [14][90/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.5011 (0.3569)\tPrec@1 83.594 (87.706)\tPrec@5 99.219 (99.571)\t\n",
            "TRAINING - Epoch: [14][100/390]\tTime 0.068 (0.059)\tData 0.006 (0.006)\tLoss 0.3960 (0.3586)\tPrec@1 85.938 (87.593)\tPrec@5 100.000 (99.582)\t\n",
            "TRAINING - Epoch: [14][110/390]\tTime 0.058 (0.059)\tData 0.007 (0.006)\tLoss 0.3189 (0.3604)\tPrec@1 91.406 (87.528)\tPrec@5 100.000 (99.571)\t\n",
            "TRAINING - Epoch: [14][120/390]\tTime 0.061 (0.059)\tData 0.000 (0.005)\tLoss 0.4170 (0.3603)\tPrec@1 84.375 (87.494)\tPrec@5 100.000 (99.593)\t\n",
            "TRAINING - Epoch: [14][130/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2810 (0.3598)\tPrec@1 89.844 (87.500)\tPrec@5 100.000 (99.583)\t\n",
            "TRAINING - Epoch: [14][140/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.3190 (0.3590)\tPrec@1 88.281 (87.566)\tPrec@5 99.219 (99.596)\t\n",
            "TRAINING - Epoch: [14][150/390]\tTime 0.064 (0.058)\tData 0.009 (0.005)\tLoss 0.4464 (0.3604)\tPrec@1 85.938 (87.598)\tPrec@5 98.438 (99.581)\t\n",
            "TRAINING - Epoch: [14][160/390]\tTime 0.054 (0.058)\tData 0.004 (0.005)\tLoss 0.4501 (0.3616)\tPrec@1 82.812 (87.534)\tPrec@5 99.219 (99.578)\t\n",
            "TRAINING - Epoch: [14][170/390]\tTime 0.054 (0.058)\tData 0.007 (0.005)\tLoss 0.2374 (0.3614)\tPrec@1 91.406 (87.527)\tPrec@5 100.000 (99.571)\t\n",
            "TRAINING - Epoch: [14][180/390]\tTime 0.046 (0.058)\tData 0.000 (0.005)\tLoss 0.3556 (0.3604)\tPrec@1 88.281 (87.552)\tPrec@5 100.000 (99.577)\t\n",
            "TRAINING - Epoch: [14][190/390]\tTime 0.061 (0.057)\tData 0.007 (0.005)\tLoss 0.2681 (0.3602)\tPrec@1 89.844 (87.565)\tPrec@5 100.000 (99.579)\t\n",
            "TRAINING - Epoch: [14][200/390]\tTime 0.064 (0.057)\tData 0.007 (0.005)\tLoss 0.2969 (0.3593)\tPrec@1 91.406 (87.624)\tPrec@5 99.219 (99.580)\t\n",
            "TRAINING - Epoch: [14][210/390]\tTime 0.054 (0.057)\tData 0.008 (0.005)\tLoss 0.3900 (0.3602)\tPrec@1 87.500 (87.637)\tPrec@5 99.219 (99.578)\t\n",
            "TRAINING - Epoch: [14][220/390]\tTime 0.061 (0.057)\tData 0.000 (0.005)\tLoss 0.3333 (0.3598)\tPrec@1 88.281 (87.627)\tPrec@5 100.000 (99.579)\t\n",
            "TRAINING - Epoch: [14][230/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.4113 (0.3591)\tPrec@1 85.156 (87.632)\tPrec@5 98.438 (99.574)\t\n",
            "TRAINING - Epoch: [14][240/390]\tTime 0.070 (0.057)\tData 0.007 (0.005)\tLoss 0.3949 (0.3600)\tPrec@1 82.812 (87.597)\tPrec@5 100.000 (99.582)\t\n",
            "TRAINING - Epoch: [14][250/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.3771 (0.3612)\tPrec@1 87.500 (87.519)\tPrec@5 99.219 (99.580)\t\n",
            "TRAINING - Epoch: [14][260/390]\tTime 0.058 (0.057)\tData 0.007 (0.005)\tLoss 0.3550 (0.3627)\tPrec@1 85.156 (87.476)\tPrec@5 100.000 (99.581)\t\n",
            "TRAINING - Epoch: [14][270/390]\tTime 0.053 (0.057)\tData 0.005 (0.005)\tLoss 0.3048 (0.3625)\tPrec@1 87.500 (87.477)\tPrec@5 100.000 (99.573)\t\n",
            "TRAINING - Epoch: [14][280/390]\tTime 0.051 (0.057)\tData 0.000 (0.005)\tLoss 0.5107 (0.3632)\tPrec@1 82.031 (87.433)\tPrec@5 99.219 (99.575)\t\n",
            "TRAINING - Epoch: [14][290/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2864 (0.3625)\tPrec@1 89.062 (87.460)\tPrec@5 100.000 (99.581)\t\n",
            "TRAINING - Epoch: [14][300/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.3433 (0.3617)\tPrec@1 88.281 (87.469)\tPrec@5 99.219 (99.582)\t\n",
            "TRAINING - Epoch: [14][310/390]\tTime 0.053 (0.057)\tData 0.005 (0.004)\tLoss 0.4850 (0.3624)\tPrec@1 82.812 (87.467)\tPrec@5 99.219 (99.583)\t\n",
            "TRAINING - Epoch: [14][320/390]\tTime 0.055 (0.056)\tData 0.008 (0.004)\tLoss 0.2832 (0.3622)\tPrec@1 89.844 (87.461)\tPrec@5 99.219 (99.581)\t\n",
            "TRAINING - Epoch: [14][330/390]\tTime 0.057 (0.056)\tData 0.000 (0.004)\tLoss 0.2792 (0.3621)\tPrec@1 91.406 (87.495)\tPrec@5 100.000 (99.580)\t\n",
            "TRAINING - Epoch: [14][340/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.5160 (0.3633)\tPrec@1 85.156 (87.440)\tPrec@5 97.656 (99.567)\t\n",
            "TRAINING - Epoch: [14][350/390]\tTime 0.051 (0.056)\tData 0.000 (0.004)\tLoss 0.2235 (0.3631)\tPrec@1 93.750 (87.469)\tPrec@5 100.000 (99.562)\t\n",
            "TRAINING - Epoch: [14][360/390]\tTime 0.071 (0.056)\tData 0.007 (0.004)\tLoss 0.3199 (0.3624)\tPrec@1 91.406 (87.485)\tPrec@5 100.000 (99.567)\t\n",
            "TRAINING - Epoch: [14][370/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.2506 (0.3619)\tPrec@1 89.844 (87.508)\tPrec@5 99.219 (99.575)\t\n",
            "TRAINING - Epoch: [14][380/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.3454 (0.3622)\tPrec@1 87.500 (87.484)\tPrec@5 98.438 (99.571)\t\n",
            "TRAINING - Epoch: [14][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.3055 (0.3614)\tPrec@1 88.281 (87.498)\tPrec@5 100.000 (99.573)\t\n",
            "EVALUATING - Epoch: [14][0/79]\tTime 0.261 (0.261)\tData 0.232 (0.232)\tLoss 0.3927 (0.3927)\tPrec@1 85.938 (85.938)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [14][10/79]\tTime 0.024 (0.052)\tData 0.005 (0.025)\tLoss 0.3554 (0.4602)\tPrec@1 86.719 (84.375)\tPrec@5 100.000 (99.290)\t\n",
            "EVALUATING - Epoch: [14][20/79]\tTime 0.038 (0.041)\tData 0.007 (0.016)\tLoss 0.3971 (0.4946)\tPrec@1 87.500 (83.780)\tPrec@5 100.000 (99.107)\t\n",
            "EVALUATING - Epoch: [14][30/79]\tTime 0.042 (0.038)\tData 0.007 (0.013)\tLoss 0.3422 (0.4905)\tPrec@1 89.062 (84.652)\tPrec@5 100.000 (99.068)\t\n",
            "EVALUATING - Epoch: [14][40/79]\tTime 0.024 (0.036)\tData 0.001 (0.011)\tLoss 0.5341 (0.4886)\tPrec@1 80.469 (84.604)\tPrec@5 99.219 (99.123)\t\n",
            "EVALUATING - Epoch: [14][50/79]\tTime 0.029 (0.034)\tData 0.002 (0.009)\tLoss 0.5193 (0.4822)\tPrec@1 83.594 (84.651)\tPrec@5 98.438 (99.173)\t\n",
            "EVALUATING - Epoch: [14][60/79]\tTime 0.033 (0.034)\tData 0.007 (0.008)\tLoss 0.4835 (0.4882)\tPrec@1 84.375 (84.516)\tPrec@5 99.219 (99.180)\t\n",
            "EVALUATING - Epoch: [14][70/79]\tTime 0.040 (0.032)\tData 0.004 (0.008)\tLoss 0.4065 (0.4874)\tPrec@1 87.500 (84.474)\tPrec@5 100.000 (99.219)\t\n",
            "EVALUATING - Epoch: [14][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.5409 (0.4821)\tPrec@1 87.500 (84.510)\tPrec@5 100.000 (99.250)\t\n",
            "\n",
            "Results - Epoch: 15\n",
            "Training Loss 0.3614 \tTraining Prec@1 87.498 \tTraining Prec@5 99.573 \tValidation Loss 0.4821 \tValidation Prec@1 84.510 \tValidation Prec@5 99.250 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 16\n",
            "\n",
            "TRAINING - Epoch: [15][0/390]\tTime 0.297 (0.297)\tData 0.177 (0.177)\tLoss 0.4048 (0.4048)\tPrec@1 83.594 (83.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [15][10/390]\tTime 0.050 (0.087)\tData 0.000 (0.021)\tLoss 0.3704 (0.3151)\tPrec@1 85.938 (88.139)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [15][20/390]\tTime 0.055 (0.071)\tData 0.006 (0.013)\tLoss 0.1837 (0.3265)\tPrec@1 93.750 (88.504)\tPrec@5 99.219 (99.628)\t\n",
            "TRAINING - Epoch: [15][30/390]\tTime 0.048 (0.066)\tData 0.000 (0.010)\tLoss 0.2919 (0.3211)\tPrec@1 91.406 (88.911)\tPrec@5 100.000 (99.622)\t\n",
            "TRAINING - Epoch: [15][40/390]\tTime 0.056 (0.064)\tData 0.006 (0.008)\tLoss 0.3971 (0.3213)\tPrec@1 82.812 (88.758)\tPrec@5 99.219 (99.657)\t\n",
            "TRAINING - Epoch: [15][50/390]\tTime 0.049 (0.062)\tData 0.002 (0.007)\tLoss 0.3219 (0.3228)\tPrec@1 89.844 (88.710)\tPrec@5 100.000 (99.678)\t\n",
            "TRAINING - Epoch: [15][60/390]\tTime 0.056 (0.061)\tData 0.007 (0.007)\tLoss 0.3560 (0.3185)\tPrec@1 86.719 (88.947)\tPrec@5 100.000 (99.667)\t\n",
            "TRAINING - Epoch: [15][70/390]\tTime 0.063 (0.060)\tData 0.006 (0.006)\tLoss 0.3783 (0.3224)\tPrec@1 85.156 (88.864)\tPrec@5 100.000 (99.659)\t\n",
            "TRAINING - Epoch: [15][80/390]\tTime 0.052 (0.059)\tData 0.000 (0.006)\tLoss 0.3322 (0.3281)\tPrec@1 89.062 (88.696)\tPrec@5 100.000 (99.672)\t\n",
            "TRAINING - Epoch: [15][90/390]\tTime 0.067 (0.059)\tData 0.007 (0.006)\tLoss 0.2895 (0.3250)\tPrec@1 89.844 (88.822)\tPrec@5 100.000 (99.674)\t\n",
            "TRAINING - Epoch: [15][100/390]\tTime 0.058 (0.059)\tData 0.011 (0.006)\tLoss 0.3738 (0.3251)\tPrec@1 89.062 (88.830)\tPrec@5 100.000 (99.691)\t\n",
            "TRAINING - Epoch: [15][110/390]\tTime 0.050 (0.059)\tData 0.000 (0.005)\tLoss 0.3200 (0.3253)\tPrec@1 90.625 (88.816)\tPrec@5 99.219 (99.683)\t\n",
            "TRAINING - Epoch: [15][120/390]\tTime 0.056 (0.058)\tData 0.007 (0.005)\tLoss 0.3307 (0.3245)\tPrec@1 91.406 (88.817)\tPrec@5 100.000 (99.697)\t\n",
            "TRAINING - Epoch: [15][130/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.4933 (0.3308)\tPrec@1 82.812 (88.615)\tPrec@5 99.219 (99.654)\t\n",
            "TRAINING - Epoch: [15][140/390]\tTime 0.061 (0.059)\tData 0.007 (0.005)\tLoss 0.2533 (0.3332)\tPrec@1 89.844 (88.531)\tPrec@5 100.000 (99.662)\t\n",
            "TRAINING - Epoch: [15][150/390]\tTime 0.059 (0.059)\tData 0.005 (0.005)\tLoss 0.4144 (0.3364)\tPrec@1 84.375 (88.385)\tPrec@5 100.000 (99.648)\t\n",
            "TRAINING - Epoch: [15][160/390]\tTime 0.062 (0.058)\tData 0.000 (0.005)\tLoss 0.4795 (0.3402)\tPrec@1 84.375 (88.262)\tPrec@5 100.000 (99.655)\t\n",
            "TRAINING - Epoch: [15][170/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.3448 (0.3425)\tPrec@1 88.281 (88.194)\tPrec@5 98.438 (99.653)\t\n",
            "TRAINING - Epoch: [15][180/390]\tTime 0.048 (0.058)\tData 0.001 (0.005)\tLoss 0.4601 (0.3429)\tPrec@1 85.156 (88.182)\tPrec@5 100.000 (99.637)\t\n",
            "TRAINING - Epoch: [15][190/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.2987 (0.3430)\tPrec@1 89.844 (88.179)\tPrec@5 100.000 (99.644)\t\n",
            "TRAINING - Epoch: [15][200/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.2775 (0.3429)\tPrec@1 90.625 (88.196)\tPrec@5 100.000 (99.646)\t\n",
            "TRAINING - Epoch: [15][210/390]\tTime 0.067 (0.057)\tData 0.006 (0.005)\tLoss 0.5102 (0.3436)\tPrec@1 85.938 (88.170)\tPrec@5 99.219 (99.641)\t\n",
            "TRAINING - Epoch: [15][220/390]\tTime 0.054 (0.057)\tData 0.006 (0.004)\tLoss 0.2580 (0.3439)\tPrec@1 92.969 (88.203)\tPrec@5 100.000 (99.646)\t\n",
            "TRAINING - Epoch: [15][230/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.2653 (0.3439)\tPrec@1 91.406 (88.210)\tPrec@5 99.219 (99.652)\t\n",
            "TRAINING - Epoch: [15][240/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.3079 (0.3446)\tPrec@1 91.406 (88.207)\tPrec@5 100.000 (99.647)\t\n",
            "TRAINING - Epoch: [15][250/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.4993 (0.3476)\tPrec@1 83.594 (88.094)\tPrec@5 99.219 (99.636)\t\n",
            "TRAINING - Epoch: [15][260/390]\tTime 0.051 (0.057)\tData 0.003 (0.004)\tLoss 0.2527 (0.3460)\tPrec@1 92.188 (88.159)\tPrec@5 100.000 (99.635)\t\n",
            "TRAINING - Epoch: [15][270/390]\tTime 0.058 (0.057)\tData 0.012 (0.004)\tLoss 0.4891 (0.3473)\tPrec@1 78.906 (88.091)\tPrec@5 99.219 (99.634)\t\n",
            "TRAINING - Epoch: [15][280/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.4706 (0.3486)\tPrec@1 84.375 (88.059)\tPrec@5 100.000 (99.622)\t\n",
            "TRAINING - Epoch: [15][290/390]\tTime 0.065 (0.057)\tData 0.007 (0.004)\tLoss 0.3087 (0.3475)\tPrec@1 89.844 (88.085)\tPrec@5 100.000 (99.624)\t\n",
            "TRAINING - Epoch: [15][300/390]\tTime 0.056 (0.057)\tData 0.000 (0.004)\tLoss 0.4162 (0.3485)\tPrec@1 83.594 (88.024)\tPrec@5 100.000 (99.621)\t\n",
            "TRAINING - Epoch: [15][310/390]\tTime 0.061 (0.057)\tData 0.001 (0.004)\tLoss 0.5219 (0.3479)\tPrec@1 85.156 (88.038)\tPrec@5 99.219 (99.618)\t\n",
            "TRAINING - Epoch: [15][320/390]\tTime 0.051 (0.057)\tData 0.003 (0.004)\tLoss 0.3993 (0.3490)\tPrec@1 85.156 (87.999)\tPrec@5 100.000 (99.628)\t\n",
            "TRAINING - Epoch: [15][330/390]\tTime 0.056 (0.057)\tData 0.000 (0.004)\tLoss 0.3206 (0.3482)\tPrec@1 89.062 (88.019)\tPrec@5 100.000 (99.632)\t\n",
            "TRAINING - Epoch: [15][340/390]\tTime 0.061 (0.057)\tData 0.008 (0.004)\tLoss 0.4105 (0.3481)\tPrec@1 86.719 (88.043)\tPrec@5 99.219 (99.633)\t\n",
            "TRAINING - Epoch: [15][350/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.3519 (0.3478)\tPrec@1 88.281 (88.034)\tPrec@5 100.000 (99.642)\t\n",
            "TRAINING - Epoch: [15][360/390]\tTime 0.068 (0.057)\tData 0.000 (0.004)\tLoss 0.4689 (0.3479)\tPrec@1 84.375 (88.041)\tPrec@5 99.219 (99.636)\t\n",
            "TRAINING - Epoch: [15][370/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.3408 (0.3482)\tPrec@1 88.281 (88.007)\tPrec@5 99.219 (99.631)\t\n",
            "TRAINING - Epoch: [15][380/390]\tTime 0.056 (0.057)\tData 0.000 (0.004)\tLoss 0.2750 (0.3474)\tPrec@1 92.188 (88.039)\tPrec@5 100.000 (99.641)\t\n",
            "TRAINING - Epoch: [15][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.3951 (0.3490)\tPrec@1 85.938 (87.959)\tPrec@5 98.438 (99.633)\t\n",
            "EVALUATING - Epoch: [15][0/79]\tTime 0.179 (0.179)\tData 0.149 (0.149)\tLoss 0.3821 (0.3821)\tPrec@1 86.719 (86.719)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [15][10/79]\tTime 0.028 (0.051)\tData 0.002 (0.022)\tLoss 0.5561 (0.5413)\tPrec@1 81.250 (82.670)\tPrec@5 99.219 (99.432)\t\n",
            "EVALUATING - Epoch: [15][20/79]\tTime 0.026 (0.043)\tData 0.006 (0.014)\tLoss 0.4183 (0.5679)\tPrec@1 89.844 (82.738)\tPrec@5 100.000 (99.368)\t\n",
            "EVALUATING - Epoch: [15][30/79]\tTime 0.019 (0.038)\tData 0.000 (0.012)\tLoss 0.4166 (0.5683)\tPrec@1 87.500 (82.964)\tPrec@5 100.000 (99.194)\t\n",
            "EVALUATING - Epoch: [15][40/79]\tTime 0.030 (0.036)\tData 0.007 (0.010)\tLoss 0.5782 (0.5710)\tPrec@1 82.812 (82.908)\tPrec@5 99.219 (99.181)\t\n",
            "EVALUATING - Epoch: [15][50/79]\tTime 0.017 (0.034)\tData 0.000 (0.009)\tLoss 0.6745 (0.5676)\tPrec@1 79.688 (83.012)\tPrec@5 100.000 (99.219)\t\n",
            "EVALUATING - Epoch: [15][60/79]\tTime 0.021 (0.033)\tData 0.000 (0.008)\tLoss 0.6940 (0.5600)\tPrec@1 80.469 (82.992)\tPrec@5 98.438 (99.270)\t\n",
            "EVALUATING - Epoch: [15][70/79]\tTime 0.025 (0.033)\tData 0.001 (0.007)\tLoss 0.4867 (0.5599)\tPrec@1 82.031 (82.812)\tPrec@5 100.000 (99.274)\t\n",
            "EVALUATING - Epoch: [15][78/79]\tTime 0.005 (0.030)\tData 0.000 (0.007)\tLoss 0.4750 (0.5584)\tPrec@1 75.000 (82.720)\tPrec@5 100.000 (99.330)\t\n",
            "\n",
            "Results - Epoch: 16\n",
            "Training Loss 0.3490 \tTraining Prec@1 87.959 \tTraining Prec@5 99.633 \tValidation Loss 0.5584 \tValidation Prec@1 82.720 \tValidation Prec@5 99.330 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 17\n",
            "\n",
            "TRAINING - Epoch: [16][0/390]\tTime 0.350 (0.350)\tData 0.250 (0.250)\tLoss 0.3469 (0.3469)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [16][10/390]\tTime 0.053 (0.085)\tData 0.000 (0.027)\tLoss 0.3592 (0.3208)\tPrec@1 86.719 (88.849)\tPrec@5 100.000 (99.503)\t\n",
            "TRAINING - Epoch: [16][20/390]\tTime 0.046 (0.071)\tData 0.000 (0.016)\tLoss 0.3750 (0.3158)\tPrec@1 87.500 (88.914)\tPrec@5 100.000 (99.628)\t\n",
            "TRAINING - Epoch: [16][30/390]\tTime 0.073 (0.066)\tData 0.010 (0.012)\tLoss 0.4244 (0.3155)\tPrec@1 85.156 (88.962)\tPrec@5 98.438 (99.622)\t\n",
            "TRAINING - Epoch: [16][40/390]\tTime 0.049 (0.063)\tData 0.000 (0.010)\tLoss 0.3792 (0.3140)\tPrec@1 86.719 (89.082)\tPrec@5 100.000 (99.657)\t\n",
            "TRAINING - Epoch: [16][50/390]\tTime 0.057 (0.062)\tData 0.000 (0.008)\tLoss 0.3394 (0.3192)\tPrec@1 88.281 (88.863)\tPrec@5 100.000 (99.663)\t\n",
            "TRAINING - Epoch: [16][60/390]\tTime 0.065 (0.061)\tData 0.000 (0.007)\tLoss 0.3137 (0.3250)\tPrec@1 86.719 (88.691)\tPrec@5 99.219 (99.654)\t\n",
            "TRAINING - Epoch: [16][70/390]\tTime 0.060 (0.060)\tData 0.000 (0.007)\tLoss 0.3497 (0.3274)\tPrec@1 83.594 (88.578)\tPrec@5 100.000 (99.659)\t\n",
            "TRAINING - Epoch: [16][80/390]\tTime 0.049 (0.059)\tData 0.000 (0.006)\tLoss 0.4063 (0.3303)\tPrec@1 81.250 (88.532)\tPrec@5 100.000 (99.662)\t\n",
            "TRAINING - Epoch: [16][90/390]\tTime 0.053 (0.059)\tData 0.000 (0.006)\tLoss 0.4306 (0.3319)\tPrec@1 86.719 (88.539)\tPrec@5 99.219 (99.639)\t\n",
            "TRAINING - Epoch: [16][100/390]\tTime 0.056 (0.058)\tData 0.000 (0.006)\tLoss 0.3838 (0.3343)\tPrec@1 86.719 (88.451)\tPrec@5 100.000 (99.629)\t\n",
            "TRAINING - Epoch: [16][110/390]\tTime 0.047 (0.058)\tData 0.000 (0.006)\tLoss 0.2520 (0.3309)\tPrec@1 91.406 (88.528)\tPrec@5 99.219 (99.634)\t\n",
            "TRAINING - Epoch: [16][120/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.3111 (0.3319)\tPrec@1 89.062 (88.481)\tPrec@5 100.000 (99.651)\t\n",
            "TRAINING - Epoch: [16][130/390]\tTime 0.059 (0.058)\tData 0.007 (0.005)\tLoss 0.2887 (0.3316)\tPrec@1 89.062 (88.526)\tPrec@5 100.000 (99.666)\t\n",
            "TRAINING - Epoch: [16][140/390]\tTime 0.056 (0.058)\tData 0.007 (0.005)\tLoss 0.3100 (0.3299)\tPrec@1 90.625 (88.630)\tPrec@5 99.219 (99.645)\t\n",
            "TRAINING - Epoch: [16][150/390]\tTime 0.052 (0.057)\tData 0.000 (0.005)\tLoss 0.3177 (0.3292)\tPrec@1 86.719 (88.638)\tPrec@5 100.000 (99.648)\t\n",
            "TRAINING - Epoch: [16][160/390]\tTime 0.054 (0.057)\tData 0.006 (0.005)\tLoss 0.5423 (0.3312)\tPrec@1 80.469 (88.558)\tPrec@5 100.000 (99.641)\t\n",
            "TRAINING - Epoch: [16][170/390]\tTime 0.052 (0.057)\tData 0.000 (0.005)\tLoss 0.3821 (0.3326)\tPrec@1 84.375 (88.514)\tPrec@5 99.219 (99.639)\t\n",
            "TRAINING - Epoch: [16][180/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.3619 (0.3313)\tPrec@1 87.500 (88.579)\tPrec@5 99.219 (99.646)\t\n",
            "TRAINING - Epoch: [16][190/390]\tTime 0.073 (0.057)\tData 0.012 (0.005)\tLoss 0.2398 (0.3299)\tPrec@1 89.844 (88.592)\tPrec@5 100.000 (99.640)\t\n",
            "TRAINING - Epoch: [16][200/390]\tTime 0.065 (0.057)\tData 0.008 (0.004)\tLoss 0.4304 (0.3319)\tPrec@1 85.938 (88.557)\tPrec@5 99.219 (99.631)\t\n",
            "TRAINING - Epoch: [16][210/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.2842 (0.3341)\tPrec@1 90.625 (88.474)\tPrec@5 100.000 (99.626)\t\n",
            "TRAINING - Epoch: [16][220/390]\tTime 0.055 (0.057)\tData 0.006 (0.004)\tLoss 0.3423 (0.3340)\tPrec@1 88.281 (88.472)\tPrec@5 100.000 (99.625)\t\n",
            "TRAINING - Epoch: [16][230/390]\tTime 0.080 (0.057)\tData 0.008 (0.004)\tLoss 0.2710 (0.3350)\tPrec@1 89.844 (88.427)\tPrec@5 100.000 (99.608)\t\n",
            "TRAINING - Epoch: [16][240/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.3058 (0.3343)\tPrec@1 89.844 (88.485)\tPrec@5 99.219 (99.605)\t\n",
            "TRAINING - Epoch: [16][250/390]\tTime 0.070 (0.057)\tData 0.007 (0.004)\tLoss 0.3662 (0.3335)\tPrec@1 89.844 (88.502)\tPrec@5 100.000 (99.617)\t\n",
            "TRAINING - Epoch: [16][260/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.4907 (0.3338)\tPrec@1 80.469 (88.491)\tPrec@5 100.000 (99.617)\t\n",
            "TRAINING - Epoch: [16][270/390]\tTime 0.051 (0.057)\tData 0.005 (0.004)\tLoss 0.2776 (0.3344)\tPrec@1 89.844 (88.440)\tPrec@5 100.000 (99.628)\t\n",
            "TRAINING - Epoch: [16][280/390]\tTime 0.052 (0.056)\tData 0.000 (0.004)\tLoss 0.3948 (0.3365)\tPrec@1 83.594 (88.373)\tPrec@5 99.219 (99.630)\t\n",
            "TRAINING - Epoch: [16][290/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.3238 (0.3365)\tPrec@1 90.625 (88.389)\tPrec@5 99.219 (99.621)\t\n",
            "TRAINING - Epoch: [16][300/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.4699 (0.3374)\tPrec@1 83.594 (88.338)\tPrec@5 100.000 (99.626)\t\n",
            "TRAINING - Epoch: [16][310/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.4304 (0.3382)\tPrec@1 85.156 (88.314)\tPrec@5 97.656 (99.618)\t\n",
            "TRAINING - Epoch: [16][320/390]\tTime 0.054 (0.056)\tData 0.004 (0.004)\tLoss 0.3001 (0.3379)\tPrec@1 86.719 (88.315)\tPrec@5 99.219 (99.623)\t\n",
            "TRAINING - Epoch: [16][330/390]\tTime 0.056 (0.056)\tData 0.000 (0.004)\tLoss 0.3466 (0.3365)\tPrec@1 86.719 (88.369)\tPrec@5 100.000 (99.625)\t\n",
            "TRAINING - Epoch: [16][340/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.4406 (0.3370)\tPrec@1 84.375 (88.366)\tPrec@5 98.438 (99.622)\t\n",
            "TRAINING - Epoch: [16][350/390]\tTime 0.055 (0.056)\tData 0.007 (0.004)\tLoss 0.2685 (0.3370)\tPrec@1 90.625 (88.373)\tPrec@5 100.000 (99.624)\t\n",
            "TRAINING - Epoch: [16][360/390]\tTime 0.051 (0.056)\tData 0.000 (0.004)\tLoss 0.2715 (0.3374)\tPrec@1 91.406 (88.379)\tPrec@5 100.000 (99.621)\t\n",
            "TRAINING - Epoch: [16][370/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.2996 (0.3379)\tPrec@1 89.062 (88.361)\tPrec@5 99.219 (99.617)\t\n",
            "TRAINING - Epoch: [16][380/390]\tTime 0.065 (0.056)\tData 0.008 (0.004)\tLoss 0.3534 (0.3389)\tPrec@1 88.281 (88.333)\tPrec@5 99.219 (99.619)\t\n",
            "TRAINING - Epoch: [16][389/390]\tTime 0.045 (0.056)\tData 0.000 (0.004)\tLoss 0.3651 (0.3385)\tPrec@1 89.844 (88.329)\tPrec@5 100.000 (99.619)\t\n",
            "EVALUATING - Epoch: [16][0/79]\tTime 0.189 (0.189)\tData 0.161 (0.161)\tLoss 0.4721 (0.4721)\tPrec@1 85.156 (85.156)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [16][10/79]\tTime 0.024 (0.049)\tData 0.005 (0.022)\tLoss 0.4139 (0.5068)\tPrec@1 83.594 (83.452)\tPrec@5 99.219 (99.716)\t\n",
            "EVALUATING - Epoch: [16][20/79]\tTime 0.031 (0.041)\tData 0.000 (0.013)\tLoss 0.5952 (0.5614)\tPrec@1 81.250 (82.440)\tPrec@5 98.438 (99.442)\t\n",
            "EVALUATING - Epoch: [16][30/79]\tTime 0.020 (0.038)\tData 0.000 (0.010)\tLoss 0.4772 (0.5580)\tPrec@1 83.594 (82.686)\tPrec@5 100.000 (99.219)\t\n",
            "EVALUATING - Epoch: [16][40/79]\tTime 0.038 (0.036)\tData 0.000 (0.008)\tLoss 0.6847 (0.5586)\tPrec@1 77.344 (82.565)\tPrec@5 99.219 (99.200)\t\n",
            "EVALUATING - Epoch: [16][50/79]\tTime 0.027 (0.035)\tData 0.013 (0.008)\tLoss 0.6125 (0.5594)\tPrec@1 82.031 (82.521)\tPrec@5 98.438 (99.234)\t\n",
            "EVALUATING - Epoch: [16][60/79]\tTime 0.038 (0.034)\tData 0.000 (0.007)\tLoss 0.6101 (0.5604)\tPrec@1 82.812 (82.480)\tPrec@5 99.219 (99.283)\t\n",
            "EVALUATING - Epoch: [16][70/79]\tTime 0.029 (0.033)\tData 0.006 (0.006)\tLoss 0.4206 (0.5556)\tPrec@1 82.812 (82.493)\tPrec@5 100.000 (99.296)\t\n",
            "EVALUATING - Epoch: [16][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.006)\tLoss 0.6504 (0.5516)\tPrec@1 81.250 (82.540)\tPrec@5 100.000 (99.330)\t\n",
            "\n",
            "Results - Epoch: 17\n",
            "Training Loss 0.3385 \tTraining Prec@1 88.329 \tTraining Prec@5 99.619 \tValidation Loss 0.5516 \tValidation Prec@1 82.540 \tValidation Prec@5 99.330 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 18\n",
            "\n",
            "TRAINING - Epoch: [17][0/390]\tTime 0.374 (0.374)\tData 0.290 (0.290)\tLoss 0.3195 (0.3195)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [17][10/390]\tTime 0.048 (0.087)\tData 0.000 (0.030)\tLoss 0.1880 (0.3250)\tPrec@1 93.750 (88.565)\tPrec@5 100.000 (99.574)\t\n",
            "TRAINING - Epoch: [17][20/390]\tTime 0.069 (0.072)\tData 0.011 (0.018)\tLoss 0.4122 (0.3164)\tPrec@1 87.500 (89.360)\tPrec@5 99.219 (99.628)\t\n",
            "TRAINING - Epoch: [17][30/390]\tTime 0.069 (0.068)\tData 0.007 (0.013)\tLoss 0.4740 (0.3211)\tPrec@1 86.719 (89.214)\tPrec@5 99.219 (99.622)\t\n",
            "TRAINING - Epoch: [17][40/390]\tTime 0.047 (0.065)\tData 0.000 (0.011)\tLoss 0.2784 (0.3237)\tPrec@1 90.625 (88.967)\tPrec@5 100.000 (99.619)\t\n",
            "TRAINING - Epoch: [17][50/390]\tTime 0.058 (0.063)\tData 0.012 (0.010)\tLoss 0.2868 (0.3237)\tPrec@1 88.281 (88.771)\tPrec@5 100.000 (99.663)\t\n",
            "TRAINING - Epoch: [17][60/390]\tTime 0.058 (0.062)\tData 0.000 (0.008)\tLoss 0.3064 (0.3225)\tPrec@1 89.844 (88.934)\tPrec@5 100.000 (99.667)\t\n",
            "TRAINING - Epoch: [17][70/390]\tTime 0.052 (0.061)\tData 0.000 (0.008)\tLoss 0.2133 (0.3146)\tPrec@1 92.188 (89.151)\tPrec@5 100.000 (99.692)\t\n",
            "TRAINING - Epoch: [17][80/390]\tTime 0.062 (0.060)\tData 0.006 (0.007)\tLoss 0.3576 (0.3161)\tPrec@1 88.281 (89.082)\tPrec@5 100.000 (99.662)\t\n",
            "TRAINING - Epoch: [17][90/390]\tTime 0.051 (0.060)\tData 0.000 (0.007)\tLoss 0.2861 (0.3140)\tPrec@1 90.625 (89.157)\tPrec@5 100.000 (99.674)\t\n",
            "TRAINING - Epoch: [17][100/390]\tTime 0.050 (0.059)\tData 0.000 (0.006)\tLoss 0.4510 (0.3161)\tPrec@1 83.594 (88.993)\tPrec@5 100.000 (99.691)\t\n",
            "TRAINING - Epoch: [17][110/390]\tTime 0.054 (0.059)\tData 0.000 (0.006)\tLoss 0.2585 (0.3163)\tPrec@1 90.625 (88.964)\tPrec@5 100.000 (99.704)\t\n",
            "TRAINING - Epoch: [17][120/390]\tTime 0.053 (0.059)\tData 0.007 (0.006)\tLoss 0.3090 (0.3142)\tPrec@1 88.281 (89.062)\tPrec@5 99.219 (99.716)\t\n",
            "TRAINING - Epoch: [17][130/390]\tTime 0.052 (0.058)\tData 0.000 (0.006)\tLoss 0.2379 (0.3133)\tPrec@1 92.969 (89.086)\tPrec@5 100.000 (99.714)\t\n",
            "TRAINING - Epoch: [17][140/390]\tTime 0.058 (0.058)\tData 0.010 (0.006)\tLoss 0.2164 (0.3126)\tPrec@1 92.188 (89.090)\tPrec@5 100.000 (99.723)\t\n",
            "TRAINING - Epoch: [17][150/390]\tTime 0.060 (0.058)\tData 0.007 (0.006)\tLoss 0.4157 (0.3151)\tPrec@1 86.719 (89.062)\tPrec@5 100.000 (99.721)\t\n",
            "TRAINING - Epoch: [17][160/390]\tTime 0.081 (0.058)\tData 0.011 (0.005)\tLoss 0.2438 (0.3161)\tPrec@1 91.406 (89.014)\tPrec@5 100.000 (99.723)\t\n",
            "TRAINING - Epoch: [17][170/390]\tTime 0.072 (0.057)\tData 0.006 (0.005)\tLoss 0.3050 (0.3157)\tPrec@1 87.500 (89.031)\tPrec@5 100.000 (99.730)\t\n",
            "TRAINING - Epoch: [17][180/390]\tTime 0.071 (0.057)\tData 0.006 (0.005)\tLoss 0.1774 (0.3169)\tPrec@1 93.750 (89.002)\tPrec@5 100.000 (99.741)\t\n",
            "TRAINING - Epoch: [17][190/390]\tTime 0.064 (0.057)\tData 0.009 (0.005)\tLoss 0.3266 (0.3174)\tPrec@1 88.281 (88.960)\tPrec@5 99.219 (99.734)\t\n",
            "TRAINING - Epoch: [17][200/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.4441 (0.3194)\tPrec@1 88.281 (88.907)\tPrec@5 100.000 (99.740)\t\n",
            "TRAINING - Epoch: [17][210/390]\tTime 0.059 (0.057)\tData 0.010 (0.005)\tLoss 0.2717 (0.3204)\tPrec@1 92.188 (88.918)\tPrec@5 99.219 (99.741)\t\n",
            "TRAINING - Epoch: [17][220/390]\tTime 0.053 (0.057)\tData 0.000 (0.005)\tLoss 0.3612 (0.3215)\tPrec@1 89.844 (88.910)\tPrec@5 100.000 (99.731)\t\n",
            "TRAINING - Epoch: [17][230/390]\tTime 0.056 (0.057)\tData 0.000 (0.005)\tLoss 0.2897 (0.3230)\tPrec@1 89.844 (88.870)\tPrec@5 100.000 (99.706)\t\n",
            "TRAINING - Epoch: [17][240/390]\tTime 0.065 (0.057)\tData 0.007 (0.005)\tLoss 0.2426 (0.3227)\tPrec@1 89.062 (88.862)\tPrec@5 100.000 (99.699)\t\n",
            "TRAINING - Epoch: [17][250/390]\tTime 0.062 (0.057)\tData 0.000 (0.005)\tLoss 0.3218 (0.3239)\tPrec@1 88.281 (88.845)\tPrec@5 99.219 (99.686)\t\n",
            "TRAINING - Epoch: [17][260/390]\tTime 0.058 (0.057)\tData 0.009 (0.005)\tLoss 0.3370 (0.3238)\tPrec@1 85.938 (88.823)\tPrec@5 99.219 (99.692)\t\n",
            "TRAINING - Epoch: [17][270/390]\tTime 0.063 (0.057)\tData 0.007 (0.005)\tLoss 0.3853 (0.3240)\tPrec@1 87.500 (88.817)\tPrec@5 100.000 (99.686)\t\n",
            "TRAINING - Epoch: [17][280/390]\tTime 0.056 (0.056)\tData 0.007 (0.005)\tLoss 0.3137 (0.3239)\tPrec@1 85.938 (88.829)\tPrec@5 100.000 (99.689)\t\n",
            "TRAINING - Epoch: [17][290/390]\tTime 0.048 (0.056)\tData 0.000 (0.005)\tLoss 0.3746 (0.3227)\tPrec@1 89.062 (88.872)\tPrec@5 99.219 (99.681)\t\n",
            "TRAINING - Epoch: [17][300/390]\tTime 0.054 (0.056)\tData 0.003 (0.005)\tLoss 0.3458 (0.3226)\tPrec@1 89.062 (88.876)\tPrec@5 100.000 (99.678)\t\n",
            "TRAINING - Epoch: [17][310/390]\tTime 0.070 (0.056)\tData 0.002 (0.004)\tLoss 0.3873 (0.3225)\tPrec@1 85.938 (88.867)\tPrec@5 100.000 (99.683)\t\n",
            "TRAINING - Epoch: [17][320/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.2978 (0.3225)\tPrec@1 91.406 (88.860)\tPrec@5 99.219 (99.671)\t\n",
            "TRAINING - Epoch: [17][330/390]\tTime 0.055 (0.056)\tData 0.000 (0.004)\tLoss 0.4661 (0.3231)\tPrec@1 83.594 (88.834)\tPrec@5 100.000 (99.670)\t\n",
            "TRAINING - Epoch: [17][340/390]\tTime 0.060 (0.056)\tData 0.007 (0.004)\tLoss 0.3661 (0.3234)\tPrec@1 87.500 (88.808)\tPrec@5 99.219 (99.661)\t\n",
            "TRAINING - Epoch: [17][350/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.3272 (0.3229)\tPrec@1 89.844 (88.802)\tPrec@5 99.219 (99.664)\t\n",
            "TRAINING - Epoch: [17][360/390]\tTime 0.062 (0.056)\tData 0.012 (0.004)\tLoss 0.4212 (0.3232)\tPrec@1 86.719 (88.790)\tPrec@5 100.000 (99.665)\t\n",
            "TRAINING - Epoch: [17][370/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.3110 (0.3241)\tPrec@1 88.281 (88.778)\tPrec@5 100.000 (99.655)\t\n",
            "TRAINING - Epoch: [17][380/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.4204 (0.3246)\tPrec@1 87.500 (88.784)\tPrec@5 98.438 (99.649)\t\n",
            "TRAINING - Epoch: [17][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.3638 (0.3238)\tPrec@1 84.375 (88.784)\tPrec@5 100.000 (99.657)\t\n",
            "EVALUATING - Epoch: [17][0/79]\tTime 0.250 (0.250)\tData 0.210 (0.210)\tLoss 0.5334 (0.5334)\tPrec@1 84.375 (84.375)\tPrec@5 98.438 (98.438)\t\n",
            "EVALUATING - Epoch: [17][10/79]\tTime 0.035 (0.055)\tData 0.007 (0.024)\tLoss 0.5458 (0.5739)\tPrec@1 82.031 (82.315)\tPrec@5 97.656 (98.864)\t\n",
            "EVALUATING - Epoch: [17][20/79]\tTime 0.014 (0.042)\tData 0.000 (0.015)\tLoss 0.6102 (0.6140)\tPrec@1 79.688 (80.804)\tPrec@5 98.438 (99.033)\t\n",
            "EVALUATING - Epoch: [17][30/79]\tTime 0.050 (0.039)\tData 0.009 (0.013)\tLoss 0.5472 (0.5927)\tPrec@1 85.156 (81.502)\tPrec@5 99.219 (98.942)\t\n",
            "EVALUATING - Epoch: [17][40/79]\tTime 0.044 (0.037)\tData 0.007 (0.011)\tLoss 0.7826 (0.5985)\tPrec@1 71.094 (81.269)\tPrec@5 98.438 (98.895)\t\n",
            "EVALUATING - Epoch: [17][50/79]\tTime 0.036 (0.035)\tData 0.000 (0.009)\tLoss 0.5925 (0.5977)\tPrec@1 80.469 (81.265)\tPrec@5 99.219 (98.989)\t\n",
            "EVALUATING - Epoch: [17][60/79]\tTime 0.044 (0.035)\tData 0.010 (0.008)\tLoss 0.5019 (0.5847)\tPrec@1 84.375 (81.519)\tPrec@5 100.000 (99.039)\t\n",
            "EVALUATING - Epoch: [17][70/79]\tTime 0.037 (0.034)\tData 0.005 (0.008)\tLoss 0.3727 (0.5849)\tPrec@1 89.062 (81.393)\tPrec@5 100.000 (99.065)\t\n",
            "EVALUATING - Epoch: [17][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.3318 (0.5811)\tPrec@1 87.500 (81.450)\tPrec@5 100.000 (99.100)\t\n",
            "\n",
            "Results - Epoch: 18\n",
            "Training Loss 0.3238 \tTraining Prec@1 88.784 \tTraining Prec@5 99.657 \tValidation Loss 0.5811 \tValidation Prec@1 81.450 \tValidation Prec@5 99.100 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 19\n",
            "\n",
            "TRAINING - Epoch: [18][0/390]\tTime 0.359 (0.359)\tData 0.271 (0.271)\tLoss 0.4214 (0.4214)\tPrec@1 82.812 (82.812)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [18][10/390]\tTime 0.049 (0.089)\tData 0.000 (0.028)\tLoss 0.3433 (0.2975)\tPrec@1 89.844 (89.134)\tPrec@5 100.000 (99.716)\t\n",
            "TRAINING - Epoch: [18][20/390]\tTime 0.058 (0.072)\tData 0.007 (0.017)\tLoss 0.1614 (0.2983)\tPrec@1 95.312 (89.211)\tPrec@5 100.000 (99.665)\t\n",
            "TRAINING - Epoch: [18][30/390]\tTime 0.048 (0.067)\tData 0.000 (0.013)\tLoss 0.2344 (0.2969)\tPrec@1 93.750 (89.239)\tPrec@5 100.000 (99.748)\t\n",
            "TRAINING - Epoch: [18][40/390]\tTime 0.049 (0.063)\tData 0.000 (0.010)\tLoss 0.3400 (0.2892)\tPrec@1 89.062 (89.558)\tPrec@5 99.219 (99.752)\t\n",
            "TRAINING - Epoch: [18][50/390]\tTime 0.047 (0.062)\tData 0.000 (0.009)\tLoss 0.2296 (0.2870)\tPrec@1 92.969 (89.568)\tPrec@5 100.000 (99.786)\t\n",
            "TRAINING - Epoch: [18][60/390]\tTime 0.046 (0.060)\tData 0.000 (0.008)\tLoss 0.1281 (0.2854)\tPrec@1 95.312 (89.664)\tPrec@5 100.000 (99.782)\t\n",
            "TRAINING - Epoch: [18][70/390]\tTime 0.046 (0.060)\tData 0.000 (0.007)\tLoss 0.2828 (0.2832)\tPrec@1 90.625 (89.822)\tPrec@5 100.000 (99.758)\t\n",
            "TRAINING - Epoch: [18][80/390]\tTime 0.048 (0.059)\tData 0.000 (0.007)\tLoss 0.2046 (0.2827)\tPrec@1 92.969 (89.892)\tPrec@5 100.000 (99.740)\t\n",
            "TRAINING - Epoch: [18][90/390]\tTime 0.056 (0.058)\tData 0.008 (0.006)\tLoss 0.2645 (0.2823)\tPrec@1 92.188 (90.015)\tPrec@5 98.438 (99.717)\t\n",
            "TRAINING - Epoch: [18][100/390]\tTime 0.049 (0.058)\tData 0.000 (0.006)\tLoss 0.3330 (0.2843)\tPrec@1 82.812 (89.851)\tPrec@5 100.000 (99.737)\t\n",
            "TRAINING - Epoch: [18][110/390]\tTime 0.053 (0.058)\tData 0.004 (0.006)\tLoss 0.3376 (0.2865)\tPrec@1 89.844 (89.759)\tPrec@5 99.219 (99.747)\t\n",
            "TRAINING - Epoch: [18][120/390]\tTime 0.056 (0.057)\tData 0.000 (0.005)\tLoss 0.3374 (0.2892)\tPrec@1 89.062 (89.631)\tPrec@5 100.000 (99.755)\t\n",
            "TRAINING - Epoch: [18][130/390]\tTime 0.053 (0.057)\tData 0.006 (0.005)\tLoss 0.2261 (0.2885)\tPrec@1 92.969 (89.665)\tPrec@5 100.000 (99.750)\t\n",
            "TRAINING - Epoch: [18][140/390]\tTime 0.056 (0.057)\tData 0.000 (0.005)\tLoss 0.1879 (0.2896)\tPrec@1 94.531 (89.661)\tPrec@5 100.000 (99.717)\t\n",
            "TRAINING - Epoch: [18][150/390]\tTime 0.051 (0.057)\tData 0.000 (0.005)\tLoss 0.3165 (0.2939)\tPrec@1 88.281 (89.549)\tPrec@5 100.000 (99.705)\t\n",
            "TRAINING - Epoch: [18][160/390]\tTime 0.059 (0.057)\tData 0.006 (0.005)\tLoss 0.2112 (0.2948)\tPrec@1 92.969 (89.523)\tPrec@5 100.000 (99.704)\t\n",
            "TRAINING - Epoch: [18][170/390]\tTime 0.065 (0.057)\tData 0.008 (0.005)\tLoss 0.3463 (0.2948)\tPrec@1 85.938 (89.533)\tPrec@5 100.000 (99.708)\t\n",
            "TRAINING - Epoch: [18][180/390]\tTime 0.054 (0.057)\tData 0.007 (0.005)\tLoss 0.3365 (0.2994)\tPrec@1 88.281 (89.386)\tPrec@5 98.438 (99.698)\t\n",
            "TRAINING - Epoch: [18][190/390]\tTime 0.051 (0.057)\tData 0.000 (0.005)\tLoss 0.3549 (0.3008)\tPrec@1 88.281 (89.341)\tPrec@5 98.438 (99.693)\t\n",
            "TRAINING - Epoch: [18][200/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2229 (0.3032)\tPrec@1 92.188 (89.272)\tPrec@5 100.000 (99.689)\t\n",
            "TRAINING - Epoch: [18][210/390]\tTime 0.051 (0.056)\tData 0.000 (0.004)\tLoss 0.3022 (0.3045)\tPrec@1 89.062 (89.214)\tPrec@5 100.000 (99.693)\t\n",
            "TRAINING - Epoch: [18][220/390]\tTime 0.066 (0.057)\tData 0.009 (0.004)\tLoss 0.2951 (0.3047)\tPrec@1 89.844 (89.232)\tPrec@5 100.000 (99.696)\t\n",
            "TRAINING - Epoch: [18][230/390]\tTime 0.058 (0.057)\tData 0.007 (0.005)\tLoss 0.3147 (0.3044)\tPrec@1 88.281 (89.276)\tPrec@5 100.000 (99.696)\t\n",
            "TRAINING - Epoch: [18][240/390]\tTime 0.065 (0.057)\tData 0.011 (0.004)\tLoss 0.3021 (0.3055)\tPrec@1 89.844 (89.251)\tPrec@5 100.000 (99.692)\t\n",
            "TRAINING - Epoch: [18][250/390]\tTime 0.053 (0.056)\tData 0.000 (0.004)\tLoss 0.3922 (0.3061)\tPrec@1 86.719 (89.218)\tPrec@5 100.000 (99.679)\t\n",
            "TRAINING - Epoch: [18][260/390]\tTime 0.058 (0.056)\tData 0.007 (0.004)\tLoss 0.4032 (0.3091)\tPrec@1 87.500 (89.122)\tPrec@5 100.000 (99.683)\t\n",
            "TRAINING - Epoch: [18][270/390]\tTime 0.063 (0.056)\tData 0.006 (0.004)\tLoss 0.2758 (0.3088)\tPrec@1 89.844 (89.126)\tPrec@5 100.000 (99.686)\t\n",
            "TRAINING - Epoch: [18][280/390]\tTime 0.051 (0.056)\tData 0.000 (0.004)\tLoss 0.2435 (0.3084)\tPrec@1 93.750 (89.140)\tPrec@5 100.000 (99.683)\t\n",
            "TRAINING - Epoch: [18][290/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.2768 (0.3077)\tPrec@1 91.406 (89.162)\tPrec@5 99.219 (99.683)\t\n",
            "TRAINING - Epoch: [18][300/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.3965 (0.3087)\tPrec@1 83.594 (89.127)\tPrec@5 99.219 (99.676)\t\n",
            "TRAINING - Epoch: [18][310/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.2845 (0.3092)\tPrec@1 90.625 (89.100)\tPrec@5 100.000 (99.681)\t\n",
            "TRAINING - Epoch: [18][320/390]\tTime 0.061 (0.056)\tData 0.009 (0.004)\tLoss 0.3650 (0.3105)\tPrec@1 88.281 (89.070)\tPrec@5 99.219 (99.674)\t\n",
            "TRAINING - Epoch: [18][330/390]\tTime 0.052 (0.056)\tData 0.003 (0.004)\tLoss 0.3234 (0.3103)\tPrec@1 90.625 (89.096)\tPrec@5 100.000 (99.672)\t\n",
            "TRAINING - Epoch: [18][340/390]\tTime 0.052 (0.056)\tData 0.000 (0.004)\tLoss 0.3887 (0.3107)\tPrec@1 84.375 (89.088)\tPrec@5 100.000 (99.677)\t\n",
            "TRAINING - Epoch: [18][350/390]\tTime 0.066 (0.056)\tData 0.000 (0.004)\tLoss 0.3330 (0.3103)\tPrec@1 89.062 (89.085)\tPrec@5 99.219 (99.679)\t\n",
            "TRAINING - Epoch: [18][360/390]\tTime 0.052 (0.056)\tData 0.004 (0.004)\tLoss 0.3114 (0.3101)\tPrec@1 87.500 (89.114)\tPrec@5 99.219 (99.675)\t\n",
            "TRAINING - Epoch: [18][370/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.2771 (0.3095)\tPrec@1 91.406 (89.130)\tPrec@5 99.219 (99.680)\t\n",
            "TRAINING - Epoch: [18][380/390]\tTime 0.055 (0.056)\tData 0.009 (0.004)\tLoss 0.4528 (0.3108)\tPrec@1 85.938 (89.083)\tPrec@5 98.438 (99.678)\t\n",
            "TRAINING - Epoch: [18][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.3402 (0.3109)\tPrec@1 85.938 (89.067)\tPrec@5 100.000 (99.673)\t\n",
            "EVALUATING - Epoch: [18][0/79]\tTime 0.294 (0.294)\tData 0.261 (0.261)\tLoss 0.3640 (0.3640)\tPrec@1 89.062 (89.062)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [18][10/79]\tTime 0.027 (0.055)\tData 0.001 (0.028)\tLoss 0.3497 (0.4011)\tPrec@1 85.938 (86.719)\tPrec@5 100.000 (99.574)\t\n",
            "EVALUATING - Epoch: [18][20/79]\tTime 0.013 (0.043)\tData 0.000 (0.017)\tLoss 0.4075 (0.4103)\tPrec@1 86.719 (86.607)\tPrec@5 100.000 (99.554)\t\n",
            "EVALUATING - Epoch: [18][30/79]\tTime 0.026 (0.039)\tData 0.007 (0.014)\tLoss 0.3272 (0.4051)\tPrec@1 90.625 (86.618)\tPrec@5 100.000 (99.446)\t\n",
            "EVALUATING - Epoch: [18][40/79]\tTime 0.041 (0.037)\tData 0.003 (0.012)\tLoss 0.5268 (0.4051)\tPrec@1 82.812 (86.566)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [18][50/79]\tTime 0.033 (0.035)\tData 0.005 (0.011)\tLoss 0.3756 (0.4026)\tPrec@1 85.938 (86.458)\tPrec@5 100.000 (99.571)\t\n",
            "EVALUATING - Epoch: [18][60/79]\tTime 0.035 (0.035)\tData 0.000 (0.009)\tLoss 0.4879 (0.4040)\tPrec@1 85.156 (86.424)\tPrec@5 99.219 (99.590)\t\n",
            "EVALUATING - Epoch: [18][70/79]\tTime 0.019 (0.034)\tData 0.002 (0.009)\tLoss 0.3312 (0.4032)\tPrec@1 87.500 (86.433)\tPrec@5 100.000 (99.615)\t\n",
            "EVALUATING - Epoch: [18][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.008)\tLoss 0.1809 (0.4003)\tPrec@1 93.750 (86.590)\tPrec@5 100.000 (99.630)\t\n",
            "\n",
            "Results - Epoch: 19\n",
            "Training Loss 0.3109 \tTraining Prec@1 89.067 \tTraining Prec@5 99.673 \tValidation Loss 0.4003 \tValidation Prec@1 86.590 \tValidation Prec@5 99.630 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 20\n",
            "\n",
            "TRAINING - Epoch: [19][0/390]\tTime 0.362 (0.362)\tData 0.255 (0.255)\tLoss 0.2741 (0.2741)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [19][10/390]\tTime 0.051 (0.088)\tData 0.000 (0.027)\tLoss 0.2179 (0.2456)\tPrec@1 92.969 (91.974)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [19][20/390]\tTime 0.050 (0.072)\tData 0.002 (0.016)\tLoss 0.3219 (0.2858)\tPrec@1 87.500 (90.439)\tPrec@5 100.000 (99.740)\t\n",
            "TRAINING - Epoch: [19][30/390]\tTime 0.057 (0.067)\tData 0.000 (0.012)\tLoss 0.3555 (0.2945)\tPrec@1 88.281 (90.045)\tPrec@5 99.219 (99.773)\t\n",
            "TRAINING - Epoch: [19][40/390]\tTime 0.054 (0.064)\tData 0.007 (0.009)\tLoss 0.2382 (0.2982)\tPrec@1 92.188 (89.710)\tPrec@5 100.000 (99.676)\t\n",
            "TRAINING - Epoch: [19][50/390]\tTime 0.048 (0.062)\tData 0.000 (0.008)\tLoss 0.2739 (0.2939)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (99.740)\t\n",
            "TRAINING - Epoch: [19][60/390]\tTime 0.046 (0.061)\tData 0.000 (0.007)\tLoss 0.2305 (0.2932)\tPrec@1 90.625 (89.869)\tPrec@5 99.219 (99.718)\t\n",
            "TRAINING - Epoch: [19][70/390]\tTime 0.075 (0.061)\tData 0.000 (0.007)\tLoss 0.3137 (0.2916)\tPrec@1 89.062 (89.855)\tPrec@5 99.219 (99.736)\t\n",
            "TRAINING - Epoch: [19][80/390]\tTime 0.056 (0.061)\tData 0.006 (0.006)\tLoss 0.3135 (0.2914)\tPrec@1 88.281 (89.892)\tPrec@5 100.000 (99.749)\t\n",
            "TRAINING - Epoch: [19][90/390]\tTime 0.047 (0.060)\tData 0.000 (0.006)\tLoss 0.3305 (0.2955)\tPrec@1 86.719 (89.741)\tPrec@5 100.000 (99.760)\t\n",
            "TRAINING - Epoch: [19][100/390]\tTime 0.051 (0.060)\tData 0.000 (0.006)\tLoss 0.3009 (0.2953)\tPrec@1 91.406 (89.751)\tPrec@5 100.000 (99.768)\t\n",
            "TRAINING - Epoch: [19][110/390]\tTime 0.072 (0.059)\tData 0.011 (0.005)\tLoss 0.3721 (0.3004)\tPrec@1 90.625 (89.619)\tPrec@5 100.000 (99.740)\t\n",
            "TRAINING - Epoch: [19][120/390]\tTime 0.046 (0.059)\tData 0.000 (0.005)\tLoss 0.2466 (0.2992)\tPrec@1 91.406 (89.611)\tPrec@5 100.000 (99.748)\t\n",
            "TRAINING - Epoch: [19][130/390]\tTime 0.053 (0.059)\tData 0.000 (0.005)\tLoss 0.2574 (0.2983)\tPrec@1 91.406 (89.552)\tPrec@5 100.000 (99.761)\t\n",
            "TRAINING - Epoch: [19][140/390]\tTime 0.061 (0.059)\tData 0.007 (0.005)\tLoss 0.3823 (0.3004)\tPrec@1 86.719 (89.473)\tPrec@5 99.219 (99.740)\t\n",
            "TRAINING - Epoch: [19][150/390]\tTime 0.066 (0.059)\tData 0.007 (0.005)\tLoss 0.3141 (0.3003)\tPrec@1 92.188 (89.528)\tPrec@5 99.219 (99.736)\t\n",
            "TRAINING - Epoch: [19][160/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 0.2509 (0.3022)\tPrec@1 90.625 (89.465)\tPrec@5 99.219 (99.728)\t\n",
            "TRAINING - Epoch: [19][170/390]\tTime 0.057 (0.059)\tData 0.007 (0.005)\tLoss 0.2931 (0.3027)\tPrec@1 87.500 (89.410)\tPrec@5 100.000 (99.721)\t\n",
            "TRAINING - Epoch: [19][180/390]\tTime 0.063 (0.058)\tData 0.000 (0.005)\tLoss 0.2154 (0.3062)\tPrec@1 91.406 (89.300)\tPrec@5 100.000 (99.698)\t\n",
            "TRAINING - Epoch: [19][190/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.4485 (0.3068)\tPrec@1 85.938 (89.292)\tPrec@5 97.656 (99.685)\t\n",
            "TRAINING - Epoch: [19][200/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.2020 (0.3058)\tPrec@1 92.969 (89.331)\tPrec@5 100.000 (99.685)\t\n",
            "TRAINING - Epoch: [19][210/390]\tTime 0.054 (0.058)\tData 0.007 (0.004)\tLoss 0.1850 (0.3053)\tPrec@1 92.969 (89.318)\tPrec@5 100.000 (99.678)\t\n",
            "TRAINING - Epoch: [19][220/390]\tTime 0.059 (0.058)\tData 0.007 (0.004)\tLoss 0.3424 (0.3053)\tPrec@1 85.938 (89.342)\tPrec@5 99.219 (99.678)\t\n",
            "TRAINING - Epoch: [19][230/390]\tTime 0.066 (0.058)\tData 0.007 (0.004)\tLoss 0.3417 (0.3050)\tPrec@1 89.062 (89.309)\tPrec@5 98.438 (99.679)\t\n",
            "TRAINING - Epoch: [19][240/390]\tTime 0.046 (0.058)\tData 0.000 (0.004)\tLoss 0.2997 (0.3049)\tPrec@1 91.406 (89.289)\tPrec@5 100.000 (99.682)\t\n",
            "TRAINING - Epoch: [19][250/390]\tTime 0.061 (0.058)\tData 0.008 (0.004)\tLoss 0.2967 (0.3054)\tPrec@1 91.406 (89.280)\tPrec@5 100.000 (99.676)\t\n",
            "TRAINING - Epoch: [19][260/390]\tTime 0.047 (0.058)\tData 0.000 (0.004)\tLoss 0.2508 (0.3060)\tPrec@1 92.188 (89.239)\tPrec@5 100.000 (99.674)\t\n",
            "TRAINING - Epoch: [19][270/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2785 (0.3052)\tPrec@1 89.844 (89.279)\tPrec@5 100.000 (99.677)\t\n",
            "TRAINING - Epoch: [19][280/390]\tTime 0.055 (0.057)\tData 0.005 (0.004)\tLoss 0.2413 (0.3044)\tPrec@1 90.625 (89.313)\tPrec@5 100.000 (99.680)\t\n",
            "TRAINING - Epoch: [19][290/390]\tTime 0.059 (0.057)\tData 0.007 (0.004)\tLoss 0.2088 (0.3054)\tPrec@1 93.750 (89.293)\tPrec@5 100.000 (99.672)\t\n",
            "TRAINING - Epoch: [19][300/390]\tTime 0.058 (0.057)\tData 0.008 (0.004)\tLoss 0.2745 (0.3045)\tPrec@1 90.625 (89.327)\tPrec@5 100.000 (99.676)\t\n",
            "TRAINING - Epoch: [19][310/390]\tTime 0.059 (0.057)\tData 0.000 (0.004)\tLoss 0.2885 (0.3048)\tPrec@1 90.625 (89.299)\tPrec@5 100.000 (99.678)\t\n",
            "TRAINING - Epoch: [19][320/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.3387 (0.3054)\tPrec@1 88.281 (89.284)\tPrec@5 98.438 (99.674)\t\n",
            "TRAINING - Epoch: [19][330/390]\tTime 0.056 (0.057)\tData 0.000 (0.004)\tLoss 0.2997 (0.3047)\tPrec@1 89.844 (89.303)\tPrec@5 100.000 (99.679)\t\n",
            "TRAINING - Epoch: [19][340/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2111 (0.3040)\tPrec@1 94.531 (89.321)\tPrec@5 100.000 (99.684)\t\n",
            "TRAINING - Epoch: [19][350/390]\tTime 0.054 (0.057)\tData 0.007 (0.004)\tLoss 0.3129 (0.3040)\tPrec@1 89.062 (89.336)\tPrec@5 100.000 (99.688)\t\n",
            "TRAINING - Epoch: [19][360/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.4211 (0.3047)\tPrec@1 85.156 (89.309)\tPrec@5 100.000 (99.691)\t\n",
            "TRAINING - Epoch: [19][370/390]\tTime 0.059 (0.057)\tData 0.000 (0.004)\tLoss 0.3800 (0.3057)\tPrec@1 89.062 (89.254)\tPrec@5 99.219 (99.688)\t\n",
            "TRAINING - Epoch: [19][380/390]\tTime 0.057 (0.057)\tData 0.000 (0.004)\tLoss 0.3177 (0.3055)\tPrec@1 89.062 (89.257)\tPrec@5 98.438 (99.690)\t\n",
            "TRAINING - Epoch: [19][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.2959 (0.3054)\tPrec@1 88.281 (89.251)\tPrec@5 100.000 (99.694)\t\n",
            "EVALUATING - Epoch: [19][0/79]\tTime 0.203 (0.203)\tData 0.172 (0.172)\tLoss 0.3636 (0.3636)\tPrec@1 85.938 (85.938)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [19][10/79]\tTime 0.022 (0.054)\tData 0.000 (0.025)\tLoss 0.5012 (0.5399)\tPrec@1 85.156 (83.949)\tPrec@5 97.656 (99.006)\t\n",
            "EVALUATING - Epoch: [19][20/79]\tTime 0.040 (0.042)\tData 0.010 (0.016)\tLoss 0.3623 (0.5519)\tPrec@1 89.844 (83.147)\tPrec@5 100.000 (99.070)\t\n",
            "EVALUATING - Epoch: [19][30/79]\tTime 0.019 (0.038)\tData 0.000 (0.012)\tLoss 0.3726 (0.5537)\tPrec@1 88.281 (83.745)\tPrec@5 100.000 (99.017)\t\n",
            "EVALUATING - Epoch: [19][40/79]\tTime 0.022 (0.036)\tData 0.000 (0.010)\tLoss 0.5666 (0.5454)\tPrec@1 80.469 (83.822)\tPrec@5 100.000 (99.104)\t\n",
            "EVALUATING - Epoch: [19][50/79]\tTime 0.029 (0.036)\tData 0.003 (0.009)\tLoss 0.4702 (0.5347)\tPrec@1 87.500 (84.191)\tPrec@5 100.000 (99.142)\t\n",
            "EVALUATING - Epoch: [19][60/79]\tTime 0.040 (0.035)\tData 0.009 (0.008)\tLoss 0.6718 (0.5390)\tPrec@1 83.594 (84.093)\tPrec@5 100.000 (99.206)\t\n",
            "EVALUATING - Epoch: [19][70/79]\tTime 0.021 (0.034)\tData 0.011 (0.008)\tLoss 0.4259 (0.5417)\tPrec@1 87.500 (83.935)\tPrec@5 100.000 (99.252)\t\n",
            "EVALUATING - Epoch: [19][78/79]\tTime 0.008 (0.032)\tData 0.000 (0.007)\tLoss 0.3105 (0.5386)\tPrec@1 87.500 (83.970)\tPrec@5 100.000 (99.250)\t\n",
            "\n",
            "Results - Epoch: 20\n",
            "Training Loss 0.3054 \tTraining Prec@1 89.251 \tTraining Prec@5 99.694 \tValidation Loss 0.5386 \tValidation Prec@1 83.970 \tValidation Prec@5 99.250 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 21\n",
            "\n",
            "TRAINING - Epoch: [20][0/390]\tTime 0.361 (0.361)\tData 0.279 (0.279)\tLoss 0.2572 (0.2572)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [20][10/390]\tTime 0.051 (0.085)\tData 0.000 (0.027)\tLoss 0.2929 (0.3003)\tPrec@1 90.625 (89.418)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [20][20/390]\tTime 0.047 (0.070)\tData 0.000 (0.016)\tLoss 0.3716 (0.2961)\tPrec@1 85.938 (89.844)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [20][30/390]\tTime 0.057 (0.066)\tData 0.007 (0.012)\tLoss 0.2696 (0.2952)\tPrec@1 87.500 (89.819)\tPrec@5 100.000 (99.773)\t\n",
            "TRAINING - Epoch: [20][40/390]\tTime 0.055 (0.063)\tData 0.007 (0.010)\tLoss 0.4039 (0.2972)\tPrec@1 86.719 (89.672)\tPrec@5 99.219 (99.714)\t\n",
            "TRAINING - Epoch: [20][50/390]\tTime 0.058 (0.062)\tData 0.009 (0.009)\tLoss 0.2579 (0.2976)\tPrec@1 89.844 (89.568)\tPrec@5 100.000 (99.724)\t\n",
            "TRAINING - Epoch: [20][60/390]\tTime 0.064 (0.061)\tData 0.009 (0.008)\tLoss 0.2802 (0.2924)\tPrec@1 92.969 (89.805)\tPrec@5 100.000 (99.757)\t\n",
            "TRAINING - Epoch: [20][70/390]\tTime 0.051 (0.061)\tData 0.000 (0.007)\tLoss 0.2801 (0.2970)\tPrec@1 89.844 (89.569)\tPrec@5 100.000 (99.725)\t\n",
            "TRAINING - Epoch: [20][80/390]\tTime 0.051 (0.060)\tData 0.000 (0.006)\tLoss 0.2650 (0.2971)\tPrec@1 89.062 (89.632)\tPrec@5 100.000 (99.740)\t\n",
            "TRAINING - Epoch: [20][90/390]\tTime 0.051 (0.059)\tData 0.000 (0.006)\tLoss 0.3372 (0.2966)\tPrec@1 89.844 (89.698)\tPrec@5 100.000 (99.760)\t\n",
            "TRAINING - Epoch: [20][100/390]\tTime 0.062 (0.059)\tData 0.009 (0.006)\tLoss 0.2820 (0.2980)\tPrec@1 90.625 (89.658)\tPrec@5 100.000 (99.737)\t\n",
            "TRAINING - Epoch: [20][110/390]\tTime 0.049 (0.059)\tData 0.000 (0.005)\tLoss 0.1641 (0.2948)\tPrec@1 96.094 (89.766)\tPrec@5 100.000 (99.740)\t\n",
            "TRAINING - Epoch: [20][120/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.2712 (0.2953)\tPrec@1 94.531 (89.805)\tPrec@5 98.438 (99.722)\t\n",
            "TRAINING - Epoch: [20][130/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.2541 (0.2964)\tPrec@1 92.969 (89.707)\tPrec@5 99.219 (99.726)\t\n",
            "TRAINING - Epoch: [20][140/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.2721 (0.2975)\tPrec@1 89.844 (89.639)\tPrec@5 99.219 (99.740)\t\n",
            "TRAINING - Epoch: [20][150/390]\tTime 0.065 (0.058)\tData 0.000 (0.005)\tLoss 0.3084 (0.2972)\tPrec@1 88.281 (89.657)\tPrec@5 100.000 (99.752)\t\n",
            "TRAINING - Epoch: [20][160/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2772 (0.2987)\tPrec@1 89.844 (89.582)\tPrec@5 100.000 (99.723)\t\n",
            "TRAINING - Epoch: [20][170/390]\tTime 0.058 (0.058)\tData 0.007 (0.005)\tLoss 0.1544 (0.2979)\tPrec@1 96.094 (89.629)\tPrec@5 100.000 (99.726)\t\n",
            "TRAINING - Epoch: [20][180/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2190 (0.2972)\tPrec@1 92.188 (89.654)\tPrec@5 99.219 (99.698)\t\n",
            "TRAINING - Epoch: [20][190/390]\tTime 0.061 (0.058)\tData 0.000 (0.005)\tLoss 0.1694 (0.2968)\tPrec@1 93.750 (89.676)\tPrec@5 100.000 (99.701)\t\n",
            "TRAINING - Epoch: [20][200/390]\tTime 0.054 (0.058)\tData 0.000 (0.005)\tLoss 0.2643 (0.2948)\tPrec@1 90.625 (89.731)\tPrec@5 100.000 (99.705)\t\n",
            "TRAINING - Epoch: [20][210/390]\tTime 0.072 (0.058)\tData 0.006 (0.005)\tLoss 0.2774 (0.2938)\tPrec@1 90.625 (89.770)\tPrec@5 100.000 (99.711)\t\n",
            "TRAINING - Epoch: [20][220/390]\tTime 0.063 (0.058)\tData 0.007 (0.004)\tLoss 0.3080 (0.2942)\tPrec@1 87.500 (89.741)\tPrec@5 99.219 (99.700)\t\n",
            "TRAINING - Epoch: [20][230/390]\tTime 0.056 (0.058)\tData 0.007 (0.004)\tLoss 0.2567 (0.2941)\tPrec@1 92.969 (89.756)\tPrec@5 99.219 (99.702)\t\n",
            "TRAINING - Epoch: [20][240/390]\tTime 0.062 (0.057)\tData 0.005 (0.004)\tLoss 0.2352 (0.2944)\tPrec@1 91.406 (89.740)\tPrec@5 99.219 (99.699)\t\n",
            "TRAINING - Epoch: [20][250/390]\tTime 0.072 (0.057)\tData 0.014 (0.004)\tLoss 0.4200 (0.2942)\tPrec@1 84.375 (89.722)\tPrec@5 99.219 (99.692)\t\n",
            "TRAINING - Epoch: [20][260/390]\tTime 0.054 (0.057)\tData 0.008 (0.004)\tLoss 0.1572 (0.2944)\tPrec@1 95.312 (89.766)\tPrec@5 100.000 (99.692)\t\n",
            "TRAINING - Epoch: [20][270/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2894 (0.2945)\tPrec@1 91.406 (89.749)\tPrec@5 100.000 (99.697)\t\n",
            "TRAINING - Epoch: [20][280/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.1895 (0.2935)\tPrec@1 92.969 (89.780)\tPrec@5 100.000 (99.705)\t\n",
            "TRAINING - Epoch: [20][290/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1954 (0.2950)\tPrec@1 92.969 (89.734)\tPrec@5 100.000 (99.699)\t\n",
            "TRAINING - Epoch: [20][300/390]\tTime 0.075 (0.057)\tData 0.013 (0.004)\tLoss 0.2335 (0.2946)\tPrec@1 92.969 (89.743)\tPrec@5 100.000 (99.707)\t\n",
            "TRAINING - Epoch: [20][310/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.3395 (0.2955)\tPrec@1 88.281 (89.713)\tPrec@5 99.219 (99.706)\t\n",
            "TRAINING - Epoch: [20][320/390]\tTime 0.062 (0.057)\tData 0.012 (0.004)\tLoss 0.2733 (0.2959)\tPrec@1 92.188 (89.717)\tPrec@5 100.000 (99.710)\t\n",
            "TRAINING - Epoch: [20][330/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2911 (0.2965)\tPrec@1 89.844 (89.704)\tPrec@5 100.000 (99.712)\t\n",
            "TRAINING - Epoch: [20][340/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2259 (0.2962)\tPrec@1 90.625 (89.713)\tPrec@5 99.219 (99.714)\t\n",
            "TRAINING - Epoch: [20][350/390]\tTime 0.052 (0.057)\tData 0.002 (0.004)\tLoss 0.2709 (0.2966)\tPrec@1 91.406 (89.677)\tPrec@5 100.000 (99.722)\t\n",
            "TRAINING - Epoch: [20][360/390]\tTime 0.055 (0.057)\tData 0.000 (0.004)\tLoss 0.2662 (0.2976)\tPrec@1 89.844 (89.638)\tPrec@5 100.000 (99.716)\t\n",
            "TRAINING - Epoch: [20][370/390]\tTime 0.066 (0.057)\tData 0.007 (0.004)\tLoss 0.2945 (0.2978)\tPrec@1 88.281 (89.614)\tPrec@5 100.000 (99.720)\t\n",
            "TRAINING - Epoch: [20][380/390]\tTime 0.058 (0.057)\tData 0.007 (0.004)\tLoss 0.3819 (0.2983)\tPrec@1 84.375 (89.600)\tPrec@5 100.000 (99.719)\t\n",
            "TRAINING - Epoch: [20][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.2099 (0.2986)\tPrec@1 92.969 (89.595)\tPrec@5 100.000 (99.720)\t\n",
            "EVALUATING - Epoch: [20][0/79]\tTime 0.221 (0.221)\tData 0.199 (0.199)\tLoss 0.4633 (0.4633)\tPrec@1 83.594 (83.594)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [20][10/79]\tTime 0.038 (0.052)\tData 0.005 (0.026)\tLoss 0.4756 (0.5418)\tPrec@1 85.156 (83.381)\tPrec@5 99.219 (99.148)\t\n",
            "EVALUATING - Epoch: [20][20/79]\tTime 0.022 (0.042)\tData 0.003 (0.015)\tLoss 0.5691 (0.5631)\tPrec@1 82.031 (82.701)\tPrec@5 96.875 (98.921)\t\n",
            "EVALUATING - Epoch: [20][30/79]\tTime 0.014 (0.038)\tData 0.000 (0.011)\tLoss 0.3483 (0.5690)\tPrec@1 88.281 (82.762)\tPrec@5 100.000 (98.816)\t\n",
            "EVALUATING - Epoch: [20][40/79]\tTime 0.036 (0.036)\tData 0.009 (0.010)\tLoss 0.7763 (0.5686)\tPrec@1 78.125 (83.041)\tPrec@5 100.000 (98.800)\t\n",
            "EVALUATING - Epoch: [20][50/79]\tTime 0.043 (0.035)\tData 0.004 (0.008)\tLoss 0.4998 (0.5621)\tPrec@1 83.594 (83.211)\tPrec@5 100.000 (98.943)\t\n",
            "EVALUATING - Epoch: [20][60/79]\tTime 0.039 (0.034)\tData 0.003 (0.008)\tLoss 0.5315 (0.5748)\tPrec@1 82.812 (82.838)\tPrec@5 98.438 (98.911)\t\n",
            "EVALUATING - Epoch: [20][70/79]\tTime 0.019 (0.033)\tData 0.000 (0.007)\tLoss 0.4133 (0.5763)\tPrec@1 91.406 (82.868)\tPrec@5 100.000 (98.988)\t\n",
            "EVALUATING - Epoch: [20][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.006)\tLoss 0.3430 (0.5717)\tPrec@1 87.500 (83.070)\tPrec@5 100.000 (98.990)\t\n",
            "\n",
            "Results - Epoch: 21\n",
            "Training Loss 0.2986 \tTraining Prec@1 89.595 \tTraining Prec@5 99.720 \tValidation Loss 0.5717 \tValidation Prec@1 83.070 \tValidation Prec@5 98.990 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 22\n",
            "\n",
            "TRAINING - Epoch: [21][0/390]\tTime 0.360 (0.360)\tData 0.261 (0.261)\tLoss 0.4339 (0.4339)\tPrec@1 85.938 (85.938)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [21][10/390]\tTime 0.048 (0.086)\tData 0.000 (0.027)\tLoss 0.2539 (0.2792)\tPrec@1 92.188 (90.696)\tPrec@5 99.219 (99.787)\t\n",
            "TRAINING - Epoch: [21][20/390]\tTime 0.056 (0.071)\tData 0.000 (0.016)\tLoss 0.2943 (0.2816)\tPrec@1 88.281 (90.885)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [21][30/390]\tTime 0.048 (0.066)\tData 0.000 (0.012)\tLoss 0.3417 (0.2774)\tPrec@1 88.281 (90.726)\tPrec@5 99.219 (99.798)\t\n",
            "TRAINING - Epoch: [21][40/390]\tTime 0.059 (0.063)\tData 0.010 (0.010)\tLoss 0.3244 (0.2727)\tPrec@1 89.844 (90.796)\tPrec@5 100.000 (99.829)\t\n",
            "TRAINING - Epoch: [21][50/390]\tTime 0.059 (0.062)\tData 0.010 (0.009)\tLoss 0.2707 (0.2741)\tPrec@1 87.500 (90.594)\tPrec@5 100.000 (99.770)\t\n",
            "TRAINING - Epoch: [21][60/390]\tTime 0.047 (0.061)\tData 0.000 (0.008)\tLoss 0.3103 (0.2831)\tPrec@1 86.719 (90.228)\tPrec@5 99.219 (99.680)\t\n",
            "TRAINING - Epoch: [21][70/390]\tTime 0.054 (0.060)\tData 0.000 (0.007)\tLoss 0.3175 (0.2805)\tPrec@1 89.844 (90.383)\tPrec@5 100.000 (99.703)\t\n",
            "TRAINING - Epoch: [21][80/390]\tTime 0.052 (0.059)\tData 0.000 (0.007)\tLoss 0.2713 (0.2778)\tPrec@1 92.969 (90.451)\tPrec@5 99.219 (99.701)\t\n",
            "TRAINING - Epoch: [21][90/390]\tTime 0.061 (0.059)\tData 0.000 (0.006)\tLoss 0.2058 (0.2731)\tPrec@1 90.625 (90.565)\tPrec@5 100.000 (99.725)\t\n",
            "TRAINING - Epoch: [21][100/390]\tTime 0.048 (0.058)\tData 0.000 (0.006)\tLoss 0.1985 (0.2725)\tPrec@1 95.312 (90.524)\tPrec@5 100.000 (99.737)\t\n",
            "TRAINING - Epoch: [21][110/390]\tTime 0.047 (0.058)\tData 0.000 (0.006)\tLoss 0.3036 (0.2727)\tPrec@1 89.062 (90.491)\tPrec@5 99.219 (99.726)\t\n",
            "TRAINING - Epoch: [21][120/390]\tTime 0.048 (0.058)\tData 0.000 (0.006)\tLoss 0.3073 (0.2730)\tPrec@1 89.062 (90.522)\tPrec@5 99.219 (99.703)\t\n",
            "TRAINING - Epoch: [21][130/390]\tTime 0.047 (0.057)\tData 0.000 (0.006)\tLoss 0.2925 (0.2729)\tPrec@1 89.844 (90.542)\tPrec@5 100.000 (99.708)\t\n",
            "TRAINING - Epoch: [21][140/390]\tTime 0.062 (0.057)\tData 0.007 (0.005)\tLoss 0.2573 (0.2779)\tPrec@1 92.969 (90.376)\tPrec@5 99.219 (99.690)\t\n",
            "TRAINING - Epoch: [21][150/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.3479 (0.2777)\tPrec@1 88.281 (90.382)\tPrec@5 100.000 (99.695)\t\n",
            "TRAINING - Epoch: [21][160/390]\tTime 0.047 (0.057)\tData 0.000 (0.005)\tLoss 0.1897 (0.2769)\tPrec@1 92.188 (90.441)\tPrec@5 100.000 (99.714)\t\n",
            "TRAINING - Epoch: [21][170/390]\tTime 0.051 (0.057)\tData 0.000 (0.005)\tLoss 0.2567 (0.2771)\tPrec@1 91.406 (90.456)\tPrec@5 100.000 (99.721)\t\n",
            "TRAINING - Epoch: [21][180/390]\tTime 0.058 (0.057)\tData 0.007 (0.005)\tLoss 0.3615 (0.2771)\tPrec@1 92.188 (90.478)\tPrec@5 98.438 (99.715)\t\n",
            "TRAINING - Epoch: [21][190/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.1964 (0.2764)\tPrec@1 93.750 (90.494)\tPrec@5 100.000 (99.710)\t\n",
            "TRAINING - Epoch: [21][200/390]\tTime 0.060 (0.057)\tData 0.007 (0.005)\tLoss 0.2076 (0.2772)\tPrec@1 94.531 (90.454)\tPrec@5 100.000 (99.712)\t\n",
            "TRAINING - Epoch: [21][210/390]\tTime 0.064 (0.057)\tData 0.006 (0.005)\tLoss 0.2990 (0.2769)\tPrec@1 87.500 (90.440)\tPrec@5 100.000 (99.707)\t\n",
            "TRAINING - Epoch: [21][220/390]\tTime 0.055 (0.057)\tData 0.007 (0.005)\tLoss 0.3644 (0.2771)\tPrec@1 87.500 (90.424)\tPrec@5 100.000 (99.714)\t\n",
            "TRAINING - Epoch: [21][230/390]\tTime 0.064 (0.057)\tData 0.000 (0.005)\tLoss 0.2809 (0.2770)\tPrec@1 89.062 (90.398)\tPrec@5 100.000 (99.716)\t\n",
            "TRAINING - Epoch: [21][240/390]\tTime 0.051 (0.057)\tData 0.000 (0.005)\tLoss 0.3381 (0.2797)\tPrec@1 89.062 (90.336)\tPrec@5 99.219 (99.715)\t\n",
            "TRAINING - Epoch: [21][250/390]\tTime 0.055 (0.057)\tData 0.006 (0.005)\tLoss 0.3570 (0.2809)\tPrec@1 87.500 (90.251)\tPrec@5 100.000 (99.723)\t\n",
            "TRAINING - Epoch: [21][260/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.3181 (0.2820)\tPrec@1 87.500 (90.221)\tPrec@5 100.000 (99.713)\t\n",
            "TRAINING - Epoch: [21][270/390]\tTime 0.046 (0.056)\tData 0.000 (0.005)\tLoss 0.5167 (0.2830)\tPrec@1 85.938 (90.210)\tPrec@5 100.000 (99.706)\t\n",
            "TRAINING - Epoch: [21][280/390]\tTime 0.056 (0.056)\tData 0.007 (0.005)\tLoss 0.2395 (0.2823)\tPrec@1 88.281 (90.236)\tPrec@5 99.219 (99.705)\t\n",
            "TRAINING - Epoch: [21][290/390]\tTime 0.046 (0.056)\tData 0.000 (0.005)\tLoss 0.2889 (0.2837)\tPrec@1 91.406 (90.195)\tPrec@5 100.000 (99.702)\t\n",
            "TRAINING - Epoch: [21][300/390]\tTime 0.052 (0.056)\tData 0.006 (0.005)\tLoss 0.2827 (0.2854)\tPrec@1 87.500 (90.129)\tPrec@5 99.219 (99.686)\t\n",
            "TRAINING - Epoch: [21][310/390]\tTime 0.048 (0.056)\tData 0.000 (0.005)\tLoss 0.3867 (0.2872)\tPrec@1 86.719 (90.060)\tPrec@5 100.000 (99.683)\t\n",
            "TRAINING - Epoch: [21][320/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.3305 (0.2869)\tPrec@1 89.844 (90.073)\tPrec@5 100.000 (99.688)\t\n",
            "TRAINING - Epoch: [21][330/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.2805 (0.2867)\tPrec@1 90.625 (90.070)\tPrec@5 100.000 (99.691)\t\n",
            "TRAINING - Epoch: [21][340/390]\tTime 0.055 (0.056)\tData 0.000 (0.004)\tLoss 0.2678 (0.2866)\tPrec@1 89.844 (90.066)\tPrec@5 100.000 (99.698)\t\n",
            "TRAINING - Epoch: [21][350/390]\tTime 0.052 (0.056)\tData 0.005 (0.004)\tLoss 0.2477 (0.2856)\tPrec@1 92.969 (90.102)\tPrec@5 100.000 (99.704)\t\n",
            "TRAINING - Epoch: [21][360/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.3081 (0.2859)\tPrec@1 90.625 (90.110)\tPrec@5 99.219 (99.706)\t\n",
            "TRAINING - Epoch: [21][370/390]\tTime 0.068 (0.056)\tData 0.000 (0.004)\tLoss 0.4054 (0.2863)\tPrec@1 84.375 (90.088)\tPrec@5 100.000 (99.703)\t\n",
            "TRAINING - Epoch: [21][380/390]\tTime 0.055 (0.056)\tData 0.007 (0.004)\tLoss 0.3755 (0.2870)\tPrec@1 85.156 (90.063)\tPrec@5 100.000 (99.711)\t\n",
            "TRAINING - Epoch: [21][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.2583 (0.2877)\tPrec@1 90.625 (90.024)\tPrec@5 100.000 (99.716)\t\n",
            "EVALUATING - Epoch: [21][0/79]\tTime 0.186 (0.186)\tData 0.157 (0.157)\tLoss 0.3223 (0.3223)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [21][10/79]\tTime 0.024 (0.053)\tData 0.001 (0.024)\tLoss 0.3632 (0.4089)\tPrec@1 85.156 (85.085)\tPrec@5 100.000 (99.645)\t\n",
            "EVALUATING - Epoch: [21][20/79]\tTime 0.037 (0.041)\tData 0.007 (0.015)\tLoss 0.5223 (0.4660)\tPrec@1 85.938 (84.412)\tPrec@5 98.438 (99.330)\t\n",
            "EVALUATING - Epoch: [21][30/79]\tTime 0.025 (0.038)\tData 0.003 (0.012)\tLoss 0.3257 (0.4696)\tPrec@1 86.719 (84.854)\tPrec@5 100.000 (99.320)\t\n",
            "EVALUATING - Epoch: [21][40/79]\tTime 0.032 (0.037)\tData 0.003 (0.010)\tLoss 0.5793 (0.4685)\tPrec@1 79.688 (84.966)\tPrec@5 99.219 (99.276)\t\n",
            "EVALUATING - Epoch: [21][50/79]\tTime 0.042 (0.036)\tData 0.015 (0.009)\tLoss 0.3260 (0.4600)\tPrec@1 87.500 (85.126)\tPrec@5 100.000 (99.341)\t\n",
            "EVALUATING - Epoch: [21][60/79]\tTime 0.024 (0.035)\tData 0.000 (0.008)\tLoss 0.5430 (0.4575)\tPrec@1 83.594 (85.246)\tPrec@5 100.000 (99.334)\t\n",
            "EVALUATING - Epoch: [21][70/79]\tTime 0.031 (0.034)\tData 0.005 (0.008)\tLoss 0.3740 (0.4603)\tPrec@1 88.281 (85.090)\tPrec@5 100.000 (99.362)\t\n",
            "EVALUATING - Epoch: [21][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.3723 (0.4584)\tPrec@1 87.500 (85.140)\tPrec@5 100.000 (99.380)\t\n",
            "\n",
            "Results - Epoch: 22\n",
            "Training Loss 0.2877 \tTraining Prec@1 90.024 \tTraining Prec@5 99.716 \tValidation Loss 0.4584 \tValidation Prec@1 85.140 \tValidation Prec@5 99.380 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 23\n",
            "\n",
            "TRAINING - Epoch: [22][0/390]\tTime 0.396 (0.396)\tData 0.284 (0.284)\tLoss 0.3444 (0.3444)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [22][10/390]\tTime 0.063 (0.088)\tData 0.007 (0.029)\tLoss 0.3501 (0.2463)\tPrec@1 88.281 (92.045)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [22][20/390]\tTime 0.075 (0.072)\tData 0.009 (0.016)\tLoss 0.3926 (0.2610)\tPrec@1 88.281 (91.295)\tPrec@5 97.656 (99.814)\t\n",
            "TRAINING - Epoch: [22][30/390]\tTime 0.049 (0.066)\tData 0.000 (0.012)\tLoss 0.3880 (0.2625)\tPrec@1 88.281 (90.927)\tPrec@5 99.219 (99.748)\t\n",
            "TRAINING - Epoch: [22][40/390]\tTime 0.053 (0.064)\tData 0.000 (0.010)\tLoss 0.2886 (0.2708)\tPrec@1 89.844 (90.777)\tPrec@5 100.000 (99.733)\t\n",
            "TRAINING - Epoch: [22][50/390]\tTime 0.053 (0.062)\tData 0.000 (0.008)\tLoss 0.2407 (0.2676)\tPrec@1 92.188 (91.023)\tPrec@5 99.219 (99.755)\t\n",
            "TRAINING - Epoch: [22][60/390]\tTime 0.056 (0.061)\tData 0.000 (0.007)\tLoss 0.2163 (0.2695)\tPrec@1 95.312 (90.958)\tPrec@5 100.000 (99.782)\t\n",
            "TRAINING - Epoch: [22][70/390]\tTime 0.061 (0.060)\tData 0.000 (0.007)\tLoss 0.2867 (0.2690)\tPrec@1 89.062 (90.834)\tPrec@5 100.000 (99.780)\t\n",
            "TRAINING - Epoch: [22][80/390]\tTime 0.063 (0.059)\tData 0.006 (0.006)\tLoss 0.3879 (0.2709)\tPrec@1 88.281 (90.837)\tPrec@5 100.000 (99.769)\t\n",
            "TRAINING - Epoch: [22][90/390]\tTime 0.061 (0.059)\tData 0.007 (0.006)\tLoss 0.3567 (0.2725)\tPrec@1 85.156 (90.719)\tPrec@5 99.219 (99.751)\t\n",
            "TRAINING - Epoch: [22][100/390]\tTime 0.063 (0.058)\tData 0.007 (0.006)\tLoss 0.3194 (0.2710)\tPrec@1 88.281 (90.702)\tPrec@5 100.000 (99.768)\t\n",
            "TRAINING - Epoch: [22][110/390]\tTime 0.065 (0.058)\tData 0.009 (0.005)\tLoss 0.2140 (0.2745)\tPrec@1 94.531 (90.583)\tPrec@5 100.000 (99.768)\t\n",
            "TRAINING - Epoch: [22][120/390]\tTime 0.054 (0.058)\tData 0.000 (0.005)\tLoss 0.2641 (0.2737)\tPrec@1 89.844 (90.625)\tPrec@5 99.219 (99.761)\t\n",
            "TRAINING - Epoch: [22][130/390]\tTime 0.047 (0.057)\tData 0.000 (0.005)\tLoss 0.3692 (0.2758)\tPrec@1 86.719 (90.506)\tPrec@5 99.219 (99.744)\t\n",
            "TRAINING - Epoch: [22][140/390]\tTime 0.057 (0.057)\tData 0.009 (0.005)\tLoss 0.2494 (0.2754)\tPrec@1 91.406 (90.486)\tPrec@5 100.000 (99.751)\t\n",
            "TRAINING - Epoch: [22][150/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.2771 (0.2757)\tPrec@1 90.625 (90.449)\tPrec@5 100.000 (99.757)\t\n",
            "TRAINING - Epoch: [22][160/390]\tTime 0.061 (0.057)\tData 0.007 (0.005)\tLoss 0.2173 (0.2758)\tPrec@1 92.188 (90.450)\tPrec@5 99.219 (99.757)\t\n",
            "TRAINING - Epoch: [22][170/390]\tTime 0.066 (0.057)\tData 0.013 (0.004)\tLoss 0.2976 (0.2765)\tPrec@1 88.281 (90.465)\tPrec@5 100.000 (99.762)\t\n",
            "TRAINING - Epoch: [22][180/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.3089 (0.2793)\tPrec@1 89.062 (90.388)\tPrec@5 100.000 (99.754)\t\n",
            "TRAINING - Epoch: [22][190/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2575 (0.2780)\tPrec@1 88.281 (90.392)\tPrec@5 100.000 (99.759)\t\n",
            "TRAINING - Epoch: [22][200/390]\tTime 0.051 (0.057)\tData 0.004 (0.004)\tLoss 0.1550 (0.2763)\tPrec@1 94.531 (90.473)\tPrec@5 100.000 (99.755)\t\n",
            "TRAINING - Epoch: [22][210/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.3425 (0.2762)\tPrec@1 85.938 (90.466)\tPrec@5 100.000 (99.752)\t\n",
            "TRAINING - Epoch: [22][220/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2777 (0.2771)\tPrec@1 89.062 (90.438)\tPrec@5 100.000 (99.753)\t\n",
            "TRAINING - Epoch: [22][230/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.2310 (0.2763)\tPrec@1 92.188 (90.449)\tPrec@5 99.219 (99.753)\t\n",
            "TRAINING - Epoch: [22][240/390]\tTime 0.045 (0.056)\tData 0.000 (0.004)\tLoss 0.2554 (0.2769)\tPrec@1 91.406 (90.440)\tPrec@5 100.000 (99.754)\t\n",
            "TRAINING - Epoch: [22][250/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.2793 (0.2793)\tPrec@1 89.062 (90.342)\tPrec@5 100.000 (99.748)\t\n",
            "TRAINING - Epoch: [22][260/390]\tTime 0.051 (0.056)\tData 0.006 (0.004)\tLoss 0.3232 (0.2819)\tPrec@1 90.625 (90.290)\tPrec@5 98.438 (99.740)\t\n",
            "TRAINING - Epoch: [22][270/390]\tTime 0.050 (0.056)\tData 0.000 (0.004)\tLoss 0.2409 (0.2831)\tPrec@1 94.531 (90.265)\tPrec@5 100.000 (99.741)\t\n",
            "TRAINING - Epoch: [22][280/390]\tTime 0.052 (0.056)\tData 0.006 (0.004)\tLoss 0.2176 (0.2828)\tPrec@1 92.188 (90.269)\tPrec@5 100.000 (99.739)\t\n",
            "TRAINING - Epoch: [22][290/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.2201 (0.2824)\tPrec@1 93.750 (90.279)\tPrec@5 99.219 (99.734)\t\n",
            "TRAINING - Epoch: [22][300/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.2644 (0.2815)\tPrec@1 92.188 (90.295)\tPrec@5 100.000 (99.735)\t\n",
            "TRAINING - Epoch: [22][310/390]\tTime 0.050 (0.056)\tData 0.000 (0.004)\tLoss 0.2412 (0.2817)\tPrec@1 89.844 (90.268)\tPrec@5 99.219 (99.731)\t\n",
            "TRAINING - Epoch: [22][320/390]\tTime 0.058 (0.056)\tData 0.006 (0.004)\tLoss 0.3830 (0.2825)\tPrec@1 89.062 (90.240)\tPrec@5 98.438 (99.727)\t\n",
            "TRAINING - Epoch: [22][330/390]\tTime 0.054 (0.056)\tData 0.006 (0.004)\tLoss 0.3188 (0.2821)\tPrec@1 92.969 (90.287)\tPrec@5 100.000 (99.731)\t\n",
            "TRAINING - Epoch: [22][340/390]\tTime 0.049 (0.056)\tData 0.002 (0.004)\tLoss 0.4313 (0.2826)\tPrec@1 86.719 (90.281)\tPrec@5 98.438 (99.730)\t\n",
            "TRAINING - Epoch: [22][350/390]\tTime 0.068 (0.056)\tData 0.013 (0.004)\tLoss 0.2037 (0.2827)\tPrec@1 92.969 (90.256)\tPrec@5 99.219 (99.728)\t\n",
            "TRAINING - Epoch: [22][360/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.3049 (0.2818)\tPrec@1 90.625 (90.274)\tPrec@5 100.000 (99.736)\t\n",
            "TRAINING - Epoch: [22][370/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.3264 (0.2817)\tPrec@1 89.062 (90.282)\tPrec@5 100.000 (99.737)\t\n",
            "TRAINING - Epoch: [22][380/390]\tTime 0.055 (0.056)\tData 0.007 (0.004)\tLoss 0.2774 (0.2812)\tPrec@1 89.062 (90.287)\tPrec@5 100.000 (99.742)\t\n",
            "TRAINING - Epoch: [22][389/390]\tTime 0.041 (0.055)\tData 0.000 (0.004)\tLoss 0.2463 (0.2801)\tPrec@1 90.625 (90.323)\tPrec@5 100.000 (99.746)\t\n",
            "EVALUATING - Epoch: [22][0/79]\tTime 0.207 (0.207)\tData 0.161 (0.161)\tLoss 0.3629 (0.3629)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [22][10/79]\tTime 0.031 (0.054)\tData 0.001 (0.022)\tLoss 0.4242 (0.4551)\tPrec@1 82.031 (84.659)\tPrec@5 100.000 (99.361)\t\n",
            "EVALUATING - Epoch: [22][20/79]\tTime 0.019 (0.041)\tData 0.000 (0.013)\tLoss 0.4940 (0.5104)\tPrec@1 81.250 (83.780)\tPrec@5 99.219 (99.107)\t\n",
            "EVALUATING - Epoch: [22][30/79]\tTime 0.027 (0.038)\tData 0.005 (0.011)\tLoss 0.5586 (0.5099)\tPrec@1 85.938 (83.997)\tPrec@5 100.000 (99.194)\t\n",
            "EVALUATING - Epoch: [22][40/79]\tTime 0.037 (0.036)\tData 0.004 (0.009)\tLoss 0.5379 (0.5090)\tPrec@1 85.938 (84.013)\tPrec@5 99.219 (99.295)\t\n",
            "EVALUATING - Epoch: [22][50/79]\tTime 0.015 (0.034)\tData 0.000 (0.008)\tLoss 0.5794 (0.4968)\tPrec@1 79.688 (84.268)\tPrec@5 100.000 (99.326)\t\n",
            "EVALUATING - Epoch: [22][60/79]\tTime 0.029 (0.033)\tData 0.000 (0.007)\tLoss 0.5091 (0.4975)\tPrec@1 85.156 (84.260)\tPrec@5 99.219 (99.372)\t\n",
            "EVALUATING - Epoch: [22][70/79]\tTime 0.036 (0.033)\tData 0.003 (0.007)\tLoss 0.4533 (0.4990)\tPrec@1 85.938 (84.232)\tPrec@5 99.219 (99.351)\t\n",
            "EVALUATING - Epoch: [22][78/79]\tTime 0.005 (0.030)\tData 0.000 (0.006)\tLoss 0.2666 (0.4960)\tPrec@1 93.750 (84.220)\tPrec@5 100.000 (99.340)\t\n",
            "\n",
            "Results - Epoch: 23\n",
            "Training Loss 0.2801 \tTraining Prec@1 90.323 \tTraining Prec@5 99.746 \tValidation Loss 0.4960 \tValidation Prec@1 84.220 \tValidation Prec@5 99.340 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 24\n",
            "\n",
            "TRAINING - Epoch: [23][0/390]\tTime 0.396 (0.396)\tData 0.304 (0.304)\tLoss 0.2285 (0.2285)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [23][10/390]\tTime 0.056 (0.088)\tData 0.010 (0.033)\tLoss 0.2432 (0.2483)\tPrec@1 93.750 (91.406)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [23][20/390]\tTime 0.057 (0.072)\tData 0.000 (0.019)\tLoss 0.2905 (0.2533)\tPrec@1 90.625 (91.369)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [23][30/390]\tTime 0.046 (0.066)\tData 0.000 (0.013)\tLoss 0.1681 (0.2408)\tPrec@1 95.312 (91.759)\tPrec@5 100.000 (99.849)\t\n",
            "TRAINING - Epoch: [23][40/390]\tTime 0.048 (0.064)\tData 0.001 (0.012)\tLoss 0.2302 (0.2399)\tPrec@1 90.625 (91.730)\tPrec@5 100.000 (99.829)\t\n",
            "TRAINING - Epoch: [23][50/390]\tTime 0.055 (0.062)\tData 0.007 (0.010)\tLoss 0.2370 (0.2385)\tPrec@1 89.062 (91.682)\tPrec@5 100.000 (99.831)\t\n",
            "TRAINING - Epoch: [23][60/390]\tTime 0.069 (0.061)\tData 0.013 (0.009)\tLoss 0.2133 (0.2348)\tPrec@1 92.969 (91.867)\tPrec@5 100.000 (99.846)\t\n",
            "TRAINING - Epoch: [23][70/390]\tTime 0.062 (0.060)\tData 0.000 (0.008)\tLoss 0.1989 (0.2337)\tPrec@1 91.406 (91.824)\tPrec@5 99.219 (99.846)\t\n",
            "TRAINING - Epoch: [23][80/390]\tTime 0.047 (0.059)\tData 0.000 (0.008)\tLoss 0.3775 (0.2400)\tPrec@1 88.281 (91.734)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [23][90/390]\tTime 0.075 (0.059)\tData 0.000 (0.007)\tLoss 0.2852 (0.2411)\tPrec@1 90.625 (91.707)\tPrec@5 100.000 (99.811)\t\n",
            "TRAINING - Epoch: [23][100/390]\tTime 0.047 (0.059)\tData 0.000 (0.007)\tLoss 0.1639 (0.2432)\tPrec@1 93.750 (91.561)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [23][110/390]\tTime 0.050 (0.058)\tData 0.000 (0.006)\tLoss 0.2782 (0.2463)\tPrec@1 91.406 (91.519)\tPrec@5 100.000 (99.796)\t\n",
            "TRAINING - Epoch: [23][120/390]\tTime 0.064 (0.058)\tData 0.009 (0.006)\tLoss 0.2085 (0.2506)\tPrec@1 91.406 (91.393)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [23][130/390]\tTime 0.052 (0.058)\tData 0.005 (0.006)\tLoss 0.3995 (0.2547)\tPrec@1 85.156 (91.180)\tPrec@5 99.219 (99.797)\t\n",
            "TRAINING - Epoch: [23][140/390]\tTime 0.070 (0.058)\tData 0.000 (0.006)\tLoss 0.3223 (0.2534)\tPrec@1 87.500 (91.212)\tPrec@5 99.219 (99.784)\t\n",
            "TRAINING - Epoch: [23][150/390]\tTime 0.053 (0.058)\tData 0.004 (0.006)\tLoss 0.2373 (0.2543)\tPrec@1 91.406 (91.153)\tPrec@5 100.000 (99.788)\t\n",
            "TRAINING - Epoch: [23][160/390]\tTime 0.055 (0.058)\tData 0.006 (0.005)\tLoss 0.3094 (0.2560)\tPrec@1 89.062 (91.144)\tPrec@5 100.000 (99.777)\t\n",
            "TRAINING - Epoch: [23][170/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.2853 (0.2574)\tPrec@1 90.625 (91.082)\tPrec@5 100.000 (99.781)\t\n",
            "TRAINING - Epoch: [23][180/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.2641 (0.2590)\tPrec@1 88.281 (91.022)\tPrec@5 100.000 (99.784)\t\n",
            "TRAINING - Epoch: [23][190/390]\tTime 0.064 (0.057)\tData 0.004 (0.005)\tLoss 0.3376 (0.2604)\tPrec@1 89.062 (90.956)\tPrec@5 100.000 (99.791)\t\n",
            "TRAINING - Epoch: [23][200/390]\tTime 0.063 (0.057)\tData 0.007 (0.005)\tLoss 0.5294 (0.2629)\tPrec@1 85.156 (90.897)\tPrec@5 97.656 (99.771)\t\n",
            "TRAINING - Epoch: [23][210/390]\tTime 0.056 (0.057)\tData 0.007 (0.005)\tLoss 0.1384 (0.2632)\tPrec@1 95.312 (90.877)\tPrec@5 100.000 (99.774)\t\n",
            "TRAINING - Epoch: [23][220/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.2606 (0.2644)\tPrec@1 89.844 (90.837)\tPrec@5 100.000 (99.781)\t\n",
            "TRAINING - Epoch: [23][230/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.2176 (0.2630)\tPrec@1 92.188 (90.912)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [23][240/390]\tTime 0.049 (0.057)\tData 0.003 (0.005)\tLoss 0.3912 (0.2633)\tPrec@1 86.719 (90.914)\tPrec@5 100.000 (99.789)\t\n",
            "TRAINING - Epoch: [23][250/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.2364 (0.2637)\tPrec@1 94.531 (90.890)\tPrec@5 100.000 (99.785)\t\n",
            "TRAINING - Epoch: [23][260/390]\tTime 0.053 (0.057)\tData 0.000 (0.005)\tLoss 0.2046 (0.2636)\tPrec@1 92.969 (90.888)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [23][270/390]\tTime 0.076 (0.057)\tData 0.007 (0.005)\tLoss 0.1716 (0.2635)\tPrec@1 94.531 (90.873)\tPrec@5 100.000 (99.792)\t\n",
            "TRAINING - Epoch: [23][280/390]\tTime 0.072 (0.057)\tData 0.005 (0.005)\tLoss 0.2187 (0.2656)\tPrec@1 94.531 (90.811)\tPrec@5 100.000 (99.783)\t\n",
            "TRAINING - Epoch: [23][290/390]\tTime 0.048 (0.056)\tData 0.000 (0.005)\tLoss 0.1905 (0.2661)\tPrec@1 92.969 (90.800)\tPrec@5 100.000 (99.780)\t\n",
            "TRAINING - Epoch: [23][300/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.2594 (0.2673)\tPrec@1 89.844 (90.765)\tPrec@5 100.000 (99.782)\t\n",
            "TRAINING - Epoch: [23][310/390]\tTime 0.058 (0.056)\tData 0.000 (0.004)\tLoss 0.2797 (0.2684)\tPrec@1 91.406 (90.728)\tPrec@5 99.219 (99.781)\t\n",
            "TRAINING - Epoch: [23][320/390]\tTime 0.066 (0.056)\tData 0.007 (0.004)\tLoss 0.2654 (0.2694)\tPrec@1 91.406 (90.696)\tPrec@5 99.219 (99.774)\t\n",
            "TRAINING - Epoch: [23][330/390]\tTime 0.046 (0.056)\tData 0.000 (0.004)\tLoss 0.1758 (0.2702)\tPrec@1 93.750 (90.675)\tPrec@5 100.000 (99.771)\t\n",
            "TRAINING - Epoch: [23][340/390]\tTime 0.059 (0.056)\tData 0.009 (0.004)\tLoss 0.3003 (0.2699)\tPrec@1 85.938 (90.652)\tPrec@5 100.000 (99.771)\t\n",
            "TRAINING - Epoch: [23][350/390]\tTime 0.056 (0.056)\tData 0.000 (0.004)\tLoss 0.4410 (0.2714)\tPrec@1 88.281 (90.601)\tPrec@5 99.219 (99.773)\t\n",
            "TRAINING - Epoch: [23][360/390]\tTime 0.071 (0.056)\tData 0.007 (0.004)\tLoss 0.3730 (0.2718)\tPrec@1 87.500 (90.586)\tPrec@5 99.219 (99.764)\t\n",
            "TRAINING - Epoch: [23][370/390]\tTime 0.050 (0.056)\tData 0.000 (0.004)\tLoss 0.1732 (0.2717)\tPrec@1 94.531 (90.572)\tPrec@5 100.000 (99.762)\t\n",
            "TRAINING - Epoch: [23][380/390]\tTime 0.063 (0.056)\tData 0.000 (0.004)\tLoss 0.3184 (0.2723)\tPrec@1 88.281 (90.533)\tPrec@5 99.219 (99.756)\t\n",
            "TRAINING - Epoch: [23][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.3961 (0.2729)\tPrec@1 86.719 (90.511)\tPrec@5 99.219 (99.754)\t\n",
            "EVALUATING - Epoch: [23][0/79]\tTime 0.203 (0.203)\tData 0.158 (0.158)\tLoss 0.6344 (0.6344)\tPrec@1 81.250 (81.250)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [23][10/79]\tTime 0.025 (0.053)\tData 0.000 (0.019)\tLoss 0.7849 (0.7374)\tPrec@1 75.781 (78.480)\tPrec@5 100.000 (98.651)\t\n",
            "EVALUATING - Epoch: [23][20/79]\tTime 0.012 (0.043)\tData 0.000 (0.013)\tLoss 0.7249 (0.7611)\tPrec@1 75.000 (77.679)\tPrec@5 99.219 (98.586)\t\n",
            "EVALUATING - Epoch: [23][30/79]\tTime 0.020 (0.038)\tData 0.004 (0.010)\tLoss 0.5892 (0.7558)\tPrec@1 83.594 (78.049)\tPrec@5 100.000 (98.690)\t\n",
            "EVALUATING - Epoch: [23][40/79]\tTime 0.012 (0.036)\tData 0.000 (0.009)\tLoss 1.0937 (0.7674)\tPrec@1 74.219 (77.572)\tPrec@5 98.438 (98.761)\t\n",
            "EVALUATING - Epoch: [23][50/79]\tTime 0.026 (0.035)\tData 0.001 (0.007)\tLoss 0.8957 (0.7511)\tPrec@1 72.656 (77.742)\tPrec@5 100.000 (98.882)\t\n",
            "EVALUATING - Epoch: [23][60/79]\tTime 0.013 (0.034)\tData 0.000 (0.007)\tLoss 0.7221 (0.7508)\tPrec@1 83.594 (77.766)\tPrec@5 98.438 (98.847)\t\n",
            "EVALUATING - Epoch: [23][70/79]\tTime 0.019 (0.033)\tData 0.006 (0.007)\tLoss 0.5601 (0.7525)\tPrec@1 82.031 (77.608)\tPrec@5 99.219 (98.856)\t\n",
            "EVALUATING - Epoch: [23][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.006)\tLoss 0.4698 (0.7497)\tPrec@1 87.500 (77.770)\tPrec@5 100.000 (98.840)\t\n",
            "\n",
            "Results - Epoch: 24\n",
            "Training Loss 0.2729 \tTraining Prec@1 90.511 \tTraining Prec@5 99.754 \tValidation Loss 0.7497 \tValidation Prec@1 77.770 \tValidation Prec@5 98.840 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 25\n",
            "\n",
            "TRAINING - Epoch: [24][0/390]\tTime 0.393 (0.393)\tData 0.295 (0.295)\tLoss 0.2611 (0.2611)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [24][10/390]\tTime 0.069 (0.090)\tData 0.000 (0.028)\tLoss 0.2189 (0.2422)\tPrec@1 92.969 (91.690)\tPrec@5 100.000 (99.716)\t\n",
            "TRAINING - Epoch: [24][20/390]\tTime 0.049 (0.073)\tData 0.000 (0.016)\tLoss 0.1763 (0.2486)\tPrec@1 94.531 (91.369)\tPrec@5 99.219 (99.665)\t\n",
            "TRAINING - Epoch: [24][30/390]\tTime 0.046 (0.067)\tData 0.000 (0.012)\tLoss 0.1475 (0.2448)\tPrec@1 94.531 (91.154)\tPrec@5 100.000 (99.773)\t\n",
            "TRAINING - Epoch: [24][40/390]\tTime 0.048 (0.064)\tData 0.000 (0.010)\tLoss 0.1718 (0.2490)\tPrec@1 93.750 (91.216)\tPrec@5 100.000 (99.809)\t\n",
            "TRAINING - Epoch: [24][50/390]\tTime 0.052 (0.062)\tData 0.000 (0.010)\tLoss 0.2692 (0.2519)\tPrec@1 89.844 (91.115)\tPrec@5 100.000 (99.831)\t\n",
            "TRAINING - Epoch: [24][60/390]\tTime 0.056 (0.061)\tData 0.007 (0.009)\tLoss 0.2506 (0.2583)\tPrec@1 91.406 (90.881)\tPrec@5 100.000 (99.846)\t\n",
            "TRAINING - Epoch: [24][70/390]\tTime 0.065 (0.060)\tData 0.008 (0.008)\tLoss 0.2574 (0.2571)\tPrec@1 91.406 (90.955)\tPrec@5 100.000 (99.835)\t\n",
            "TRAINING - Epoch: [24][80/390]\tTime 0.058 (0.059)\tData 0.000 (0.008)\tLoss 0.2166 (0.2595)\tPrec@1 93.750 (90.953)\tPrec@5 100.000 (99.846)\t\n",
            "TRAINING - Epoch: [24][90/390]\tTime 0.050 (0.059)\tData 0.000 (0.007)\tLoss 0.2206 (0.2604)\tPrec@1 92.188 (90.883)\tPrec@5 99.219 (99.828)\t\n",
            "TRAINING - Epoch: [24][100/390]\tTime 0.066 (0.059)\tData 0.006 (0.007)\tLoss 0.1849 (0.2593)\tPrec@1 93.750 (90.919)\tPrec@5 100.000 (99.830)\t\n",
            "TRAINING - Epoch: [24][110/390]\tTime 0.053 (0.058)\tData 0.000 (0.007)\tLoss 0.2275 (0.2600)\tPrec@1 91.406 (90.907)\tPrec@5 100.000 (99.831)\t\n",
            "TRAINING - Epoch: [24][120/390]\tTime 0.048 (0.058)\tData 0.000 (0.006)\tLoss 0.1648 (0.2574)\tPrec@1 96.094 (91.006)\tPrec@5 100.000 (99.826)\t\n",
            "TRAINING - Epoch: [24][130/390]\tTime 0.055 (0.058)\tData 0.007 (0.006)\tLoss 0.2962 (0.2573)\tPrec@1 91.406 (91.031)\tPrec@5 100.000 (99.839)\t\n",
            "TRAINING - Epoch: [24][140/390]\tTime 0.047 (0.058)\tData 0.000 (0.006)\tLoss 0.2342 (0.2581)\tPrec@1 95.312 (91.057)\tPrec@5 100.000 (99.839)\t\n",
            "TRAINING - Epoch: [24][150/390]\tTime 0.046 (0.057)\tData 0.000 (0.006)\tLoss 0.3138 (0.2585)\tPrec@1 89.062 (91.060)\tPrec@5 100.000 (99.845)\t\n",
            "TRAINING - Epoch: [24][160/390]\tTime 0.063 (0.057)\tData 0.011 (0.006)\tLoss 0.2814 (0.2599)\tPrec@1 87.500 (90.926)\tPrec@5 100.000 (99.854)\t\n",
            "TRAINING - Epoch: [24][170/390]\tTime 0.058 (0.057)\tData 0.006 (0.005)\tLoss 0.3446 (0.2593)\tPrec@1 89.844 (90.949)\tPrec@5 99.219 (99.849)\t\n",
            "TRAINING - Epoch: [24][180/390]\tTime 0.054 (0.057)\tData 0.003 (0.005)\tLoss 0.3208 (0.2590)\tPrec@1 89.844 (90.992)\tPrec@5 98.438 (99.840)\t\n",
            "TRAINING - Epoch: [24][190/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.2786 (0.2601)\tPrec@1 90.625 (90.956)\tPrec@5 100.000 (99.840)\t\n",
            "TRAINING - Epoch: [24][200/390]\tTime 0.060 (0.057)\tData 0.007 (0.005)\tLoss 0.3434 (0.2612)\tPrec@1 86.719 (90.940)\tPrec@5 100.000 (99.845)\t\n",
            "TRAINING - Epoch: [24][210/390]\tTime 0.058 (0.057)\tData 0.000 (0.005)\tLoss 0.2085 (0.2615)\tPrec@1 92.188 (90.892)\tPrec@5 100.000 (99.837)\t\n",
            "TRAINING - Epoch: [24][220/390]\tTime 0.054 (0.057)\tData 0.000 (0.005)\tLoss 0.2827 (0.2604)\tPrec@1 90.625 (90.954)\tPrec@5 100.000 (99.834)\t\n",
            "TRAINING - Epoch: [24][230/390]\tTime 0.056 (0.057)\tData 0.009 (0.005)\tLoss 0.2819 (0.2625)\tPrec@1 92.188 (90.892)\tPrec@5 100.000 (99.828)\t\n",
            "TRAINING - Epoch: [24][240/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.2914 (0.2631)\tPrec@1 91.406 (90.897)\tPrec@5 100.000 (99.818)\t\n",
            "TRAINING - Epoch: [24][250/390]\tTime 0.069 (0.057)\tData 0.012 (0.005)\tLoss 0.2452 (0.2629)\tPrec@1 89.844 (90.899)\tPrec@5 100.000 (99.826)\t\n",
            "TRAINING - Epoch: [24][260/390]\tTime 0.076 (0.057)\tData 0.006 (0.005)\tLoss 0.2603 (0.2629)\tPrec@1 90.625 (90.885)\tPrec@5 100.000 (99.820)\t\n",
            "TRAINING - Epoch: [24][270/390]\tTime 0.057 (0.057)\tData 0.008 (0.005)\tLoss 0.2857 (0.2643)\tPrec@1 88.281 (90.833)\tPrec@5 99.219 (99.815)\t\n",
            "TRAINING - Epoch: [24][280/390]\tTime 0.059 (0.057)\tData 0.012 (0.005)\tLoss 0.2259 (0.2636)\tPrec@1 91.406 (90.872)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [24][290/390]\tTime 0.063 (0.057)\tData 0.007 (0.005)\tLoss 0.1285 (0.2628)\tPrec@1 94.531 (90.864)\tPrec@5 100.000 (99.823)\t\n",
            "TRAINING - Epoch: [24][300/390]\tTime 0.057 (0.057)\tData 0.008 (0.005)\tLoss 0.3763 (0.2637)\tPrec@1 87.500 (90.830)\tPrec@5 99.219 (99.821)\t\n",
            "TRAINING - Epoch: [24][310/390]\tTime 0.046 (0.056)\tData 0.000 (0.005)\tLoss 0.2410 (0.2638)\tPrec@1 90.625 (90.816)\tPrec@5 99.219 (99.817)\t\n",
            "TRAINING - Epoch: [24][320/390]\tTime 0.046 (0.056)\tData 0.000 (0.005)\tLoss 0.2751 (0.2632)\tPrec@1 92.188 (90.856)\tPrec@5 99.219 (99.817)\t\n",
            "TRAINING - Epoch: [24][330/390]\tTime 0.067 (0.056)\tData 0.008 (0.005)\tLoss 0.3768 (0.2632)\tPrec@1 86.719 (90.868)\tPrec@5 100.000 (99.821)\t\n",
            "TRAINING - Epoch: [24][340/390]\tTime 0.056 (0.056)\tData 0.009 (0.005)\tLoss 0.1832 (0.2634)\tPrec@1 93.750 (90.863)\tPrec@5 99.219 (99.817)\t\n",
            "TRAINING - Epoch: [24][350/390]\tTime 0.070 (0.056)\tData 0.009 (0.004)\tLoss 0.3118 (0.2645)\tPrec@1 90.625 (90.812)\tPrec@5 99.219 (99.813)\t\n",
            "TRAINING - Epoch: [24][360/390]\tTime 0.053 (0.056)\tData 0.005 (0.004)\tLoss 0.2425 (0.2645)\tPrec@1 91.406 (90.781)\tPrec@5 99.219 (99.814)\t\n",
            "TRAINING - Epoch: [24][370/390]\tTime 0.063 (0.056)\tData 0.000 (0.004)\tLoss 0.2697 (0.2658)\tPrec@1 89.844 (90.737)\tPrec@5 100.000 (99.813)\t\n",
            "TRAINING - Epoch: [24][380/390]\tTime 0.054 (0.056)\tData 0.006 (0.004)\tLoss 0.1669 (0.2652)\tPrec@1 95.312 (90.750)\tPrec@5 100.000 (99.815)\t\n",
            "TRAINING - Epoch: [24][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.4491 (0.2665)\tPrec@1 86.719 (90.715)\tPrec@5 97.656 (99.806)\t\n",
            "EVALUATING - Epoch: [24][0/79]\tTime 0.283 (0.283)\tData 0.253 (0.253)\tLoss 0.5555 (0.5555)\tPrec@1 83.594 (83.594)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [24][10/79]\tTime 0.048 (0.051)\tData 0.011 (0.028)\tLoss 0.5493 (0.6269)\tPrec@1 85.938 (81.463)\tPrec@5 99.219 (99.574)\t\n",
            "EVALUATING - Epoch: [24][20/79]\tTime 0.029 (0.042)\tData 0.000 (0.016)\tLoss 0.4968 (0.6487)\tPrec@1 84.375 (80.878)\tPrec@5 99.219 (99.330)\t\n",
            "EVALUATING - Epoch: [24][30/79]\tTime 0.013 (0.038)\tData 0.000 (0.013)\tLoss 0.5354 (0.6350)\tPrec@1 85.938 (81.376)\tPrec@5 100.000 (99.168)\t\n",
            "EVALUATING - Epoch: [24][40/79]\tTime 0.020 (0.036)\tData 0.000 (0.011)\tLoss 0.8873 (0.6250)\tPrec@1 74.219 (81.593)\tPrec@5 98.438 (99.104)\t\n",
            "EVALUATING - Epoch: [24][50/79]\tTime 0.032 (0.035)\tData 0.000 (0.009)\tLoss 0.7228 (0.6196)\tPrec@1 75.781 (81.725)\tPrec@5 100.000 (99.157)\t\n",
            "EVALUATING - Epoch: [24][60/79]\tTime 0.028 (0.034)\tData 0.000 (0.009)\tLoss 0.7070 (0.6189)\tPrec@1 81.250 (81.826)\tPrec@5 98.438 (99.142)\t\n",
            "EVALUATING - Epoch: [24][70/79]\tTime 0.023 (0.033)\tData 0.010 (0.008)\tLoss 0.5953 (0.6209)\tPrec@1 86.719 (81.679)\tPrec@5 100.000 (99.175)\t\n",
            "EVALUATING - Epoch: [24][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.2391 (0.6182)\tPrec@1 93.750 (81.770)\tPrec@5 100.000 (99.190)\t\n",
            "\n",
            "Results - Epoch: 25\n",
            "Training Loss 0.2665 \tTraining Prec@1 90.715 \tTraining Prec@5 99.806 \tValidation Loss 0.6182 \tValidation Prec@1 81.770 \tValidation Prec@5 99.190 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 26\n",
            "\n",
            "TRAINING - Epoch: [25][0/390]\tTime 0.399 (0.399)\tData 0.274 (0.274)\tLoss 0.2408 (0.2408)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [25][10/390]\tTime 0.059 (0.088)\tData 0.007 (0.029)\tLoss 0.3195 (0.2451)\tPrec@1 89.844 (91.122)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [25][20/390]\tTime 0.055 (0.072)\tData 0.007 (0.016)\tLoss 0.3634 (0.2579)\tPrec@1 85.938 (90.737)\tPrec@5 100.000 (99.702)\t\n",
            "TRAINING - Epoch: [25][30/390]\tTime 0.056 (0.066)\tData 0.006 (0.012)\tLoss 0.2150 (0.2522)\tPrec@1 91.406 (90.852)\tPrec@5 100.000 (99.798)\t\n",
            "TRAINING - Epoch: [25][40/390]\tTime 0.049 (0.063)\tData 0.000 (0.010)\tLoss 0.3157 (0.2638)\tPrec@1 89.844 (90.377)\tPrec@5 100.000 (99.829)\t\n",
            "TRAINING - Epoch: [25][50/390]\tTime 0.046 (0.061)\tData 0.000 (0.008)\tLoss 0.3558 (0.2659)\tPrec@1 88.281 (90.564)\tPrec@5 100.000 (99.770)\t\n",
            "TRAINING - Epoch: [25][60/390]\tTime 0.056 (0.060)\tData 0.000 (0.007)\tLoss 0.2336 (0.2655)\tPrec@1 89.062 (90.612)\tPrec@5 99.219 (99.769)\t\n",
            "TRAINING - Epoch: [25][70/390]\tTime 0.056 (0.060)\tData 0.007 (0.007)\tLoss 0.1934 (0.2672)\tPrec@1 92.969 (90.526)\tPrec@5 100.000 (99.791)\t\n",
            "TRAINING - Epoch: [25][80/390]\tTime 0.049 (0.059)\tData 0.002 (0.006)\tLoss 0.3391 (0.2711)\tPrec@1 90.625 (90.451)\tPrec@5 100.000 (99.778)\t\n",
            "TRAINING - Epoch: [25][90/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.2564 (0.2698)\tPrec@1 91.406 (90.488)\tPrec@5 99.219 (99.760)\t\n",
            "TRAINING - Epoch: [25][100/390]\tTime 0.049 (0.058)\tData 0.000 (0.006)\tLoss 0.2904 (0.2678)\tPrec@1 89.844 (90.617)\tPrec@5 100.000 (99.776)\t\n",
            "TRAINING - Epoch: [25][110/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.2653 (0.2649)\tPrec@1 93.750 (90.752)\tPrec@5 100.000 (99.796)\t\n",
            "TRAINING - Epoch: [25][120/390]\tTime 0.058 (0.058)\tData 0.006 (0.005)\tLoss 0.3509 (0.2610)\tPrec@1 89.062 (90.916)\tPrec@5 100.000 (99.800)\t\n",
            "TRAINING - Epoch: [25][130/390]\tTime 0.056 (0.058)\tData 0.007 (0.005)\tLoss 0.2082 (0.2594)\tPrec@1 94.531 (91.007)\tPrec@5 100.000 (99.791)\t\n",
            "TRAINING - Epoch: [25][140/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.3608 (0.2574)\tPrec@1 85.156 (91.057)\tPrec@5 100.000 (99.795)\t\n",
            "TRAINING - Epoch: [25][150/390]\tTime 0.079 (0.058)\tData 0.007 (0.005)\tLoss 0.3550 (0.2577)\tPrec@1 89.062 (91.049)\tPrec@5 100.000 (99.783)\t\n",
            "TRAINING - Epoch: [25][160/390]\tTime 0.070 (0.057)\tData 0.009 (0.005)\tLoss 0.2065 (0.2557)\tPrec@1 91.406 (91.086)\tPrec@5 100.000 (99.791)\t\n",
            "TRAINING - Epoch: [25][170/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.3091 (0.2586)\tPrec@1 89.844 (90.981)\tPrec@5 100.000 (99.790)\t\n",
            "TRAINING - Epoch: [25][180/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2624 (0.2589)\tPrec@1 92.188 (90.944)\tPrec@5 99.219 (99.789)\t\n",
            "TRAINING - Epoch: [25][190/390]\tTime 0.053 (0.057)\tData 0.005 (0.004)\tLoss 0.2522 (0.2621)\tPrec@1 92.969 (90.903)\tPrec@5 100.000 (99.763)\t\n",
            "TRAINING - Epoch: [25][200/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.3120 (0.2618)\tPrec@1 89.062 (90.878)\tPrec@5 100.000 (99.767)\t\n",
            "TRAINING - Epoch: [25][210/390]\tTime 0.054 (0.057)\tData 0.000 (0.004)\tLoss 0.2762 (0.2619)\tPrec@1 92.969 (90.932)\tPrec@5 99.219 (99.756)\t\n",
            "TRAINING - Epoch: [25][220/390]\tTime 0.055 (0.057)\tData 0.006 (0.004)\tLoss 0.1972 (0.2608)\tPrec@1 92.969 (90.971)\tPrec@5 100.000 (99.767)\t\n",
            "TRAINING - Epoch: [25][230/390]\tTime 0.056 (0.057)\tData 0.004 (0.004)\tLoss 0.2233 (0.2599)\tPrec@1 89.062 (90.987)\tPrec@5 100.000 (99.773)\t\n",
            "TRAINING - Epoch: [25][240/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.2963 (0.2599)\tPrec@1 90.625 (90.972)\tPrec@5 100.000 (99.773)\t\n",
            "TRAINING - Epoch: [25][250/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.3481 (0.2602)\tPrec@1 87.500 (90.949)\tPrec@5 99.219 (99.773)\t\n",
            "TRAINING - Epoch: [25][260/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2357 (0.2609)\tPrec@1 92.188 (90.936)\tPrec@5 99.219 (99.773)\t\n",
            "TRAINING - Epoch: [25][270/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2916 (0.2613)\tPrec@1 90.625 (90.908)\tPrec@5 100.000 (99.769)\t\n",
            "TRAINING - Epoch: [25][280/390]\tTime 0.057 (0.057)\tData 0.010 (0.004)\tLoss 0.2575 (0.2620)\tPrec@1 89.062 (90.861)\tPrec@5 99.219 (99.766)\t\n",
            "TRAINING - Epoch: [25][290/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.2715 (0.2627)\tPrec@1 92.188 (90.853)\tPrec@5 100.000 (99.764)\t\n",
            "TRAINING - Epoch: [25][300/390]\tTime 0.055 (0.057)\tData 0.009 (0.004)\tLoss 0.2186 (0.2626)\tPrec@1 89.844 (90.861)\tPrec@5 100.000 (99.761)\t\n",
            "TRAINING - Epoch: [25][310/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.1796 (0.2619)\tPrec@1 94.531 (90.889)\tPrec@5 99.219 (99.761)\t\n",
            "TRAINING - Epoch: [25][320/390]\tTime 0.060 (0.056)\tData 0.000 (0.004)\tLoss 0.2518 (0.2614)\tPrec@1 90.625 (90.890)\tPrec@5 100.000 (99.761)\t\n",
            "TRAINING - Epoch: [25][330/390]\tTime 0.064 (0.056)\tData 0.006 (0.004)\tLoss 0.2401 (0.2620)\tPrec@1 93.750 (90.894)\tPrec@5 99.219 (99.762)\t\n",
            "TRAINING - Epoch: [25][340/390]\tTime 0.064 (0.056)\tData 0.013 (0.004)\tLoss 0.2502 (0.2633)\tPrec@1 92.969 (90.870)\tPrec@5 99.219 (99.757)\t\n",
            "TRAINING - Epoch: [25][350/390]\tTime 0.056 (0.056)\tData 0.008 (0.004)\tLoss 0.2103 (0.2623)\tPrec@1 91.406 (90.894)\tPrec@5 100.000 (99.757)\t\n",
            "TRAINING - Epoch: [25][360/390]\tTime 0.066 (0.056)\tData 0.006 (0.004)\tLoss 0.2559 (0.2627)\tPrec@1 88.281 (90.893)\tPrec@5 100.000 (99.753)\t\n",
            "TRAINING - Epoch: [25][370/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.3395 (0.2633)\tPrec@1 86.719 (90.852)\tPrec@5 100.000 (99.752)\t\n",
            "TRAINING - Epoch: [25][380/390]\tTime 0.077 (0.056)\tData 0.007 (0.004)\tLoss 0.1710 (0.2625)\tPrec@1 92.969 (90.892)\tPrec@5 100.000 (99.754)\t\n",
            "TRAINING - Epoch: [25][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.2719 (0.2629)\tPrec@1 90.625 (90.861)\tPrec@5 100.000 (99.756)\t\n",
            "EVALUATING - Epoch: [25][0/79]\tTime 0.209 (0.209)\tData 0.179 (0.179)\tLoss 0.3340 (0.3340)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [25][10/79]\tTime 0.052 (0.054)\tData 0.010 (0.028)\tLoss 0.4171 (0.4319)\tPrec@1 86.719 (86.577)\tPrec@5 99.219 (99.432)\t\n",
            "EVALUATING - Epoch: [25][20/79]\tTime 0.017 (0.043)\tData 0.000 (0.016)\tLoss 0.4139 (0.4642)\tPrec@1 82.031 (85.603)\tPrec@5 98.438 (99.293)\t\n",
            "EVALUATING - Epoch: [25][30/79]\tTime 0.035 (0.039)\tData 0.016 (0.013)\tLoss 0.3561 (0.4470)\tPrec@1 88.281 (86.139)\tPrec@5 100.000 (99.345)\t\n",
            "EVALUATING - Epoch: [25][40/79]\tTime 0.027 (0.036)\tData 0.000 (0.011)\tLoss 0.6606 (0.4369)\tPrec@1 80.469 (86.414)\tPrec@5 100.000 (99.428)\t\n",
            "EVALUATING - Epoch: [25][50/79]\tTime 0.045 (0.035)\tData 0.005 (0.010)\tLoss 0.4960 (0.4399)\tPrec@1 82.812 (86.428)\tPrec@5 100.000 (99.464)\t\n",
            "EVALUATING - Epoch: [25][60/79]\tTime 0.056 (0.034)\tData 0.009 (0.009)\tLoss 0.4274 (0.4387)\tPrec@1 85.156 (86.565)\tPrec@5 99.219 (99.475)\t\n",
            "EVALUATING - Epoch: [25][70/79]\tTime 0.028 (0.034)\tData 0.000 (0.009)\tLoss 0.2759 (0.4345)\tPrec@1 92.969 (86.532)\tPrec@5 100.000 (99.494)\t\n",
            "EVALUATING - Epoch: [25][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.008)\tLoss 0.1355 (0.4297)\tPrec@1 93.750 (86.660)\tPrec@5 100.000 (99.480)\t\n",
            "\n",
            "Results - Epoch: 26\n",
            "Training Loss 0.2629 \tTraining Prec@1 90.861 \tTraining Prec@5 99.756 \tValidation Loss 0.4297 \tValidation Prec@1 86.660 \tValidation Prec@5 99.480 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 27\n",
            "\n",
            "TRAINING - Epoch: [26][0/390]\tTime 0.327 (0.327)\tData 0.177 (0.177)\tLoss 0.1917 (0.1917)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [26][10/390]\tTime 0.047 (0.088)\tData 0.000 (0.018)\tLoss 0.2312 (0.2527)\tPrec@1 90.625 (91.406)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [26][20/390]\tTime 0.048 (0.072)\tData 0.000 (0.011)\tLoss 0.1509 (0.2566)\tPrec@1 95.312 (90.811)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [26][30/390]\tTime 0.058 (0.067)\tData 0.008 (0.009)\tLoss 0.2545 (0.2559)\tPrec@1 90.625 (91.028)\tPrec@5 100.000 (99.748)\t\n",
            "TRAINING - Epoch: [26][40/390]\tTime 0.053 (0.064)\tData 0.000 (0.008)\tLoss 0.2407 (0.2476)\tPrec@1 92.969 (91.540)\tPrec@5 100.000 (99.809)\t\n",
            "TRAINING - Epoch: [26][50/390]\tTime 0.050 (0.062)\tData 0.001 (0.007)\tLoss 0.3158 (0.2464)\tPrec@1 87.500 (91.559)\tPrec@5 99.219 (99.801)\t\n",
            "TRAINING - Epoch: [26][60/390]\tTime 0.056 (0.061)\tData 0.006 (0.006)\tLoss 0.2322 (0.2447)\tPrec@1 92.188 (91.470)\tPrec@5 100.000 (99.782)\t\n",
            "TRAINING - Epoch: [26][70/390]\tTime 0.047 (0.060)\tData 0.000 (0.006)\tLoss 0.3285 (0.2430)\tPrec@1 87.500 (91.450)\tPrec@5 100.000 (99.780)\t\n",
            "TRAINING - Epoch: [26][80/390]\tTime 0.055 (0.059)\tData 0.007 (0.006)\tLoss 0.2209 (0.2413)\tPrec@1 91.406 (91.570)\tPrec@5 100.000 (99.788)\t\n",
            "TRAINING - Epoch: [26][90/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 0.1246 (0.2385)\tPrec@1 95.312 (91.707)\tPrec@5 100.000 (99.811)\t\n",
            "TRAINING - Epoch: [26][100/390]\tTime 0.053 (0.059)\tData 0.000 (0.005)\tLoss 0.1866 (0.2411)\tPrec@1 92.188 (91.522)\tPrec@5 100.000 (99.822)\t\n",
            "TRAINING - Epoch: [26][110/390]\tTime 0.062 (0.059)\tData 0.012 (0.005)\tLoss 0.3560 (0.2412)\tPrec@1 85.156 (91.505)\tPrec@5 100.000 (99.838)\t\n",
            "TRAINING - Epoch: [26][120/390]\tTime 0.058 (0.059)\tData 0.009 (0.005)\tLoss 0.3364 (0.2423)\tPrec@1 88.281 (91.490)\tPrec@5 100.000 (99.839)\t\n",
            "TRAINING - Epoch: [26][130/390]\tTime 0.050 (0.058)\tData 0.003 (0.005)\tLoss 0.3113 (0.2439)\tPrec@1 88.281 (91.424)\tPrec@5 100.000 (99.833)\t\n",
            "TRAINING - Epoch: [26][140/390]\tTime 0.052 (0.058)\tData 0.004 (0.005)\tLoss 0.2899 (0.2481)\tPrec@1 87.500 (91.318)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [26][150/390]\tTime 0.062 (0.058)\tData 0.008 (0.005)\tLoss 0.3552 (0.2496)\tPrec@1 85.938 (91.282)\tPrec@5 100.000 (99.819)\t\n",
            "TRAINING - Epoch: [26][160/390]\tTime 0.064 (0.058)\tData 0.007 (0.005)\tLoss 0.2501 (0.2515)\tPrec@1 89.844 (91.270)\tPrec@5 100.000 (99.830)\t\n",
            "TRAINING - Epoch: [26][170/390]\tTime 0.060 (0.058)\tData 0.007 (0.005)\tLoss 0.3609 (0.2534)\tPrec@1 87.500 (91.210)\tPrec@5 100.000 (99.822)\t\n",
            "TRAINING - Epoch: [26][180/390]\tTime 0.056 (0.058)\tData 0.007 (0.004)\tLoss 0.2937 (0.2544)\tPrec@1 89.844 (91.190)\tPrec@5 99.219 (99.814)\t\n",
            "TRAINING - Epoch: [26][190/390]\tTime 0.050 (0.058)\tData 0.000 (0.004)\tLoss 0.2728 (0.2563)\tPrec@1 89.844 (91.132)\tPrec@5 100.000 (99.812)\t\n",
            "TRAINING - Epoch: [26][200/390]\tTime 0.071 (0.058)\tData 0.007 (0.004)\tLoss 0.2484 (0.2575)\tPrec@1 92.969 (91.084)\tPrec@5 100.000 (99.813)\t\n",
            "TRAINING - Epoch: [26][210/390]\tTime 0.062 (0.058)\tData 0.010 (0.004)\tLoss 0.2626 (0.2570)\tPrec@1 89.844 (91.080)\tPrec@5 99.219 (99.819)\t\n",
            "TRAINING - Epoch: [26][220/390]\tTime 0.060 (0.058)\tData 0.011 (0.004)\tLoss 0.2436 (0.2577)\tPrec@1 90.625 (91.032)\tPrec@5 100.000 (99.813)\t\n",
            "TRAINING - Epoch: [26][230/390]\tTime 0.053 (0.058)\tData 0.004 (0.004)\tLoss 0.3367 (0.2570)\tPrec@1 90.625 (91.092)\tPrec@5 99.219 (99.817)\t\n",
            "TRAINING - Epoch: [26][240/390]\tTime 0.059 (0.058)\tData 0.009 (0.004)\tLoss 0.2085 (0.2562)\tPrec@1 92.969 (91.127)\tPrec@5 99.219 (99.818)\t\n",
            "TRAINING - Epoch: [26][250/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2224 (0.2569)\tPrec@1 92.188 (91.089)\tPrec@5 100.000 (99.816)\t\n",
            "TRAINING - Epoch: [26][260/390]\tTime 0.057 (0.057)\tData 0.006 (0.004)\tLoss 0.3150 (0.2577)\tPrec@1 86.719 (91.053)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [26][270/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.2805 (0.2582)\tPrec@1 89.062 (91.017)\tPrec@5 100.000 (99.821)\t\n",
            "TRAINING - Epoch: [26][280/390]\tTime 0.058 (0.057)\tData 0.000 (0.004)\tLoss 0.3407 (0.2583)\tPrec@1 90.625 (91.020)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [26][290/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2175 (0.2584)\tPrec@1 92.188 (90.998)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [26][300/390]\tTime 0.059 (0.057)\tData 0.007 (0.004)\tLoss 0.2042 (0.2579)\tPrec@1 91.406 (91.004)\tPrec@5 100.000 (99.818)\t\n",
            "TRAINING - Epoch: [26][310/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2853 (0.2579)\tPrec@1 91.406 (91.019)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [26][320/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.2136 (0.2581)\tPrec@1 92.188 (90.997)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [26][330/390]\tTime 0.056 (0.057)\tData 0.000 (0.004)\tLoss 0.2693 (0.2584)\tPrec@1 89.844 (90.991)\tPrec@5 100.000 (99.816)\t\n",
            "TRAINING - Epoch: [26][340/390]\tTime 0.052 (0.057)\tData 0.005 (0.004)\tLoss 0.1728 (0.2574)\tPrec@1 92.188 (91.037)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [26][350/390]\tTime 0.054 (0.057)\tData 0.000 (0.004)\tLoss 0.2349 (0.2576)\tPrec@1 90.625 (91.046)\tPrec@5 99.219 (99.815)\t\n",
            "TRAINING - Epoch: [26][360/390]\tTime 0.053 (0.057)\tData 0.006 (0.004)\tLoss 0.3096 (0.2575)\tPrec@1 88.281 (91.034)\tPrec@5 100.000 (99.818)\t\n",
            "TRAINING - Epoch: [26][370/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1827 (0.2580)\tPrec@1 93.750 (91.029)\tPrec@5 100.000 (99.813)\t\n",
            "TRAINING - Epoch: [26][380/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.3229 (0.2582)\tPrec@1 92.188 (91.039)\tPrec@5 100.000 (99.811)\t\n",
            "TRAINING - Epoch: [26][389/390]\tTime 0.043 (0.056)\tData 0.000 (0.004)\tLoss 0.3464 (0.2581)\tPrec@1 84.375 (91.022)\tPrec@5 100.000 (99.814)\t\n",
            "EVALUATING - Epoch: [26][0/79]\tTime 0.239 (0.239)\tData 0.208 (0.208)\tLoss 0.4985 (0.4985)\tPrec@1 85.938 (85.938)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [26][10/79]\tTime 0.047 (0.058)\tData 0.002 (0.025)\tLoss 0.3413 (0.3694)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (99.645)\t\n",
            "EVALUATING - Epoch: [26][20/79]\tTime 0.018 (0.045)\tData 0.000 (0.015)\tLoss 0.2934 (0.4044)\tPrec@1 89.844 (87.240)\tPrec@5 98.438 (99.516)\t\n",
            "EVALUATING - Epoch: [26][30/79]\tTime 0.034 (0.037)\tData 0.014 (0.011)\tLoss 0.3802 (0.3997)\tPrec@1 88.281 (87.399)\tPrec@5 100.000 (99.521)\t\n",
            "EVALUATING - Epoch: [26][40/79]\tTime 0.055 (0.036)\tData 0.006 (0.010)\tLoss 0.5527 (0.3988)\tPrec@1 78.906 (87.424)\tPrec@5 98.438 (99.428)\t\n",
            "EVALUATING - Epoch: [26][50/79]\tTime 0.044 (0.035)\tData 0.000 (0.009)\tLoss 0.4490 (0.3951)\tPrec@1 82.812 (87.423)\tPrec@5 100.000 (99.510)\t\n",
            "EVALUATING - Epoch: [26][60/79]\tTime 0.032 (0.035)\tData 0.012 (0.008)\tLoss 0.3919 (0.3985)\tPrec@1 85.938 (87.295)\tPrec@5 100.000 (99.501)\t\n",
            "EVALUATING - Epoch: [26][70/79]\tTime 0.015 (0.035)\tData 0.000 (0.008)\tLoss 0.3621 (0.3984)\tPrec@1 90.625 (87.225)\tPrec@5 100.000 (99.527)\t\n",
            "EVALUATING - Epoch: [26][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.1600 (0.3949)\tPrec@1 93.750 (87.310)\tPrec@5 100.000 (99.530)\t\n",
            "\n",
            "Results - Epoch: 27\n",
            "Training Loss 0.2581 \tTraining Prec@1 91.022 \tTraining Prec@5 99.814 \tValidation Loss 0.3949 \tValidation Prec@1 87.310 \tValidation Prec@5 99.530 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 28\n",
            "\n",
            "TRAINING - Epoch: [27][0/390]\tTime 0.329 (0.329)\tData 0.219 (0.219)\tLoss 0.1750 (0.1750)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [27][10/390]\tTime 0.047 (0.087)\tData 0.000 (0.022)\tLoss 0.1854 (0.2115)\tPrec@1 92.969 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [27][20/390]\tTime 0.046 (0.072)\tData 0.000 (0.013)\tLoss 0.2738 (0.2225)\tPrec@1 90.625 (91.815)\tPrec@5 99.219 (99.814)\t\n",
            "TRAINING - Epoch: [27][30/390]\tTime 0.049 (0.066)\tData 0.000 (0.010)\tLoss 0.1872 (0.2161)\tPrec@1 93.750 (92.188)\tPrec@5 100.000 (99.849)\t\n",
            "TRAINING - Epoch: [27][40/390]\tTime 0.050 (0.063)\tData 0.000 (0.008)\tLoss 0.2521 (0.2225)\tPrec@1 92.188 (91.940)\tPrec@5 100.000 (99.867)\t\n",
            "TRAINING - Epoch: [27][50/390]\tTime 0.068 (0.062)\tData 0.012 (0.007)\tLoss 0.1942 (0.2227)\tPrec@1 92.969 (92.096)\tPrec@5 99.219 (99.862)\t\n",
            "TRAINING - Epoch: [27][60/390]\tTime 0.055 (0.061)\tData 0.000 (0.007)\tLoss 0.2156 (0.2255)\tPrec@1 92.969 (91.931)\tPrec@5 100.000 (99.872)\t\n",
            "TRAINING - Epoch: [27][70/390]\tTime 0.049 (0.060)\tData 0.000 (0.006)\tLoss 0.2240 (0.2228)\tPrec@1 90.625 (92.044)\tPrec@5 100.000 (99.890)\t\n",
            "TRAINING - Epoch: [27][80/390]\tTime 0.044 (0.059)\tData 0.000 (0.006)\tLoss 0.2683 (0.2288)\tPrec@1 89.844 (91.869)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [27][90/390]\tTime 0.046 (0.059)\tData 0.000 (0.005)\tLoss 0.1625 (0.2310)\tPrec@1 94.531 (91.861)\tPrec@5 100.000 (99.888)\t\n",
            "TRAINING - Epoch: [27][100/390]\tTime 0.057 (0.058)\tData 0.007 (0.005)\tLoss 0.1844 (0.2321)\tPrec@1 92.188 (91.754)\tPrec@5 100.000 (99.884)\t\n",
            "TRAINING - Epoch: [27][110/390]\tTime 0.053 (0.059)\tData 0.004 (0.005)\tLoss 0.2204 (0.2338)\tPrec@1 91.406 (91.653)\tPrec@5 100.000 (99.880)\t\n",
            "TRAINING - Epoch: [27][120/390]\tTime 0.077 (0.059)\tData 0.008 (0.005)\tLoss 0.2013 (0.2348)\tPrec@1 94.531 (91.671)\tPrec@5 100.000 (99.864)\t\n",
            "TRAINING - Epoch: [27][130/390]\tTime 0.074 (0.059)\tData 0.007 (0.005)\tLoss 0.2327 (0.2360)\tPrec@1 92.188 (91.698)\tPrec@5 99.219 (99.839)\t\n",
            "TRAINING - Epoch: [27][140/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 0.1419 (0.2359)\tPrec@1 93.750 (91.783)\tPrec@5 100.000 (99.823)\t\n",
            "TRAINING - Epoch: [27][150/390]\tTime 0.069 (0.059)\tData 0.010 (0.005)\tLoss 0.1814 (0.2379)\tPrec@1 92.969 (91.717)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [27][160/390]\tTime 0.050 (0.058)\tData 0.002 (0.005)\tLoss 0.2820 (0.2396)\tPrec@1 90.625 (91.639)\tPrec@5 100.000 (99.816)\t\n",
            "TRAINING - Epoch: [27][170/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.2239 (0.2431)\tPrec@1 90.625 (91.511)\tPrec@5 100.000 (99.794)\t\n",
            "TRAINING - Epoch: [27][180/390]\tTime 0.054 (0.058)\tData 0.007 (0.005)\tLoss 0.2324 (0.2420)\tPrec@1 94.531 (91.575)\tPrec@5 99.219 (99.801)\t\n",
            "TRAINING - Epoch: [27][190/390]\tTime 0.059 (0.058)\tData 0.000 (0.005)\tLoss 0.2625 (0.2422)\tPrec@1 91.406 (91.541)\tPrec@5 100.000 (99.808)\t\n",
            "TRAINING - Epoch: [27][200/390]\tTime 0.051 (0.058)\tData 0.000 (0.004)\tLoss 0.2123 (0.2415)\tPrec@1 92.969 (91.581)\tPrec@5 100.000 (99.810)\t\n",
            "TRAINING - Epoch: [27][210/390]\tTime 0.070 (0.058)\tData 0.007 (0.004)\tLoss 0.1721 (0.2411)\tPrec@1 94.531 (91.554)\tPrec@5 100.000 (99.815)\t\n",
            "TRAINING - Epoch: [27][220/390]\tTime 0.055 (0.058)\tData 0.009 (0.004)\tLoss 0.2872 (0.2417)\tPrec@1 86.719 (91.530)\tPrec@5 100.000 (99.809)\t\n",
            "TRAINING - Epoch: [27][230/390]\tTime 0.057 (0.058)\tData 0.000 (0.004)\tLoss 0.2804 (0.2428)\tPrec@1 91.406 (91.508)\tPrec@5 100.000 (99.804)\t\n",
            "TRAINING - Epoch: [27][240/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.1859 (0.2429)\tPrec@1 91.406 (91.474)\tPrec@5 100.000 (99.805)\t\n",
            "TRAINING - Epoch: [27][250/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2059 (0.2422)\tPrec@1 91.406 (91.515)\tPrec@5 100.000 (99.810)\t\n",
            "TRAINING - Epoch: [27][260/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.3703 (0.2426)\tPrec@1 90.625 (91.523)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [27][270/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1876 (0.2432)\tPrec@1 94.531 (91.493)\tPrec@5 100.000 (99.810)\t\n",
            "TRAINING - Epoch: [27][280/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2874 (0.2447)\tPrec@1 88.281 (91.437)\tPrec@5 100.000 (99.800)\t\n",
            "TRAINING - Epoch: [27][290/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2770 (0.2459)\tPrec@1 86.719 (91.366)\tPrec@5 100.000 (99.793)\t\n",
            "TRAINING - Epoch: [27][300/390]\tTime 0.082 (0.057)\tData 0.007 (0.004)\tLoss 0.3026 (0.2469)\tPrec@1 89.844 (91.339)\tPrec@5 100.000 (99.792)\t\n",
            "TRAINING - Epoch: [27][310/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.2135 (0.2475)\tPrec@1 94.531 (91.323)\tPrec@5 100.000 (99.797)\t\n",
            "TRAINING - Epoch: [27][320/390]\tTime 0.064 (0.057)\tData 0.008 (0.004)\tLoss 0.2318 (0.2484)\tPrec@1 92.188 (91.285)\tPrec@5 100.000 (99.800)\t\n",
            "TRAINING - Epoch: [27][330/390]\tTime 0.060 (0.057)\tData 0.011 (0.004)\tLoss 0.2443 (0.2481)\tPrec@1 92.969 (91.274)\tPrec@5 100.000 (99.806)\t\n",
            "TRAINING - Epoch: [27][340/390]\tTime 0.076 (0.057)\tData 0.003 (0.004)\tLoss 0.3672 (0.2484)\tPrec@1 85.156 (91.260)\tPrec@5 99.219 (99.801)\t\n",
            "TRAINING - Epoch: [27][350/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1721 (0.2484)\tPrec@1 94.531 (91.259)\tPrec@5 100.000 (99.802)\t\n",
            "TRAINING - Epoch: [27][360/390]\tTime 0.070 (0.057)\tData 0.010 (0.004)\tLoss 0.1602 (0.2483)\tPrec@1 94.531 (91.283)\tPrec@5 100.000 (99.805)\t\n",
            "TRAINING - Epoch: [27][370/390]\tTime 0.067 (0.057)\tData 0.010 (0.004)\tLoss 0.2918 (0.2489)\tPrec@1 89.844 (91.225)\tPrec@5 100.000 (99.804)\t\n",
            "TRAINING - Epoch: [27][380/390]\tTime 0.058 (0.057)\tData 0.007 (0.004)\tLoss 0.2454 (0.2487)\tPrec@1 90.625 (91.230)\tPrec@5 100.000 (99.807)\t\n",
            "TRAINING - Epoch: [27][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.2134 (0.2486)\tPrec@1 92.969 (91.242)\tPrec@5 100.000 (99.810)\t\n",
            "EVALUATING - Epoch: [27][0/79]\tTime 0.216 (0.216)\tData 0.172 (0.172)\tLoss 0.4091 (0.4091)\tPrec@1 85.938 (85.938)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [27][10/79]\tTime 0.039 (0.056)\tData 0.003 (0.025)\tLoss 0.3306 (0.3922)\tPrec@1 89.062 (87.358)\tPrec@5 100.000 (99.645)\t\n",
            "EVALUATING - Epoch: [27][20/79]\tTime 0.031 (0.046)\tData 0.000 (0.014)\tLoss 0.4387 (0.4154)\tPrec@1 87.500 (86.979)\tPrec@5 99.219 (99.516)\t\n",
            "EVALUATING - Epoch: [27][30/79]\tTime 0.029 (0.042)\tData 0.000 (0.012)\tLoss 0.3662 (0.4163)\tPrec@1 89.062 (86.971)\tPrec@5 100.000 (99.446)\t\n",
            "EVALUATING - Epoch: [27][40/79]\tTime 0.029 (0.039)\tData 0.007 (0.010)\tLoss 0.5199 (0.4137)\tPrec@1 83.594 (87.081)\tPrec@5 100.000 (99.466)\t\n",
            "EVALUATING - Epoch: [27][50/79]\tTime 0.012 (0.036)\tData 0.000 (0.009)\tLoss 0.3733 (0.4100)\tPrec@1 90.625 (87.117)\tPrec@5 100.000 (99.525)\t\n",
            "EVALUATING - Epoch: [27][60/79]\tTime 0.049 (0.035)\tData 0.009 (0.008)\tLoss 0.2799 (0.4098)\tPrec@1 91.406 (87.154)\tPrec@5 99.219 (99.526)\t\n",
            "EVALUATING - Epoch: [27][70/79]\tTime 0.020 (0.035)\tData 0.000 (0.007)\tLoss 0.3340 (0.4047)\tPrec@1 89.844 (87.247)\tPrec@5 100.000 (99.593)\t\n",
            "EVALUATING - Epoch: [27][78/79]\tTime 0.005 (0.033)\tData 0.000 (0.006)\tLoss 0.2361 (0.4016)\tPrec@1 93.750 (87.260)\tPrec@5 100.000 (99.620)\t\n",
            "\n",
            "Results - Epoch: 28\n",
            "Training Loss 0.2486 \tTraining Prec@1 91.242 \tTraining Prec@5 99.810 \tValidation Loss 0.4016 \tValidation Prec@1 87.260 \tValidation Prec@5 99.620 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 29\n",
            "\n",
            "TRAINING - Epoch: [28][0/390]\tTime 0.383 (0.383)\tData 0.276 (0.276)\tLoss 0.3491 (0.3491)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [28][10/390]\tTime 0.072 (0.088)\tData 0.000 (0.027)\tLoss 0.2324 (0.2224)\tPrec@1 92.969 (92.045)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [28][20/390]\tTime 0.061 (0.075)\tData 0.000 (0.016)\tLoss 0.1251 (0.2181)\tPrec@1 96.094 (92.299)\tPrec@5 100.000 (99.851)\t\n",
            "TRAINING - Epoch: [28][30/390]\tTime 0.049 (0.069)\tData 0.000 (0.012)\tLoss 0.2003 (0.2162)\tPrec@1 92.188 (92.414)\tPrec@5 100.000 (99.824)\t\n",
            "TRAINING - Epoch: [28][40/390]\tTime 0.074 (0.067)\tData 0.003 (0.010)\tLoss 0.2293 (0.2160)\tPrec@1 92.188 (92.492)\tPrec@5 100.000 (99.829)\t\n",
            "TRAINING - Epoch: [28][50/390]\tTime 0.055 (0.064)\tData 0.000 (0.009)\tLoss 0.2800 (0.2191)\tPrec@1 91.406 (92.479)\tPrec@5 99.219 (99.831)\t\n",
            "TRAINING - Epoch: [28][60/390]\tTime 0.061 (0.064)\tData 0.007 (0.008)\tLoss 0.2633 (0.2192)\tPrec@1 89.062 (92.469)\tPrec@5 100.000 (99.821)\t\n",
            "TRAINING - Epoch: [28][70/390]\tTime 0.056 (0.063)\tData 0.007 (0.007)\tLoss 0.1592 (0.2176)\tPrec@1 93.750 (92.551)\tPrec@5 100.000 (99.824)\t\n",
            "TRAINING - Epoch: [28][80/390]\tTime 0.062 (0.062)\tData 0.000 (0.007)\tLoss 0.1706 (0.2212)\tPrec@1 93.750 (92.477)\tPrec@5 100.000 (99.807)\t\n",
            "TRAINING - Epoch: [28][90/390]\tTime 0.059 (0.062)\tData 0.009 (0.007)\tLoss 0.2374 (0.2246)\tPrec@1 92.188 (92.282)\tPrec@5 100.000 (99.794)\t\n",
            "TRAINING - Epoch: [28][100/390]\tTime 0.082 (0.062)\tData 0.006 (0.006)\tLoss 0.2498 (0.2260)\tPrec@1 90.625 (92.257)\tPrec@5 100.000 (99.799)\t\n",
            "TRAINING - Epoch: [28][110/390]\tTime 0.060 (0.061)\tData 0.010 (0.006)\tLoss 0.2095 (0.2304)\tPrec@1 91.406 (92.089)\tPrec@5 100.000 (99.796)\t\n",
            "TRAINING - Epoch: [28][120/390]\tTime 0.086 (0.061)\tData 0.009 (0.006)\tLoss 0.1347 (0.2311)\tPrec@1 93.750 (92.071)\tPrec@5 100.000 (99.793)\t\n",
            "TRAINING - Epoch: [28][130/390]\tTime 0.046 (0.060)\tData 0.000 (0.005)\tLoss 0.3024 (0.2356)\tPrec@1 91.406 (91.943)\tPrec@5 99.219 (99.791)\t\n",
            "TRAINING - Epoch: [28][140/390]\tTime 0.068 (0.060)\tData 0.009 (0.005)\tLoss 0.2345 (0.2358)\tPrec@1 92.969 (91.966)\tPrec@5 99.219 (99.789)\t\n",
            "TRAINING - Epoch: [28][150/390]\tTime 0.049 (0.060)\tData 0.000 (0.005)\tLoss 0.2223 (0.2361)\tPrec@1 90.625 (91.893)\tPrec@5 100.000 (99.798)\t\n",
            "TRAINING - Epoch: [28][160/390]\tTime 0.067 (0.060)\tData 0.010 (0.005)\tLoss 0.2330 (0.2382)\tPrec@1 92.188 (91.794)\tPrec@5 100.000 (99.801)\t\n",
            "TRAINING - Epoch: [28][170/390]\tTime 0.060 (0.059)\tData 0.006 (0.005)\tLoss 0.4199 (0.2404)\tPrec@1 89.062 (91.781)\tPrec@5 100.000 (99.799)\t\n",
            "TRAINING - Epoch: [28][180/390]\tTime 0.053 (0.059)\tData 0.007 (0.005)\tLoss 0.2921 (0.2400)\tPrec@1 91.406 (91.821)\tPrec@5 100.000 (99.806)\t\n",
            "TRAINING - Epoch: [28][190/390]\tTime 0.066 (0.059)\tData 0.007 (0.005)\tLoss 0.2879 (0.2420)\tPrec@1 89.062 (91.733)\tPrec@5 100.000 (99.795)\t\n",
            "TRAINING - Epoch: [28][200/390]\tTime 0.062 (0.059)\tData 0.006 (0.005)\tLoss 0.2963 (0.2429)\tPrec@1 88.281 (91.686)\tPrec@5 100.000 (99.798)\t\n",
            "TRAINING - Epoch: [28][210/390]\tTime 0.051 (0.059)\tData 0.000 (0.005)\tLoss 0.2495 (0.2435)\tPrec@1 91.406 (91.669)\tPrec@5 100.000 (99.807)\t\n",
            "TRAINING - Epoch: [28][220/390]\tTime 0.062 (0.059)\tData 0.009 (0.005)\tLoss 0.2557 (0.2460)\tPrec@1 92.188 (91.618)\tPrec@5 100.000 (99.802)\t\n",
            "TRAINING - Epoch: [28][230/390]\tTime 0.051 (0.059)\tData 0.000 (0.005)\tLoss 0.2375 (0.2459)\tPrec@1 89.844 (91.606)\tPrec@5 100.000 (99.804)\t\n",
            "TRAINING - Epoch: [28][240/390]\tTime 0.053 (0.059)\tData 0.000 (0.005)\tLoss 0.1950 (0.2456)\tPrec@1 92.969 (91.607)\tPrec@5 100.000 (99.805)\t\n",
            "TRAINING - Epoch: [28][250/390]\tTime 0.049 (0.059)\tData 0.000 (0.005)\tLoss 0.2589 (0.2456)\tPrec@1 90.625 (91.596)\tPrec@5 100.000 (99.798)\t\n",
            "TRAINING - Epoch: [28][260/390]\tTime 0.059 (0.059)\tData 0.009 (0.005)\tLoss 0.2379 (0.2446)\tPrec@1 91.406 (91.607)\tPrec@5 99.219 (99.802)\t\n",
            "TRAINING - Epoch: [28][270/390]\tTime 0.072 (0.059)\tData 0.007 (0.005)\tLoss 0.1593 (0.2452)\tPrec@1 92.969 (91.559)\tPrec@5 100.000 (99.795)\t\n",
            "TRAINING - Epoch: [28][280/390]\tTime 0.069 (0.059)\tData 0.012 (0.005)\tLoss 0.3167 (0.2467)\tPrec@1 88.281 (91.504)\tPrec@5 99.219 (99.786)\t\n",
            "TRAINING - Epoch: [28][290/390]\tTime 0.066 (0.059)\tData 0.006 (0.005)\tLoss 0.3570 (0.2472)\tPrec@1 86.719 (91.500)\tPrec@5 100.000 (99.791)\t\n",
            "TRAINING - Epoch: [28][300/390]\tTime 0.064 (0.059)\tData 0.000 (0.005)\tLoss 0.2245 (0.2470)\tPrec@1 92.188 (91.515)\tPrec@5 100.000 (99.790)\t\n",
            "TRAINING - Epoch: [28][310/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.2504 (0.2477)\tPrec@1 92.188 (91.482)\tPrec@5 99.219 (99.789)\t\n",
            "TRAINING - Epoch: [28][320/390]\tTime 0.060 (0.059)\tData 0.008 (0.004)\tLoss 0.3538 (0.2485)\tPrec@1 86.719 (91.460)\tPrec@5 100.000 (99.793)\t\n",
            "TRAINING - Epoch: [28][330/390]\tTime 0.053 (0.059)\tData 0.000 (0.004)\tLoss 0.3174 (0.2493)\tPrec@1 89.844 (91.430)\tPrec@5 99.219 (99.792)\t\n",
            "TRAINING - Epoch: [28][340/390]\tTime 0.068 (0.059)\tData 0.009 (0.004)\tLoss 0.2311 (0.2496)\tPrec@1 92.188 (91.420)\tPrec@5 100.000 (99.796)\t\n",
            "TRAINING - Epoch: [28][350/390]\tTime 0.055 (0.059)\tData 0.000 (0.004)\tLoss 0.1907 (0.2494)\tPrec@1 91.406 (91.411)\tPrec@5 99.219 (99.795)\t\n",
            "TRAINING - Epoch: [28][360/390]\tTime 0.064 (0.059)\tData 0.000 (0.004)\tLoss 0.3430 (0.2503)\tPrec@1 87.500 (91.367)\tPrec@5 100.000 (99.797)\t\n",
            "TRAINING - Epoch: [28][370/390]\tTime 0.049 (0.059)\tData 0.000 (0.004)\tLoss 0.2060 (0.2496)\tPrec@1 91.406 (91.396)\tPrec@5 100.000 (99.798)\t\n",
            "TRAINING - Epoch: [28][380/390]\tTime 0.069 (0.059)\tData 0.007 (0.004)\tLoss 0.3149 (0.2493)\tPrec@1 91.406 (91.417)\tPrec@5 100.000 (99.799)\t\n",
            "TRAINING - Epoch: [28][389/390]\tTime 0.040 (0.058)\tData 0.000 (0.004)\tLoss 0.2775 (0.2496)\tPrec@1 89.062 (91.400)\tPrec@5 100.000 (99.802)\t\n",
            "EVALUATING - Epoch: [28][0/79]\tTime 0.284 (0.284)\tData 0.241 (0.241)\tLoss 0.2473 (0.2473)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [28][10/79]\tTime 0.040 (0.058)\tData 0.010 (0.026)\tLoss 0.2960 (0.3512)\tPrec@1 91.406 (88.849)\tPrec@5 100.000 (99.858)\t\n",
            "EVALUATING - Epoch: [28][20/79]\tTime 0.042 (0.047)\tData 0.001 (0.015)\tLoss 0.3794 (0.3824)\tPrec@1 87.500 (88.021)\tPrec@5 98.438 (99.665)\t\n",
            "EVALUATING - Epoch: [28][30/79]\tTime 0.051 (0.042)\tData 0.000 (0.012)\tLoss 0.2548 (0.3850)\tPrec@1 90.625 (87.903)\tPrec@5 100.000 (99.471)\t\n",
            "EVALUATING - Epoch: [28][40/79]\tTime 0.036 (0.039)\tData 0.007 (0.010)\tLoss 0.4529 (0.3834)\tPrec@1 82.812 (87.748)\tPrec@5 99.219 (99.466)\t\n",
            "EVALUATING - Epoch: [28][50/79]\tTime 0.025 (0.037)\tData 0.005 (0.009)\tLoss 0.3456 (0.3817)\tPrec@1 87.500 (87.837)\tPrec@5 100.000 (99.525)\t\n",
            "EVALUATING - Epoch: [28][60/79]\tTime 0.045 (0.037)\tData 0.007 (0.008)\tLoss 0.3440 (0.3813)\tPrec@1 87.500 (87.820)\tPrec@5 100.000 (99.539)\t\n",
            "EVALUATING - Epoch: [28][70/79]\tTime 0.030 (0.036)\tData 0.000 (0.007)\tLoss 0.2577 (0.3799)\tPrec@1 92.969 (87.874)\tPrec@5 100.000 (99.560)\t\n",
            "EVALUATING - Epoch: [28][78/79]\tTime 0.005 (0.033)\tData 0.000 (0.007)\tLoss 0.2901 (0.3758)\tPrec@1 87.500 (87.990)\tPrec@5 100.000 (99.590)\t\n",
            "\n",
            "Results - Epoch: 29\n",
            "Training Loss 0.2496 \tTraining Prec@1 91.400 \tTraining Prec@5 99.802 \tValidation Loss 0.3758 \tValidation Prec@1 87.990 \tValidation Prec@5 99.590 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 30\n",
            "\n",
            "TRAINING - Epoch: [29][0/390]\tTime 0.402 (0.402)\tData 0.268 (0.268)\tLoss 0.2322 (0.2322)\tPrec@1 91.406 (91.406)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [29][10/390]\tTime 0.047 (0.090)\tData 0.000 (0.027)\tLoss 0.3114 (0.2202)\tPrec@1 88.281 (92.259)\tPrec@5 99.219 (99.858)\t\n",
            "TRAINING - Epoch: [29][20/390]\tTime 0.049 (0.074)\tData 0.000 (0.015)\tLoss 0.2693 (0.2288)\tPrec@1 92.188 (92.039)\tPrec@5 99.219 (99.851)\t\n",
            "TRAINING - Epoch: [29][30/390]\tTime 0.058 (0.069)\tData 0.008 (0.011)\tLoss 0.1638 (0.2215)\tPrec@1 94.531 (92.288)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [29][40/390]\tTime 0.056 (0.066)\tData 0.005 (0.009)\tLoss 0.2620 (0.2228)\tPrec@1 92.969 (92.226)\tPrec@5 100.000 (99.886)\t\n",
            "TRAINING - Epoch: [29][50/390]\tTime 0.056 (0.065)\tData 0.000 (0.008)\tLoss 0.1819 (0.2211)\tPrec@1 96.094 (92.356)\tPrec@5 100.000 (99.862)\t\n",
            "TRAINING - Epoch: [29][60/390]\tTime 0.068 (0.064)\tData 0.013 (0.008)\tLoss 0.1932 (0.2216)\tPrec@1 92.188 (92.277)\tPrec@5 100.000 (99.885)\t\n",
            "TRAINING - Epoch: [29][70/390]\tTime 0.048 (0.063)\tData 0.000 (0.007)\tLoss 0.2570 (0.2216)\tPrec@1 89.844 (92.243)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [29][80/390]\tTime 0.056 (0.063)\tData 0.007 (0.007)\tLoss 0.2586 (0.2211)\tPrec@1 89.062 (92.245)\tPrec@5 100.000 (99.894)\t\n",
            "TRAINING - Epoch: [29][90/390]\tTime 0.051 (0.063)\tData 0.000 (0.006)\tLoss 0.2085 (0.2197)\tPrec@1 93.750 (92.342)\tPrec@5 100.000 (99.888)\t\n",
            "TRAINING - Epoch: [29][100/390]\tTime 0.050 (0.062)\tData 0.000 (0.006)\tLoss 0.2108 (0.2228)\tPrec@1 91.406 (92.164)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [29][110/390]\tTime 0.050 (0.062)\tData 0.000 (0.005)\tLoss 0.1276 (0.2227)\tPrec@1 95.312 (92.216)\tPrec@5 100.000 (99.894)\t\n",
            "TRAINING - Epoch: [29][120/390]\tTime 0.056 (0.061)\tData 0.000 (0.005)\tLoss 0.2476 (0.2240)\tPrec@1 91.406 (92.162)\tPrec@5 100.000 (99.897)\t\n",
            "TRAINING - Epoch: [29][130/390]\tTime 0.077 (0.061)\tData 0.013 (0.005)\tLoss 0.2010 (0.2239)\tPrec@1 94.531 (92.146)\tPrec@5 99.219 (99.875)\t\n",
            "TRAINING - Epoch: [29][140/390]\tTime 0.070 (0.061)\tData 0.007 (0.005)\tLoss 0.2370 (0.2272)\tPrec@1 90.625 (92.055)\tPrec@5 100.000 (99.873)\t\n",
            "TRAINING - Epoch: [29][150/390]\tTime 0.048 (0.061)\tData 0.000 (0.005)\tLoss 0.3413 (0.2260)\tPrec@1 89.844 (92.074)\tPrec@5 100.000 (99.881)\t\n",
            "TRAINING - Epoch: [29][160/390]\tTime 0.052 (0.061)\tData 0.000 (0.005)\tLoss 0.2309 (0.2266)\tPrec@1 92.969 (92.105)\tPrec@5 100.000 (99.869)\t\n",
            "TRAINING - Epoch: [29][170/390]\tTime 0.062 (0.061)\tData 0.010 (0.005)\tLoss 0.1769 (0.2266)\tPrec@1 94.531 (92.119)\tPrec@5 100.000 (99.872)\t\n",
            "TRAINING - Epoch: [29][180/390]\tTime 0.062 (0.060)\tData 0.007 (0.005)\tLoss 0.2101 (0.2262)\tPrec@1 94.531 (92.153)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [29][190/390]\tTime 0.052 (0.060)\tData 0.000 (0.005)\tLoss 0.3084 (0.2266)\tPrec@1 89.844 (92.130)\tPrec@5 100.000 (99.873)\t\n",
            "TRAINING - Epoch: [29][200/390]\tTime 0.055 (0.060)\tData 0.006 (0.005)\tLoss 0.2977 (0.2290)\tPrec@1 89.062 (92.048)\tPrec@5 100.000 (99.860)\t\n",
            "TRAINING - Epoch: [29][210/390]\tTime 0.066 (0.060)\tData 0.011 (0.005)\tLoss 0.3609 (0.2308)\tPrec@1 86.719 (91.965)\tPrec@5 99.219 (99.859)\t\n",
            "TRAINING - Epoch: [29][220/390]\tTime 0.049 (0.060)\tData 0.000 (0.004)\tLoss 0.2555 (0.2311)\tPrec@1 91.406 (91.947)\tPrec@5 100.000 (99.866)\t\n",
            "TRAINING - Epoch: [29][230/390]\tTime 0.055 (0.060)\tData 0.000 (0.004)\tLoss 0.2144 (0.2316)\tPrec@1 90.625 (91.920)\tPrec@5 100.000 (99.868)\t\n",
            "TRAINING - Epoch: [29][240/390]\tTime 0.053 (0.060)\tData 0.004 (0.004)\tLoss 0.2284 (0.2317)\tPrec@1 92.188 (91.922)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [29][250/390]\tTime 0.054 (0.059)\tData 0.000 (0.004)\tLoss 0.2927 (0.2330)\tPrec@1 89.844 (91.907)\tPrec@5 100.000 (99.879)\t\n",
            "TRAINING - Epoch: [29][260/390]\tTime 0.049 (0.059)\tData 0.000 (0.004)\tLoss 0.2026 (0.2325)\tPrec@1 93.750 (91.942)\tPrec@5 100.000 (99.880)\t\n",
            "TRAINING - Epoch: [29][270/390]\tTime 0.048 (0.059)\tData 0.000 (0.004)\tLoss 0.1741 (0.2326)\tPrec@1 94.531 (91.937)\tPrec@5 100.000 (99.882)\t\n",
            "TRAINING - Epoch: [29][280/390]\tTime 0.066 (0.059)\tData 0.007 (0.004)\tLoss 0.3619 (0.2334)\tPrec@1 88.281 (91.929)\tPrec@5 99.219 (99.861)\t\n",
            "TRAINING - Epoch: [29][290/390]\tTime 0.074 (0.059)\tData 0.000 (0.004)\tLoss 0.1870 (0.2333)\tPrec@1 94.531 (91.916)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [29][300/390]\tTime 0.046 (0.059)\tData 0.000 (0.004)\tLoss 0.1992 (0.2333)\tPrec@1 93.750 (91.894)\tPrec@5 100.000 (99.860)\t\n",
            "TRAINING - Epoch: [29][310/390]\tTime 0.048 (0.059)\tData 0.000 (0.004)\tLoss 0.1523 (0.2331)\tPrec@1 95.312 (91.904)\tPrec@5 99.219 (99.854)\t\n",
            "TRAINING - Epoch: [29][320/390]\tTime 0.048 (0.059)\tData 0.000 (0.004)\tLoss 0.1995 (0.2336)\tPrec@1 92.188 (91.895)\tPrec@5 100.000 (99.852)\t\n",
            "TRAINING - Epoch: [29][330/390]\tTime 0.051 (0.059)\tData 0.000 (0.004)\tLoss 0.3359 (0.2342)\tPrec@1 89.844 (91.890)\tPrec@5 100.000 (99.849)\t\n",
            "TRAINING - Epoch: [29][340/390]\tTime 0.067 (0.059)\tData 0.006 (0.004)\tLoss 0.2084 (0.2344)\tPrec@1 95.312 (91.883)\tPrec@5 100.000 (99.849)\t\n",
            "TRAINING - Epoch: [29][350/390]\tTime 0.058 (0.059)\tData 0.007 (0.004)\tLoss 0.2419 (0.2353)\tPrec@1 91.406 (91.840)\tPrec@5 100.000 (99.844)\t\n",
            "TRAINING - Epoch: [29][360/390]\tTime 0.064 (0.059)\tData 0.008 (0.004)\tLoss 0.3612 (0.2350)\tPrec@1 86.719 (91.833)\tPrec@5 99.219 (99.842)\t\n",
            "TRAINING - Epoch: [29][370/390]\tTime 0.077 (0.058)\tData 0.006 (0.004)\tLoss 0.2373 (0.2352)\tPrec@1 93.750 (91.830)\tPrec@5 100.000 (99.840)\t\n",
            "TRAINING - Epoch: [29][380/390]\tTime 0.065 (0.058)\tData 0.007 (0.004)\tLoss 0.2066 (0.2354)\tPrec@1 92.969 (91.843)\tPrec@5 100.000 (99.842)\t\n",
            "TRAINING - Epoch: [29][389/390]\tTime 0.040 (0.058)\tData 0.000 (0.004)\tLoss 0.2253 (0.2361)\tPrec@1 92.188 (91.823)\tPrec@5 100.000 (99.844)\t\n",
            "EVALUATING - Epoch: [29][0/79]\tTime 0.300 (0.300)\tData 0.274 (0.274)\tLoss 0.4241 (0.4241)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [29][10/79]\tTime 0.025 (0.057)\tData 0.000 (0.029)\tLoss 0.2968 (0.4250)\tPrec@1 88.281 (85.938)\tPrec@5 100.000 (99.716)\t\n",
            "EVALUATING - Epoch: [29][20/79]\tTime 0.012 (0.041)\tData 0.000 (0.017)\tLoss 0.5176 (0.4601)\tPrec@1 86.719 (85.379)\tPrec@5 100.000 (99.368)\t\n",
            "EVALUATING - Epoch: [29][30/79]\tTime 0.040 (0.039)\tData 0.000 (0.013)\tLoss 0.3447 (0.4520)\tPrec@1 89.844 (85.635)\tPrec@5 100.000 (99.395)\t\n",
            "EVALUATING - Epoch: [29][40/79]\tTime 0.024 (0.037)\tData 0.005 (0.011)\tLoss 0.5500 (0.4511)\tPrec@1 84.375 (85.861)\tPrec@5 98.438 (99.371)\t\n",
            "EVALUATING - Epoch: [29][50/79]\tTime 0.017 (0.035)\tData 0.000 (0.010)\tLoss 0.4722 (0.4474)\tPrec@1 82.812 (86.091)\tPrec@5 100.000 (99.449)\t\n",
            "EVALUATING - Epoch: [29][60/79]\tTime 0.012 (0.034)\tData 0.000 (0.009)\tLoss 0.4849 (0.4424)\tPrec@1 89.062 (86.296)\tPrec@5 100.000 (99.488)\t\n",
            "EVALUATING - Epoch: [29][70/79]\tTime 0.020 (0.033)\tData 0.007 (0.008)\tLoss 0.3636 (0.4434)\tPrec@1 89.844 (86.191)\tPrec@5 100.000 (99.505)\t\n",
            "EVALUATING - Epoch: [29][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.008)\tLoss 0.3137 (0.4405)\tPrec@1 93.750 (86.230)\tPrec@5 100.000 (99.520)\t\n",
            "\n",
            "Results - Epoch: 30\n",
            "Training Loss 0.2361 \tTraining Prec@1 91.823 \tTraining Prec@5 99.844 \tValidation Loss 0.4405 \tValidation Prec@1 86.230 \tValidation Prec@5 99.520 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 31\n",
            "\n",
            "TRAINING - Epoch: [30][0/390]\tTime 0.367 (0.367)\tData 0.245 (0.245)\tLoss 0.1267 (0.1267)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [30][10/390]\tTime 0.050 (0.089)\tData 0.003 (0.027)\tLoss 0.1588 (0.1971)\tPrec@1 94.531 (93.253)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [30][20/390]\tTime 0.067 (0.074)\tData 0.013 (0.017)\tLoss 0.2474 (0.2068)\tPrec@1 91.406 (93.192)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [30][30/390]\tTime 0.059 (0.069)\tData 0.000 (0.012)\tLoss 0.2664 (0.2012)\tPrec@1 91.406 (93.196)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [30][40/390]\tTime 0.055 (0.066)\tData 0.005 (0.010)\tLoss 0.2280 (0.2037)\tPrec@1 92.969 (93.178)\tPrec@5 100.000 (99.886)\t\n",
            "TRAINING - Epoch: [30][50/390]\tTime 0.054 (0.064)\tData 0.000 (0.009)\tLoss 0.2708 (0.2103)\tPrec@1 92.188 (93.076)\tPrec@5 100.000 (99.877)\t\n",
            "TRAINING - Epoch: [30][60/390]\tTime 0.051 (0.062)\tData 0.000 (0.008)\tLoss 0.2700 (0.2133)\tPrec@1 89.062 (92.866)\tPrec@5 100.000 (99.846)\t\n",
            "TRAINING - Epoch: [30][70/390]\tTime 0.056 (0.062)\tData 0.006 (0.007)\tLoss 0.1277 (0.2105)\tPrec@1 94.531 (92.859)\tPrec@5 100.000 (99.868)\t\n",
            "TRAINING - Epoch: [30][80/390]\tTime 0.052 (0.061)\tData 0.000 (0.007)\tLoss 0.2826 (0.2145)\tPrec@1 92.188 (92.776)\tPrec@5 100.000 (99.855)\t\n",
            "TRAINING - Epoch: [30][90/390]\tTime 0.047 (0.060)\tData 0.000 (0.006)\tLoss 0.2397 (0.2170)\tPrec@1 91.406 (92.677)\tPrec@5 100.000 (99.845)\t\n",
            "TRAINING - Epoch: [30][100/390]\tTime 0.079 (0.060)\tData 0.007 (0.006)\tLoss 0.3291 (0.2196)\tPrec@1 88.281 (92.559)\tPrec@5 100.000 (99.845)\t\n",
            "TRAINING - Epoch: [30][110/390]\tTime 0.052 (0.060)\tData 0.003 (0.006)\tLoss 0.2627 (0.2198)\tPrec@1 90.625 (92.532)\tPrec@5 100.000 (99.852)\t\n",
            "TRAINING - Epoch: [30][120/390]\tTime 0.049 (0.059)\tData 0.000 (0.005)\tLoss 0.1739 (0.2206)\tPrec@1 93.750 (92.465)\tPrec@5 100.000 (99.845)\t\n",
            "TRAINING - Epoch: [30][130/390]\tTime 0.062 (0.059)\tData 0.007 (0.005)\tLoss 0.2269 (0.2204)\tPrec@1 91.406 (92.468)\tPrec@5 100.000 (99.845)\t\n",
            "TRAINING - Epoch: [30][140/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.2182 (0.2218)\tPrec@1 91.406 (92.376)\tPrec@5 99.219 (99.845)\t\n",
            "TRAINING - Epoch: [30][150/390]\tTime 0.060 (0.059)\tData 0.008 (0.005)\tLoss 0.2449 (0.2217)\tPrec@1 91.406 (92.389)\tPrec@5 100.000 (99.840)\t\n",
            "TRAINING - Epoch: [30][160/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 0.2547 (0.2236)\tPrec@1 90.625 (92.294)\tPrec@5 100.000 (99.845)\t\n",
            "TRAINING - Epoch: [30][170/390]\tTime 0.051 (0.059)\tData 0.000 (0.005)\tLoss 0.2711 (0.2239)\tPrec@1 89.844 (92.279)\tPrec@5 99.219 (99.845)\t\n",
            "TRAINING - Epoch: [30][180/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2230 (0.2247)\tPrec@1 92.188 (92.231)\tPrec@5 100.000 (99.853)\t\n",
            "TRAINING - Epoch: [30][190/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2219 (0.2259)\tPrec@1 92.969 (92.192)\tPrec@5 100.000 (99.861)\t\n",
            "TRAINING - Epoch: [30][200/390]\tTime 0.060 (0.058)\tData 0.000 (0.005)\tLoss 0.1596 (0.2276)\tPrec@1 96.094 (92.133)\tPrec@5 100.000 (99.852)\t\n",
            "TRAINING - Epoch: [30][210/390]\tTime 0.064 (0.058)\tData 0.007 (0.005)\tLoss 0.1725 (0.2285)\tPrec@1 94.531 (92.117)\tPrec@5 100.000 (99.856)\t\n",
            "TRAINING - Epoch: [30][220/390]\tTime 0.078 (0.058)\tData 0.005 (0.005)\tLoss 0.2994 (0.2284)\tPrec@1 89.062 (92.106)\tPrec@5 100.000 (99.855)\t\n",
            "TRAINING - Epoch: [30][230/390]\tTime 0.052 (0.058)\tData 0.000 (0.004)\tLoss 0.2437 (0.2279)\tPrec@1 89.844 (92.127)\tPrec@5 100.000 (99.855)\t\n",
            "TRAINING - Epoch: [30][240/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.2323 (0.2279)\tPrec@1 91.406 (92.119)\tPrec@5 100.000 (99.854)\t\n",
            "TRAINING - Epoch: [30][250/390]\tTime 0.054 (0.058)\tData 0.006 (0.004)\tLoss 0.3694 (0.2291)\tPrec@1 86.719 (92.060)\tPrec@5 100.000 (99.854)\t\n",
            "TRAINING - Epoch: [30][260/390]\tTime 0.050 (0.058)\tData 0.000 (0.004)\tLoss 0.2765 (0.2288)\tPrec@1 90.625 (92.065)\tPrec@5 100.000 (99.859)\t\n",
            "TRAINING - Epoch: [30][270/390]\tTime 0.063 (0.058)\tData 0.009 (0.004)\tLoss 0.2064 (0.2298)\tPrec@1 90.625 (92.015)\tPrec@5 100.000 (99.856)\t\n",
            "TRAINING - Epoch: [30][280/390]\tTime 0.063 (0.058)\tData 0.011 (0.004)\tLoss 0.2959 (0.2291)\tPrec@1 89.062 (92.051)\tPrec@5 100.000 (99.853)\t\n",
            "TRAINING - Epoch: [30][290/390]\tTime 0.053 (0.058)\tData 0.000 (0.004)\tLoss 0.2907 (0.2310)\tPrec@1 89.844 (91.986)\tPrec@5 100.000 (99.855)\t\n",
            "TRAINING - Epoch: [30][300/390]\tTime 0.056 (0.058)\tData 0.006 (0.004)\tLoss 0.2680 (0.2314)\tPrec@1 87.500 (91.951)\tPrec@5 100.000 (99.857)\t\n",
            "TRAINING - Epoch: [30][310/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2358 (0.2316)\tPrec@1 92.188 (91.926)\tPrec@5 100.000 (99.859)\t\n",
            "TRAINING - Epoch: [30][320/390]\tTime 0.063 (0.057)\tData 0.000 (0.004)\tLoss 0.2399 (0.2321)\tPrec@1 92.188 (91.905)\tPrec@5 99.219 (99.859)\t\n",
            "TRAINING - Epoch: [30][330/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.2534 (0.2322)\tPrec@1 92.188 (91.895)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [30][340/390]\tTime 0.073 (0.057)\tData 0.007 (0.004)\tLoss 0.2723 (0.2338)\tPrec@1 91.406 (91.828)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [30][350/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.2317 (0.2346)\tPrec@1 92.188 (91.811)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [30][360/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.3222 (0.2351)\tPrec@1 86.719 (91.768)\tPrec@5 100.000 (99.861)\t\n",
            "TRAINING - Epoch: [30][370/390]\tTime 0.080 (0.057)\tData 0.007 (0.004)\tLoss 0.3605 (0.2354)\tPrec@1 87.500 (91.768)\tPrec@5 100.000 (99.859)\t\n",
            "TRAINING - Epoch: [30][380/390]\tTime 0.059 (0.057)\tData 0.011 (0.004)\tLoss 0.2086 (0.2355)\tPrec@1 92.188 (91.784)\tPrec@5 99.219 (99.856)\t\n",
            "TRAINING - Epoch: [30][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.3334 (0.2373)\tPrec@1 89.062 (91.741)\tPrec@5 99.219 (99.844)\t\n",
            "EVALUATING - Epoch: [30][0/79]\tTime 0.203 (0.203)\tData 0.173 (0.173)\tLoss 0.3447 (0.3447)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [30][10/79]\tTime 0.038 (0.051)\tData 0.005 (0.024)\tLoss 0.3923 (0.4066)\tPrec@1 84.375 (86.364)\tPrec@5 100.000 (99.574)\t\n",
            "EVALUATING - Epoch: [30][20/79]\tTime 0.037 (0.044)\tData 0.009 (0.016)\tLoss 0.5185 (0.4384)\tPrec@1 81.250 (85.342)\tPrec@5 100.000 (99.479)\t\n",
            "EVALUATING - Epoch: [30][30/79]\tTime 0.030 (0.039)\tData 0.000 (0.012)\tLoss 0.3247 (0.4344)\tPrec@1 85.938 (85.862)\tPrec@5 100.000 (99.320)\t\n",
            "EVALUATING - Epoch: [30][40/79]\tTime 0.027 (0.037)\tData 0.004 (0.011)\tLoss 0.7277 (0.4395)\tPrec@1 79.688 (85.995)\tPrec@5 97.656 (99.333)\t\n",
            "EVALUATING - Epoch: [30][50/79]\tTime 0.029 (0.035)\tData 0.001 (0.009)\tLoss 0.4227 (0.4389)\tPrec@1 85.156 (85.968)\tPrec@5 99.219 (99.403)\t\n",
            "EVALUATING - Epoch: [30][60/79]\tTime 0.041 (0.036)\tData 0.008 (0.009)\tLoss 0.3786 (0.4327)\tPrec@1 85.156 (86.130)\tPrec@5 99.219 (99.436)\t\n",
            "EVALUATING - Epoch: [30][70/79]\tTime 0.027 (0.035)\tData 0.005 (0.008)\tLoss 0.2669 (0.4311)\tPrec@1 93.750 (86.103)\tPrec@5 99.219 (99.439)\t\n",
            "EVALUATING - Epoch: [30][78/79]\tTime 0.007 (0.032)\tData 0.000 (0.007)\tLoss 0.0274 (0.4274)\tPrec@1 100.000 (86.130)\tPrec@5 100.000 (99.450)\t\n",
            "\n",
            "Results - Epoch: 31\n",
            "Training Loss 0.2373 \tTraining Prec@1 91.741 \tTraining Prec@5 99.844 \tValidation Loss 0.4274 \tValidation Prec@1 86.130 \tValidation Prec@5 99.450 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 32\n",
            "\n",
            "TRAINING - Epoch: [31][0/390]\tTime 0.394 (0.394)\tData 0.285 (0.285)\tLoss 0.1941 (0.1941)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [31][10/390]\tTime 0.049 (0.089)\tData 0.000 (0.028)\tLoss 0.1990 (0.2262)\tPrec@1 92.969 (92.827)\tPrec@5 100.000 (99.716)\t\n",
            "TRAINING - Epoch: [31][20/390]\tTime 0.048 (0.074)\tData 0.000 (0.016)\tLoss 0.3353 (0.2379)\tPrec@1 85.156 (92.188)\tPrec@5 100.000 (99.777)\t\n",
            "TRAINING - Epoch: [31][30/390]\tTime 0.057 (0.068)\tData 0.000 (0.013)\tLoss 0.2049 (0.2358)\tPrec@1 93.750 (92.188)\tPrec@5 99.219 (99.748)\t\n",
            "TRAINING - Epoch: [31][40/390]\tTime 0.076 (0.066)\tData 0.003 (0.010)\tLoss 0.1830 (0.2318)\tPrec@1 92.969 (92.149)\tPrec@5 100.000 (99.790)\t\n",
            "TRAINING - Epoch: [31][50/390]\tTime 0.063 (0.064)\tData 0.000 (0.009)\tLoss 0.1850 (0.2278)\tPrec@1 93.750 (92.295)\tPrec@5 100.000 (99.801)\t\n",
            "TRAINING - Epoch: [31][60/390]\tTime 0.049 (0.063)\tData 0.000 (0.009)\tLoss 0.2664 (0.2294)\tPrec@1 90.625 (92.123)\tPrec@5 98.438 (99.782)\t\n",
            "TRAINING - Epoch: [31][70/390]\tTime 0.066 (0.062)\tData 0.000 (0.008)\tLoss 0.1770 (0.2299)\tPrec@1 93.750 (92.077)\tPrec@5 100.000 (99.791)\t\n",
            "TRAINING - Epoch: [31][80/390]\tTime 0.088 (0.062)\tData 0.007 (0.007)\tLoss 0.3279 (0.2273)\tPrec@1 89.844 (92.120)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [31][90/390]\tTime 0.057 (0.062)\tData 0.000 (0.007)\tLoss 0.2342 (0.2272)\tPrec@1 93.750 (92.145)\tPrec@5 100.000 (99.820)\t\n",
            "TRAINING - Epoch: [31][100/390]\tTime 0.055 (0.062)\tData 0.000 (0.006)\tLoss 0.2337 (0.2277)\tPrec@1 91.406 (92.118)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [31][110/390]\tTime 0.077 (0.061)\tData 0.000 (0.006)\tLoss 0.2196 (0.2283)\tPrec@1 92.969 (92.047)\tPrec@5 98.438 (99.810)\t\n",
            "TRAINING - Epoch: [31][120/390]\tTime 0.074 (0.061)\tData 0.007 (0.006)\tLoss 0.2238 (0.2263)\tPrec@1 89.844 (92.091)\tPrec@5 100.000 (99.819)\t\n",
            "TRAINING - Epoch: [31][130/390]\tTime 0.050 (0.061)\tData 0.001 (0.005)\tLoss 0.2563 (0.2256)\tPrec@1 90.625 (92.152)\tPrec@5 99.219 (99.821)\t\n",
            "TRAINING - Epoch: [31][140/390]\tTime 0.048 (0.060)\tData 0.000 (0.005)\tLoss 0.2144 (0.2243)\tPrec@1 92.969 (92.138)\tPrec@5 100.000 (99.828)\t\n",
            "TRAINING - Epoch: [31][150/390]\tTime 0.047 (0.060)\tData 0.000 (0.005)\tLoss 0.2379 (0.2247)\tPrec@1 91.406 (92.156)\tPrec@5 99.219 (99.829)\t\n",
            "TRAINING - Epoch: [31][160/390]\tTime 0.072 (0.060)\tData 0.008 (0.005)\tLoss 0.1877 (0.2229)\tPrec@1 93.750 (92.183)\tPrec@5 100.000 (99.825)\t\n",
            "TRAINING - Epoch: [31][170/390]\tTime 0.068 (0.060)\tData 0.012 (0.005)\tLoss 0.2369 (0.2233)\tPrec@1 92.969 (92.174)\tPrec@5 100.000 (99.822)\t\n",
            "TRAINING - Epoch: [31][180/390]\tTime 0.074 (0.060)\tData 0.008 (0.005)\tLoss 0.1598 (0.2238)\tPrec@1 94.531 (92.153)\tPrec@5 100.000 (99.832)\t\n",
            "TRAINING - Epoch: [31][190/390]\tTime 0.050 (0.059)\tData 0.000 (0.005)\tLoss 0.2115 (0.2241)\tPrec@1 93.750 (92.167)\tPrec@5 100.000 (99.828)\t\n",
            "TRAINING - Epoch: [31][200/390]\tTime 0.063 (0.059)\tData 0.008 (0.005)\tLoss 0.2408 (0.2251)\tPrec@1 89.844 (92.114)\tPrec@5 100.000 (99.829)\t\n",
            "TRAINING - Epoch: [31][210/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 0.2260 (0.2250)\tPrec@1 93.750 (92.091)\tPrec@5 100.000 (99.819)\t\n",
            "TRAINING - Epoch: [31][220/390]\tTime 0.049 (0.059)\tData 0.000 (0.005)\tLoss 0.3231 (0.2257)\tPrec@1 87.500 (92.081)\tPrec@5 100.000 (99.827)\t\n",
            "TRAINING - Epoch: [31][230/390]\tTime 0.055 (0.059)\tData 0.007 (0.005)\tLoss 0.2325 (0.2253)\tPrec@1 91.406 (92.120)\tPrec@5 100.000 (99.821)\t\n",
            "TRAINING - Epoch: [31][240/390]\tTime 0.055 (0.059)\tData 0.007 (0.005)\tLoss 0.3216 (0.2249)\tPrec@1 92.188 (92.145)\tPrec@5 100.000 (99.825)\t\n",
            "TRAINING - Epoch: [31][250/390]\tTime 0.052 (0.059)\tData 0.000 (0.005)\tLoss 0.2652 (0.2261)\tPrec@1 90.625 (92.094)\tPrec@5 100.000 (99.819)\t\n",
            "TRAINING - Epoch: [31][260/390]\tTime 0.061 (0.059)\tData 0.007 (0.005)\tLoss 0.2901 (0.2277)\tPrec@1 87.500 (92.041)\tPrec@5 100.000 (99.823)\t\n",
            "TRAINING - Epoch: [31][270/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2563 (0.2283)\tPrec@1 89.844 (92.006)\tPrec@5 100.000 (99.821)\t\n",
            "TRAINING - Epoch: [31][280/390]\tTime 0.046 (0.058)\tData 0.000 (0.004)\tLoss 0.2510 (0.2299)\tPrec@1 91.406 (91.943)\tPrec@5 100.000 (99.811)\t\n",
            "TRAINING - Epoch: [31][290/390]\tTime 0.058 (0.058)\tData 0.000 (0.004)\tLoss 0.3172 (0.2315)\tPrec@1 89.844 (91.906)\tPrec@5 99.219 (99.807)\t\n",
            "TRAINING - Epoch: [31][300/390]\tTime 0.055 (0.058)\tData 0.001 (0.004)\tLoss 0.2178 (0.2314)\tPrec@1 89.844 (91.894)\tPrec@5 100.000 (99.808)\t\n",
            "TRAINING - Epoch: [31][310/390]\tTime 0.046 (0.058)\tData 0.000 (0.004)\tLoss 0.3090 (0.2318)\tPrec@1 89.844 (91.868)\tPrec@5 99.219 (99.804)\t\n",
            "TRAINING - Epoch: [31][320/390]\tTime 0.048 (0.058)\tData 0.000 (0.004)\tLoss 0.2472 (0.2309)\tPrec@1 88.281 (91.895)\tPrec@5 100.000 (99.810)\t\n",
            "TRAINING - Epoch: [31][330/390]\tTime 0.055 (0.058)\tData 0.000 (0.004)\tLoss 0.1466 (0.2307)\tPrec@1 94.531 (91.907)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [31][340/390]\tTime 0.057 (0.058)\tData 0.000 (0.004)\tLoss 0.2540 (0.2305)\tPrec@1 92.188 (91.913)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [31][350/390]\tTime 0.058 (0.058)\tData 0.000 (0.004)\tLoss 0.2026 (0.2305)\tPrec@1 92.969 (91.918)\tPrec@5 100.000 (99.822)\t\n",
            "TRAINING - Epoch: [31][360/390]\tTime 0.053 (0.058)\tData 0.005 (0.004)\tLoss 0.1742 (0.2304)\tPrec@1 94.531 (91.930)\tPrec@5 100.000 (99.820)\t\n",
            "TRAINING - Epoch: [31][370/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.2586 (0.2305)\tPrec@1 91.406 (91.928)\tPrec@5 100.000 (99.821)\t\n",
            "TRAINING - Epoch: [31][380/390]\tTime 0.054 (0.058)\tData 0.006 (0.004)\tLoss 0.2102 (0.2308)\tPrec@1 93.750 (91.927)\tPrec@5 99.219 (99.820)\t\n",
            "TRAINING - Epoch: [31][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1545 (0.2306)\tPrec@1 95.312 (91.939)\tPrec@5 100.000 (99.822)\t\n",
            "EVALUATING - Epoch: [31][0/79]\tTime 0.235 (0.235)\tData 0.196 (0.196)\tLoss 0.4329 (0.4329)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [31][10/79]\tTime 0.028 (0.057)\tData 0.000 (0.025)\tLoss 0.4227 (0.4607)\tPrec@1 87.500 (86.364)\tPrec@5 100.000 (99.574)\t\n",
            "EVALUATING - Epoch: [31][20/79]\tTime 0.025 (0.045)\tData 0.000 (0.015)\tLoss 0.4935 (0.4782)\tPrec@1 84.375 (85.603)\tPrec@5 99.219 (99.516)\t\n",
            "EVALUATING - Epoch: [31][30/79]\tTime 0.013 (0.041)\tData 0.000 (0.012)\tLoss 0.3553 (0.4803)\tPrec@1 89.844 (85.685)\tPrec@5 100.000 (99.471)\t\n",
            "EVALUATING - Epoch: [31][40/79]\tTime 0.017 (0.037)\tData 0.003 (0.010)\tLoss 0.5665 (0.4735)\tPrec@1 80.469 (85.861)\tPrec@5 100.000 (99.486)\t\n",
            "EVALUATING - Epoch: [31][50/79]\tTime 0.035 (0.037)\tData 0.005 (0.009)\tLoss 0.3370 (0.4646)\tPrec@1 90.625 (86.075)\tPrec@5 100.000 (99.586)\t\n",
            "EVALUATING - Epoch: [31][60/79]\tTime 0.037 (0.036)\tData 0.001 (0.008)\tLoss 0.4748 (0.4605)\tPrec@1 85.156 (86.219)\tPrec@5 100.000 (99.590)\t\n",
            "EVALUATING - Epoch: [31][70/79]\tTime 0.021 (0.035)\tData 0.006 (0.008)\tLoss 0.3722 (0.4619)\tPrec@1 86.719 (86.103)\tPrec@5 100.000 (99.626)\t\n",
            "EVALUATING - Epoch: [31][78/79]\tTime 0.006 (0.033)\tData 0.000 (0.007)\tLoss 0.0827 (0.4641)\tPrec@1 100.000 (86.150)\tPrec@5 100.000 (99.610)\t\n",
            "\n",
            "Results - Epoch: 32\n",
            "Training Loss 0.2306 \tTraining Prec@1 91.939 \tTraining Prec@5 99.822 \tValidation Loss 0.4641 \tValidation Prec@1 86.150 \tValidation Prec@5 99.610 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 33\n",
            "\n",
            "TRAINING - Epoch: [32][0/390]\tTime 0.405 (0.405)\tData 0.297 (0.297)\tLoss 0.3338 (0.3338)\tPrec@1 89.062 (89.062)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [32][10/390]\tTime 0.054 (0.090)\tData 0.000 (0.031)\tLoss 0.0836 (0.2162)\tPrec@1 97.656 (92.898)\tPrec@5 100.000 (99.645)\t\n",
            "TRAINING - Epoch: [32][20/390]\tTime 0.050 (0.074)\tData 0.000 (0.018)\tLoss 0.1403 (0.2041)\tPrec@1 96.094 (93.341)\tPrec@5 100.000 (99.777)\t\n",
            "TRAINING - Epoch: [32][30/390]\tTime 0.048 (0.067)\tData 0.000 (0.013)\tLoss 0.2179 (0.2111)\tPrec@1 93.750 (92.843)\tPrec@5 100.000 (99.824)\t\n",
            "TRAINING - Epoch: [32][40/390]\tTime 0.063 (0.065)\tData 0.008 (0.011)\tLoss 0.2379 (0.2099)\tPrec@1 90.625 (92.797)\tPrec@5 100.000 (99.829)\t\n",
            "TRAINING - Epoch: [32][50/390]\tTime 0.055 (0.063)\tData 0.008 (0.010)\tLoss 0.1466 (0.2119)\tPrec@1 96.094 (92.785)\tPrec@5 100.000 (99.831)\t\n",
            "TRAINING - Epoch: [32][60/390]\tTime 0.062 (0.063)\tData 0.007 (0.009)\tLoss 0.2163 (0.2131)\tPrec@1 91.406 (92.585)\tPrec@5 99.219 (99.821)\t\n",
            "TRAINING - Epoch: [32][70/390]\tTime 0.063 (0.062)\tData 0.000 (0.008)\tLoss 0.1846 (0.2143)\tPrec@1 92.969 (92.507)\tPrec@5 100.000 (99.824)\t\n",
            "TRAINING - Epoch: [32][80/390]\tTime 0.071 (0.061)\tData 0.000 (0.008)\tLoss 0.1809 (0.2148)\tPrec@1 94.531 (92.525)\tPrec@5 100.000 (99.826)\t\n",
            "TRAINING - Epoch: [32][90/390]\tTime 0.054 (0.061)\tData 0.008 (0.007)\tLoss 0.1569 (0.2140)\tPrec@1 97.656 (92.565)\tPrec@5 100.000 (99.837)\t\n",
            "TRAINING - Epoch: [32][100/390]\tTime 0.053 (0.060)\tData 0.000 (0.007)\tLoss 0.2128 (0.2184)\tPrec@1 93.750 (92.505)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [32][110/390]\tTime 0.047 (0.060)\tData 0.000 (0.007)\tLoss 0.1788 (0.2204)\tPrec@1 93.750 (92.483)\tPrec@5 100.000 (99.824)\t\n",
            "TRAINING - Epoch: [32][120/390]\tTime 0.060 (0.060)\tData 0.010 (0.007)\tLoss 0.1572 (0.2199)\tPrec@1 94.531 (92.439)\tPrec@5 100.000 (99.832)\t\n",
            "TRAINING - Epoch: [32][130/390]\tTime 0.061 (0.060)\tData 0.013 (0.006)\tLoss 0.2778 (0.2211)\tPrec@1 91.406 (92.372)\tPrec@5 100.000 (99.839)\t\n",
            "TRAINING - Epoch: [32][140/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.2302 (0.2220)\tPrec@1 92.188 (92.298)\tPrec@5 100.000 (99.850)\t\n",
            "TRAINING - Epoch: [32][150/390]\tTime 0.051 (0.059)\tData 0.000 (0.006)\tLoss 0.2702 (0.2225)\tPrec@1 92.188 (92.296)\tPrec@5 99.219 (99.850)\t\n",
            "TRAINING - Epoch: [32][160/390]\tTime 0.049 (0.059)\tData 0.002 (0.006)\tLoss 0.1570 (0.2208)\tPrec@1 92.969 (92.333)\tPrec@5 100.000 (99.854)\t\n",
            "TRAINING - Epoch: [32][170/390]\tTime 0.054 (0.059)\tData 0.006 (0.006)\tLoss 0.1786 (0.2205)\tPrec@1 92.188 (92.320)\tPrec@5 100.000 (99.854)\t\n",
            "TRAINING - Epoch: [32][180/390]\tTime 0.060 (0.059)\tData 0.000 (0.006)\tLoss 0.2630 (0.2210)\tPrec@1 92.188 (92.330)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [32][190/390]\tTime 0.066 (0.059)\tData 0.007 (0.005)\tLoss 0.2071 (0.2198)\tPrec@1 92.188 (92.380)\tPrec@5 100.000 (99.861)\t\n",
            "TRAINING - Epoch: [32][200/390]\tTime 0.058 (0.059)\tData 0.000 (0.005)\tLoss 0.1764 (0.2205)\tPrec@1 94.531 (92.378)\tPrec@5 99.219 (99.864)\t\n",
            "TRAINING - Epoch: [32][210/390]\tTime 0.052 (0.059)\tData 0.000 (0.005)\tLoss 0.2093 (0.2215)\tPrec@1 90.625 (92.328)\tPrec@5 100.000 (99.870)\t\n",
            "TRAINING - Epoch: [32][220/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2594 (0.2229)\tPrec@1 89.844 (92.279)\tPrec@5 100.000 (99.869)\t\n",
            "TRAINING - Epoch: [32][230/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1936 (0.2227)\tPrec@1 92.969 (92.272)\tPrec@5 100.000 (99.865)\t\n",
            "TRAINING - Epoch: [32][240/390]\tTime 0.061 (0.058)\tData 0.007 (0.005)\tLoss 0.3309 (0.2230)\tPrec@1 89.062 (92.246)\tPrec@5 100.000 (99.870)\t\n",
            "TRAINING - Epoch: [32][250/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1716 (0.2233)\tPrec@1 94.531 (92.222)\tPrec@5 100.000 (99.869)\t\n",
            "TRAINING - Epoch: [32][260/390]\tTime 0.053 (0.058)\tData 0.000 (0.005)\tLoss 0.1402 (0.2231)\tPrec@1 93.750 (92.217)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [32][270/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2753 (0.2246)\tPrec@1 90.625 (92.164)\tPrec@5 100.000 (99.876)\t\n",
            "TRAINING - Epoch: [32][280/390]\tTime 0.057 (0.058)\tData 0.007 (0.005)\tLoss 0.3942 (0.2246)\tPrec@1 86.719 (92.160)\tPrec@5 99.219 (99.875)\t\n",
            "TRAINING - Epoch: [32][290/390]\tTime 0.054 (0.058)\tData 0.006 (0.005)\tLoss 0.2549 (0.2246)\tPrec@1 89.062 (92.163)\tPrec@5 100.000 (99.879)\t\n",
            "TRAINING - Epoch: [32][300/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.1917 (0.2250)\tPrec@1 94.531 (92.146)\tPrec@5 100.000 (99.878)\t\n",
            "TRAINING - Epoch: [32][310/390]\tTime 0.053 (0.058)\tData 0.006 (0.005)\tLoss 0.3489 (0.2251)\tPrec@1 86.719 (92.132)\tPrec@5 100.000 (99.877)\t\n",
            "TRAINING - Epoch: [32][320/390]\tTime 0.073 (0.058)\tData 0.003 (0.005)\tLoss 0.2029 (0.2258)\tPrec@1 92.188 (92.105)\tPrec@5 100.000 (99.876)\t\n",
            "TRAINING - Epoch: [32][330/390]\tTime 0.054 (0.058)\tData 0.006 (0.005)\tLoss 0.3162 (0.2257)\tPrec@1 89.844 (92.107)\tPrec@5 99.219 (99.873)\t\n",
            "TRAINING - Epoch: [32][340/390]\tTime 0.062 (0.058)\tData 0.006 (0.004)\tLoss 0.1810 (0.2256)\tPrec@1 93.750 (92.128)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [32][350/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2353 (0.2261)\tPrec@1 89.844 (92.114)\tPrec@5 100.000 (99.875)\t\n",
            "TRAINING - Epoch: [32][360/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2814 (0.2264)\tPrec@1 92.188 (92.088)\tPrec@5 98.438 (99.870)\t\n",
            "TRAINING - Epoch: [32][370/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2686 (0.2274)\tPrec@1 90.625 (92.072)\tPrec@5 100.000 (99.867)\t\n",
            "TRAINING - Epoch: [32][380/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.1415 (0.2278)\tPrec@1 97.656 (92.091)\tPrec@5 100.000 (99.867)\t\n",
            "TRAINING - Epoch: [32][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1885 (0.2280)\tPrec@1 92.188 (92.079)\tPrec@5 100.000 (99.868)\t\n",
            "EVALUATING - Epoch: [32][0/79]\tTime 0.277 (0.277)\tData 0.245 (0.245)\tLoss 0.3642 (0.3642)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [32][10/79]\tTime 0.012 (0.052)\tData 0.000 (0.026)\tLoss 0.4125 (0.4506)\tPrec@1 84.375 (85.227)\tPrec@5 99.219 (99.432)\t\n",
            "EVALUATING - Epoch: [32][20/79]\tTime 0.040 (0.039)\tData 0.002 (0.014)\tLoss 0.5030 (0.4944)\tPrec@1 81.250 (84.338)\tPrec@5 99.219 (99.591)\t\n",
            "EVALUATING - Epoch: [32][30/79]\tTime 0.033 (0.038)\tData 0.004 (0.011)\tLoss 0.4659 (0.5056)\tPrec@1 84.375 (84.173)\tPrec@5 100.000 (99.420)\t\n",
            "EVALUATING - Epoch: [32][40/79]\tTime 0.028 (0.037)\tData 0.004 (0.009)\tLoss 0.6698 (0.5051)\tPrec@1 75.781 (84.108)\tPrec@5 97.656 (99.371)\t\n",
            "EVALUATING - Epoch: [32][50/79]\tTime 0.023 (0.035)\tData 0.005 (0.008)\tLoss 0.4702 (0.4984)\tPrec@1 85.156 (84.252)\tPrec@5 100.000 (99.433)\t\n",
            "EVALUATING - Epoch: [32][60/79]\tTime 0.041 (0.034)\tData 0.000 (0.008)\tLoss 0.4411 (0.4907)\tPrec@1 85.156 (84.426)\tPrec@5 99.219 (99.488)\t\n",
            "EVALUATING - Epoch: [32][70/79]\tTime 0.024 (0.034)\tData 0.000 (0.007)\tLoss 0.2810 (0.4895)\tPrec@1 89.844 (84.419)\tPrec@5 100.000 (99.516)\t\n",
            "EVALUATING - Epoch: [32][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.3649 (0.4863)\tPrec@1 87.500 (84.510)\tPrec@5 100.000 (99.540)\t\n",
            "\n",
            "Results - Epoch: 33\n",
            "Training Loss 0.2280 \tTraining Prec@1 92.079 \tTraining Prec@5 99.868 \tValidation Loss 0.4863 \tValidation Prec@1 84.510 \tValidation Prec@5 99.540 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 34\n",
            "\n",
            "TRAINING - Epoch: [33][0/390]\tTime 0.386 (0.386)\tData 0.255 (0.255)\tLoss 0.1715 (0.1715)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [33][10/390]\tTime 0.062 (0.087)\tData 0.011 (0.026)\tLoss 0.1567 (0.1862)\tPrec@1 95.312 (94.247)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [33][20/390]\tTime 0.054 (0.072)\tData 0.010 (0.016)\tLoss 0.1972 (0.2089)\tPrec@1 91.406 (93.266)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [33][30/390]\tTime 0.058 (0.067)\tData 0.000 (0.012)\tLoss 0.2836 (0.2233)\tPrec@1 90.625 (92.692)\tPrec@5 100.000 (99.773)\t\n",
            "TRAINING - Epoch: [33][40/390]\tTime 0.050 (0.064)\tData 0.000 (0.009)\tLoss 0.1775 (0.2213)\tPrec@1 92.188 (92.397)\tPrec@5 100.000 (99.771)\t\n",
            "TRAINING - Epoch: [33][50/390]\tTime 0.051 (0.063)\tData 0.003 (0.008)\tLoss 0.2293 (0.2101)\tPrec@1 92.188 (92.862)\tPrec@5 100.000 (99.816)\t\n",
            "TRAINING - Epoch: [33][60/390]\tTime 0.052 (0.061)\tData 0.005 (0.008)\tLoss 0.1686 (0.2066)\tPrec@1 93.750 (92.943)\tPrec@5 100.000 (99.834)\t\n",
            "TRAINING - Epoch: [33][70/390]\tTime 0.060 (0.060)\tData 0.000 (0.007)\tLoss 0.2859 (0.2128)\tPrec@1 91.406 (92.705)\tPrec@5 99.219 (99.846)\t\n",
            "TRAINING - Epoch: [33][80/390]\tTime 0.064 (0.060)\tData 0.006 (0.006)\tLoss 0.2543 (0.2111)\tPrec@1 92.188 (92.718)\tPrec@5 99.219 (99.855)\t\n",
            "TRAINING - Epoch: [33][90/390]\tTime 0.068 (0.059)\tData 0.007 (0.006)\tLoss 0.1576 (0.2128)\tPrec@1 94.531 (92.625)\tPrec@5 100.000 (99.854)\t\n",
            "TRAINING - Epoch: [33][100/390]\tTime 0.054 (0.059)\tData 0.003 (0.006)\tLoss 0.1648 (0.2113)\tPrec@1 94.531 (92.659)\tPrec@5 100.000 (99.861)\t\n",
            "TRAINING - Epoch: [33][110/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.1314 (0.2126)\tPrec@1 96.875 (92.652)\tPrec@5 99.219 (99.859)\t\n",
            "TRAINING - Epoch: [33][120/390]\tTime 0.064 (0.059)\tData 0.001 (0.006)\tLoss 0.1844 (0.2113)\tPrec@1 93.750 (92.730)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [33][130/390]\tTime 0.054 (0.058)\tData 0.006 (0.005)\tLoss 0.1465 (0.2099)\tPrec@1 96.875 (92.778)\tPrec@5 100.000 (99.857)\t\n",
            "TRAINING - Epoch: [33][140/390]\tTime 0.055 (0.058)\tData 0.006 (0.005)\tLoss 0.2328 (0.2095)\tPrec@1 92.188 (92.780)\tPrec@5 100.000 (99.850)\t\n",
            "TRAINING - Epoch: [33][150/390]\tTime 0.056 (0.058)\tData 0.008 (0.005)\tLoss 0.2521 (0.2107)\tPrec@1 90.625 (92.746)\tPrec@5 100.000 (99.855)\t\n",
            "TRAINING - Epoch: [33][160/390]\tTime 0.066 (0.058)\tData 0.006 (0.005)\tLoss 0.1530 (0.2103)\tPrec@1 95.312 (92.789)\tPrec@5 100.000 (99.859)\t\n",
            "TRAINING - Epoch: [33][170/390]\tTime 0.055 (0.058)\tData 0.006 (0.005)\tLoss 0.1727 (0.2113)\tPrec@1 93.750 (92.740)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [33][180/390]\tTime 0.074 (0.058)\tData 0.007 (0.005)\tLoss 0.2472 (0.2109)\tPrec@1 92.969 (92.779)\tPrec@5 100.000 (99.866)\t\n",
            "TRAINING - Epoch: [33][190/390]\tTime 0.052 (0.058)\tData 0.003 (0.005)\tLoss 0.1322 (0.2099)\tPrec@1 96.094 (92.797)\tPrec@5 99.219 (99.869)\t\n",
            "TRAINING - Epoch: [33][200/390]\tTime 0.071 (0.058)\tData 0.002 (0.005)\tLoss 0.3139 (0.2100)\tPrec@1 90.625 (92.774)\tPrec@5 99.219 (99.864)\t\n",
            "TRAINING - Epoch: [33][210/390]\tTime 0.058 (0.058)\tData 0.007 (0.005)\tLoss 0.2956 (0.2110)\tPrec@1 89.062 (92.710)\tPrec@5 100.000 (99.863)\t\n",
            "TRAINING - Epoch: [33][220/390]\tTime 0.061 (0.057)\tData 0.007 (0.005)\tLoss 0.2344 (0.2113)\tPrec@1 90.625 (92.682)\tPrec@5 100.000 (99.862)\t\n",
            "TRAINING - Epoch: [33][230/390]\tTime 0.062 (0.057)\tData 0.007 (0.004)\tLoss 0.2355 (0.2130)\tPrec@1 92.969 (92.627)\tPrec@5 99.219 (99.858)\t\n",
            "TRAINING - Epoch: [33][240/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2505 (0.2129)\tPrec@1 90.625 (92.619)\tPrec@5 99.219 (99.861)\t\n",
            "TRAINING - Epoch: [33][250/390]\tTime 0.069 (0.057)\tData 0.000 (0.004)\tLoss 0.2938 (0.2125)\tPrec@1 88.281 (92.629)\tPrec@5 100.000 (99.866)\t\n",
            "TRAINING - Epoch: [33][260/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2208 (0.2145)\tPrec@1 92.188 (92.565)\tPrec@5 100.000 (99.862)\t\n",
            "TRAINING - Epoch: [33][270/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.1692 (0.2143)\tPrec@1 92.969 (92.559)\tPrec@5 100.000 (99.865)\t\n",
            "TRAINING - Epoch: [33][280/390]\tTime 0.055 (0.057)\tData 0.008 (0.004)\tLoss 0.2286 (0.2151)\tPrec@1 91.406 (92.502)\tPrec@5 100.000 (99.861)\t\n",
            "TRAINING - Epoch: [33][290/390]\tTime 0.052 (0.057)\tData 0.006 (0.004)\tLoss 0.3657 (0.2158)\tPrec@1 87.500 (92.475)\tPrec@5 99.219 (99.858)\t\n",
            "TRAINING - Epoch: [33][300/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.2161 (0.2171)\tPrec@1 92.188 (92.421)\tPrec@5 100.000 (99.855)\t\n",
            "TRAINING - Epoch: [33][310/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2494 (0.2173)\tPrec@1 92.188 (92.416)\tPrec@5 100.000 (99.854)\t\n",
            "TRAINING - Epoch: [33][320/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.1888 (0.2179)\tPrec@1 92.188 (92.399)\tPrec@5 99.219 (99.849)\t\n",
            "TRAINING - Epoch: [33][330/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.3843 (0.2192)\tPrec@1 86.719 (92.353)\tPrec@5 99.219 (99.847)\t\n",
            "TRAINING - Epoch: [33][340/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2388 (0.2209)\tPrec@1 91.406 (92.302)\tPrec@5 100.000 (99.846)\t\n",
            "TRAINING - Epoch: [33][350/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.1755 (0.2223)\tPrec@1 92.188 (92.225)\tPrec@5 100.000 (99.844)\t\n",
            "TRAINING - Epoch: [33][360/390]\tTime 0.075 (0.057)\tData 0.006 (0.004)\tLoss 0.3444 (0.2236)\tPrec@1 89.062 (92.192)\tPrec@5 100.000 (99.849)\t\n",
            "TRAINING - Epoch: [33][370/390]\tTime 0.061 (0.057)\tData 0.007 (0.004)\tLoss 0.1532 (0.2234)\tPrec@1 94.531 (92.200)\tPrec@5 100.000 (99.846)\t\n",
            "TRAINING - Epoch: [33][380/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1411 (0.2235)\tPrec@1 96.094 (92.200)\tPrec@5 100.000 (99.846)\t\n",
            "TRAINING - Epoch: [33][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.1921 (0.2241)\tPrec@1 92.969 (92.175)\tPrec@5 100.000 (99.848)\t\n",
            "EVALUATING - Epoch: [33][0/79]\tTime 0.285 (0.285)\tData 0.255 (0.255)\tLoss 0.3101 (0.3101)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [33][10/79]\tTime 0.043 (0.055)\tData 0.007 (0.027)\tLoss 0.3611 (0.4238)\tPrec@1 89.062 (86.861)\tPrec@5 100.000 (99.361)\t\n",
            "EVALUATING - Epoch: [33][20/79]\tTime 0.040 (0.043)\tData 0.012 (0.016)\tLoss 0.4422 (0.4339)\tPrec@1 85.938 (86.496)\tPrec@5 99.219 (99.293)\t\n",
            "EVALUATING - Epoch: [33][30/79]\tTime 0.047 (0.038)\tData 0.005 (0.013)\tLoss 0.3032 (0.4334)\tPrec@1 92.188 (86.442)\tPrec@5 100.000 (99.244)\t\n",
            "EVALUATING - Epoch: [33][40/79]\tTime 0.028 (0.037)\tData 0.005 (0.010)\tLoss 0.5084 (0.4227)\tPrec@1 85.156 (86.662)\tPrec@5 99.219 (99.314)\t\n",
            "EVALUATING - Epoch: [33][50/79]\tTime 0.027 (0.036)\tData 0.000 (0.009)\tLoss 0.4158 (0.4163)\tPrec@1 86.719 (86.903)\tPrec@5 100.000 (99.372)\t\n",
            "EVALUATING - Epoch: [33][60/79]\tTime 0.032 (0.034)\tData 0.010 (0.008)\tLoss 0.2672 (0.4075)\tPrec@1 94.531 (87.154)\tPrec@5 99.219 (99.424)\t\n",
            "EVALUATING - Epoch: [33][70/79]\tTime 0.026 (0.034)\tData 0.010 (0.008)\tLoss 0.1962 (0.4084)\tPrec@1 95.312 (87.027)\tPrec@5 100.000 (99.450)\t\n",
            "EVALUATING - Epoch: [33][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.4458 (0.4037)\tPrec@1 93.750 (87.170)\tPrec@5 100.000 (99.440)\t\n",
            "\n",
            "Results - Epoch: 34\n",
            "Training Loss 0.2241 \tTraining Prec@1 92.175 \tTraining Prec@5 99.848 \tValidation Loss 0.4037 \tValidation Prec@1 87.170 \tValidation Prec@5 99.440 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 35\n",
            "\n",
            "TRAINING - Epoch: [34][0/390]\tTime 0.380 (0.380)\tData 0.271 (0.271)\tLoss 0.1685 (0.1685)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [34][10/390]\tTime 0.056 (0.088)\tData 0.007 (0.028)\tLoss 0.1713 (0.1889)\tPrec@1 92.969 (93.821)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [34][20/390]\tTime 0.067 (0.073)\tData 0.007 (0.017)\tLoss 0.1883 (0.1787)\tPrec@1 92.188 (93.899)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [34][30/390]\tTime 0.074 (0.067)\tData 0.007 (0.012)\tLoss 0.1510 (0.1791)\tPrec@1 93.750 (93.926)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [34][40/390]\tTime 0.047 (0.064)\tData 0.000 (0.010)\tLoss 0.2466 (0.1803)\tPrec@1 92.188 (93.883)\tPrec@5 99.219 (99.924)\t\n",
            "TRAINING - Epoch: [34][50/390]\tTime 0.046 (0.062)\tData 0.000 (0.009)\tLoss 0.2455 (0.1808)\tPrec@1 90.625 (93.919)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [34][60/390]\tTime 0.048 (0.061)\tData 0.000 (0.008)\tLoss 0.2032 (0.1873)\tPrec@1 93.750 (93.609)\tPrec@5 100.000 (99.910)\t\n",
            "TRAINING - Epoch: [34][70/390]\tTime 0.063 (0.061)\tData 0.000 (0.007)\tLoss 0.2661 (0.1877)\tPrec@1 90.625 (93.596)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [34][80/390]\tTime 0.059 (0.060)\tData 0.011 (0.006)\tLoss 0.1752 (0.1855)\tPrec@1 93.750 (93.615)\tPrec@5 100.000 (99.894)\t\n",
            "TRAINING - Epoch: [34][90/390]\tTime 0.050 (0.060)\tData 0.000 (0.006)\tLoss 0.2443 (0.1859)\tPrec@1 90.625 (93.535)\tPrec@5 100.000 (99.897)\t\n",
            "TRAINING - Epoch: [34][100/390]\tTime 0.050 (0.059)\tData 0.000 (0.006)\tLoss 0.1614 (0.1902)\tPrec@1 92.969 (93.386)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [34][110/390]\tTime 0.046 (0.059)\tData 0.000 (0.006)\tLoss 0.1727 (0.1923)\tPrec@1 95.312 (93.328)\tPrec@5 99.219 (99.880)\t\n",
            "TRAINING - Epoch: [34][120/390]\tTime 0.049 (0.059)\tData 0.000 (0.006)\tLoss 0.1843 (0.1956)\tPrec@1 93.750 (93.188)\tPrec@5 100.000 (99.884)\t\n",
            "TRAINING - Epoch: [34][130/390]\tTime 0.057 (0.058)\tData 0.000 (0.006)\tLoss 0.2262 (0.1970)\tPrec@1 90.625 (93.100)\tPrec@5 100.000 (99.881)\t\n",
            "TRAINING - Epoch: [34][140/390]\tTime 0.055 (0.058)\tData 0.000 (0.005)\tLoss 0.2403 (0.1998)\tPrec@1 89.062 (92.996)\tPrec@5 99.219 (99.878)\t\n",
            "TRAINING - Epoch: [34][150/390]\tTime 0.079 (0.058)\tData 0.006 (0.005)\tLoss 0.1578 (0.2014)\tPrec@1 93.750 (92.948)\tPrec@5 100.000 (99.876)\t\n",
            "TRAINING - Epoch: [34][160/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.3087 (0.2032)\tPrec@1 85.938 (92.886)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [34][170/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.3624 (0.2054)\tPrec@1 86.719 (92.832)\tPrec@5 100.000 (99.881)\t\n",
            "TRAINING - Epoch: [34][180/390]\tTime 0.059 (0.058)\tData 0.007 (0.005)\tLoss 0.1672 (0.2047)\tPrec@1 93.750 (92.839)\tPrec@5 100.000 (99.888)\t\n",
            "TRAINING - Epoch: [34][190/390]\tTime 0.053 (0.058)\tData 0.000 (0.005)\tLoss 0.2040 (0.2064)\tPrec@1 93.750 (92.768)\tPrec@5 100.000 (99.890)\t\n",
            "TRAINING - Epoch: [34][200/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.3110 (0.2071)\tPrec@1 91.406 (92.763)\tPrec@5 98.438 (99.880)\t\n",
            "TRAINING - Epoch: [34][210/390]\tTime 0.050 (0.057)\tData 0.001 (0.004)\tLoss 0.2233 (0.2079)\tPrec@1 92.969 (92.710)\tPrec@5 99.219 (99.882)\t\n",
            "TRAINING - Epoch: [34][220/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.3979 (0.2107)\tPrec@1 88.281 (92.629)\tPrec@5 99.219 (99.876)\t\n",
            "TRAINING - Epoch: [34][230/390]\tTime 0.053 (0.057)\tData 0.004 (0.004)\tLoss 0.1726 (0.2104)\tPrec@1 96.875 (92.698)\tPrec@5 99.219 (99.871)\t\n",
            "TRAINING - Epoch: [34][240/390]\tTime 0.080 (0.057)\tData 0.000 (0.004)\tLoss 0.2997 (0.2119)\tPrec@1 87.500 (92.641)\tPrec@5 99.219 (99.864)\t\n",
            "TRAINING - Epoch: [34][250/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1617 (0.2123)\tPrec@1 94.531 (92.648)\tPrec@5 99.219 (99.866)\t\n",
            "TRAINING - Epoch: [34][260/390]\tTime 0.052 (0.057)\tData 0.005 (0.004)\tLoss 0.2767 (0.2129)\tPrec@1 87.500 (92.619)\tPrec@5 100.000 (99.868)\t\n",
            "TRAINING - Epoch: [34][270/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1996 (0.2145)\tPrec@1 92.969 (92.531)\tPrec@5 100.000 (99.873)\t\n",
            "TRAINING - Epoch: [34][280/390]\tTime 0.060 (0.057)\tData 0.006 (0.004)\tLoss 0.1476 (0.2155)\tPrec@1 93.750 (92.496)\tPrec@5 100.000 (99.875)\t\n",
            "TRAINING - Epoch: [34][290/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2170 (0.2166)\tPrec@1 92.188 (92.437)\tPrec@5 100.000 (99.877)\t\n",
            "TRAINING - Epoch: [34][300/390]\tTime 0.053 (0.057)\tData 0.005 (0.004)\tLoss 0.2515 (0.2166)\tPrec@1 91.406 (92.455)\tPrec@5 100.000 (99.878)\t\n",
            "TRAINING - Epoch: [34][310/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2299 (0.2166)\tPrec@1 91.406 (92.436)\tPrec@5 100.000 (99.882)\t\n",
            "TRAINING - Epoch: [34][320/390]\tTime 0.047 (0.056)\tData 0.000 (0.004)\tLoss 0.2138 (0.2175)\tPrec@1 91.406 (92.411)\tPrec@5 100.000 (99.881)\t\n",
            "TRAINING - Epoch: [34][330/390]\tTime 0.049 (0.056)\tData 0.003 (0.004)\tLoss 0.2192 (0.2167)\tPrec@1 92.188 (92.452)\tPrec@5 100.000 (99.875)\t\n",
            "TRAINING - Epoch: [34][340/390]\tTime 0.058 (0.056)\tData 0.007 (0.004)\tLoss 0.2223 (0.2153)\tPrec@1 90.625 (92.497)\tPrec@5 100.000 (99.872)\t\n",
            "TRAINING - Epoch: [34][350/390]\tTime 0.056 (0.056)\tData 0.007 (0.004)\tLoss 0.1862 (0.2162)\tPrec@1 93.750 (92.452)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [34][360/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.2348 (0.2166)\tPrec@1 92.188 (92.449)\tPrec@5 100.000 (99.868)\t\n",
            "TRAINING - Epoch: [34][370/390]\tTime 0.060 (0.056)\tData 0.007 (0.004)\tLoss 0.1749 (0.2158)\tPrec@1 93.750 (92.484)\tPrec@5 100.000 (99.869)\t\n",
            "TRAINING - Epoch: [34][380/390]\tTime 0.050 (0.056)\tData 0.000 (0.004)\tLoss 0.3017 (0.2158)\tPrec@1 89.844 (92.479)\tPrec@5 100.000 (99.867)\t\n",
            "TRAINING - Epoch: [34][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.2325 (0.2157)\tPrec@1 92.188 (92.488)\tPrec@5 99.219 (99.864)\t\n",
            "EVALUATING - Epoch: [34][0/79]\tTime 0.195 (0.195)\tData 0.167 (0.167)\tLoss 0.4017 (0.4017)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [34][10/79]\tTime 0.034 (0.049)\tData 0.003 (0.024)\tLoss 0.4640 (0.4039)\tPrec@1 86.719 (87.571)\tPrec@5 100.000 (99.503)\t\n",
            "EVALUATING - Epoch: [34][20/79]\tTime 0.039 (0.044)\tData 0.000 (0.015)\tLoss 0.5293 (0.4437)\tPrec@1 83.594 (86.942)\tPrec@5 98.438 (99.330)\t\n",
            "EVALUATING - Epoch: [34][30/79]\tTime 0.033 (0.039)\tData 0.000 (0.012)\tLoss 0.3522 (0.4409)\tPrec@1 87.500 (86.769)\tPrec@5 100.000 (99.244)\t\n",
            "EVALUATING - Epoch: [34][40/79]\tTime 0.013 (0.036)\tData 0.000 (0.010)\tLoss 0.6072 (0.4347)\tPrec@1 81.250 (86.814)\tPrec@5 100.000 (99.371)\t\n",
            "EVALUATING - Epoch: [34][50/79]\tTime 0.031 (0.035)\tData 0.005 (0.009)\tLoss 0.4589 (0.4216)\tPrec@1 89.844 (87.178)\tPrec@5 100.000 (99.464)\t\n",
            "EVALUATING - Epoch: [34][60/79]\tTime 0.018 (0.034)\tData 0.000 (0.008)\tLoss 0.4420 (0.4219)\tPrec@1 87.500 (87.295)\tPrec@5 99.219 (99.475)\t\n",
            "EVALUATING - Epoch: [34][70/79]\tTime 0.039 (0.033)\tData 0.005 (0.008)\tLoss 0.3648 (0.4240)\tPrec@1 86.719 (87.170)\tPrec@5 100.000 (99.483)\t\n",
            "EVALUATING - Epoch: [34][78/79]\tTime 0.006 (0.031)\tData 0.000 (0.007)\tLoss 0.5725 (0.4205)\tPrec@1 87.500 (87.260)\tPrec@5 100.000 (99.490)\t\n",
            "\n",
            "Results - Epoch: 35\n",
            "Training Loss 0.2157 \tTraining Prec@1 92.488 \tTraining Prec@5 99.864 \tValidation Loss 0.4205 \tValidation Prec@1 87.260 \tValidation Prec@5 99.490 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 36\n",
            "\n",
            "TRAINING - Epoch: [35][0/390]\tTime 0.367 (0.367)\tData 0.250 (0.250)\tLoss 0.1892 (0.1892)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [35][10/390]\tTime 0.054 (0.085)\tData 0.000 (0.026)\tLoss 0.1510 (0.1849)\tPrec@1 92.969 (93.111)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [35][20/390]\tTime 0.050 (0.071)\tData 0.004 (0.016)\tLoss 0.2055 (0.1947)\tPrec@1 92.969 (92.820)\tPrec@5 100.000 (99.851)\t\n",
            "TRAINING - Epoch: [35][30/390]\tTime 0.048 (0.066)\tData 0.000 (0.012)\tLoss 0.2041 (0.2000)\tPrec@1 92.188 (92.994)\tPrec@5 100.000 (99.849)\t\n",
            "TRAINING - Epoch: [35][40/390]\tTime 0.067 (0.064)\tData 0.008 (0.010)\tLoss 0.1287 (0.1972)\tPrec@1 95.312 (92.988)\tPrec@5 100.000 (99.867)\t\n",
            "TRAINING - Epoch: [35][50/390]\tTime 0.065 (0.062)\tData 0.007 (0.009)\tLoss 0.1910 (0.1966)\tPrec@1 92.188 (92.984)\tPrec@5 99.219 (99.877)\t\n",
            "TRAINING - Epoch: [35][60/390]\tTime 0.053 (0.061)\tData 0.000 (0.008)\tLoss 0.1665 (0.1944)\tPrec@1 95.312 (93.122)\tPrec@5 100.000 (99.898)\t\n",
            "TRAINING - Epoch: [35][70/390]\tTime 0.060 (0.061)\tData 0.010 (0.007)\tLoss 0.1489 (0.1940)\tPrec@1 95.312 (93.123)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [35][80/390]\tTime 0.071 (0.060)\tData 0.001 (0.007)\tLoss 0.1181 (0.1914)\tPrec@1 94.531 (93.248)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [35][90/390]\tTime 0.058 (0.060)\tData 0.007 (0.006)\tLoss 0.2353 (0.1932)\tPrec@1 91.406 (93.209)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [35][100/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.2054 (0.1949)\tPrec@1 94.531 (93.201)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [35][110/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.2747 (0.1964)\tPrec@1 90.625 (93.152)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [35][120/390]\tTime 0.066 (0.059)\tData 0.006 (0.005)\tLoss 0.1590 (0.1965)\tPrec@1 96.094 (93.175)\tPrec@5 99.219 (99.903)\t\n",
            "TRAINING - Epoch: [35][130/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.1352 (0.1969)\tPrec@1 94.531 (93.136)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [35][140/390]\tTime 0.068 (0.058)\tData 0.012 (0.005)\tLoss 0.1490 (0.1978)\tPrec@1 94.531 (93.107)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [35][150/390]\tTime 0.063 (0.058)\tData 0.007 (0.005)\tLoss 0.2610 (0.1998)\tPrec@1 89.844 (93.031)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [35][160/390]\tTime 0.053 (0.058)\tData 0.000 (0.005)\tLoss 0.2655 (0.2011)\tPrec@1 88.281 (92.978)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [35][170/390]\tTime 0.049 (0.058)\tData 0.001 (0.005)\tLoss 0.1812 (0.2013)\tPrec@1 93.750 (92.923)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [35][180/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2336 (0.2024)\tPrec@1 89.844 (92.891)\tPrec@5 100.000 (99.892)\t\n",
            "TRAINING - Epoch: [35][190/390]\tTime 0.060 (0.058)\tData 0.006 (0.005)\tLoss 0.1480 (0.2014)\tPrec@1 92.969 (92.887)\tPrec@5 100.000 (99.898)\t\n",
            "TRAINING - Epoch: [35][200/390]\tTime 0.056 (0.057)\tData 0.007 (0.005)\tLoss 0.1753 (0.2023)\tPrec@1 92.969 (92.868)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [35][210/390]\tTime 0.055 (0.057)\tData 0.008 (0.005)\tLoss 0.3623 (0.2043)\tPrec@1 85.938 (92.791)\tPrec@5 100.000 (99.893)\t\n",
            "TRAINING - Epoch: [35][220/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.1649 (0.2047)\tPrec@1 95.312 (92.778)\tPrec@5 100.000 (99.894)\t\n",
            "TRAINING - Epoch: [35][230/390]\tTime 0.066 (0.057)\tData 0.008 (0.004)\tLoss 0.2969 (0.2060)\tPrec@1 90.625 (92.705)\tPrec@5 100.000 (99.892)\t\n",
            "TRAINING - Epoch: [35][240/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.0947 (0.2075)\tPrec@1 98.438 (92.671)\tPrec@5 100.000 (99.887)\t\n",
            "TRAINING - Epoch: [35][250/390]\tTime 0.058 (0.057)\tData 0.007 (0.004)\tLoss 0.3079 (0.2076)\tPrec@1 91.406 (92.664)\tPrec@5 100.000 (99.891)\t\n",
            "TRAINING - Epoch: [35][260/390]\tTime 0.057 (0.057)\tData 0.000 (0.004)\tLoss 0.1792 (0.2092)\tPrec@1 92.969 (92.628)\tPrec@5 100.000 (99.886)\t\n",
            "TRAINING - Epoch: [35][270/390]\tTime 0.045 (0.057)\tData 0.000 (0.004)\tLoss 0.3321 (0.2096)\tPrec@1 86.719 (92.606)\tPrec@5 99.219 (99.885)\t\n",
            "TRAINING - Epoch: [35][280/390]\tTime 0.054 (0.057)\tData 0.000 (0.004)\tLoss 0.1815 (0.2097)\tPrec@1 93.750 (92.596)\tPrec@5 100.000 (99.878)\t\n",
            "TRAINING - Epoch: [35][290/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2621 (0.2109)\tPrec@1 89.844 (92.569)\tPrec@5 99.219 (99.866)\t\n",
            "TRAINING - Epoch: [35][300/390]\tTime 0.052 (0.057)\tData 0.004 (0.004)\tLoss 0.3050 (0.2106)\tPrec@1 87.500 (92.551)\tPrec@5 99.219 (99.868)\t\n",
            "TRAINING - Epoch: [35][310/390]\tTime 0.066 (0.057)\tData 0.008 (0.004)\tLoss 0.1923 (0.2114)\tPrec@1 92.969 (92.532)\tPrec@5 99.219 (99.864)\t\n",
            "TRAINING - Epoch: [35][320/390]\tTime 0.055 (0.057)\tData 0.000 (0.004)\tLoss 0.1826 (0.2115)\tPrec@1 92.969 (92.531)\tPrec@5 99.219 (99.864)\t\n",
            "TRAINING - Epoch: [35][330/390]\tTime 0.066 (0.057)\tData 0.006 (0.004)\tLoss 0.1312 (0.2120)\tPrec@1 96.875 (92.511)\tPrec@5 100.000 (99.861)\t\n",
            "TRAINING - Epoch: [35][340/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2065 (0.2127)\tPrec@1 92.188 (92.492)\tPrec@5 100.000 (99.860)\t\n",
            "TRAINING - Epoch: [35][350/390]\tTime 0.071 (0.057)\tData 0.007 (0.004)\tLoss 0.2386 (0.2129)\tPrec@1 92.188 (92.486)\tPrec@5 99.219 (99.862)\t\n",
            "TRAINING - Epoch: [35][360/390]\tTime 0.057 (0.057)\tData 0.012 (0.004)\tLoss 0.2490 (0.2138)\tPrec@1 90.625 (92.471)\tPrec@5 100.000 (99.864)\t\n",
            "TRAINING - Epoch: [35][370/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2865 (0.2151)\tPrec@1 89.844 (92.436)\tPrec@5 100.000 (99.863)\t\n",
            "TRAINING - Epoch: [35][380/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.3326 (0.2156)\tPrec@1 88.281 (92.407)\tPrec@5 100.000 (99.865)\t\n",
            "TRAINING - Epoch: [35][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.1527 (0.2162)\tPrec@1 96.094 (92.390)\tPrec@5 100.000 (99.866)\t\n",
            "EVALUATING - Epoch: [35][0/79]\tTime 0.272 (0.272)\tData 0.234 (0.234)\tLoss 0.5056 (0.5056)\tPrec@1 85.156 (85.156)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [35][10/79]\tTime 0.043 (0.055)\tData 0.017 (0.027)\tLoss 0.3558 (0.4563)\tPrec@1 90.625 (86.080)\tPrec@5 99.219 (99.645)\t\n",
            "EVALUATING - Epoch: [35][20/79]\tTime 0.029 (0.041)\tData 0.005 (0.016)\tLoss 0.4621 (0.4660)\tPrec@1 87.500 (85.900)\tPrec@5 99.219 (99.330)\t\n",
            "EVALUATING - Epoch: [35][30/79]\tTime 0.052 (0.039)\tData 0.012 (0.012)\tLoss 0.3871 (0.4671)\tPrec@1 90.625 (86.139)\tPrec@5 100.000 (99.269)\t\n",
            "EVALUATING - Epoch: [35][40/79]\tTime 0.030 (0.036)\tData 0.010 (0.010)\tLoss 0.5253 (0.4716)\tPrec@1 80.469 (86.090)\tPrec@5 100.000 (99.352)\t\n",
            "EVALUATING - Epoch: [35][50/79]\tTime 0.028 (0.036)\tData 0.000 (0.009)\tLoss 0.3738 (0.4602)\tPrec@1 88.281 (86.351)\tPrec@5 99.219 (99.403)\t\n",
            "EVALUATING - Epoch: [35][60/79]\tTime 0.017 (0.034)\tData 0.000 (0.009)\tLoss 0.4887 (0.4613)\tPrec@1 85.156 (86.206)\tPrec@5 99.219 (99.360)\t\n",
            "EVALUATING - Epoch: [35][70/79]\tTime 0.024 (0.034)\tData 0.000 (0.008)\tLoss 0.4196 (0.4585)\tPrec@1 86.719 (86.191)\tPrec@5 99.219 (99.395)\t\n",
            "EVALUATING - Epoch: [35][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.008)\tLoss 0.8405 (0.4584)\tPrec@1 75.000 (86.180)\tPrec@5 100.000 (99.390)\t\n",
            "\n",
            "Results - Epoch: 36\n",
            "Training Loss 0.2162 \tTraining Prec@1 92.390 \tTraining Prec@5 99.866 \tValidation Loss 0.4584 \tValidation Prec@1 86.180 \tValidation Prec@5 99.390 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 37\n",
            "\n",
            "TRAINING - Epoch: [36][0/390]\tTime 0.286 (0.286)\tData 0.191 (0.191)\tLoss 0.1623 (0.1623)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [36][10/390]\tTime 0.049 (0.089)\tData 0.000 (0.024)\tLoss 0.2250 (0.2018)\tPrec@1 92.969 (93.750)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [36][20/390]\tTime 0.055 (0.073)\tData 0.007 (0.014)\tLoss 0.1400 (0.1963)\tPrec@1 96.875 (93.452)\tPrec@5 100.000 (99.702)\t\n",
            "TRAINING - Epoch: [36][30/390]\tTime 0.049 (0.067)\tData 0.000 (0.010)\tLoss 0.1546 (0.1959)\tPrec@1 95.312 (93.196)\tPrec@5 100.000 (99.748)\t\n",
            "TRAINING - Epoch: [36][40/390]\tTime 0.048 (0.064)\tData 0.000 (0.009)\tLoss 0.2422 (0.1980)\tPrec@1 89.062 (92.835)\tPrec@5 100.000 (99.809)\t\n",
            "TRAINING - Epoch: [36][50/390]\tTime 0.056 (0.063)\tData 0.007 (0.008)\tLoss 0.1442 (0.1946)\tPrec@1 96.094 (93.015)\tPrec@5 100.000 (99.816)\t\n",
            "TRAINING - Epoch: [36][60/390]\tTime 0.048 (0.062)\tData 0.000 (0.007)\tLoss 0.2538 (0.1963)\tPrec@1 90.625 (92.918)\tPrec@5 100.000 (99.846)\t\n",
            "TRAINING - Epoch: [36][70/390]\tTime 0.069 (0.061)\tData 0.007 (0.007)\tLoss 0.2583 (0.1985)\tPrec@1 92.969 (92.771)\tPrec@5 100.000 (99.835)\t\n",
            "TRAINING - Epoch: [36][80/390]\tTime 0.069 (0.061)\tData 0.007 (0.006)\tLoss 0.1715 (0.1956)\tPrec@1 93.750 (92.901)\tPrec@5 100.000 (99.855)\t\n",
            "TRAINING - Epoch: [36][90/390]\tTime 0.051 (0.060)\tData 0.000 (0.006)\tLoss 0.2800 (0.1962)\tPrec@1 88.281 (92.891)\tPrec@5 100.000 (99.863)\t\n",
            "TRAINING - Epoch: [36][100/390]\tTime 0.054 (0.060)\tData 0.006 (0.006)\tLoss 0.2529 (0.1964)\tPrec@1 90.625 (92.938)\tPrec@5 100.000 (99.861)\t\n",
            "TRAINING - Epoch: [36][110/390]\tTime 0.056 (0.059)\tData 0.000 (0.006)\tLoss 0.1773 (0.1956)\tPrec@1 93.750 (92.955)\tPrec@5 100.000 (99.859)\t\n",
            "TRAINING - Epoch: [36][120/390]\tTime 0.056 (0.059)\tData 0.000 (0.005)\tLoss 0.2938 (0.1980)\tPrec@1 92.188 (92.885)\tPrec@5 99.219 (99.864)\t\n",
            "TRAINING - Epoch: [36][130/390]\tTime 0.070 (0.059)\tData 0.009 (0.005)\tLoss 0.1848 (0.1977)\tPrec@1 92.969 (92.903)\tPrec@5 100.000 (99.857)\t\n",
            "TRAINING - Epoch: [36][140/390]\tTime 0.051 (0.058)\tData 0.004 (0.005)\tLoss 0.1921 (0.1973)\tPrec@1 92.969 (92.902)\tPrec@5 100.000 (99.850)\t\n",
            "TRAINING - Epoch: [36][150/390]\tTime 0.063 (0.058)\tData 0.000 (0.005)\tLoss 0.1368 (0.1972)\tPrec@1 96.875 (92.912)\tPrec@5 100.000 (99.855)\t\n",
            "TRAINING - Epoch: [36][160/390]\tTime 0.062 (0.058)\tData 0.000 (0.005)\tLoss 0.1945 (0.1978)\tPrec@1 92.188 (92.906)\tPrec@5 100.000 (99.854)\t\n",
            "TRAINING - Epoch: [36][170/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2181 (0.1983)\tPrec@1 92.969 (92.868)\tPrec@5 100.000 (99.863)\t\n",
            "TRAINING - Epoch: [36][180/390]\tTime 0.054 (0.058)\tData 0.000 (0.004)\tLoss 0.2972 (0.1981)\tPrec@1 88.281 (92.878)\tPrec@5 99.219 (99.866)\t\n",
            "TRAINING - Epoch: [36][190/390]\tTime 0.055 (0.058)\tData 0.009 (0.004)\tLoss 0.2399 (0.1986)\tPrec@1 92.969 (92.887)\tPrec@5 100.000 (99.869)\t\n",
            "TRAINING - Epoch: [36][200/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.2126 (0.1988)\tPrec@1 94.531 (92.887)\tPrec@5 99.219 (99.868)\t\n",
            "TRAINING - Epoch: [36][210/390]\tTime 0.058 (0.058)\tData 0.000 (0.004)\tLoss 0.1983 (0.2006)\tPrec@1 95.312 (92.847)\tPrec@5 100.000 (99.863)\t\n",
            "TRAINING - Epoch: [36][220/390]\tTime 0.052 (0.058)\tData 0.000 (0.004)\tLoss 0.2130 (0.2020)\tPrec@1 92.188 (92.774)\tPrec@5 100.000 (99.862)\t\n",
            "TRAINING - Epoch: [36][230/390]\tTime 0.061 (0.058)\tData 0.000 (0.004)\tLoss 0.2073 (0.2021)\tPrec@1 91.406 (92.773)\tPrec@5 100.000 (99.865)\t\n",
            "TRAINING - Epoch: [36][240/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.1630 (0.2016)\tPrec@1 92.969 (92.790)\tPrec@5 100.000 (99.870)\t\n",
            "TRAINING - Epoch: [36][250/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.2045 (0.2015)\tPrec@1 94.531 (92.822)\tPrec@5 100.000 (99.872)\t\n",
            "TRAINING - Epoch: [36][260/390]\tTime 0.051 (0.058)\tData 0.000 (0.004)\tLoss 0.1519 (0.2027)\tPrec@1 93.750 (92.807)\tPrec@5 100.000 (99.859)\t\n",
            "TRAINING - Epoch: [36][270/390]\tTime 0.055 (0.058)\tData 0.007 (0.004)\tLoss 0.1697 (0.2042)\tPrec@1 93.750 (92.778)\tPrec@5 100.000 (99.862)\t\n",
            "TRAINING - Epoch: [36][280/390]\tTime 0.060 (0.058)\tData 0.006 (0.004)\tLoss 0.3144 (0.2054)\tPrec@1 89.844 (92.749)\tPrec@5 98.438 (99.855)\t\n",
            "TRAINING - Epoch: [36][290/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.1836 (0.2059)\tPrec@1 95.312 (92.749)\tPrec@5 99.219 (99.852)\t\n",
            "TRAINING - Epoch: [36][300/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2335 (0.2076)\tPrec@1 92.188 (92.696)\tPrec@5 100.000 (99.844)\t\n",
            "TRAINING - Epoch: [36][310/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.2900 (0.2074)\tPrec@1 92.969 (92.718)\tPrec@5 100.000 (99.847)\t\n",
            "TRAINING - Epoch: [36][320/390]\tTime 0.054 (0.057)\tData 0.001 (0.004)\tLoss 0.3052 (0.2086)\tPrec@1 89.844 (92.679)\tPrec@5 100.000 (99.849)\t\n",
            "TRAINING - Epoch: [36][330/390]\tTime 0.070 (0.057)\tData 0.010 (0.004)\tLoss 0.2353 (0.2084)\tPrec@1 91.406 (92.686)\tPrec@5 100.000 (99.849)\t\n",
            "TRAINING - Epoch: [36][340/390]\tTime 0.079 (0.057)\tData 0.000 (0.004)\tLoss 0.2120 (0.2075)\tPrec@1 93.750 (92.719)\tPrec@5 100.000 (99.853)\t\n",
            "TRAINING - Epoch: [36][350/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.3225 (0.2086)\tPrec@1 89.844 (92.713)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [36][360/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.2828 (0.2092)\tPrec@1 89.062 (92.679)\tPrec@5 100.000 (99.859)\t\n",
            "TRAINING - Epoch: [36][370/390]\tTime 0.059 (0.057)\tData 0.007 (0.004)\tLoss 0.3274 (0.2101)\tPrec@1 89.062 (92.674)\tPrec@5 99.219 (99.855)\t\n",
            "TRAINING - Epoch: [36][380/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2641 (0.2102)\tPrec@1 92.969 (92.657)\tPrec@5 99.219 (99.856)\t\n",
            "TRAINING - Epoch: [36][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.2113 (0.2106)\tPrec@1 94.531 (92.654)\tPrec@5 100.000 (99.856)\t\n",
            "EVALUATING - Epoch: [36][0/79]\tTime 0.203 (0.203)\tData 0.166 (0.166)\tLoss 0.2727 (0.2727)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [36][10/79]\tTime 0.031 (0.052)\tData 0.006 (0.026)\tLoss 0.3572 (0.3818)\tPrec@1 89.062 (87.642)\tPrec@5 100.000 (99.645)\t\n",
            "EVALUATING - Epoch: [36][20/79]\tTime 0.046 (0.044)\tData 0.007 (0.017)\tLoss 0.3749 (0.4145)\tPrec@1 87.500 (87.351)\tPrec@5 99.219 (99.665)\t\n",
            "EVALUATING - Epoch: [36][30/79]\tTime 0.049 (0.040)\tData 0.026 (0.013)\tLoss 0.3531 (0.4188)\tPrec@1 86.719 (87.324)\tPrec@5 100.000 (99.496)\t\n",
            "EVALUATING - Epoch: [36][40/79]\tTime 0.030 (0.037)\tData 0.000 (0.011)\tLoss 0.5082 (0.4248)\tPrec@1 82.031 (87.157)\tPrec@5 99.219 (99.466)\t\n",
            "EVALUATING - Epoch: [36][50/79]\tTime 0.037 (0.036)\tData 0.010 (0.010)\tLoss 0.5379 (0.4286)\tPrec@1 83.594 (87.040)\tPrec@5 100.000 (99.494)\t\n",
            "EVALUATING - Epoch: [36][60/79]\tTime 0.028 (0.035)\tData 0.000 (0.009)\tLoss 0.3925 (0.4308)\tPrec@1 89.844 (86.885)\tPrec@5 99.219 (99.462)\t\n",
            "EVALUATING - Epoch: [36][70/79]\tTime 0.041 (0.034)\tData 0.005 (0.008)\tLoss 0.3657 (0.4345)\tPrec@1 85.938 (86.730)\tPrec@5 100.000 (99.516)\t\n",
            "EVALUATING - Epoch: [36][78/79]\tTime 0.006 (0.032)\tData 0.000 (0.008)\tLoss 0.8657 (0.4319)\tPrec@1 81.250 (86.890)\tPrec@5 100.000 (99.540)\t\n",
            "\n",
            "Results - Epoch: 37\n",
            "Training Loss 0.2106 \tTraining Prec@1 92.654 \tTraining Prec@5 99.856 \tValidation Loss 0.4319 \tValidation Prec@1 86.890 \tValidation Prec@5 99.540 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 38\n",
            "\n",
            "TRAINING - Epoch: [37][0/390]\tTime 0.374 (0.374)\tData 0.279 (0.279)\tLoss 0.1481 (0.1481)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [37][10/390]\tTime 0.050 (0.088)\tData 0.000 (0.027)\tLoss 0.2253 (0.1928)\tPrec@1 91.406 (93.182)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [37][20/390]\tTime 0.048 (0.072)\tData 0.000 (0.016)\tLoss 0.1986 (0.1994)\tPrec@1 93.750 (92.894)\tPrec@5 100.000 (99.888)\t\n",
            "TRAINING - Epoch: [37][30/390]\tTime 0.064 (0.067)\tData 0.007 (0.012)\tLoss 0.1744 (0.2042)\tPrec@1 94.531 (92.893)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [37][40/390]\tTime 0.048 (0.064)\tData 0.001 (0.010)\tLoss 0.2338 (0.1982)\tPrec@1 92.969 (93.007)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [37][50/390]\tTime 0.054 (0.063)\tData 0.004 (0.009)\tLoss 0.1747 (0.2004)\tPrec@1 92.188 (92.999)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [37][60/390]\tTime 0.047 (0.061)\tData 0.000 (0.008)\tLoss 0.2221 (0.2022)\tPrec@1 89.844 (92.892)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [37][70/390]\tTime 0.047 (0.060)\tData 0.000 (0.008)\tLoss 0.2529 (0.2039)\tPrec@1 92.969 (92.925)\tPrec@5 100.000 (99.890)\t\n",
            "TRAINING - Epoch: [37][80/390]\tTime 0.054 (0.060)\tData 0.000 (0.007)\tLoss 0.1164 (0.2052)\tPrec@1 94.531 (92.930)\tPrec@5 100.000 (99.884)\t\n",
            "TRAINING - Epoch: [37][90/390]\tTime 0.075 (0.060)\tData 0.013 (0.006)\tLoss 0.2012 (0.2038)\tPrec@1 91.406 (93.003)\tPrec@5 100.000 (99.880)\t\n",
            "TRAINING - Epoch: [37][100/390]\tTime 0.050 (0.059)\tData 0.000 (0.006)\tLoss 0.3188 (0.2041)\tPrec@1 87.500 (92.992)\tPrec@5 100.000 (99.892)\t\n",
            "TRAINING - Epoch: [37][110/390]\tTime 0.057 (0.059)\tData 0.007 (0.006)\tLoss 0.2059 (0.2014)\tPrec@1 92.969 (93.110)\tPrec@5 100.000 (99.887)\t\n",
            "TRAINING - Epoch: [37][120/390]\tTime 0.053 (0.059)\tData 0.000 (0.006)\tLoss 0.2543 (0.2006)\tPrec@1 92.188 (93.156)\tPrec@5 100.000 (99.890)\t\n",
            "TRAINING - Epoch: [37][130/390]\tTime 0.055 (0.059)\tData 0.007 (0.006)\tLoss 0.1830 (0.1997)\tPrec@1 92.969 (93.195)\tPrec@5 100.000 (99.893)\t\n",
            "TRAINING - Epoch: [37][140/390]\tTime 0.059 (0.059)\tData 0.008 (0.006)\tLoss 0.1913 (0.1988)\tPrec@1 92.969 (93.163)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [37][150/390]\tTime 0.048 (0.058)\tData 0.000 (0.006)\tLoss 0.2841 (0.1997)\tPrec@1 89.844 (93.134)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [37][160/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1305 (0.1992)\tPrec@1 96.094 (93.153)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [37][170/390]\tTime 0.060 (0.058)\tData 0.007 (0.005)\tLoss 0.1302 (0.1988)\tPrec@1 96.094 (93.147)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [37][180/390]\tTime 0.053 (0.058)\tData 0.005 (0.005)\tLoss 0.1314 (0.1976)\tPrec@1 96.875 (93.150)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [37][190/390]\tTime 0.068 (0.058)\tData 0.000 (0.005)\tLoss 0.2461 (0.1994)\tPrec@1 91.406 (93.071)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [37][200/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2256 (0.1999)\tPrec@1 92.188 (93.008)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [37][210/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.2330 (0.1996)\tPrec@1 94.531 (93.032)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [37][220/390]\tTime 0.057 (0.058)\tData 0.009 (0.005)\tLoss 0.2691 (0.1998)\tPrec@1 91.406 (93.022)\tPrec@5 100.000 (99.915)\t\n",
            "TRAINING - Epoch: [37][230/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.2166 (0.2015)\tPrec@1 90.625 (92.969)\tPrec@5 99.219 (99.902)\t\n",
            "TRAINING - Epoch: [37][240/390]\tTime 0.053 (0.057)\tData 0.000 (0.005)\tLoss 0.1351 (0.2007)\tPrec@1 96.094 (92.998)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [37][250/390]\tTime 0.047 (0.057)\tData 0.000 (0.005)\tLoss 0.3263 (0.2017)\tPrec@1 87.500 (92.935)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [37][260/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.1945 (0.2015)\tPrec@1 91.406 (92.945)\tPrec@5 100.000 (99.910)\t\n",
            "TRAINING - Epoch: [37][270/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.1139 (0.2014)\tPrec@1 96.875 (92.957)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [37][280/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.2802 (0.2024)\tPrec@1 89.844 (92.913)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [37][290/390]\tTime 0.055 (0.057)\tData 0.000 (0.005)\tLoss 0.1869 (0.2024)\tPrec@1 92.188 (92.920)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [37][300/390]\tTime 0.067 (0.057)\tData 0.008 (0.005)\tLoss 0.2780 (0.2032)\tPrec@1 89.062 (92.865)\tPrec@5 99.219 (99.909)\t\n",
            "TRAINING - Epoch: [37][310/390]\tTime 0.056 (0.057)\tData 0.010 (0.005)\tLoss 0.1729 (0.2035)\tPrec@1 94.531 (92.841)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [37][320/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.1668 (0.2035)\tPrec@1 93.750 (92.825)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [37][330/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.1603 (0.2036)\tPrec@1 93.750 (92.829)\tPrec@5 99.219 (99.910)\t\n",
            "TRAINING - Epoch: [37][340/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.1710 (0.2036)\tPrec@1 92.969 (92.813)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [37][350/390]\tTime 0.054 (0.057)\tData 0.000 (0.005)\tLoss 0.2386 (0.2039)\tPrec@1 90.625 (92.795)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [37][360/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.2497 (0.2059)\tPrec@1 92.188 (92.724)\tPrec@5 100.000 (99.903)\t\n",
            "TRAINING - Epoch: [37][370/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.1622 (0.2061)\tPrec@1 94.531 (92.710)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [37][380/390]\tTime 0.059 (0.057)\tData 0.010 (0.004)\tLoss 0.1346 (0.2066)\tPrec@1 94.531 (92.682)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [37][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.2588 (0.2076)\tPrec@1 92.188 (92.640)\tPrec@5 100.000 (99.900)\t\n",
            "EVALUATING - Epoch: [37][0/79]\tTime 0.198 (0.198)\tData 0.168 (0.168)\tLoss 0.3452 (0.3452)\tPrec@1 91.406 (91.406)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [37][10/79]\tTime 0.013 (0.053)\tData 0.000 (0.022)\tLoss 0.3232 (0.4113)\tPrec@1 88.281 (87.713)\tPrec@5 100.000 (99.645)\t\n",
            "EVALUATING - Epoch: [37][20/79]\tTime 0.020 (0.043)\tData 0.001 (0.013)\tLoss 0.4356 (0.4314)\tPrec@1 87.500 (87.612)\tPrec@5 100.000 (99.516)\t\n",
            "EVALUATING - Epoch: [37][30/79]\tTime 0.047 (0.039)\tData 0.007 (0.010)\tLoss 0.3437 (0.4362)\tPrec@1 87.500 (87.324)\tPrec@5 100.000 (99.370)\t\n",
            "EVALUATING - Epoch: [37][40/79]\tTime 0.038 (0.036)\tData 0.013 (0.009)\tLoss 0.5205 (0.4331)\tPrec@1 82.812 (87.424)\tPrec@5 100.000 (99.466)\t\n",
            "EVALUATING - Epoch: [37][50/79]\tTime 0.043 (0.035)\tData 0.001 (0.008)\tLoss 0.3196 (0.4263)\tPrec@1 88.281 (87.699)\tPrec@5 100.000 (99.510)\t\n",
            "EVALUATING - Epoch: [37][60/79]\tTime 0.043 (0.034)\tData 0.006 (0.007)\tLoss 0.3177 (0.4202)\tPrec@1 89.844 (87.718)\tPrec@5 100.000 (99.501)\t\n",
            "EVALUATING - Epoch: [37][70/79]\tTime 0.027 (0.034)\tData 0.000 (0.007)\tLoss 0.2929 (0.4196)\tPrec@1 89.844 (87.632)\tPrec@5 100.000 (99.527)\t\n",
            "EVALUATING - Epoch: [37][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.006)\tLoss 0.4199 (0.4189)\tPrec@1 87.500 (87.650)\tPrec@5 100.000 (99.510)\t\n",
            "\n",
            "Results - Epoch: 38\n",
            "Training Loss 0.2076 \tTraining Prec@1 92.640 \tTraining Prec@5 99.900 \tValidation Loss 0.4189 \tValidation Prec@1 87.650 \tValidation Prec@5 99.510 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 39\n",
            "\n",
            "TRAINING - Epoch: [38][0/390]\tTime 0.388 (0.388)\tData 0.296 (0.296)\tLoss 0.2685 (0.2685)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [38][10/390]\tTime 0.055 (0.088)\tData 0.007 (0.029)\tLoss 0.1962 (0.1984)\tPrec@1 89.844 (92.472)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [38][20/390]\tTime 0.046 (0.072)\tData 0.000 (0.017)\tLoss 0.1304 (0.2019)\tPrec@1 95.312 (92.299)\tPrec@5 100.000 (99.851)\t\n",
            "TRAINING - Epoch: [38][30/390]\tTime 0.077 (0.067)\tData 0.010 (0.012)\tLoss 0.2302 (0.2117)\tPrec@1 93.750 (92.087)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [38][40/390]\tTime 0.061 (0.064)\tData 0.000 (0.010)\tLoss 0.3182 (0.2121)\tPrec@1 89.062 (92.188)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [38][50/390]\tTime 0.050 (0.062)\tData 0.000 (0.009)\tLoss 0.1993 (0.2127)\tPrec@1 91.406 (92.310)\tPrec@5 99.219 (99.893)\t\n",
            "TRAINING - Epoch: [38][60/390]\tTime 0.053 (0.061)\tData 0.006 (0.008)\tLoss 0.1878 (0.2093)\tPrec@1 90.625 (92.316)\tPrec@5 100.000 (99.898)\t\n",
            "TRAINING - Epoch: [38][70/390]\tTime 0.052 (0.060)\tData 0.006 (0.008)\tLoss 0.1135 (0.2088)\tPrec@1 92.969 (92.474)\tPrec@5 100.000 (99.890)\t\n",
            "TRAINING - Epoch: [38][80/390]\tTime 0.056 (0.060)\tData 0.007 (0.007)\tLoss 0.1722 (0.2082)\tPrec@1 95.312 (92.525)\tPrec@5 99.219 (99.884)\t\n",
            "TRAINING - Epoch: [38][90/390]\tTime 0.046 (0.059)\tData 0.000 (0.007)\tLoss 0.3301 (0.2100)\tPrec@1 89.844 (92.548)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [38][100/390]\tTime 0.071 (0.059)\tData 0.000 (0.006)\tLoss 0.1832 (0.2104)\tPrec@1 95.312 (92.582)\tPrec@5 99.219 (99.876)\t\n",
            "TRAINING - Epoch: [38][110/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.1373 (0.2069)\tPrec@1 97.656 (92.793)\tPrec@5 100.000 (99.880)\t\n",
            "TRAINING - Epoch: [38][120/390]\tTime 0.059 (0.058)\tData 0.007 (0.006)\tLoss 0.1894 (0.2085)\tPrec@1 90.625 (92.723)\tPrec@5 100.000 (99.864)\t\n",
            "TRAINING - Epoch: [38][130/390]\tTime 0.059 (0.058)\tData 0.007 (0.006)\tLoss 0.1582 (0.2067)\tPrec@1 96.094 (92.790)\tPrec@5 100.000 (99.869)\t\n",
            "TRAINING - Epoch: [38][140/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2647 (0.2077)\tPrec@1 92.188 (92.736)\tPrec@5 99.219 (99.867)\t\n",
            "TRAINING - Epoch: [38][150/390]\tTime 0.050 (0.058)\tData 0.001 (0.005)\tLoss 0.1410 (0.2090)\tPrec@1 93.750 (92.663)\tPrec@5 100.000 (99.860)\t\n",
            "TRAINING - Epoch: [38][160/390]\tTime 0.058 (0.058)\tData 0.007 (0.005)\tLoss 0.2440 (0.2087)\tPrec@1 92.969 (92.687)\tPrec@5 100.000 (99.864)\t\n",
            "TRAINING - Epoch: [38][170/390]\tTime 0.055 (0.057)\tData 0.000 (0.005)\tLoss 0.1761 (0.2087)\tPrec@1 92.969 (92.667)\tPrec@5 100.000 (99.872)\t\n",
            "TRAINING - Epoch: [38][180/390]\tTime 0.053 (0.057)\tData 0.006 (0.005)\tLoss 0.1686 (0.2092)\tPrec@1 92.969 (92.628)\tPrec@5 100.000 (99.879)\t\n",
            "TRAINING - Epoch: [38][190/390]\tTime 0.056 (0.057)\tData 0.007 (0.005)\tLoss 0.2761 (0.2087)\tPrec@1 91.406 (92.650)\tPrec@5 99.219 (99.873)\t\n",
            "TRAINING - Epoch: [38][200/390]\tTime 0.054 (0.057)\tData 0.007 (0.005)\tLoss 0.1459 (0.2085)\tPrec@1 96.094 (92.662)\tPrec@5 100.000 (99.880)\t\n",
            "TRAINING - Epoch: [38][210/390]\tTime 0.051 (0.057)\tData 0.002 (0.005)\tLoss 0.1815 (0.2084)\tPrec@1 92.969 (92.669)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [38][220/390]\tTime 0.053 (0.057)\tData 0.000 (0.005)\tLoss 0.2091 (0.2081)\tPrec@1 93.750 (92.682)\tPrec@5 100.000 (99.876)\t\n",
            "TRAINING - Epoch: [38][230/390]\tTime 0.055 (0.057)\tData 0.007 (0.005)\tLoss 0.1195 (0.2073)\tPrec@1 95.312 (92.718)\tPrec@5 100.000 (99.882)\t\n",
            "TRAINING - Epoch: [38][240/390]\tTime 0.059 (0.057)\tData 0.007 (0.005)\tLoss 0.2637 (0.2069)\tPrec@1 91.406 (92.745)\tPrec@5 100.000 (99.880)\t\n",
            "TRAINING - Epoch: [38][250/390]\tTime 0.054 (0.057)\tData 0.007 (0.005)\tLoss 0.2638 (0.2072)\tPrec@1 87.500 (92.732)\tPrec@5 99.219 (99.875)\t\n",
            "TRAINING - Epoch: [38][260/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.3266 (0.2093)\tPrec@1 92.969 (92.687)\tPrec@5 100.000 (99.877)\t\n",
            "TRAINING - Epoch: [38][270/390]\tTime 0.060 (0.057)\tData 0.013 (0.005)\tLoss 0.2374 (0.2104)\tPrec@1 90.625 (92.655)\tPrec@5 100.000 (99.870)\t\n",
            "TRAINING - Epoch: [38][280/390]\tTime 0.064 (0.057)\tData 0.013 (0.005)\tLoss 0.2500 (0.2101)\tPrec@1 92.969 (92.677)\tPrec@5 100.000 (99.869)\t\n",
            "TRAINING - Epoch: [38][290/390]\tTime 0.056 (0.057)\tData 0.007 (0.005)\tLoss 0.1932 (0.2107)\tPrec@1 92.969 (92.625)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [38][300/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.2168 (0.2100)\tPrec@1 89.844 (92.634)\tPrec@5 100.000 (99.878)\t\n",
            "TRAINING - Epoch: [38][310/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.2632 (0.2104)\tPrec@1 89.844 (92.627)\tPrec@5 100.000 (99.869)\t\n",
            "TRAINING - Epoch: [38][320/390]\tTime 0.067 (0.057)\tData 0.000 (0.005)\tLoss 0.2986 (0.2107)\tPrec@1 90.625 (92.621)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [38][330/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1227 (0.2101)\tPrec@1 96.875 (92.629)\tPrec@5 100.000 (99.870)\t\n",
            "TRAINING - Epoch: [38][340/390]\tTime 0.054 (0.057)\tData 0.006 (0.004)\tLoss 0.2324 (0.2098)\tPrec@1 89.844 (92.639)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [38][350/390]\tTime 0.054 (0.057)\tData 0.006 (0.004)\tLoss 0.1769 (0.2094)\tPrec@1 93.750 (92.637)\tPrec@5 100.000 (99.875)\t\n",
            "TRAINING - Epoch: [38][360/390]\tTime 0.057 (0.056)\tData 0.000 (0.004)\tLoss 0.2176 (0.2093)\tPrec@1 93.750 (92.635)\tPrec@5 100.000 (99.877)\t\n",
            "TRAINING - Epoch: [38][370/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.2137 (0.2093)\tPrec@1 92.969 (92.638)\tPrec@5 100.000 (99.876)\t\n",
            "TRAINING - Epoch: [38][380/390]\tTime 0.056 (0.056)\tData 0.007 (0.004)\tLoss 0.4117 (0.2102)\tPrec@1 86.719 (92.616)\tPrec@5 100.000 (99.875)\t\n",
            "TRAINING - Epoch: [38][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.1090 (0.2098)\tPrec@1 97.656 (92.612)\tPrec@5 100.000 (99.878)\t\n",
            "EVALUATING - Epoch: [38][0/79]\tTime 0.272 (0.272)\tData 0.238 (0.238)\tLoss 0.3342 (0.3342)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [38][10/79]\tTime 0.032 (0.055)\tData 0.003 (0.025)\tLoss 0.3450 (0.3708)\tPrec@1 92.188 (88.707)\tPrec@5 100.000 (99.716)\t\n",
            "EVALUATING - Epoch: [38][20/79]\tTime 0.029 (0.043)\tData 0.001 (0.016)\tLoss 0.4279 (0.3987)\tPrec@1 88.281 (87.909)\tPrec@5 98.438 (99.554)\t\n",
            "EVALUATING - Epoch: [38][30/79]\tTime 0.031 (0.039)\tData 0.000 (0.012)\tLoss 0.3391 (0.4076)\tPrec@1 89.844 (87.702)\tPrec@5 100.000 (99.496)\t\n",
            "EVALUATING - Epoch: [38][40/79]\tTime 0.012 (0.036)\tData 0.000 (0.010)\tLoss 0.4960 (0.4035)\tPrec@1 84.375 (87.671)\tPrec@5 98.438 (99.486)\t\n",
            "EVALUATING - Epoch: [38][50/79]\tTime 0.038 (0.035)\tData 0.008 (0.010)\tLoss 0.3814 (0.3935)\tPrec@1 85.938 (87.822)\tPrec@5 100.000 (99.571)\t\n",
            "EVALUATING - Epoch: [38][60/79]\tTime 0.060 (0.034)\tData 0.007 (0.009)\tLoss 0.2456 (0.3907)\tPrec@1 92.188 (87.769)\tPrec@5 100.000 (99.603)\t\n",
            "EVALUATING - Epoch: [38][70/79]\tTime 0.018 (0.033)\tData 0.005 (0.008)\tLoss 0.2104 (0.3944)\tPrec@1 93.750 (87.786)\tPrec@5 100.000 (99.626)\t\n",
            "EVALUATING - Epoch: [38][78/79]\tTime 0.006 (0.031)\tData 0.000 (0.007)\tLoss 0.3993 (0.3923)\tPrec@1 87.500 (87.800)\tPrec@5 100.000 (99.630)\t\n",
            "\n",
            "Results - Epoch: 39\n",
            "Training Loss 0.2098 \tTraining Prec@1 92.612 \tTraining Prec@5 99.878 \tValidation Loss 0.3923 \tValidation Prec@1 87.800 \tValidation Prec@5 99.630 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 40\n",
            "\n",
            "TRAINING - Epoch: [39][0/390]\tTime 0.377 (0.377)\tData 0.286 (0.286)\tLoss 0.2133 (0.2133)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [39][10/390]\tTime 0.048 (0.088)\tData 0.000 (0.030)\tLoss 0.2081 (0.1723)\tPrec@1 92.969 (94.389)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [39][20/390]\tTime 0.052 (0.073)\tData 0.000 (0.017)\tLoss 0.1064 (0.1661)\tPrec@1 96.094 (94.680)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [39][30/390]\tTime 0.055 (0.067)\tData 0.007 (0.013)\tLoss 0.2207 (0.1811)\tPrec@1 91.406 (93.926)\tPrec@5 100.000 (99.849)\t\n",
            "TRAINING - Epoch: [39][40/390]\tTime 0.066 (0.064)\tData 0.007 (0.011)\tLoss 0.2149 (0.1845)\tPrec@1 91.406 (93.693)\tPrec@5 100.000 (99.867)\t\n",
            "TRAINING - Epoch: [39][50/390]\tTime 0.050 (0.062)\tData 0.000 (0.009)\tLoss 0.1443 (0.1831)\tPrec@1 95.312 (93.735)\tPrec@5 99.219 (99.877)\t\n",
            "TRAINING - Epoch: [39][60/390]\tTime 0.058 (0.062)\tData 0.011 (0.009)\tLoss 0.1871 (0.1839)\tPrec@1 90.625 (93.596)\tPrec@5 100.000 (99.898)\t\n",
            "TRAINING - Epoch: [39][70/390]\tTime 0.047 (0.061)\tData 0.000 (0.008)\tLoss 0.3162 (0.1854)\tPrec@1 91.406 (93.607)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [39][80/390]\tTime 0.049 (0.060)\tData 0.000 (0.007)\tLoss 0.1688 (0.1873)\tPrec@1 95.312 (93.547)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [39][90/390]\tTime 0.075 (0.060)\tData 0.011 (0.007)\tLoss 0.1545 (0.1905)\tPrec@1 95.312 (93.407)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [39][100/390]\tTime 0.063 (0.060)\tData 0.012 (0.006)\tLoss 0.1929 (0.1893)\tPrec@1 93.750 (93.456)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [39][110/390]\tTime 0.055 (0.060)\tData 0.006 (0.006)\tLoss 0.2357 (0.1909)\tPrec@1 91.406 (93.356)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [39][120/390]\tTime 0.048 (0.059)\tData 0.002 (0.006)\tLoss 0.1691 (0.1925)\tPrec@1 95.312 (93.324)\tPrec@5 100.000 (99.910)\t\n",
            "TRAINING - Epoch: [39][130/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.1890 (0.1936)\tPrec@1 96.094 (93.285)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [39][140/390]\tTime 0.065 (0.059)\tData 0.009 (0.006)\tLoss 0.1940 (0.1919)\tPrec@1 92.969 (93.357)\tPrec@5 99.219 (99.906)\t\n",
            "TRAINING - Epoch: [39][150/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.1409 (0.1914)\tPrec@1 92.188 (93.326)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [39][160/390]\tTime 0.056 (0.058)\tData 0.007 (0.005)\tLoss 0.2224 (0.1921)\tPrec@1 93.750 (93.333)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [39][170/390]\tTime 0.070 (0.058)\tData 0.008 (0.005)\tLoss 0.1824 (0.1919)\tPrec@1 92.188 (93.311)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [39][180/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2386 (0.1925)\tPrec@1 92.969 (93.297)\tPrec@5 99.219 (99.909)\t\n",
            "TRAINING - Epoch: [39][190/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1635 (0.1927)\tPrec@1 94.531 (93.284)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [39][200/390]\tTime 0.054 (0.058)\tData 0.006 (0.005)\tLoss 0.2687 (0.1930)\tPrec@1 89.844 (93.252)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [39][210/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2192 (0.1931)\tPrec@1 92.969 (93.217)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [39][220/390]\tTime 0.050 (0.057)\tData 0.004 (0.005)\tLoss 0.1605 (0.1932)\tPrec@1 95.312 (93.223)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [39][230/390]\tTime 0.073 (0.057)\tData 0.009 (0.005)\tLoss 0.2232 (0.1933)\tPrec@1 91.406 (93.199)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [39][240/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.1488 (0.1938)\tPrec@1 94.531 (93.179)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [39][250/390]\tTime 0.069 (0.057)\tData 0.000 (0.005)\tLoss 0.2174 (0.1946)\tPrec@1 91.406 (93.121)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [39][260/390]\tTime 0.058 (0.057)\tData 0.007 (0.005)\tLoss 0.2097 (0.1940)\tPrec@1 94.531 (93.148)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [39][270/390]\tTime 0.054 (0.057)\tData 0.000 (0.005)\tLoss 0.1397 (0.1944)\tPrec@1 93.750 (93.127)\tPrec@5 100.000 (99.902)\t\n",
            "TRAINING - Epoch: [39][280/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.1882 (0.1958)\tPrec@1 92.188 (93.063)\tPrec@5 100.000 (99.897)\t\n",
            "TRAINING - Epoch: [39][290/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.2215 (0.1952)\tPrec@1 91.406 (93.073)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [39][300/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.2608 (0.1956)\tPrec@1 90.625 (93.070)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [39][310/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.2690 (0.1956)\tPrec@1 91.406 (93.062)\tPrec@5 100.000 (99.897)\t\n",
            "TRAINING - Epoch: [39][320/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2030 (0.1969)\tPrec@1 92.969 (93.030)\tPrec@5 100.000 (99.893)\t\n",
            "TRAINING - Epoch: [39][330/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1144 (0.1971)\tPrec@1 97.656 (93.032)\tPrec@5 99.219 (99.894)\t\n",
            "TRAINING - Epoch: [39][340/390]\tTime 0.063 (0.057)\tData 0.000 (0.004)\tLoss 0.2530 (0.1981)\tPrec@1 92.188 (92.999)\tPrec@5 99.219 (99.895)\t\n",
            "TRAINING - Epoch: [39][350/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.3067 (0.1995)\tPrec@1 88.281 (92.962)\tPrec@5 100.000 (99.893)\t\n",
            "TRAINING - Epoch: [39][360/390]\tTime 0.061 (0.057)\tData 0.007 (0.004)\tLoss 0.0913 (0.1992)\tPrec@1 97.656 (92.969)\tPrec@5 100.000 (99.896)\t\n",
            "TRAINING - Epoch: [39][370/390]\tTime 0.055 (0.057)\tData 0.006 (0.004)\tLoss 0.2428 (0.1998)\tPrec@1 92.969 (92.931)\tPrec@5 99.219 (99.893)\t\n",
            "TRAINING - Epoch: [39][380/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2658 (0.2004)\tPrec@1 92.188 (92.901)\tPrec@5 100.000 (99.893)\t\n",
            "TRAINING - Epoch: [39][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.2247 (0.2008)\tPrec@1 92.969 (92.897)\tPrec@5 100.000 (99.890)\t\n",
            "EVALUATING - Epoch: [39][0/79]\tTime 0.274 (0.274)\tData 0.241 (0.241)\tLoss 0.3708 (0.3708)\tPrec@1 89.062 (89.062)\tPrec@5 98.438 (98.438)\t\n",
            "EVALUATING - Epoch: [39][10/79]\tTime 0.042 (0.051)\tData 0.009 (0.026)\tLoss 0.3755 (0.4076)\tPrec@1 85.156 (86.506)\tPrec@5 99.219 (99.361)\t\n",
            "EVALUATING - Epoch: [39][20/79]\tTime 0.028 (0.042)\tData 0.009 (0.015)\tLoss 0.3147 (0.4246)\tPrec@1 90.625 (86.644)\tPrec@5 99.219 (99.405)\t\n",
            "EVALUATING - Epoch: [39][30/79]\tTime 0.032 (0.039)\tData 0.008 (0.013)\tLoss 0.3506 (0.4215)\tPrec@1 89.844 (87.172)\tPrec@5 100.000 (99.370)\t\n",
            "EVALUATING - Epoch: [39][40/79]\tTime 0.013 (0.036)\tData 0.000 (0.011)\tLoss 0.3713 (0.4197)\tPrec@1 85.938 (87.157)\tPrec@5 100.000 (99.390)\t\n",
            "EVALUATING - Epoch: [39][50/79]\tTime 0.024 (0.035)\tData 0.007 (0.010)\tLoss 0.3181 (0.4093)\tPrec@1 89.844 (87.331)\tPrec@5 100.000 (99.494)\t\n",
            "EVALUATING - Epoch: [39][60/79]\tTime 0.040 (0.035)\tData 0.010 (0.009)\tLoss 0.3019 (0.3996)\tPrec@1 92.969 (87.628)\tPrec@5 100.000 (99.539)\t\n",
            "EVALUATING - Epoch: [39][70/79]\tTime 0.043 (0.034)\tData 0.000 (0.008)\tLoss 0.3492 (0.3985)\tPrec@1 90.625 (87.555)\tPrec@5 100.000 (99.571)\t\n",
            "EVALUATING - Epoch: [39][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.008)\tLoss 0.5361 (0.3973)\tPrec@1 93.750 (87.660)\tPrec@5 100.000 (99.550)\t\n",
            "\n",
            "Results - Epoch: 40\n",
            "Training Loss 0.2008 \tTraining Prec@1 92.897 \tTraining Prec@5 99.890 \tValidation Loss 0.3973 \tValidation Prec@1 87.660 \tValidation Prec@5 99.550 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 41\n",
            "\n",
            "TRAINING - Epoch: [40][0/390]\tTime 0.401 (0.401)\tData 0.289 (0.289)\tLoss 0.1765 (0.1765)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [40][10/390]\tTime 0.051 (0.089)\tData 0.001 (0.030)\tLoss 0.1654 (0.1839)\tPrec@1 95.312 (93.750)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [40][20/390]\tTime 0.059 (0.073)\tData 0.000 (0.018)\tLoss 0.1565 (0.1721)\tPrec@1 94.531 (94.085)\tPrec@5 100.000 (99.851)\t\n",
            "TRAINING - Epoch: [40][30/390]\tTime 0.059 (0.067)\tData 0.000 (0.012)\tLoss 0.2152 (0.1756)\tPrec@1 89.062 (93.725)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [40][40/390]\tTime 0.070 (0.065)\tData 0.000 (0.010)\tLoss 0.2335 (0.1726)\tPrec@1 90.625 (93.883)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [40][50/390]\tTime 0.062 (0.063)\tData 0.007 (0.009)\tLoss 0.1748 (0.1745)\tPrec@1 92.188 (93.811)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [40][60/390]\tTime 0.069 (0.062)\tData 0.007 (0.008)\tLoss 0.1795 (0.1745)\tPrec@1 92.188 (93.840)\tPrec@5 99.219 (99.885)\t\n",
            "TRAINING - Epoch: [40][70/390]\tTime 0.065 (0.061)\tData 0.007 (0.007)\tLoss 0.1453 (0.1780)\tPrec@1 92.969 (93.684)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [40][80/390]\tTime 0.056 (0.061)\tData 0.006 (0.007)\tLoss 0.1932 (0.1818)\tPrec@1 92.969 (93.576)\tPrec@5 100.000 (99.884)\t\n",
            "TRAINING - Epoch: [40][90/390]\tTime 0.075 (0.060)\tData 0.008 (0.006)\tLoss 0.2811 (0.1822)\tPrec@1 92.188 (93.578)\tPrec@5 99.219 (99.888)\t\n",
            "TRAINING - Epoch: [40][100/390]\tTime 0.046 (0.060)\tData 0.000 (0.006)\tLoss 0.0978 (0.1861)\tPrec@1 97.656 (93.533)\tPrec@5 100.000 (99.876)\t\n",
            "TRAINING - Epoch: [40][110/390]\tTime 0.067 (0.060)\tData 0.009 (0.006)\tLoss 0.1887 (0.1874)\tPrec@1 91.406 (93.525)\tPrec@5 100.000 (99.859)\t\n",
            "TRAINING - Epoch: [40][120/390]\tTime 0.052 (0.059)\tData 0.000 (0.006)\tLoss 0.1694 (0.1872)\tPrec@1 94.531 (93.543)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [40][130/390]\tTime 0.064 (0.059)\tData 0.013 (0.006)\tLoss 0.1292 (0.1884)\tPrec@1 96.094 (93.446)\tPrec@5 100.000 (99.863)\t\n",
            "TRAINING - Epoch: [40][140/390]\tTime 0.054 (0.059)\tData 0.003 (0.006)\tLoss 0.2360 (0.1920)\tPrec@1 94.531 (93.296)\tPrec@5 99.219 (99.861)\t\n",
            "TRAINING - Epoch: [40][150/390]\tTime 0.076 (0.059)\tData 0.006 (0.006)\tLoss 0.2431 (0.1922)\tPrec@1 90.625 (93.295)\tPrec@5 100.000 (99.855)\t\n",
            "TRAINING - Epoch: [40][160/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1268 (0.1918)\tPrec@1 95.312 (93.318)\tPrec@5 100.000 (99.854)\t\n",
            "TRAINING - Epoch: [40][170/390]\tTime 0.061 (0.058)\tData 0.007 (0.005)\tLoss 0.1680 (0.1913)\tPrec@1 92.969 (93.353)\tPrec@5 100.000 (99.854)\t\n",
            "TRAINING - Epoch: [40][180/390]\tTime 0.076 (0.058)\tData 0.011 (0.005)\tLoss 0.1389 (0.1928)\tPrec@1 95.312 (93.310)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [40][190/390]\tTime 0.055 (0.058)\tData 0.007 (0.005)\tLoss 0.1928 (0.1938)\tPrec@1 93.750 (93.251)\tPrec@5 100.000 (99.857)\t\n",
            "TRAINING - Epoch: [40][200/390]\tTime 0.054 (0.058)\tData 0.004 (0.005)\tLoss 0.1969 (0.1947)\tPrec@1 92.188 (93.202)\tPrec@5 100.000 (99.864)\t\n",
            "TRAINING - Epoch: [40][210/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.2148 (0.1951)\tPrec@1 90.625 (93.154)\tPrec@5 100.000 (99.867)\t\n",
            "TRAINING - Epoch: [40][220/390]\tTime 0.060 (0.058)\tData 0.000 (0.005)\tLoss 0.3001 (0.1956)\tPrec@1 88.281 (93.107)\tPrec@5 100.000 (99.869)\t\n",
            "TRAINING - Epoch: [40][230/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2729 (0.1952)\tPrec@1 90.625 (93.124)\tPrec@5 100.000 (99.875)\t\n",
            "TRAINING - Epoch: [40][240/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1599 (0.1953)\tPrec@1 92.969 (93.095)\tPrec@5 100.000 (99.880)\t\n",
            "TRAINING - Epoch: [40][250/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.1830 (0.1969)\tPrec@1 94.531 (93.034)\tPrec@5 100.000 (99.882)\t\n",
            "TRAINING - Epoch: [40][260/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1414 (0.1969)\tPrec@1 96.094 (93.038)\tPrec@5 100.000 (99.886)\t\n",
            "TRAINING - Epoch: [40][270/390]\tTime 0.062 (0.058)\tData 0.010 (0.005)\tLoss 0.1338 (0.1970)\tPrec@1 96.094 (93.032)\tPrec@5 100.000 (99.885)\t\n",
            "TRAINING - Epoch: [40][280/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.2229 (0.1968)\tPrec@1 92.188 (93.055)\tPrec@5 100.000 (99.886)\t\n",
            "TRAINING - Epoch: [40][290/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.2427 (0.1973)\tPrec@1 91.406 (93.025)\tPrec@5 100.000 (99.890)\t\n",
            "TRAINING - Epoch: [40][300/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1753 (0.1978)\tPrec@1 93.750 (93.015)\tPrec@5 99.219 (99.888)\t\n",
            "TRAINING - Epoch: [40][310/390]\tTime 0.060 (0.057)\tData 0.009 (0.004)\tLoss 0.1658 (0.1975)\tPrec@1 93.750 (93.016)\tPrec@5 100.000 (99.892)\t\n",
            "TRAINING - Epoch: [40][320/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.3348 (0.1986)\tPrec@1 88.281 (92.974)\tPrec@5 100.000 (99.893)\t\n",
            "TRAINING - Epoch: [40][330/390]\tTime 0.074 (0.057)\tData 0.003 (0.004)\tLoss 0.2825 (0.1999)\tPrec@1 92.188 (92.933)\tPrec@5 100.000 (99.891)\t\n",
            "TRAINING - Epoch: [40][340/390]\tTime 0.060 (0.057)\tData 0.007 (0.004)\tLoss 0.2003 (0.1998)\tPrec@1 92.188 (92.928)\tPrec@5 100.000 (99.892)\t\n",
            "TRAINING - Epoch: [40][350/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.1526 (0.2002)\tPrec@1 93.750 (92.929)\tPrec@5 100.000 (99.895)\t\n",
            "TRAINING - Epoch: [40][360/390]\tTime 0.055 (0.057)\tData 0.009 (0.004)\tLoss 0.1447 (0.1998)\tPrec@1 94.531 (92.938)\tPrec@5 100.000 (99.894)\t\n",
            "TRAINING - Epoch: [40][370/390]\tTime 0.072 (0.057)\tData 0.006 (0.004)\tLoss 0.1821 (0.2003)\tPrec@1 92.188 (92.933)\tPrec@5 100.000 (99.895)\t\n",
            "TRAINING - Epoch: [40][380/390]\tTime 0.053 (0.057)\tData 0.006 (0.004)\tLoss 0.2882 (0.2008)\tPrec@1 92.188 (92.907)\tPrec@5 100.000 (99.897)\t\n",
            "TRAINING - Epoch: [40][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1262 (0.2007)\tPrec@1 95.312 (92.909)\tPrec@5 100.000 (99.900)\t\n",
            "EVALUATING - Epoch: [40][0/79]\tTime 0.204 (0.204)\tData 0.174 (0.174)\tLoss 0.3673 (0.3673)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [40][10/79]\tTime 0.014 (0.050)\tData 0.000 (0.022)\tLoss 0.4317 (0.4368)\tPrec@1 86.719 (86.293)\tPrec@5 100.000 (99.645)\t\n",
            "EVALUATING - Epoch: [40][20/79]\tTime 0.042 (0.043)\tData 0.012 (0.014)\tLoss 0.4067 (0.4547)\tPrec@1 89.062 (86.719)\tPrec@5 100.000 (99.479)\t\n",
            "EVALUATING - Epoch: [40][30/79]\tTime 0.035 (0.039)\tData 0.000 (0.011)\tLoss 0.2886 (0.4536)\tPrec@1 90.625 (86.568)\tPrec@5 100.000 (99.370)\t\n",
            "EVALUATING - Epoch: [40][40/79]\tTime 0.025 (0.036)\tData 0.000 (0.009)\tLoss 0.4886 (0.4551)\tPrec@1 86.719 (86.833)\tPrec@5 100.000 (99.352)\t\n",
            "EVALUATING - Epoch: [40][50/79]\tTime 0.020 (0.035)\tData 0.000 (0.008)\tLoss 0.3790 (0.4431)\tPrec@1 89.062 (87.178)\tPrec@5 100.000 (99.387)\t\n",
            "EVALUATING - Epoch: [40][60/79]\tTime 0.033 (0.034)\tData 0.000 (0.007)\tLoss 0.3952 (0.4384)\tPrec@1 86.719 (87.346)\tPrec@5 98.438 (99.372)\t\n",
            "EVALUATING - Epoch: [40][70/79]\tTime 0.038 (0.034)\tData 0.002 (0.007)\tLoss 0.5007 (0.4466)\tPrec@1 89.844 (87.192)\tPrec@5 100.000 (99.351)\t\n",
            "EVALUATING - Epoch: [40][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.006)\tLoss 0.4691 (0.4445)\tPrec@1 93.750 (87.260)\tPrec@5 100.000 (99.370)\t\n",
            "\n",
            "Results - Epoch: 41\n",
            "Training Loss 0.2007 \tTraining Prec@1 92.909 \tTraining Prec@5 99.900 \tValidation Loss 0.4445 \tValidation Prec@1 87.260 \tValidation Prec@5 99.370 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 42\n",
            "\n",
            "TRAINING - Epoch: [41][0/390]\tTime 0.405 (0.405)\tData 0.276 (0.276)\tLoss 0.1905 (0.1905)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [41][10/390]\tTime 0.051 (0.089)\tData 0.002 (0.028)\tLoss 0.2302 (0.1717)\tPrec@1 90.625 (93.608)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [41][20/390]\tTime 0.049 (0.073)\tData 0.000 (0.016)\tLoss 0.2048 (0.1907)\tPrec@1 92.969 (92.932)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [41][30/390]\tTime 0.050 (0.067)\tData 0.000 (0.012)\tLoss 0.1215 (0.1864)\tPrec@1 96.094 (93.221)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [41][40/390]\tTime 0.052 (0.065)\tData 0.000 (0.010)\tLoss 0.1345 (0.1818)\tPrec@1 96.875 (93.445)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [41][50/390]\tTime 0.055 (0.063)\tData 0.008 (0.009)\tLoss 0.1530 (0.1858)\tPrec@1 93.750 (93.306)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [41][60/390]\tTime 0.068 (0.061)\tData 0.000 (0.008)\tLoss 0.1596 (0.1885)\tPrec@1 94.531 (93.340)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [41][70/390]\tTime 0.053 (0.061)\tData 0.000 (0.007)\tLoss 0.1755 (0.1894)\tPrec@1 92.969 (93.442)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [41][80/390]\tTime 0.050 (0.060)\tData 0.000 (0.007)\tLoss 0.1796 (0.1894)\tPrec@1 92.188 (93.374)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [41][90/390]\tTime 0.050 (0.060)\tData 0.000 (0.006)\tLoss 0.1543 (0.1876)\tPrec@1 96.094 (93.432)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [41][100/390]\tTime 0.046 (0.060)\tData 0.000 (0.006)\tLoss 0.2721 (0.1885)\tPrec@1 91.406 (93.433)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [41][110/390]\tTime 0.059 (0.059)\tData 0.011 (0.006)\tLoss 0.1834 (0.1890)\tPrec@1 95.312 (93.440)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [41][120/390]\tTime 0.070 (0.059)\tData 0.000 (0.005)\tLoss 0.1569 (0.1867)\tPrec@1 93.750 (93.492)\tPrec@5 99.219 (99.929)\t\n",
            "TRAINING - Epoch: [41][130/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.2017 (0.1853)\tPrec@1 91.406 (93.559)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [41][140/390]\tTime 0.050 (0.059)\tData 0.000 (0.005)\tLoss 0.3015 (0.1860)\tPrec@1 88.281 (93.506)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [41][150/390]\tTime 0.058 (0.059)\tData 0.000 (0.005)\tLoss 0.2530 (0.1868)\tPrec@1 92.969 (93.481)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [41][160/390]\tTime 0.059 (0.059)\tData 0.008 (0.005)\tLoss 0.2515 (0.1881)\tPrec@1 88.281 (93.420)\tPrec@5 99.219 (99.927)\t\n",
            "TRAINING - Epoch: [41][170/390]\tTime 0.065 (0.058)\tData 0.009 (0.005)\tLoss 0.1610 (0.1897)\tPrec@1 94.531 (93.389)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [41][180/390]\tTime 0.072 (0.058)\tData 0.006 (0.005)\tLoss 0.3080 (0.1902)\tPrec@1 89.844 (93.379)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [41][190/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.2529 (0.1918)\tPrec@1 89.844 (93.280)\tPrec@5 100.000 (99.918)\t\n",
            "TRAINING - Epoch: [41][200/390]\tTime 0.054 (0.058)\tData 0.000 (0.004)\tLoss 0.2720 (0.1923)\tPrec@1 89.062 (93.225)\tPrec@5 100.000 (99.918)\t\n",
            "TRAINING - Epoch: [41][210/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.1608 (0.1930)\tPrec@1 93.750 (93.184)\tPrec@5 100.000 (99.919)\t\n",
            "TRAINING - Epoch: [41][220/390]\tTime 0.055 (0.057)\tData 0.006 (0.004)\tLoss 0.2311 (0.1924)\tPrec@1 92.969 (93.191)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [41][230/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.1165 (0.1923)\tPrec@1 96.094 (93.189)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [41][240/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1467 (0.1928)\tPrec@1 94.531 (93.176)\tPrec@5 100.000 (99.925)\t\n",
            "TRAINING - Epoch: [41][250/390]\tTime 0.081 (0.057)\tData 0.007 (0.004)\tLoss 0.3153 (0.1933)\tPrec@1 91.406 (93.168)\tPrec@5 99.219 (99.919)\t\n",
            "TRAINING - Epoch: [41][260/390]\tTime 0.062 (0.057)\tData 0.000 (0.004)\tLoss 0.2862 (0.1942)\tPrec@1 89.844 (93.169)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [41][270/390]\tTime 0.052 (0.057)\tData 0.005 (0.004)\tLoss 0.1192 (0.1937)\tPrec@1 97.656 (93.205)\tPrec@5 99.219 (99.916)\t\n",
            "TRAINING - Epoch: [41][280/390]\tTime 0.058 (0.057)\tData 0.000 (0.004)\tLoss 0.1283 (0.1946)\tPrec@1 96.094 (93.174)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [41][290/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2452 (0.1946)\tPrec@1 93.750 (93.165)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [41][300/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.2813 (0.1963)\tPrec@1 90.625 (93.119)\tPrec@5 99.219 (99.914)\t\n",
            "TRAINING - Epoch: [41][310/390]\tTime 0.060 (0.057)\tData 0.006 (0.004)\tLoss 0.1243 (0.1974)\tPrec@1 95.312 (93.057)\tPrec@5 100.000 (99.915)\t\n",
            "TRAINING - Epoch: [41][320/390]\tTime 0.059 (0.057)\tData 0.000 (0.004)\tLoss 0.2147 (0.1973)\tPrec@1 92.969 (93.066)\tPrec@5 100.000 (99.910)\t\n",
            "TRAINING - Epoch: [41][330/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.2163 (0.1991)\tPrec@1 91.406 (93.007)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [41][340/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.2246 (0.1995)\tPrec@1 90.625 (92.971)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [41][350/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.1399 (0.1995)\tPrec@1 94.531 (92.991)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [41][360/390]\tTime 0.064 (0.057)\tData 0.006 (0.004)\tLoss 0.1035 (0.1992)\tPrec@1 96.094 (92.997)\tPrec@5 100.000 (99.903)\t\n",
            "TRAINING - Epoch: [41][370/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.1502 (0.1994)\tPrec@1 93.750 (92.992)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [41][380/390]\tTime 0.072 (0.057)\tData 0.008 (0.004)\tLoss 0.2330 (0.1998)\tPrec@1 89.844 (92.956)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [41][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.2969 (0.2001)\tPrec@1 87.500 (92.935)\tPrec@5 100.000 (99.902)\t\n",
            "EVALUATING - Epoch: [41][0/79]\tTime 0.234 (0.234)\tData 0.186 (0.186)\tLoss 0.4198 (0.4198)\tPrec@1 85.156 (85.156)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [41][10/79]\tTime 0.026 (0.057)\tData 0.005 (0.026)\tLoss 0.4632 (0.4491)\tPrec@1 84.375 (87.145)\tPrec@5 100.000 (99.290)\t\n",
            "EVALUATING - Epoch: [41][20/79]\tTime 0.023 (0.044)\tData 0.000 (0.016)\tLoss 0.4950 (0.4776)\tPrec@1 86.719 (86.644)\tPrec@5 96.875 (99.070)\t\n",
            "EVALUATING - Epoch: [41][30/79]\tTime 0.023 (0.039)\tData 0.000 (0.012)\tLoss 0.2868 (0.4713)\tPrec@1 90.625 (86.542)\tPrec@5 100.000 (99.143)\t\n",
            "EVALUATING - Epoch: [41][40/79]\tTime 0.039 (0.037)\tData 0.001 (0.010)\tLoss 0.5015 (0.4684)\tPrec@1 85.156 (86.490)\tPrec@5 99.219 (99.181)\t\n",
            "EVALUATING - Epoch: [41][50/79]\tTime 0.028 (0.035)\tData 0.009 (0.009)\tLoss 0.3867 (0.4540)\tPrec@1 90.625 (86.581)\tPrec@5 100.000 (99.265)\t\n",
            "EVALUATING - Epoch: [41][60/79]\tTime 0.018 (0.035)\tData 0.004 (0.008)\tLoss 0.3697 (0.4523)\tPrec@1 87.500 (86.693)\tPrec@5 99.219 (99.270)\t\n",
            "EVALUATING - Epoch: [41][70/79]\tTime 0.020 (0.035)\tData 0.001 (0.008)\tLoss 0.3306 (0.4534)\tPrec@1 92.188 (86.708)\tPrec@5 100.000 (99.307)\t\n",
            "EVALUATING - Epoch: [41][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.4576 (0.4535)\tPrec@1 93.750 (86.730)\tPrec@5 100.000 (99.250)\t\n",
            "\n",
            "Results - Epoch: 42\n",
            "Training Loss 0.2001 \tTraining Prec@1 92.935 \tTraining Prec@5 99.902 \tValidation Loss 0.4535 \tValidation Prec@1 86.730 \tValidation Prec@5 99.250 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 43\n",
            "\n",
            "TRAINING - Epoch: [42][0/390]\tTime 0.335 (0.335)\tData 0.214 (0.214)\tLoss 0.2071 (0.2071)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [42][10/390]\tTime 0.072 (0.090)\tData 0.000 (0.023)\tLoss 0.1974 (0.1922)\tPrec@1 91.406 (93.324)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [42][20/390]\tTime 0.058 (0.073)\tData 0.000 (0.013)\tLoss 0.1479 (0.1873)\tPrec@1 94.531 (93.490)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [42][30/390]\tTime 0.049 (0.067)\tData 0.000 (0.010)\tLoss 0.1469 (0.1825)\tPrec@1 93.750 (93.498)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [42][40/390]\tTime 0.048 (0.064)\tData 0.000 (0.008)\tLoss 0.2393 (0.1810)\tPrec@1 90.625 (93.693)\tPrec@5 99.219 (99.962)\t\n",
            "TRAINING - Epoch: [42][50/390]\tTime 0.047 (0.063)\tData 0.000 (0.007)\tLoss 0.2067 (0.1809)\tPrec@1 92.188 (93.673)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [42][60/390]\tTime 0.051 (0.062)\tData 0.000 (0.006)\tLoss 0.2083 (0.1803)\tPrec@1 94.531 (93.737)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [42][70/390]\tTime 0.053 (0.061)\tData 0.000 (0.006)\tLoss 0.1886 (0.1822)\tPrec@1 95.312 (93.673)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [42][80/390]\tTime 0.056 (0.061)\tData 0.007 (0.005)\tLoss 0.1911 (0.1842)\tPrec@1 94.531 (93.547)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [42][90/390]\tTime 0.081 (0.060)\tData 0.007 (0.005)\tLoss 0.1432 (0.1815)\tPrec@1 95.312 (93.647)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [42][100/390]\tTime 0.061 (0.060)\tData 0.006 (0.005)\tLoss 0.2923 (0.1798)\tPrec@1 88.281 (93.719)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [42][110/390]\tTime 0.060 (0.060)\tData 0.011 (0.005)\tLoss 0.2758 (0.1817)\tPrec@1 90.625 (93.673)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [42][120/390]\tTime 0.049 (0.059)\tData 0.000 (0.005)\tLoss 0.2075 (0.1815)\tPrec@1 93.750 (93.647)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [42][130/390]\tTime 0.078 (0.059)\tData 0.013 (0.005)\tLoss 0.2211 (0.1813)\tPrec@1 93.750 (93.649)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [42][140/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.2163 (0.1810)\tPrec@1 90.625 (93.639)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [42][150/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.1514 (0.1820)\tPrec@1 94.531 (93.636)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [42][160/390]\tTime 0.058 (0.059)\tData 0.006 (0.004)\tLoss 0.2662 (0.1827)\tPrec@1 89.844 (93.609)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [42][170/390]\tTime 0.063 (0.059)\tData 0.006 (0.004)\tLoss 0.1838 (0.1847)\tPrec@1 95.312 (93.526)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [42][180/390]\tTime 0.065 (0.058)\tData 0.000 (0.004)\tLoss 0.1998 (0.1866)\tPrec@1 90.625 (93.469)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [42][190/390]\tTime 0.058 (0.058)\tData 0.006 (0.004)\tLoss 0.2709 (0.1863)\tPrec@1 91.406 (93.472)\tPrec@5 99.219 (99.918)\t\n",
            "TRAINING - Epoch: [42][200/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.1346 (0.1872)\tPrec@1 94.531 (93.427)\tPrec@5 100.000 (99.918)\t\n",
            "TRAINING - Epoch: [42][210/390]\tTime 0.048 (0.058)\tData 0.000 (0.004)\tLoss 0.1724 (0.1885)\tPrec@1 95.312 (93.391)\tPrec@5 100.000 (99.919)\t\n",
            "TRAINING - Epoch: [42][220/390]\tTime 0.051 (0.058)\tData 0.004 (0.004)\tLoss 0.1478 (0.1888)\tPrec@1 94.531 (93.396)\tPrec@5 99.219 (99.919)\t\n",
            "TRAINING - Epoch: [42][230/390]\tTime 0.061 (0.058)\tData 0.000 (0.004)\tLoss 0.2034 (0.1893)\tPrec@1 95.312 (93.388)\tPrec@5 100.000 (99.919)\t\n",
            "TRAINING - Epoch: [42][240/390]\tTime 0.054 (0.058)\tData 0.000 (0.004)\tLoss 0.2473 (0.1893)\tPrec@1 92.188 (93.374)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [42][250/390]\tTime 0.048 (0.058)\tData 0.000 (0.004)\tLoss 0.1470 (0.1898)\tPrec@1 91.406 (93.339)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [42][260/390]\tTime 0.047 (0.058)\tData 0.000 (0.004)\tLoss 0.2534 (0.1892)\tPrec@1 91.406 (93.367)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [42][270/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.1681 (0.1895)\tPrec@1 94.531 (93.364)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [42][280/390]\tTime 0.070 (0.058)\tData 0.007 (0.004)\tLoss 0.2677 (0.1893)\tPrec@1 91.406 (93.383)\tPrec@5 100.000 (99.919)\t\n",
            "TRAINING - Epoch: [42][290/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.1635 (0.1894)\tPrec@1 94.531 (93.390)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [42][300/390]\tTime 0.053 (0.057)\tData 0.007 (0.004)\tLoss 0.2519 (0.1885)\tPrec@1 90.625 (93.426)\tPrec@5 100.000 (99.920)\t\n",
            "TRAINING - Epoch: [42][310/390]\tTime 0.068 (0.057)\tData 0.008 (0.004)\tLoss 0.1815 (0.1886)\tPrec@1 94.531 (93.406)\tPrec@5 100.000 (99.920)\t\n",
            "TRAINING - Epoch: [42][320/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.3129 (0.1899)\tPrec@1 88.281 (93.344)\tPrec@5 99.219 (99.915)\t\n",
            "TRAINING - Epoch: [42][330/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2396 (0.1904)\tPrec@1 91.406 (93.306)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [42][340/390]\tTime 0.061 (0.057)\tData 0.007 (0.004)\tLoss 0.4712 (0.1932)\tPrec@1 83.594 (93.216)\tPrec@5 99.219 (99.915)\t\n",
            "TRAINING - Epoch: [42][350/390]\tTime 0.047 (0.057)\tData 0.001 (0.004)\tLoss 0.2077 (0.1930)\tPrec@1 92.188 (93.222)\tPrec@5 100.000 (99.918)\t\n",
            "TRAINING - Epoch: [42][360/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.1855 (0.1929)\tPrec@1 93.750 (93.218)\tPrec@5 100.000 (99.918)\t\n",
            "TRAINING - Epoch: [42][370/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2308 (0.1934)\tPrec@1 92.969 (93.190)\tPrec@5 99.219 (99.914)\t\n",
            "TRAINING - Epoch: [42][380/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2091 (0.1934)\tPrec@1 92.188 (93.166)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [42][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1755 (0.1941)\tPrec@1 93.750 (93.149)\tPrec@5 100.000 (99.912)\t\n",
            "EVALUATING - Epoch: [42][0/79]\tTime 0.204 (0.204)\tData 0.181 (0.181)\tLoss 0.4234 (0.4234)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [42][10/79]\tTime 0.032 (0.054)\tData 0.005 (0.026)\tLoss 0.2391 (0.3857)\tPrec@1 91.406 (88.352)\tPrec@5 100.000 (99.503)\t\n",
            "EVALUATING - Epoch: [42][20/79]\tTime 0.025 (0.042)\tData 0.003 (0.015)\tLoss 0.3904 (0.4215)\tPrec@1 86.719 (87.463)\tPrec@5 100.000 (99.405)\t\n",
            "EVALUATING - Epoch: [42][30/79]\tTime 0.032 (0.039)\tData 0.006 (0.012)\tLoss 0.4200 (0.4239)\tPrec@1 89.062 (87.550)\tPrec@5 100.000 (99.420)\t\n",
            "EVALUATING - Epoch: [42][40/79]\tTime 0.036 (0.037)\tData 0.001 (0.010)\tLoss 0.5423 (0.4194)\tPrec@1 83.594 (87.386)\tPrec@5 99.219 (99.447)\t\n",
            "EVALUATING - Epoch: [42][50/79]\tTime 0.029 (0.035)\tData 0.000 (0.009)\tLoss 0.4800 (0.4073)\tPrec@1 85.938 (87.699)\tPrec@5 99.219 (99.494)\t\n",
            "EVALUATING - Epoch: [42][60/79]\tTime 0.032 (0.035)\tData 0.001 (0.008)\tLoss 0.2913 (0.3998)\tPrec@1 88.281 (87.820)\tPrec@5 100.000 (99.526)\t\n",
            "EVALUATING - Epoch: [42][70/79]\tTime 0.020 (0.034)\tData 0.004 (0.007)\tLoss 0.3814 (0.3962)\tPrec@1 89.062 (87.830)\tPrec@5 99.219 (99.549)\t\n",
            "EVALUATING - Epoch: [42][78/79]\tTime 0.006 (0.032)\tData 0.000 (0.006)\tLoss 0.0657 (0.3920)\tPrec@1 100.000 (87.940)\tPrec@5 100.000 (99.560)\t\n",
            "\n",
            "Results - Epoch: 43\n",
            "Training Loss 0.1941 \tTraining Prec@1 93.149 \tTraining Prec@5 99.912 \tValidation Loss 0.3920 \tValidation Prec@1 87.940 \tValidation Prec@5 99.560 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 44\n",
            "\n",
            "TRAINING - Epoch: [43][0/390]\tTime 0.321 (0.321)\tData 0.171 (0.171)\tLoss 0.2133 (0.2133)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [43][10/390]\tTime 0.066 (0.094)\tData 0.011 (0.021)\tLoss 0.2538 (0.1789)\tPrec@1 91.406 (93.679)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [43][20/390]\tTime 0.061 (0.075)\tData 0.000 (0.011)\tLoss 0.1558 (0.1785)\tPrec@1 94.531 (93.899)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [43][30/390]\tTime 0.048 (0.069)\tData 0.000 (0.008)\tLoss 0.3517 (0.1844)\tPrec@1 86.719 (93.498)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [43][40/390]\tTime 0.074 (0.067)\tData 0.009 (0.007)\tLoss 0.1773 (0.1805)\tPrec@1 95.312 (93.693)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [43][50/390]\tTime 0.049 (0.065)\tData 0.000 (0.007)\tLoss 0.1438 (0.1814)\tPrec@1 94.531 (93.643)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [43][60/390]\tTime 0.060 (0.064)\tData 0.007 (0.006)\tLoss 0.2972 (0.1787)\tPrec@1 90.625 (93.750)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [43][70/390]\tTime 0.055 (0.062)\tData 0.000 (0.005)\tLoss 0.3020 (0.1823)\tPrec@1 88.281 (93.552)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [43][80/390]\tTime 0.053 (0.062)\tData 0.000 (0.005)\tLoss 0.1062 (0.1821)\tPrec@1 96.875 (93.596)\tPrec@5 99.219 (99.913)\t\n",
            "TRAINING - Epoch: [43][90/390]\tTime 0.073 (0.061)\tData 0.006 (0.005)\tLoss 0.1367 (0.1809)\tPrec@1 96.094 (93.638)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [43][100/390]\tTime 0.058 (0.061)\tData 0.007 (0.005)\tLoss 0.1280 (0.1792)\tPrec@1 95.312 (93.719)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [43][110/390]\tTime 0.048 (0.061)\tData 0.000 (0.005)\tLoss 0.1712 (0.1793)\tPrec@1 92.969 (93.644)\tPrec@5 99.219 (99.909)\t\n",
            "TRAINING - Epoch: [43][120/390]\tTime 0.056 (0.061)\tData 0.000 (0.005)\tLoss 0.2387 (0.1782)\tPrec@1 92.969 (93.640)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [43][130/390]\tTime 0.052 (0.061)\tData 0.000 (0.004)\tLoss 0.2100 (0.1788)\tPrec@1 92.969 (93.661)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [43][140/390]\tTime 0.049 (0.061)\tData 0.000 (0.004)\tLoss 0.1689 (0.1785)\tPrec@1 94.531 (93.684)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [43][150/390]\tTime 0.063 (0.060)\tData 0.009 (0.004)\tLoss 0.1442 (0.1782)\tPrec@1 95.312 (93.662)\tPrec@5 100.000 (99.902)\t\n",
            "TRAINING - Epoch: [43][160/390]\tTime 0.056 (0.060)\tData 0.007 (0.004)\tLoss 0.1517 (0.1782)\tPrec@1 92.969 (93.663)\tPrec@5 100.000 (99.898)\t\n",
            "TRAINING - Epoch: [43][170/390]\tTime 0.053 (0.060)\tData 0.000 (0.004)\tLoss 0.1243 (0.1799)\tPrec@1 95.312 (93.618)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [43][180/390]\tTime 0.052 (0.060)\tData 0.000 (0.004)\tLoss 0.2002 (0.1813)\tPrec@1 93.750 (93.547)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [43][190/390]\tTime 0.053 (0.059)\tData 0.004 (0.004)\tLoss 0.2101 (0.1824)\tPrec@1 92.969 (93.505)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [43][200/390]\tTime 0.057 (0.059)\tData 0.008 (0.004)\tLoss 0.1866 (0.1839)\tPrec@1 92.969 (93.435)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [43][210/390]\tTime 0.055 (0.059)\tData 0.007 (0.004)\tLoss 0.3573 (0.1865)\tPrec@1 85.938 (93.343)\tPrec@5 99.219 (99.904)\t\n",
            "TRAINING - Epoch: [43][220/390]\tTime 0.051 (0.059)\tData 0.003 (0.004)\tLoss 0.2367 (0.1878)\tPrec@1 89.844 (93.287)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [43][230/390]\tTime 0.048 (0.059)\tData 0.000 (0.004)\tLoss 0.3629 (0.1906)\tPrec@1 86.719 (93.185)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [43][240/390]\tTime 0.065 (0.059)\tData 0.007 (0.004)\tLoss 0.1968 (0.1908)\tPrec@1 92.969 (93.160)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [43][250/390]\tTime 0.070 (0.059)\tData 0.009 (0.004)\tLoss 0.2065 (0.1897)\tPrec@1 92.969 (93.199)\tPrec@5 100.000 (99.910)\t\n",
            "TRAINING - Epoch: [43][260/390]\tTime 0.048 (0.059)\tData 0.000 (0.004)\tLoss 0.2550 (0.1909)\tPrec@1 92.969 (93.178)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [43][270/390]\tTime 0.048 (0.058)\tData 0.000 (0.004)\tLoss 0.1629 (0.1912)\tPrec@1 95.312 (93.150)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [43][280/390]\tTime 0.065 (0.058)\tData 0.007 (0.004)\tLoss 0.1309 (0.1916)\tPrec@1 94.531 (93.152)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [43][290/390]\tTime 0.050 (0.058)\tData 0.000 (0.004)\tLoss 0.1095 (0.1914)\tPrec@1 96.094 (93.170)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [43][300/390]\tTime 0.057 (0.058)\tData 0.007 (0.004)\tLoss 0.1708 (0.1913)\tPrec@1 93.750 (93.200)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [43][310/390]\tTime 0.056 (0.058)\tData 0.007 (0.004)\tLoss 0.1238 (0.1908)\tPrec@1 94.531 (93.222)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [43][320/390]\tTime 0.056 (0.058)\tData 0.007 (0.004)\tLoss 0.1526 (0.1909)\tPrec@1 94.531 (93.207)\tPrec@5 100.000 (99.920)\t\n",
            "TRAINING - Epoch: [43][330/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.1255 (0.1916)\tPrec@1 95.312 (93.184)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [43][340/390]\tTime 0.057 (0.058)\tData 0.007 (0.004)\tLoss 0.2034 (0.1933)\tPrec@1 90.625 (93.134)\tPrec@5 99.219 (99.922)\t\n",
            "TRAINING - Epoch: [43][350/390]\tTime 0.066 (0.058)\tData 0.009 (0.004)\tLoss 0.1872 (0.1938)\tPrec@1 93.750 (93.107)\tPrec@5 99.219 (99.918)\t\n",
            "TRAINING - Epoch: [43][360/390]\tTime 0.053 (0.058)\tData 0.007 (0.004)\tLoss 0.1730 (0.1946)\tPrec@1 92.188 (93.094)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [43][370/390]\tTime 0.046 (0.058)\tData 0.000 (0.004)\tLoss 0.3262 (0.1952)\tPrec@1 88.281 (93.070)\tPrec@5 99.219 (99.914)\t\n",
            "TRAINING - Epoch: [43][380/390]\tTime 0.069 (0.058)\tData 0.007 (0.004)\tLoss 0.1848 (0.1955)\tPrec@1 94.531 (93.061)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [43][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1431 (0.1948)\tPrec@1 95.312 (93.099)\tPrec@5 100.000 (99.912)\t\n",
            "EVALUATING - Epoch: [43][0/79]\tTime 0.282 (0.282)\tData 0.250 (0.250)\tLoss 0.6372 (0.6372)\tPrec@1 83.594 (83.594)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [43][10/79]\tTime 0.039 (0.051)\tData 0.005 (0.026)\tLoss 0.3064 (0.4640)\tPrec@1 88.281 (86.648)\tPrec@5 100.000 (99.574)\t\n",
            "EVALUATING - Epoch: [43][20/79]\tTime 0.009 (0.042)\tData 0.000 (0.016)\tLoss 0.5650 (0.4887)\tPrec@1 82.812 (86.496)\tPrec@5 100.000 (99.368)\t\n",
            "EVALUATING - Epoch: [43][30/79]\tTime 0.048 (0.039)\tData 0.008 (0.012)\tLoss 0.2872 (0.4873)\tPrec@1 89.844 (86.391)\tPrec@5 100.000 (99.294)\t\n",
            "EVALUATING - Epoch: [43][40/79]\tTime 0.030 (0.035)\tData 0.005 (0.010)\tLoss 0.6897 (0.4790)\tPrec@1 82.031 (86.700)\tPrec@5 98.438 (99.295)\t\n",
            "EVALUATING - Epoch: [43][50/79]\tTime 0.036 (0.036)\tData 0.002 (0.008)\tLoss 0.3009 (0.4669)\tPrec@1 89.062 (86.949)\tPrec@5 100.000 (99.372)\t\n",
            "EVALUATING - Epoch: [43][60/79]\tTime 0.031 (0.035)\tData 0.007 (0.008)\tLoss 0.4034 (0.4622)\tPrec@1 88.281 (87.052)\tPrec@5 100.000 (99.385)\t\n",
            "EVALUATING - Epoch: [43][70/79]\tTime 0.026 (0.034)\tData 0.002 (0.007)\tLoss 0.3790 (0.4593)\tPrec@1 89.844 (86.950)\tPrec@5 100.000 (99.461)\t\n",
            "EVALUATING - Epoch: [43][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.2395 (0.4585)\tPrec@1 93.750 (86.970)\tPrec@5 100.000 (99.450)\t\n",
            "\n",
            "Results - Epoch: 44\n",
            "Training Loss 0.1948 \tTraining Prec@1 93.099 \tTraining Prec@5 99.912 \tValidation Loss 0.4585 \tValidation Prec@1 86.970 \tValidation Prec@5 99.450 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 45\n",
            "\n",
            "TRAINING - Epoch: [44][0/390]\tTime 0.347 (0.347)\tData 0.211 (0.211)\tLoss 0.0755 (0.0755)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [44][10/390]\tTime 0.071 (0.088)\tData 0.013 (0.023)\tLoss 0.1069 (0.1482)\tPrec@1 96.875 (94.815)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [44][20/390]\tTime 0.058 (0.073)\tData 0.010 (0.014)\tLoss 0.1156 (0.1422)\tPrec@1 96.875 (94.792)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [44][30/390]\tTime 0.061 (0.067)\tData 0.008 (0.011)\tLoss 0.2053 (0.1526)\tPrec@1 91.406 (94.456)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [44][40/390]\tTime 0.049 (0.064)\tData 0.000 (0.009)\tLoss 0.1575 (0.1604)\tPrec@1 96.094 (94.264)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [44][50/390]\tTime 0.054 (0.063)\tData 0.008 (0.008)\tLoss 0.2331 (0.1638)\tPrec@1 91.406 (94.087)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [44][60/390]\tTime 0.063 (0.062)\tData 0.007 (0.008)\tLoss 0.1838 (0.1646)\tPrec@1 92.969 (94.173)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [44][70/390]\tTime 0.055 (0.061)\tData 0.006 (0.007)\tLoss 0.1944 (0.1648)\tPrec@1 94.531 (94.146)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [44][80/390]\tTime 0.048 (0.060)\tData 0.000 (0.007)\tLoss 0.1479 (0.1638)\tPrec@1 92.969 (94.174)\tPrec@5 100.000 (99.952)\t\n",
            "TRAINING - Epoch: [44][90/390]\tTime 0.075 (0.060)\tData 0.000 (0.006)\tLoss 0.2477 (0.1620)\tPrec@1 89.062 (94.239)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [44][100/390]\tTime 0.051 (0.059)\tData 0.000 (0.006)\tLoss 0.1331 (0.1618)\tPrec@1 95.312 (94.253)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [44][110/390]\tTime 0.051 (0.059)\tData 0.000 (0.006)\tLoss 0.1968 (0.1626)\tPrec@1 92.188 (94.250)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [44][120/390]\tTime 0.056 (0.059)\tData 0.007 (0.006)\tLoss 0.1701 (0.1624)\tPrec@1 93.750 (94.286)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [44][130/390]\tTime 0.050 (0.059)\tData 0.000 (0.005)\tLoss 0.3552 (0.1641)\tPrec@1 89.062 (94.227)\tPrec@5 99.219 (99.940)\t\n",
            "TRAINING - Epoch: [44][140/390]\tTime 0.071 (0.059)\tData 0.006 (0.005)\tLoss 0.1146 (0.1635)\tPrec@1 97.656 (94.287)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [44][150/390]\tTime 0.066 (0.058)\tData 0.004 (0.005)\tLoss 0.1908 (0.1648)\tPrec@1 92.969 (94.247)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [44][160/390]\tTime 0.059 (0.058)\tData 0.006 (0.005)\tLoss 0.1794 (0.1660)\tPrec@1 93.750 (94.216)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [44][170/390]\tTime 0.070 (0.058)\tData 0.007 (0.005)\tLoss 0.1989 (0.1683)\tPrec@1 92.969 (94.115)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [44][180/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.1854 (0.1703)\tPrec@1 92.969 (94.031)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [44][190/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.2199 (0.1715)\tPrec@1 92.969 (93.991)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [44][200/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1652 (0.1729)\tPrec@1 92.188 (93.929)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [44][210/390]\tTime 0.053 (0.058)\tData 0.006 (0.005)\tLoss 0.1621 (0.1737)\tPrec@1 92.188 (93.906)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [44][220/390]\tTime 0.075 (0.058)\tData 0.011 (0.005)\tLoss 0.1595 (0.1738)\tPrec@1 95.312 (93.898)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [44][230/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.1665 (0.1743)\tPrec@1 94.531 (93.899)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [44][240/390]\tTime 0.049 (0.057)\tData 0.001 (0.005)\tLoss 0.1532 (0.1754)\tPrec@1 96.875 (93.889)\tPrec@5 100.000 (99.932)\t\n",
            "TRAINING - Epoch: [44][250/390]\tTime 0.058 (0.057)\tData 0.007 (0.004)\tLoss 0.1402 (0.1751)\tPrec@1 94.531 (93.881)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [44][260/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.1425 (0.1750)\tPrec@1 94.531 (93.870)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [44][270/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.2181 (0.1755)\tPrec@1 91.406 (93.836)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [44][280/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2481 (0.1766)\tPrec@1 92.969 (93.792)\tPrec@5 99.219 (99.930)\t\n",
            "TRAINING - Epoch: [44][290/390]\tTime 0.058 (0.057)\tData 0.009 (0.004)\tLoss 0.1722 (0.1771)\tPrec@1 96.875 (93.785)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [44][300/390]\tTime 0.065 (0.057)\tData 0.007 (0.004)\tLoss 0.1984 (0.1786)\tPrec@1 92.969 (93.727)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [44][310/390]\tTime 0.053 (0.057)\tData 0.001 (0.004)\tLoss 0.2459 (0.1793)\tPrec@1 90.625 (93.712)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [44][320/390]\tTime 0.053 (0.057)\tData 0.006 (0.004)\tLoss 0.1943 (0.1806)\tPrec@1 92.969 (93.662)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [44][330/390]\tTime 0.058 (0.057)\tData 0.007 (0.004)\tLoss 0.1911 (0.1822)\tPrec@1 94.531 (93.615)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [44][340/390]\tTime 0.056 (0.057)\tData 0.006 (0.004)\tLoss 0.1952 (0.1826)\tPrec@1 92.188 (93.601)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [44][350/390]\tTime 0.056 (0.057)\tData 0.000 (0.004)\tLoss 0.1822 (0.1834)\tPrec@1 96.094 (93.583)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [44][360/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1918 (0.1841)\tPrec@1 92.969 (93.549)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [44][370/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.3243 (0.1856)\tPrec@1 89.062 (93.510)\tPrec@5 97.656 (99.916)\t\n",
            "TRAINING - Epoch: [44][380/390]\tTime 0.059 (0.057)\tData 0.006 (0.004)\tLoss 0.1525 (0.1861)\tPrec@1 94.531 (93.514)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [44][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.1998 (0.1870)\tPrec@1 93.750 (93.482)\tPrec@5 100.000 (99.914)\t\n",
            "EVALUATING - Epoch: [44][0/79]\tTime 0.297 (0.297)\tData 0.255 (0.255)\tLoss 0.3823 (0.3823)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [44][10/79]\tTime 0.034 (0.056)\tData 0.005 (0.028)\tLoss 0.3904 (0.4162)\tPrec@1 86.719 (87.358)\tPrec@5 100.000 (99.432)\t\n",
            "EVALUATING - Epoch: [44][20/79]\tTime 0.037 (0.045)\tData 0.007 (0.017)\tLoss 0.3237 (0.4423)\tPrec@1 88.281 (86.793)\tPrec@5 99.219 (99.330)\t\n",
            "EVALUATING - Epoch: [44][30/79]\tTime 0.034 (0.041)\tData 0.006 (0.012)\tLoss 0.2868 (0.4302)\tPrec@1 92.188 (87.122)\tPrec@5 100.000 (99.294)\t\n",
            "EVALUATING - Epoch: [44][40/79]\tTime 0.030 (0.037)\tData 0.007 (0.011)\tLoss 0.3798 (0.4268)\tPrec@1 85.938 (87.062)\tPrec@5 100.000 (99.314)\t\n",
            "EVALUATING - Epoch: [44][50/79]\tTime 0.050 (0.036)\tData 0.011 (0.010)\tLoss 0.3991 (0.4218)\tPrec@1 85.938 (86.994)\tPrec@5 100.000 (99.372)\t\n",
            "EVALUATING - Epoch: [44][60/79]\tTime 0.031 (0.036)\tData 0.000 (0.009)\tLoss 0.4044 (0.4152)\tPrec@1 88.281 (87.218)\tPrec@5 100.000 (99.411)\t\n",
            "EVALUATING - Epoch: [44][70/79]\tTime 0.040 (0.035)\tData 0.013 (0.008)\tLoss 0.3064 (0.4155)\tPrec@1 91.406 (87.225)\tPrec@5 100.000 (99.472)\t\n",
            "EVALUATING - Epoch: [44][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.008)\tLoss 0.3529 (0.4147)\tPrec@1 93.750 (87.260)\tPrec@5 100.000 (99.490)\t\n",
            "\n",
            "Results - Epoch: 45\n",
            "Training Loss 0.1870 \tTraining Prec@1 93.482 \tTraining Prec@5 99.914 \tValidation Loss 0.4147 \tValidation Prec@1 87.260 \tValidation Prec@5 99.490 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 46\n",
            "\n",
            "TRAINING - Epoch: [45][0/390]\tTime 0.296 (0.296)\tData 0.193 (0.193)\tLoss 0.1191 (0.1191)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [45][10/390]\tTime 0.047 (0.088)\tData 0.000 (0.024)\tLoss 0.0939 (0.1853)\tPrec@1 96.875 (93.040)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [45][20/390]\tTime 0.066 (0.074)\tData 0.007 (0.014)\tLoss 0.2026 (0.1810)\tPrec@1 92.188 (93.638)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [45][30/390]\tTime 0.057 (0.069)\tData 0.000 (0.011)\tLoss 0.1485 (0.1820)\tPrec@1 93.750 (93.548)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [45][40/390]\tTime 0.049 (0.066)\tData 0.000 (0.009)\tLoss 0.1632 (0.1846)\tPrec@1 93.750 (93.559)\tPrec@5 100.000 (99.886)\t\n",
            "TRAINING - Epoch: [45][50/390]\tTime 0.052 (0.064)\tData 0.000 (0.009)\tLoss 0.1205 (0.1848)\tPrec@1 96.875 (93.627)\tPrec@5 99.219 (99.862)\t\n",
            "TRAINING - Epoch: [45][60/390]\tTime 0.064 (0.063)\tData 0.010 (0.008)\tLoss 0.1986 (0.1835)\tPrec@1 93.750 (93.660)\tPrec@5 100.000 (99.885)\t\n",
            "TRAINING - Epoch: [45][70/390]\tTime 0.062 (0.062)\tData 0.000 (0.007)\tLoss 0.1444 (0.1815)\tPrec@1 93.750 (93.574)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [45][80/390]\tTime 0.054 (0.061)\tData 0.003 (0.007)\tLoss 0.2420 (0.1806)\tPrec@1 93.750 (93.721)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [45][90/390]\tTime 0.071 (0.061)\tData 0.008 (0.006)\tLoss 0.1311 (0.1796)\tPrec@1 94.531 (93.759)\tPrec@5 100.000 (99.897)\t\n",
            "TRAINING - Epoch: [45][100/390]\tTime 0.048 (0.060)\tData 0.000 (0.006)\tLoss 0.1069 (0.1781)\tPrec@1 96.875 (93.851)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [45][110/390]\tTime 0.048 (0.060)\tData 0.000 (0.006)\tLoss 0.1775 (0.1766)\tPrec@1 93.750 (93.870)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [45][120/390]\tTime 0.061 (0.060)\tData 0.007 (0.006)\tLoss 0.1965 (0.1761)\tPrec@1 92.969 (93.860)\tPrec@5 99.219 (99.903)\t\n",
            "TRAINING - Epoch: [45][130/390]\tTime 0.062 (0.060)\tData 0.000 (0.005)\tLoss 0.1827 (0.1744)\tPrec@1 95.312 (93.911)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [45][140/390]\tTime 0.071 (0.059)\tData 0.007 (0.005)\tLoss 0.1837 (0.1738)\tPrec@1 92.969 (93.972)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [45][150/390]\tTime 0.054 (0.059)\tData 0.006 (0.005)\tLoss 0.1417 (0.1750)\tPrec@1 96.875 (93.972)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [45][160/390]\tTime 0.054 (0.059)\tData 0.000 (0.005)\tLoss 0.0999 (0.1755)\tPrec@1 97.656 (93.930)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [45][170/390]\tTime 0.059 (0.059)\tData 0.006 (0.005)\tLoss 0.2029 (0.1760)\tPrec@1 89.844 (93.937)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [45][180/390]\tTime 0.061 (0.059)\tData 0.008 (0.005)\tLoss 0.1424 (0.1760)\tPrec@1 94.531 (93.940)\tPrec@5 100.000 (99.918)\t\n",
            "TRAINING - Epoch: [45][190/390]\tTime 0.055 (0.059)\tData 0.008 (0.005)\tLoss 0.1727 (0.1755)\tPrec@1 91.406 (93.918)\tPrec@5 100.000 (99.918)\t\n",
            "TRAINING - Epoch: [45][200/390]\tTime 0.053 (0.058)\tData 0.007 (0.005)\tLoss 0.2493 (0.1756)\tPrec@1 91.406 (93.870)\tPrec@5 99.219 (99.911)\t\n",
            "TRAINING - Epoch: [45][210/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.1417 (0.1752)\tPrec@1 95.312 (93.906)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [45][220/390]\tTime 0.055 (0.058)\tData 0.006 (0.005)\tLoss 0.2057 (0.1761)\tPrec@1 94.531 (93.874)\tPrec@5 100.000 (99.915)\t\n",
            "TRAINING - Epoch: [45][230/390]\tTime 0.052 (0.058)\tData 0.007 (0.005)\tLoss 0.2021 (0.1764)\tPrec@1 92.969 (93.882)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [45][240/390]\tTime 0.058 (0.058)\tData 0.007 (0.005)\tLoss 0.2366 (0.1766)\tPrec@1 90.625 (93.857)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [45][250/390]\tTime 0.056 (0.058)\tData 0.007 (0.005)\tLoss 0.2395 (0.1784)\tPrec@1 91.406 (93.784)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [45][260/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2173 (0.1789)\tPrec@1 92.969 (93.756)\tPrec@5 99.219 (99.904)\t\n",
            "TRAINING - Epoch: [45][270/390]\tTime 0.054 (0.058)\tData 0.000 (0.005)\tLoss 0.0806 (0.1790)\tPrec@1 98.438 (93.762)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [45][280/390]\tTime 0.060 (0.058)\tData 0.007 (0.005)\tLoss 0.1739 (0.1801)\tPrec@1 93.750 (93.719)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [45][290/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2461 (0.1814)\tPrec@1 90.625 (93.656)\tPrec@5 100.000 (99.903)\t\n",
            "TRAINING - Epoch: [45][300/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.0793 (0.1823)\tPrec@1 96.875 (93.620)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [45][310/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.2370 (0.1833)\tPrec@1 89.844 (93.589)\tPrec@5 100.000 (99.902)\t\n",
            "TRAINING - Epoch: [45][320/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.1780 (0.1839)\tPrec@1 93.750 (93.567)\tPrec@5 100.000 (99.903)\t\n",
            "TRAINING - Epoch: [45][330/390]\tTime 0.065 (0.057)\tData 0.000 (0.004)\tLoss 0.2079 (0.1838)\tPrec@1 90.625 (93.559)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [45][340/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.1792 (0.1840)\tPrec@1 93.750 (93.551)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [45][350/390]\tTime 0.061 (0.058)\tData 0.007 (0.004)\tLoss 0.2877 (0.1840)\tPrec@1 90.625 (93.561)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [45][360/390]\tTime 0.046 (0.058)\tData 0.000 (0.004)\tLoss 0.1363 (0.1834)\tPrec@1 94.531 (93.579)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [45][370/390]\tTime 0.061 (0.058)\tData 0.008 (0.004)\tLoss 0.2923 (0.1831)\tPrec@1 86.719 (93.571)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [45][380/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.1776 (0.1831)\tPrec@1 92.969 (93.565)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [45][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1709 (0.1832)\tPrec@1 94.531 (93.572)\tPrec@5 100.000 (99.914)\t\n",
            "EVALUATING - Epoch: [45][0/79]\tTime 0.200 (0.200)\tData 0.166 (0.166)\tLoss 0.3570 (0.3570)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [45][10/79]\tTime 0.048 (0.056)\tData 0.016 (0.024)\tLoss 0.3631 (0.4224)\tPrec@1 87.500 (87.074)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [45][20/79]\tTime 0.020 (0.043)\tData 0.000 (0.014)\tLoss 0.3072 (0.4312)\tPrec@1 89.844 (87.128)\tPrec@5 100.000 (99.591)\t\n",
            "EVALUATING - Epoch: [45][30/79]\tTime 0.027 (0.038)\tData 0.000 (0.010)\tLoss 0.3131 (0.4299)\tPrec@1 89.062 (87.223)\tPrec@5 100.000 (99.521)\t\n",
            "EVALUATING - Epoch: [45][40/79]\tTime 0.027 (0.036)\tData 0.007 (0.009)\tLoss 0.6017 (0.4265)\tPrec@1 84.375 (87.271)\tPrec@5 100.000 (99.505)\t\n",
            "EVALUATING - Epoch: [45][50/79]\tTime 0.027 (0.035)\tData 0.007 (0.009)\tLoss 0.3970 (0.4208)\tPrec@1 88.281 (87.439)\tPrec@5 100.000 (99.540)\t\n",
            "EVALUATING - Epoch: [45][60/79]\tTime 0.027 (0.034)\tData 0.000 (0.008)\tLoss 0.5172 (0.4188)\tPrec@1 85.938 (87.500)\tPrec@5 100.000 (99.501)\t\n",
            "EVALUATING - Epoch: [45][70/79]\tTime 0.015 (0.034)\tData 0.000 (0.008)\tLoss 0.4000 (0.4212)\tPrec@1 88.281 (87.588)\tPrec@5 99.219 (99.527)\t\n",
            "EVALUATING - Epoch: [45][78/79]\tTime 0.006 (0.031)\tData 0.000 (0.007)\tLoss 0.5142 (0.4207)\tPrec@1 93.750 (87.530)\tPrec@5 100.000 (99.520)\t\n",
            "\n",
            "Results - Epoch: 46\n",
            "Training Loss 0.1832 \tTraining Prec@1 93.572 \tTraining Prec@5 99.914 \tValidation Loss 0.4207 \tValidation Prec@1 87.530 \tValidation Prec@5 99.520 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 47\n",
            "\n",
            "TRAINING - Epoch: [46][0/390]\tTime 0.352 (0.352)\tData 0.282 (0.282)\tLoss 0.1504 (0.1504)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [46][10/390]\tTime 0.059 (0.089)\tData 0.003 (0.030)\tLoss 0.1467 (0.1644)\tPrec@1 96.875 (94.531)\tPrec@5 99.219 (99.858)\t\n",
            "TRAINING - Epoch: [46][20/390]\tTime 0.049 (0.073)\tData 0.000 (0.018)\tLoss 0.2052 (0.1650)\tPrec@1 92.969 (94.234)\tPrec@5 100.000 (99.888)\t\n",
            "TRAINING - Epoch: [46][30/390]\tTime 0.064 (0.068)\tData 0.007 (0.014)\tLoss 0.1713 (0.1601)\tPrec@1 92.969 (94.279)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [46][40/390]\tTime 0.061 (0.065)\tData 0.007 (0.012)\tLoss 0.0995 (0.1628)\tPrec@1 96.094 (94.284)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [46][50/390]\tTime 0.052 (0.063)\tData 0.005 (0.011)\tLoss 0.2446 (0.1675)\tPrec@1 91.406 (94.072)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [46][60/390]\tTime 0.047 (0.062)\tData 0.000 (0.009)\tLoss 0.0892 (0.1685)\tPrec@1 96.875 (94.134)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [46][70/390]\tTime 0.061 (0.061)\tData 0.007 (0.008)\tLoss 0.2496 (0.1706)\tPrec@1 92.188 (94.146)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [46][80/390]\tTime 0.070 (0.061)\tData 0.007 (0.008)\tLoss 0.1584 (0.1715)\tPrec@1 93.750 (94.049)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [46][90/390]\tTime 0.052 (0.060)\tData 0.000 (0.007)\tLoss 0.1406 (0.1712)\tPrec@1 94.531 (93.973)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [46][100/390]\tTime 0.077 (0.060)\tData 0.000 (0.007)\tLoss 0.1900 (0.1746)\tPrec@1 92.188 (93.912)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [46][110/390]\tTime 0.051 (0.060)\tData 0.003 (0.007)\tLoss 0.2278 (0.1776)\tPrec@1 92.188 (93.799)\tPrec@5 99.219 (99.901)\t\n",
            "TRAINING - Epoch: [46][120/390]\tTime 0.080 (0.060)\tData 0.008 (0.007)\tLoss 0.1473 (0.1800)\tPrec@1 95.312 (93.737)\tPrec@5 100.000 (99.910)\t\n",
            "TRAINING - Epoch: [46][130/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.1673 (0.1795)\tPrec@1 95.312 (93.750)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [46][140/390]\tTime 0.056 (0.059)\tData 0.007 (0.006)\tLoss 0.2093 (0.1818)\tPrec@1 92.188 (93.689)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [46][150/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.2572 (0.1826)\tPrec@1 92.188 (93.641)\tPrec@5 100.000 (99.902)\t\n",
            "TRAINING - Epoch: [46][160/390]\tTime 0.063 (0.059)\tData 0.007 (0.006)\tLoss 0.1790 (0.1834)\tPrec@1 93.750 (93.614)\tPrec@5 100.000 (99.903)\t\n",
            "TRAINING - Epoch: [46][170/390]\tTime 0.055 (0.059)\tData 0.008 (0.006)\tLoss 0.2249 (0.1851)\tPrec@1 94.531 (93.563)\tPrec@5 99.219 (99.895)\t\n",
            "TRAINING - Epoch: [46][180/390]\tTime 0.049 (0.059)\tData 0.000 (0.006)\tLoss 0.2162 (0.1854)\tPrec@1 92.969 (93.539)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [46][190/390]\tTime 0.069 (0.058)\tData 0.002 (0.005)\tLoss 0.1521 (0.1880)\tPrec@1 94.531 (93.460)\tPrec@5 100.000 (99.890)\t\n",
            "TRAINING - Epoch: [46][200/390]\tTime 0.067 (0.058)\tData 0.006 (0.005)\tLoss 0.2193 (0.1878)\tPrec@1 93.750 (93.424)\tPrec@5 100.000 (99.891)\t\n",
            "TRAINING - Epoch: [46][210/390]\tTime 0.054 (0.058)\tData 0.007 (0.005)\tLoss 0.2477 (0.1884)\tPrec@1 94.531 (93.406)\tPrec@5 99.219 (99.882)\t\n",
            "TRAINING - Epoch: [46][220/390]\tTime 0.055 (0.058)\tData 0.006 (0.005)\tLoss 0.1675 (0.1880)\tPrec@1 94.531 (93.407)\tPrec@5 100.000 (99.887)\t\n",
            "TRAINING - Epoch: [46][230/390]\tTime 0.055 (0.058)\tData 0.005 (0.005)\tLoss 0.1580 (0.1876)\tPrec@1 94.531 (93.419)\tPrec@5 100.000 (99.892)\t\n",
            "TRAINING - Epoch: [46][240/390]\tTime 0.063 (0.058)\tData 0.006 (0.005)\tLoss 0.2241 (0.1880)\tPrec@1 91.406 (93.410)\tPrec@5 100.000 (99.890)\t\n",
            "TRAINING - Epoch: [46][250/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.0966 (0.1872)\tPrec@1 96.875 (93.439)\tPrec@5 100.000 (99.891)\t\n",
            "TRAINING - Epoch: [46][260/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.2324 (0.1880)\tPrec@1 92.969 (93.427)\tPrec@5 100.000 (99.886)\t\n",
            "TRAINING - Epoch: [46][270/390]\tTime 0.059 (0.057)\tData 0.010 (0.005)\tLoss 0.1830 (0.1874)\tPrec@1 92.188 (93.433)\tPrec@5 100.000 (99.882)\t\n",
            "TRAINING - Epoch: [46][280/390]\tTime 0.060 (0.057)\tData 0.007 (0.005)\tLoss 0.1484 (0.1879)\tPrec@1 93.750 (93.425)\tPrec@5 100.000 (99.875)\t\n",
            "TRAINING - Epoch: [46][290/390]\tTime 0.061 (0.057)\tData 0.006 (0.005)\tLoss 0.2237 (0.1885)\tPrec@1 91.406 (93.382)\tPrec@5 100.000 (99.877)\t\n",
            "TRAINING - Epoch: [46][300/390]\tTime 0.051 (0.057)\tData 0.004 (0.005)\tLoss 0.1349 (0.1893)\tPrec@1 96.094 (93.358)\tPrec@5 98.438 (99.870)\t\n",
            "TRAINING - Epoch: [46][310/390]\tTime 0.055 (0.057)\tData 0.000 (0.005)\tLoss 0.2762 (0.1897)\tPrec@1 90.625 (93.336)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [46][320/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.1669 (0.1901)\tPrec@1 92.188 (93.292)\tPrec@5 100.000 (99.878)\t\n",
            "TRAINING - Epoch: [46][330/390]\tTime 0.063 (0.057)\tData 0.007 (0.005)\tLoss 0.1826 (0.1896)\tPrec@1 95.312 (93.316)\tPrec@5 100.000 (99.880)\t\n",
            "TRAINING - Epoch: [46][340/390]\tTime 0.056 (0.057)\tData 0.007 (0.005)\tLoss 0.1499 (0.1897)\tPrec@1 96.094 (93.319)\tPrec@5 100.000 (99.879)\t\n",
            "TRAINING - Epoch: [46][350/390]\tTime 0.054 (0.057)\tData 0.008 (0.005)\tLoss 0.1880 (0.1902)\tPrec@1 91.406 (93.314)\tPrec@5 100.000 (99.875)\t\n",
            "TRAINING - Epoch: [46][360/390]\tTime 0.062 (0.057)\tData 0.007 (0.005)\tLoss 0.1865 (0.1902)\tPrec@1 91.406 (93.304)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [46][370/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.1535 (0.1905)\tPrec@1 96.094 (93.299)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [46][380/390]\tTime 0.053 (0.057)\tData 0.007 (0.005)\tLoss 0.1136 (0.1901)\tPrec@1 95.312 (93.309)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [46][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.2508 (0.1908)\tPrec@1 92.188 (93.289)\tPrec@5 100.000 (99.874)\t\n",
            "EVALUATING - Epoch: [46][0/79]\tTime 0.193 (0.193)\tData 0.150 (0.150)\tLoss 0.3129 (0.3129)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [46][10/79]\tTime 0.025 (0.054)\tData 0.005 (0.024)\tLoss 0.2870 (0.3429)\tPrec@1 91.406 (88.991)\tPrec@5 100.000 (99.929)\t\n",
            "EVALUATING - Epoch: [46][20/79]\tTime 0.029 (0.042)\tData 0.000 (0.014)\tLoss 0.3997 (0.3700)\tPrec@1 87.500 (88.653)\tPrec@5 99.219 (99.814)\t\n",
            "EVALUATING - Epoch: [46][30/79]\tTime 0.056 (0.039)\tData 0.006 (0.011)\tLoss 0.3817 (0.3892)\tPrec@1 88.281 (88.684)\tPrec@5 100.000 (99.698)\t\n",
            "EVALUATING - Epoch: [46][40/79]\tTime 0.035 (0.036)\tData 0.007 (0.009)\tLoss 0.4534 (0.3977)\tPrec@1 86.719 (88.643)\tPrec@5 99.219 (99.638)\t\n",
            "EVALUATING - Epoch: [46][50/79]\tTime 0.026 (0.035)\tData 0.005 (0.008)\tLoss 0.3956 (0.3991)\tPrec@1 87.500 (88.557)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [46][60/79]\tTime 0.037 (0.034)\tData 0.006 (0.008)\tLoss 0.3243 (0.3927)\tPrec@1 89.062 (88.717)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [46][70/79]\tTime 0.020 (0.033)\tData 0.006 (0.008)\tLoss 0.2255 (0.3908)\tPrec@1 92.188 (88.600)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [46][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.2834 (0.3893)\tPrec@1 93.750 (88.640)\tPrec@5 100.000 (99.720)\t\n",
            "\n",
            "Results - Epoch: 47\n",
            "Training Loss 0.1908 \tTraining Prec@1 93.289 \tTraining Prec@5 99.874 \tValidation Loss 0.3893 \tValidation Prec@1 88.640 \tValidation Prec@5 99.720 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 48\n",
            "\n",
            "TRAINING - Epoch: [47][0/390]\tTime 0.354 (0.354)\tData 0.282 (0.282)\tLoss 0.1796 (0.1796)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [47][10/390]\tTime 0.055 (0.089)\tData 0.007 (0.028)\tLoss 0.2376 (0.1807)\tPrec@1 93.750 (93.892)\tPrec@5 100.000 (99.716)\t\n",
            "TRAINING - Epoch: [47][20/390]\tTime 0.075 (0.074)\tData 0.007 (0.016)\tLoss 0.1477 (0.1702)\tPrec@1 95.312 (94.271)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [47][30/390]\tTime 0.059 (0.069)\tData 0.006 (0.012)\tLoss 0.2062 (0.1769)\tPrec@1 91.406 (93.952)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [47][40/390]\tTime 0.049 (0.065)\tData 0.000 (0.010)\tLoss 0.1188 (0.1776)\tPrec@1 96.875 (94.074)\tPrec@5 100.000 (99.867)\t\n",
            "TRAINING - Epoch: [47][50/390]\tTime 0.058 (0.063)\tData 0.007 (0.009)\tLoss 0.1609 (0.1770)\tPrec@1 93.750 (94.010)\tPrec@5 100.000 (99.877)\t\n",
            "TRAINING - Epoch: [47][60/390]\tTime 0.046 (0.062)\tData 0.000 (0.008)\tLoss 0.1078 (0.1735)\tPrec@1 96.094 (94.057)\tPrec@5 100.000 (99.885)\t\n",
            "TRAINING - Epoch: [47][70/390]\tTime 0.057 (0.061)\tData 0.000 (0.007)\tLoss 0.1861 (0.1762)\tPrec@1 92.188 (93.915)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [47][80/390]\tTime 0.047 (0.060)\tData 0.000 (0.006)\tLoss 0.1287 (0.1740)\tPrec@1 94.531 (93.981)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [47][90/390]\tTime 0.046 (0.060)\tData 0.000 (0.006)\tLoss 0.1238 (0.1728)\tPrec@1 95.312 (94.042)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [47][100/390]\tTime 0.047 (0.060)\tData 0.000 (0.006)\tLoss 0.2151 (0.1710)\tPrec@1 92.969 (94.005)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [47][110/390]\tTime 0.056 (0.060)\tData 0.000 (0.006)\tLoss 0.1875 (0.1714)\tPrec@1 92.969 (93.968)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [47][120/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.1304 (0.1708)\tPrec@1 96.094 (93.976)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [47][130/390]\tTime 0.061 (0.059)\tData 0.006 (0.005)\tLoss 0.2258 (0.1750)\tPrec@1 89.844 (93.863)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [47][140/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.1731 (0.1759)\tPrec@1 92.969 (93.844)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [47][150/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.2370 (0.1764)\tPrec@1 89.062 (93.807)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [47][160/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1744 (0.1776)\tPrec@1 92.188 (93.755)\tPrec@5 100.000 (99.918)\t\n",
            "TRAINING - Epoch: [47][170/390]\tTime 0.054 (0.058)\tData 0.000 (0.005)\tLoss 0.1756 (0.1771)\tPrec@1 94.531 (93.750)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [47][180/390]\tTime 0.070 (0.058)\tData 0.014 (0.005)\tLoss 0.1602 (0.1757)\tPrec@1 94.531 (93.815)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [47][190/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.2258 (0.1748)\tPrec@1 91.406 (93.844)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [47][200/390]\tTime 0.055 (0.058)\tData 0.000 (0.005)\tLoss 0.1294 (0.1748)\tPrec@1 96.094 (93.847)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [47][210/390]\tTime 0.059 (0.058)\tData 0.007 (0.005)\tLoss 0.2502 (0.1760)\tPrec@1 90.625 (93.802)\tPrec@5 99.219 (99.926)\t\n",
            "TRAINING - Epoch: [47][220/390]\tTime 0.053 (0.058)\tData 0.001 (0.004)\tLoss 0.1036 (0.1767)\tPrec@1 97.656 (93.761)\tPrec@5 100.000 (99.919)\t\n",
            "TRAINING - Epoch: [47][230/390]\tTime 0.052 (0.058)\tData 0.005 (0.004)\tLoss 0.2257 (0.1780)\tPrec@1 93.750 (93.699)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [47][240/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.1112 (0.1777)\tPrec@1 96.094 (93.695)\tPrec@5 100.000 (99.925)\t\n",
            "TRAINING - Epoch: [47][250/390]\tTime 0.054 (0.058)\tData 0.000 (0.004)\tLoss 0.2131 (0.1787)\tPrec@1 92.969 (93.650)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [47][260/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.2203 (0.1801)\tPrec@1 89.844 (93.597)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [47][270/390]\tTime 0.052 (0.058)\tData 0.000 (0.004)\tLoss 0.2850 (0.1805)\tPrec@1 90.625 (93.589)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [47][280/390]\tTime 0.053 (0.058)\tData 0.006 (0.004)\tLoss 0.2188 (0.1802)\tPrec@1 93.750 (93.569)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [47][290/390]\tTime 0.047 (0.058)\tData 0.000 (0.004)\tLoss 0.2595 (0.1816)\tPrec@1 91.406 (93.516)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [47][300/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2236 (0.1820)\tPrec@1 92.188 (93.503)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [47][310/390]\tTime 0.061 (0.057)\tData 0.008 (0.004)\tLoss 0.1668 (0.1829)\tPrec@1 95.312 (93.484)\tPrec@5 100.000 (99.925)\t\n",
            "TRAINING - Epoch: [47][320/390]\tTime 0.065 (0.057)\tData 0.007 (0.004)\tLoss 0.1289 (0.1825)\tPrec@1 95.312 (93.509)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [47][330/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2366 (0.1830)\tPrec@1 91.406 (93.486)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [47][340/390]\tTime 0.061 (0.057)\tData 0.001 (0.004)\tLoss 0.2123 (0.1836)\tPrec@1 92.969 (93.480)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [47][350/390]\tTime 0.054 (0.057)\tData 0.000 (0.004)\tLoss 0.1859 (0.1837)\tPrec@1 94.531 (93.463)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [47][360/390]\tTime 0.058 (0.057)\tData 0.007 (0.004)\tLoss 0.1259 (0.1831)\tPrec@1 96.094 (93.484)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [47][370/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.2294 (0.1832)\tPrec@1 92.969 (93.493)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [47][380/390]\tTime 0.080 (0.057)\tData 0.010 (0.004)\tLoss 0.2579 (0.1834)\tPrec@1 89.844 (93.485)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [47][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1804 (0.1832)\tPrec@1 96.094 (93.504)\tPrec@5 100.000 (99.916)\t\n",
            "EVALUATING - Epoch: [47][0/79]\tTime 0.203 (0.203)\tData 0.161 (0.161)\tLoss 0.3502 (0.3502)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [47][10/79]\tTime 0.035 (0.054)\tData 0.000 (0.020)\tLoss 0.3127 (0.3927)\tPrec@1 89.844 (88.281)\tPrec@5 100.000 (99.645)\t\n",
            "EVALUATING - Epoch: [47][20/79]\tTime 0.038 (0.044)\tData 0.006 (0.013)\tLoss 0.3445 (0.4120)\tPrec@1 89.062 (88.393)\tPrec@5 99.219 (99.665)\t\n",
            "EVALUATING - Epoch: [47][30/79]\tTime 0.045 (0.039)\tData 0.007 (0.011)\tLoss 0.3420 (0.4114)\tPrec@1 89.062 (88.458)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [47][40/79]\tTime 0.035 (0.037)\tData 0.001 (0.009)\tLoss 0.4831 (0.4144)\tPrec@1 82.812 (88.224)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [47][50/79]\tTime 0.029 (0.037)\tData 0.011 (0.009)\tLoss 0.3607 (0.4103)\tPrec@1 89.844 (88.235)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [47][60/79]\tTime 0.034 (0.036)\tData 0.005 (0.008)\tLoss 0.3912 (0.4100)\tPrec@1 89.062 (88.332)\tPrec@5 99.219 (99.616)\t\n",
            "EVALUATING - Epoch: [47][70/79]\tTime 0.027 (0.035)\tData 0.006 (0.008)\tLoss 0.2892 (0.4067)\tPrec@1 91.406 (88.270)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [47][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.4013 (0.4090)\tPrec@1 87.500 (88.210)\tPrec@5 100.000 (99.650)\t\n",
            "\n",
            "Results - Epoch: 48\n",
            "Training Loss 0.1832 \tTraining Prec@1 93.504 \tTraining Prec@5 99.916 \tValidation Loss 0.4090 \tValidation Prec@1 88.210 \tValidation Prec@5 99.650 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 49\n",
            "\n",
            "TRAINING - Epoch: [48][0/390]\tTime 0.270 (0.270)\tData 0.184 (0.184)\tLoss 0.2345 (0.2345)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [48][10/390]\tTime 0.051 (0.086)\tData 0.000 (0.022)\tLoss 0.1539 (0.1655)\tPrec@1 94.531 (94.247)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [48][20/390]\tTime 0.059 (0.072)\tData 0.011 (0.014)\tLoss 0.1188 (0.1604)\tPrec@1 95.312 (94.382)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [48][30/390]\tTime 0.060 (0.067)\tData 0.011 (0.010)\tLoss 0.2170 (0.1583)\tPrec@1 92.969 (94.481)\tPrec@5 99.219 (99.899)\t\n",
            "TRAINING - Epoch: [48][40/390]\tTime 0.048 (0.064)\tData 0.000 (0.009)\tLoss 0.0760 (0.1541)\tPrec@1 97.656 (94.722)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [48][50/390]\tTime 0.057 (0.063)\tData 0.007 (0.008)\tLoss 0.1742 (0.1553)\tPrec@1 94.531 (94.715)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [48][60/390]\tTime 0.056 (0.062)\tData 0.007 (0.008)\tLoss 0.1199 (0.1561)\tPrec@1 95.312 (94.621)\tPrec@5 100.000 (99.898)\t\n",
            "TRAINING - Epoch: [48][70/390]\tTime 0.062 (0.061)\tData 0.000 (0.007)\tLoss 0.1415 (0.1616)\tPrec@1 96.094 (94.454)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [48][80/390]\tTime 0.072 (0.060)\tData 0.012 (0.006)\tLoss 0.1483 (0.1616)\tPrec@1 93.750 (94.396)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [48][90/390]\tTime 0.051 (0.060)\tData 0.000 (0.006)\tLoss 0.1335 (0.1627)\tPrec@1 94.531 (94.325)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [48][100/390]\tTime 0.057 (0.060)\tData 0.008 (0.006)\tLoss 0.2660 (0.1652)\tPrec@1 92.969 (94.245)\tPrec@5 99.219 (99.923)\t\n",
            "TRAINING - Epoch: [48][110/390]\tTime 0.057 (0.059)\tData 0.000 (0.005)\tLoss 0.0769 (0.1655)\tPrec@1 98.438 (94.257)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [48][120/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 0.2293 (0.1659)\tPrec@1 91.406 (94.202)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [48][130/390]\tTime 0.056 (0.059)\tData 0.008 (0.005)\tLoss 0.1903 (0.1663)\tPrec@1 93.750 (94.227)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [48][140/390]\tTime 0.052 (0.059)\tData 0.000 (0.005)\tLoss 0.1532 (0.1659)\tPrec@1 94.531 (94.243)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [48][150/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.1493 (0.1641)\tPrec@1 93.750 (94.335)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [48][160/390]\tTime 0.058 (0.058)\tData 0.000 (0.005)\tLoss 0.1312 (0.1647)\tPrec@1 96.094 (94.308)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [48][170/390]\tTime 0.063 (0.058)\tData 0.007 (0.005)\tLoss 0.2748 (0.1661)\tPrec@1 90.625 (94.243)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [48][180/390]\tTime 0.053 (0.058)\tData 0.000 (0.005)\tLoss 0.1425 (0.1672)\tPrec@1 92.969 (94.164)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [48][190/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.2527 (0.1690)\tPrec@1 91.406 (94.106)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [48][200/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.0978 (0.1693)\tPrec@1 96.094 (94.104)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [48][210/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.1772 (0.1717)\tPrec@1 95.312 (94.020)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [48][220/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.1012 (0.1726)\tPrec@1 96.094 (93.980)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [48][230/390]\tTime 0.047 (0.058)\tData 0.000 (0.004)\tLoss 0.2321 (0.1739)\tPrec@1 91.406 (93.906)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [48][240/390]\tTime 0.053 (0.058)\tData 0.000 (0.004)\tLoss 0.1395 (0.1752)\tPrec@1 94.531 (93.886)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [48][250/390]\tTime 0.046 (0.058)\tData 0.000 (0.004)\tLoss 0.1985 (0.1750)\tPrec@1 91.406 (93.875)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [48][260/390]\tTime 0.047 (0.058)\tData 0.000 (0.004)\tLoss 0.1426 (0.1752)\tPrec@1 95.312 (93.867)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [48][270/390]\tTime 0.057 (0.058)\tData 0.007 (0.004)\tLoss 0.1921 (0.1761)\tPrec@1 92.188 (93.839)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [48][280/390]\tTime 0.048 (0.058)\tData 0.000 (0.004)\tLoss 0.2246 (0.1763)\tPrec@1 91.406 (93.845)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [48][290/390]\tTime 0.057 (0.057)\tData 0.000 (0.004)\tLoss 0.1815 (0.1770)\tPrec@1 92.969 (93.804)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [48][300/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2421 (0.1778)\tPrec@1 92.969 (93.805)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [48][310/390]\tTime 0.053 (0.057)\tData 0.005 (0.004)\tLoss 0.2241 (0.1781)\tPrec@1 92.188 (93.798)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [48][320/390]\tTime 0.064 (0.057)\tData 0.000 (0.004)\tLoss 0.1914 (0.1783)\tPrec@1 94.531 (93.796)\tPrec@5 100.000 (99.915)\t\n",
            "TRAINING - Epoch: [48][330/390]\tTime 0.055 (0.057)\tData 0.003 (0.004)\tLoss 0.1344 (0.1788)\tPrec@1 94.531 (93.797)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [48][340/390]\tTime 0.058 (0.057)\tData 0.007 (0.004)\tLoss 0.2273 (0.1796)\tPrec@1 91.406 (93.764)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [48][350/390]\tTime 0.080 (0.057)\tData 0.009 (0.004)\tLoss 0.1734 (0.1800)\tPrec@1 92.969 (93.732)\tPrec@5 99.219 (99.902)\t\n",
            "TRAINING - Epoch: [48][360/390]\tTime 0.062 (0.057)\tData 0.000 (0.004)\tLoss 0.2081 (0.1802)\tPrec@1 92.969 (93.709)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [48][370/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.3071 (0.1811)\tPrec@1 87.500 (93.687)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [48][380/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2512 (0.1818)\tPrec@1 92.188 (93.656)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [48][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1873 (0.1820)\tPrec@1 92.969 (93.646)\tPrec@5 100.000 (99.900)\t\n",
            "EVALUATING - Epoch: [48][0/79]\tTime 0.272 (0.272)\tData 0.237 (0.237)\tLoss 0.3742 (0.3742)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [48][10/79]\tTime 0.036 (0.056)\tData 0.011 (0.028)\tLoss 0.2635 (0.3729)\tPrec@1 93.750 (87.926)\tPrec@5 99.219 (99.574)\t\n",
            "EVALUATING - Epoch: [48][20/79]\tTime 0.033 (0.043)\tData 0.011 (0.018)\tLoss 0.5182 (0.4000)\tPrec@1 83.594 (87.798)\tPrec@5 97.656 (99.368)\t\n",
            "EVALUATING - Epoch: [48][30/79]\tTime 0.025 (0.039)\tData 0.000 (0.014)\tLoss 0.2165 (0.3857)\tPrec@1 92.188 (88.407)\tPrec@5 100.000 (99.446)\t\n",
            "EVALUATING - Epoch: [48][40/79]\tTime 0.033 (0.037)\tData 0.000 (0.012)\tLoss 0.4570 (0.3927)\tPrec@1 89.062 (88.129)\tPrec@5 100.000 (99.543)\t\n",
            "EVALUATING - Epoch: [48][50/79]\tTime 0.053 (0.036)\tData 0.006 (0.010)\tLoss 0.3661 (0.3876)\tPrec@1 89.062 (88.327)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [48][60/79]\tTime 0.036 (0.034)\tData 0.007 (0.009)\tLoss 0.3453 (0.3855)\tPrec@1 90.625 (88.537)\tPrec@5 99.219 (99.654)\t\n",
            "EVALUATING - Epoch: [48][70/79]\tTime 0.013 (0.034)\tData 0.000 (0.008)\tLoss 0.2831 (0.3852)\tPrec@1 89.844 (88.424)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [48][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.2357 (0.3840)\tPrec@1 93.750 (88.590)\tPrec@5 100.000 (99.720)\t\n",
            "\n",
            "Results - Epoch: 49\n",
            "Training Loss 0.1820 \tTraining Prec@1 93.646 \tTraining Prec@5 99.900 \tValidation Loss 0.3840 \tValidation Prec@1 88.590 \tValidation Prec@5 99.720 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 50\n",
            "\n",
            "TRAINING - Epoch: [49][0/390]\tTime 0.287 (0.287)\tData 0.177 (0.177)\tLoss 0.1822 (0.1822)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [49][10/390]\tTime 0.047 (0.088)\tData 0.000 (0.020)\tLoss 0.2026 (0.1871)\tPrec@1 93.750 (93.679)\tPrec@5 99.219 (99.929)\t\n",
            "TRAINING - Epoch: [49][20/390]\tTime 0.058 (0.073)\tData 0.006 (0.012)\tLoss 0.0841 (0.1806)\tPrec@1 96.875 (93.862)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [49][30/390]\tTime 0.047 (0.067)\tData 0.000 (0.009)\tLoss 0.1930 (0.1806)\tPrec@1 94.531 (93.574)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [49][40/390]\tTime 0.059 (0.064)\tData 0.007 (0.008)\tLoss 0.0982 (0.1743)\tPrec@1 96.875 (93.864)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [49][50/390]\tTime 0.055 (0.063)\tData 0.007 (0.007)\tLoss 0.1198 (0.1743)\tPrec@1 95.312 (93.964)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [49][60/390]\tTime 0.057 (0.062)\tData 0.000 (0.007)\tLoss 0.1720 (0.1697)\tPrec@1 94.531 (94.083)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [49][70/390]\tTime 0.047 (0.061)\tData 0.000 (0.006)\tLoss 0.2152 (0.1715)\tPrec@1 95.312 (94.135)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [49][80/390]\tTime 0.056 (0.060)\tData 0.007 (0.006)\tLoss 0.1706 (0.1733)\tPrec@1 95.312 (93.991)\tPrec@5 100.000 (99.952)\t\n",
            "TRAINING - Epoch: [49][90/390]\tTime 0.078 (0.060)\tData 0.007 (0.006)\tLoss 0.1779 (0.1718)\tPrec@1 95.312 (94.145)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [49][100/390]\tTime 0.050 (0.060)\tData 0.000 (0.005)\tLoss 0.2309 (0.1721)\tPrec@1 92.188 (94.175)\tPrec@5 99.219 (99.923)\t\n",
            "TRAINING - Epoch: [49][110/390]\tTime 0.055 (0.059)\tData 0.000 (0.005)\tLoss 0.2482 (0.1724)\tPrec@1 89.844 (94.123)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [49][120/390]\tTime 0.072 (0.059)\tData 0.000 (0.005)\tLoss 0.2107 (0.1725)\tPrec@1 91.406 (94.105)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [49][130/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 0.2418 (0.1746)\tPrec@1 91.406 (94.042)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [49][140/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1171 (0.1745)\tPrec@1 95.312 (94.055)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [49][150/390]\tTime 0.061 (0.058)\tData 0.009 (0.005)\tLoss 0.2673 (0.1757)\tPrec@1 92.188 (94.014)\tPrec@5 100.000 (99.902)\t\n",
            "TRAINING - Epoch: [49][160/390]\tTime 0.056 (0.058)\tData 0.008 (0.005)\tLoss 0.1819 (0.1751)\tPrec@1 91.406 (94.061)\tPrec@5 100.000 (99.903)\t\n",
            "TRAINING - Epoch: [49][170/390]\tTime 0.046 (0.058)\tData 0.000 (0.005)\tLoss 0.1740 (0.1749)\tPrec@1 94.531 (94.042)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [49][180/390]\tTime 0.052 (0.058)\tData 0.000 (0.004)\tLoss 0.2122 (0.1736)\tPrec@1 93.750 (94.044)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [49][190/390]\tTime 0.058 (0.058)\tData 0.007 (0.004)\tLoss 0.1520 (0.1728)\tPrec@1 93.750 (94.057)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [49][200/390]\tTime 0.056 (0.057)\tData 0.009 (0.004)\tLoss 0.1962 (0.1734)\tPrec@1 91.406 (94.018)\tPrec@5 100.000 (99.903)\t\n",
            "TRAINING - Epoch: [49][210/390]\tTime 0.061 (0.058)\tData 0.000 (0.004)\tLoss 0.1614 (0.1727)\tPrec@1 93.750 (94.031)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [49][220/390]\tTime 0.047 (0.058)\tData 0.000 (0.004)\tLoss 0.1138 (0.1726)\tPrec@1 96.875 (94.043)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [49][230/390]\tTime 0.055 (0.057)\tData 0.000 (0.004)\tLoss 0.1718 (0.1716)\tPrec@1 97.656 (94.088)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [49][240/390]\tTime 0.058 (0.058)\tData 0.007 (0.004)\tLoss 0.0928 (0.1716)\tPrec@1 97.656 (94.110)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [49][250/390]\tTime 0.072 (0.058)\tData 0.008 (0.004)\tLoss 0.2674 (0.1735)\tPrec@1 86.719 (94.021)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [49][260/390]\tTime 0.054 (0.057)\tData 0.005 (0.004)\tLoss 0.2150 (0.1732)\tPrec@1 92.969 (94.031)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [49][270/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.1452 (0.1740)\tPrec@1 95.312 (93.972)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [49][280/390]\tTime 0.054 (0.057)\tData 0.000 (0.004)\tLoss 0.2130 (0.1758)\tPrec@1 92.188 (93.886)\tPrec@5 99.219 (99.900)\t\n",
            "TRAINING - Epoch: [49][290/390]\tTime 0.070 (0.057)\tData 0.009 (0.004)\tLoss 0.2069 (0.1758)\tPrec@1 92.188 (93.890)\tPrec@5 100.000 (99.903)\t\n",
            "TRAINING - Epoch: [49][300/390]\tTime 0.058 (0.057)\tData 0.007 (0.004)\tLoss 0.1499 (0.1757)\tPrec@1 93.750 (93.893)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [49][310/390]\tTime 0.053 (0.057)\tData 0.007 (0.004)\tLoss 0.2146 (0.1757)\tPrec@1 92.188 (93.891)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [49][320/390]\tTime 0.063 (0.057)\tData 0.000 (0.004)\tLoss 0.1573 (0.1754)\tPrec@1 95.312 (93.898)\tPrec@5 99.219 (99.905)\t\n",
            "TRAINING - Epoch: [49][330/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1910 (0.1763)\tPrec@1 92.188 (93.882)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [49][340/390]\tTime 0.061 (0.057)\tData 0.007 (0.004)\tLoss 0.1799 (0.1769)\tPrec@1 92.188 (93.858)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [49][350/390]\tTime 0.058 (0.057)\tData 0.008 (0.004)\tLoss 0.1981 (0.1779)\tPrec@1 92.188 (93.799)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [49][360/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2433 (0.1787)\tPrec@1 90.625 (93.769)\tPrec@5 99.219 (99.907)\t\n",
            "TRAINING - Epoch: [49][370/390]\tTime 0.061 (0.057)\tData 0.012 (0.004)\tLoss 0.2846 (0.1797)\tPrec@1 90.625 (93.718)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [49][380/390]\tTime 0.058 (0.057)\tData 0.000 (0.004)\tLoss 0.2546 (0.1808)\tPrec@1 92.969 (93.688)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [49][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.3114 (0.1816)\tPrec@1 92.188 (93.672)\tPrec@5 99.219 (99.900)\t\n",
            "EVALUATING - Epoch: [49][0/79]\tTime 0.286 (0.286)\tData 0.254 (0.254)\tLoss 0.3882 (0.3882)\tPrec@1 85.938 (85.938)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [49][10/79]\tTime 0.018 (0.057)\tData 0.001 (0.027)\tLoss 0.2161 (0.3492)\tPrec@1 92.188 (87.855)\tPrec@5 100.000 (99.858)\t\n",
            "EVALUATING - Epoch: [49][20/79]\tTime 0.024 (0.043)\tData 0.000 (0.016)\tLoss 0.4100 (0.3826)\tPrec@1 86.719 (87.723)\tPrec@5 98.438 (99.665)\t\n",
            "EVALUATING - Epoch: [49][30/79]\tTime 0.027 (0.039)\tData 0.011 (0.012)\tLoss 0.2716 (0.3819)\tPrec@1 95.312 (88.054)\tPrec@5 100.000 (99.672)\t\n",
            "EVALUATING - Epoch: [49][40/79]\tTime 0.014 (0.036)\tData 0.000 (0.010)\tLoss 0.3639 (0.3757)\tPrec@1 89.844 (88.262)\tPrec@5 100.000 (99.676)\t\n",
            "EVALUATING - Epoch: [49][50/79]\tTime 0.030 (0.036)\tData 0.000 (0.009)\tLoss 0.3270 (0.3686)\tPrec@1 89.062 (88.511)\tPrec@5 100.000 (99.740)\t\n",
            "EVALUATING - Epoch: [49][60/79]\tTime 0.039 (0.035)\tData 0.007 (0.008)\tLoss 0.3694 (0.3686)\tPrec@1 91.406 (88.601)\tPrec@5 100.000 (99.693)\t\n",
            "EVALUATING - Epoch: [49][70/79]\tTime 0.015 (0.034)\tData 0.000 (0.008)\tLoss 0.2851 (0.3693)\tPrec@1 93.750 (88.512)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [49][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.4254 (0.3698)\tPrec@1 93.750 (88.450)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 50\n",
            "Training Loss 0.1816 \tTraining Prec@1 93.672 \tTraining Prec@5 99.900 \tValidation Loss 0.3698 \tValidation Prec@1 88.450 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 51\n",
            "\n",
            "TRAINING - Epoch: [50][0/390]\tTime 0.383 (0.383)\tData 0.259 (0.259)\tLoss 0.1290 (0.1290)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [50][10/390]\tTime 0.047 (0.087)\tData 0.000 (0.029)\tLoss 0.1681 (0.1598)\tPrec@1 94.531 (94.815)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [50][20/390]\tTime 0.047 (0.071)\tData 0.000 (0.016)\tLoss 0.2167 (0.1557)\tPrec@1 92.969 (95.015)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [50][30/390]\tTime 0.047 (0.066)\tData 0.000 (0.012)\tLoss 0.2125 (0.1759)\tPrec@1 92.188 (94.330)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [50][40/390]\tTime 0.047 (0.064)\tData 0.000 (0.010)\tLoss 0.0952 (0.1735)\tPrec@1 96.094 (94.245)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [50][50/390]\tTime 0.057 (0.062)\tData 0.008 (0.009)\tLoss 0.0829 (0.1696)\tPrec@1 97.656 (94.409)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [50][60/390]\tTime 0.047 (0.061)\tData 0.000 (0.008)\tLoss 0.1318 (0.1622)\tPrec@1 95.312 (94.647)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [50][70/390]\tTime 0.074 (0.060)\tData 0.000 (0.007)\tLoss 0.3024 (0.1625)\tPrec@1 89.844 (94.619)\tPrec@5 99.219 (99.934)\t\n",
            "TRAINING - Epoch: [50][80/390]\tTime 0.053 (0.060)\tData 0.000 (0.006)\tLoss 0.1679 (0.1624)\tPrec@1 95.312 (94.618)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [50][90/390]\tTime 0.053 (0.059)\tData 0.005 (0.006)\tLoss 0.1923 (0.1618)\tPrec@1 93.750 (94.548)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [50][100/390]\tTime 0.052 (0.059)\tData 0.003 (0.006)\tLoss 0.2115 (0.1629)\tPrec@1 93.750 (94.454)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [50][110/390]\tTime 0.059 (0.059)\tData 0.009 (0.006)\tLoss 0.1238 (0.1643)\tPrec@1 95.312 (94.405)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [50][120/390]\tTime 0.051 (0.059)\tData 0.002 (0.006)\tLoss 0.1489 (0.1632)\tPrec@1 94.531 (94.409)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [50][130/390]\tTime 0.050 (0.059)\tData 0.002 (0.005)\tLoss 0.1004 (0.1623)\tPrec@1 97.656 (94.454)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [50][140/390]\tTime 0.056 (0.059)\tData 0.000 (0.005)\tLoss 0.0742 (0.1612)\tPrec@1 96.094 (94.476)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [50][150/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.1361 (0.1611)\tPrec@1 95.312 (94.474)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [50][160/390]\tTime 0.057 (0.058)\tData 0.007 (0.005)\tLoss 0.2299 (0.1624)\tPrec@1 92.188 (94.395)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [50][170/390]\tTime 0.068 (0.058)\tData 0.007 (0.005)\tLoss 0.1402 (0.1653)\tPrec@1 95.312 (94.303)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [50][180/390]\tTime 0.056 (0.058)\tData 0.006 (0.005)\tLoss 0.2354 (0.1658)\tPrec@1 92.188 (94.302)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [50][190/390]\tTime 0.062 (0.058)\tData 0.007 (0.005)\tLoss 0.3106 (0.1661)\tPrec@1 89.062 (94.274)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [50][200/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1516 (0.1661)\tPrec@1 93.750 (94.240)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [50][210/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.1592 (0.1666)\tPrec@1 92.969 (94.191)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [50][220/390]\tTime 0.071 (0.058)\tData 0.014 (0.005)\tLoss 0.1139 (0.1677)\tPrec@1 96.875 (94.167)\tPrec@5 100.000 (99.965)\t\n",
            "TRAINING - Epoch: [50][230/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2306 (0.1682)\tPrec@1 92.188 (94.156)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [50][240/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.2051 (0.1691)\tPrec@1 93.750 (94.145)\tPrec@5 99.219 (99.958)\t\n",
            "TRAINING - Epoch: [50][250/390]\tTime 0.053 (0.057)\tData 0.000 (0.005)\tLoss 0.1454 (0.1690)\tPrec@1 95.312 (94.127)\tPrec@5 100.000 (99.960)\t\n",
            "TRAINING - Epoch: [50][260/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1441 (0.1697)\tPrec@1 95.312 (94.103)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [50][270/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1623 (0.1711)\tPrec@1 95.312 (94.038)\tPrec@5 99.219 (99.954)\t\n",
            "TRAINING - Epoch: [50][280/390]\tTime 0.069 (0.057)\tData 0.012 (0.004)\tLoss 0.1917 (0.1707)\tPrec@1 90.625 (94.059)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [50][290/390]\tTime 0.062 (0.057)\tData 0.007 (0.004)\tLoss 0.2277 (0.1708)\tPrec@1 92.188 (94.067)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [50][300/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.1694 (0.1712)\tPrec@1 95.312 (94.056)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [50][310/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2099 (0.1718)\tPrec@1 91.406 (94.036)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [50][320/390]\tTime 0.054 (0.057)\tData 0.007 (0.004)\tLoss 0.1676 (0.1726)\tPrec@1 96.875 (94.027)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [50][330/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.1392 (0.1730)\tPrec@1 97.656 (94.014)\tPrec@5 99.219 (99.939)\t\n",
            "TRAINING - Epoch: [50][340/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.1850 (0.1730)\tPrec@1 92.969 (94.009)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [50][350/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.1436 (0.1734)\tPrec@1 96.094 (93.986)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [50][360/390]\tTime 0.070 (0.057)\tData 0.007 (0.004)\tLoss 0.2180 (0.1742)\tPrec@1 92.188 (93.964)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [50][370/390]\tTime 0.053 (0.057)\tData 0.005 (0.004)\tLoss 0.1743 (0.1742)\tPrec@1 92.188 (93.969)\tPrec@5 99.219 (99.939)\t\n",
            "TRAINING - Epoch: [50][380/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.2440 (0.1746)\tPrec@1 92.969 (93.961)\tPrec@5 100.000 (99.941)\t\n",
            "TRAINING - Epoch: [50][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.2127 (0.1745)\tPrec@1 92.969 (93.968)\tPrec@5 100.000 (99.940)\t\n",
            "EVALUATING - Epoch: [50][0/79]\tTime 0.273 (0.273)\tData 0.236 (0.236)\tLoss 0.3764 (0.3764)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [50][10/79]\tTime 0.027 (0.056)\tData 0.001 (0.024)\tLoss 0.4686 (0.4128)\tPrec@1 84.375 (87.145)\tPrec@5 99.219 (99.574)\t\n",
            "EVALUATING - Epoch: [50][20/79]\tTime 0.044 (0.045)\tData 0.001 (0.014)\tLoss 0.5094 (0.4560)\tPrec@1 82.812 (86.533)\tPrec@5 99.219 (99.368)\t\n",
            "EVALUATING - Epoch: [50][30/79]\tTime 0.024 (0.040)\tData 0.002 (0.011)\tLoss 0.4119 (0.4624)\tPrec@1 85.156 (86.265)\tPrec@5 100.000 (99.420)\t\n",
            "EVALUATING - Epoch: [50][40/79]\tTime 0.043 (0.037)\tData 0.009 (0.009)\tLoss 0.5064 (0.4595)\tPrec@1 84.375 (86.376)\tPrec@5 98.438 (99.390)\t\n",
            "EVALUATING - Epoch: [50][50/79]\tTime 0.032 (0.036)\tData 0.007 (0.008)\tLoss 0.5539 (0.4646)\tPrec@1 83.594 (86.229)\tPrec@5 100.000 (99.433)\t\n",
            "EVALUATING - Epoch: [50][60/79]\tTime 0.043 (0.035)\tData 0.000 (0.007)\tLoss 0.4140 (0.4692)\tPrec@1 86.719 (86.168)\tPrec@5 99.219 (99.385)\t\n",
            "EVALUATING - Epoch: [50][70/79]\tTime 0.026 (0.034)\tData 0.000 (0.007)\tLoss 0.2918 (0.4669)\tPrec@1 89.062 (86.268)\tPrec@5 100.000 (99.406)\t\n",
            "EVALUATING - Epoch: [50][78/79]\tTime 0.006 (0.032)\tData 0.000 (0.006)\tLoss 0.7633 (0.4630)\tPrec@1 81.250 (86.350)\tPrec@5 100.000 (99.430)\t\n",
            "\n",
            "Results - Epoch: 51\n",
            "Training Loss 0.1745 \tTraining Prec@1 93.968 \tTraining Prec@5 99.940 \tValidation Loss 0.4630 \tValidation Prec@1 86.350 \tValidation Prec@5 99.430 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 52\n",
            "\n",
            "TRAINING - Epoch: [51][0/390]\tTime 0.351 (0.351)\tData 0.257 (0.257)\tLoss 0.1871 (0.1871)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [51][10/390]\tTime 0.056 (0.092)\tData 0.000 (0.027)\tLoss 0.1690 (0.1618)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [51][20/390]\tTime 0.059 (0.076)\tData 0.007 (0.016)\tLoss 0.1653 (0.1550)\tPrec@1 92.969 (94.159)\tPrec@5 100.000 (99.851)\t\n",
            "TRAINING - Epoch: [51][30/390]\tTime 0.074 (0.070)\tData 0.011 (0.012)\tLoss 0.1137 (0.1501)\tPrec@1 95.312 (94.556)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [51][40/390]\tTime 0.063 (0.067)\tData 0.012 (0.009)\tLoss 0.1405 (0.1537)\tPrec@1 94.531 (94.474)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [51][50/390]\tTime 0.055 (0.064)\tData 0.009 (0.008)\tLoss 0.0808 (0.1551)\tPrec@1 96.094 (94.455)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [51][60/390]\tTime 0.058 (0.063)\tData 0.001 (0.007)\tLoss 0.1209 (0.1546)\tPrec@1 95.312 (94.531)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [51][70/390]\tTime 0.061 (0.062)\tData 0.006 (0.007)\tLoss 0.1133 (0.1527)\tPrec@1 94.531 (94.597)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [51][80/390]\tTime 0.058 (0.061)\tData 0.007 (0.006)\tLoss 0.1127 (0.1520)\tPrec@1 97.656 (94.686)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [51][90/390]\tTime 0.077 (0.061)\tData 0.007 (0.006)\tLoss 0.1035 (0.1518)\tPrec@1 95.312 (94.643)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [51][100/390]\tTime 0.053 (0.060)\tData 0.007 (0.006)\tLoss 0.1282 (0.1524)\tPrec@1 95.312 (94.647)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [51][110/390]\tTime 0.054 (0.060)\tData 0.000 (0.006)\tLoss 0.1328 (0.1561)\tPrec@1 95.312 (94.482)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [51][120/390]\tTime 0.077 (0.060)\tData 0.007 (0.005)\tLoss 0.2341 (0.1570)\tPrec@1 91.406 (94.434)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [51][130/390]\tTime 0.053 (0.059)\tData 0.000 (0.005)\tLoss 0.0843 (0.1603)\tPrec@1 96.875 (94.358)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [51][140/390]\tTime 0.057 (0.059)\tData 0.000 (0.005)\tLoss 0.0843 (0.1625)\tPrec@1 96.875 (94.299)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [51][150/390]\tTime 0.065 (0.059)\tData 0.012 (0.005)\tLoss 0.1872 (0.1635)\tPrec@1 94.531 (94.236)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [51][160/390]\tTime 0.054 (0.059)\tData 0.008 (0.005)\tLoss 0.2376 (0.1642)\tPrec@1 90.625 (94.196)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [51][170/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.1231 (0.1663)\tPrec@1 96.094 (94.143)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [51][180/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.2107 (0.1657)\tPrec@1 95.312 (94.190)\tPrec@5 100.000 (99.918)\t\n",
            "TRAINING - Epoch: [51][190/390]\tTime 0.053 (0.058)\tData 0.006 (0.005)\tLoss 0.1849 (0.1649)\tPrec@1 92.188 (94.224)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [51][200/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.1468 (0.1651)\tPrec@1 96.875 (94.236)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [51][210/390]\tTime 0.069 (0.058)\tData 0.007 (0.005)\tLoss 0.2057 (0.1647)\tPrec@1 93.750 (94.250)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [51][220/390]\tTime 0.064 (0.058)\tData 0.009 (0.005)\tLoss 0.1016 (0.1657)\tPrec@1 94.531 (94.213)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [51][230/390]\tTime 0.050 (0.058)\tData 0.000 (0.004)\tLoss 0.1313 (0.1663)\tPrec@1 94.531 (94.176)\tPrec@5 100.000 (99.932)\t\n",
            "TRAINING - Epoch: [51][240/390]\tTime 0.055 (0.058)\tData 0.007 (0.004)\tLoss 0.1207 (0.1667)\tPrec@1 95.312 (94.152)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [51][250/390]\tTime 0.050 (0.058)\tData 0.000 (0.004)\tLoss 0.1224 (0.1672)\tPrec@1 96.875 (94.139)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [51][260/390]\tTime 0.059 (0.058)\tData 0.007 (0.004)\tLoss 0.1488 (0.1677)\tPrec@1 93.750 (94.106)\tPrec@5 100.000 (99.925)\t\n",
            "TRAINING - Epoch: [51][270/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.1660 (0.1680)\tPrec@1 94.531 (94.105)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [51][280/390]\tTime 0.058 (0.057)\tData 0.007 (0.004)\tLoss 0.2937 (0.1697)\tPrec@1 89.844 (94.036)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [51][290/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.1720 (0.1697)\tPrec@1 94.531 (94.032)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [51][300/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2436 (0.1699)\tPrec@1 93.750 (94.046)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [51][310/390]\tTime 0.053 (0.057)\tData 0.006 (0.004)\tLoss 0.1258 (0.1701)\tPrec@1 96.094 (94.051)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [51][320/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.1225 (0.1706)\tPrec@1 96.094 (94.032)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [51][330/390]\tTime 0.062 (0.057)\tData 0.006 (0.004)\tLoss 0.3403 (0.1710)\tPrec@1 92.969 (94.017)\tPrec@5 100.000 (99.920)\t\n",
            "TRAINING - Epoch: [51][340/390]\tTime 0.056 (0.057)\tData 0.000 (0.004)\tLoss 0.2413 (0.1720)\tPrec@1 92.188 (93.972)\tPrec@5 99.219 (99.918)\t\n",
            "TRAINING - Epoch: [51][350/390]\tTime 0.054 (0.057)\tData 0.007 (0.004)\tLoss 0.1789 (0.1720)\tPrec@1 94.531 (93.970)\tPrec@5 100.000 (99.920)\t\n",
            "TRAINING - Epoch: [51][360/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.1995 (0.1725)\tPrec@1 92.969 (93.964)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [51][370/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.1239 (0.1731)\tPrec@1 96.094 (93.937)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [51][380/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2281 (0.1733)\tPrec@1 92.188 (93.924)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [51][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.1380 (0.1740)\tPrec@1 92.969 (93.906)\tPrec@5 100.000 (99.920)\t\n",
            "EVALUATING - Epoch: [51][0/79]\tTime 0.223 (0.223)\tData 0.178 (0.178)\tLoss 0.5047 (0.5047)\tPrec@1 86.719 (86.719)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [51][10/79]\tTime 0.028 (0.057)\tData 0.005 (0.023)\tLoss 0.3675 (0.4073)\tPrec@1 89.062 (87.926)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [51][20/79]\tTime 0.038 (0.044)\tData 0.000 (0.016)\tLoss 0.4694 (0.4435)\tPrec@1 86.719 (86.905)\tPrec@5 100.000 (99.554)\t\n",
            "EVALUATING - Epoch: [51][30/79]\tTime 0.036 (0.040)\tData 0.000 (0.012)\tLoss 0.4146 (0.4411)\tPrec@1 92.188 (87.097)\tPrec@5 100.000 (99.420)\t\n",
            "EVALUATING - Epoch: [51][40/79]\tTime 0.047 (0.037)\tData 0.005 (0.010)\tLoss 0.5623 (0.4444)\tPrec@1 81.250 (86.966)\tPrec@5 100.000 (99.486)\t\n",
            "EVALUATING - Epoch: [51][50/79]\tTime 0.046 (0.036)\tData 0.010 (0.009)\tLoss 0.4289 (0.4318)\tPrec@1 88.281 (87.347)\tPrec@5 99.219 (99.540)\t\n",
            "EVALUATING - Epoch: [51][60/79]\tTime 0.030 (0.035)\tData 0.000 (0.009)\tLoss 0.3594 (0.4315)\tPrec@1 87.500 (87.423)\tPrec@5 100.000 (99.565)\t\n",
            "EVALUATING - Epoch: [51][70/79]\tTime 0.043 (0.034)\tData 0.010 (0.008)\tLoss 0.2821 (0.4348)\tPrec@1 92.188 (87.313)\tPrec@5 100.000 (99.593)\t\n",
            "EVALUATING - Epoch: [51][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.4708 (0.4360)\tPrec@1 87.500 (87.270)\tPrec@5 100.000 (99.600)\t\n",
            "\n",
            "Results - Epoch: 52\n",
            "Training Loss 0.1740 \tTraining Prec@1 93.906 \tTraining Prec@5 99.920 \tValidation Loss 0.4360 \tValidation Prec@1 87.270 \tValidation Prec@5 99.600 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 53\n",
            "\n",
            "TRAINING - Epoch: [52][0/390]\tTime 0.264 (0.264)\tData 0.177 (0.177)\tLoss 0.1301 (0.1301)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [52][10/390]\tTime 0.047 (0.086)\tData 0.000 (0.023)\tLoss 0.1872 (0.1757)\tPrec@1 94.531 (94.318)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [52][20/390]\tTime 0.051 (0.072)\tData 0.000 (0.013)\tLoss 0.2061 (0.1744)\tPrec@1 91.406 (94.085)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [52][30/390]\tTime 0.057 (0.067)\tData 0.007 (0.010)\tLoss 0.1670 (0.1754)\tPrec@1 94.531 (94.002)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [52][40/390]\tTime 0.047 (0.064)\tData 0.000 (0.009)\tLoss 0.1669 (0.1729)\tPrec@1 92.969 (94.093)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [52][50/390]\tTime 0.050 (0.063)\tData 0.000 (0.008)\tLoss 0.1165 (0.1707)\tPrec@1 95.312 (94.072)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [52][60/390]\tTime 0.065 (0.062)\tData 0.000 (0.007)\tLoss 0.1988 (0.1690)\tPrec@1 93.750 (94.288)\tPrec@5 100.000 (99.898)\t\n",
            "TRAINING - Epoch: [52][70/390]\tTime 0.049 (0.061)\tData 0.000 (0.006)\tLoss 0.2536 (0.1670)\tPrec@1 91.406 (94.267)\tPrec@5 99.219 (99.879)\t\n",
            "TRAINING - Epoch: [52][80/390]\tTime 0.068 (0.060)\tData 0.007 (0.006)\tLoss 0.1742 (0.1658)\tPrec@1 95.312 (94.329)\tPrec@5 100.000 (99.884)\t\n",
            "TRAINING - Epoch: [52][90/390]\tTime 0.055 (0.060)\tData 0.007 (0.006)\tLoss 0.1653 (0.1649)\tPrec@1 94.531 (94.342)\tPrec@5 100.000 (99.897)\t\n",
            "TRAINING - Epoch: [52][100/390]\tTime 0.056 (0.060)\tData 0.007 (0.006)\tLoss 0.1484 (0.1648)\tPrec@1 93.750 (94.245)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [52][110/390]\tTime 0.046 (0.059)\tData 0.000 (0.006)\tLoss 0.1598 (0.1639)\tPrec@1 93.750 (94.306)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [52][120/390]\tTime 0.071 (0.059)\tData 0.007 (0.005)\tLoss 0.0962 (0.1621)\tPrec@1 96.094 (94.318)\tPrec@5 100.000 (99.910)\t\n",
            "TRAINING - Epoch: [52][130/390]\tTime 0.054 (0.059)\tData 0.000 (0.005)\tLoss 0.1270 (0.1620)\tPrec@1 95.312 (94.352)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [52][140/390]\tTime 0.065 (0.059)\tData 0.011 (0.005)\tLoss 0.0971 (0.1616)\tPrec@1 96.875 (94.326)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [52][150/390]\tTime 0.056 (0.058)\tData 0.000 (0.005)\tLoss 0.1873 (0.1625)\tPrec@1 93.750 (94.283)\tPrec@5 100.000 (99.902)\t\n",
            "TRAINING - Epoch: [52][160/390]\tTime 0.049 (0.059)\tData 0.000 (0.005)\tLoss 0.2552 (0.1638)\tPrec@1 89.062 (94.221)\tPrec@5 100.000 (99.903)\t\n",
            "TRAINING - Epoch: [52][170/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1375 (0.1660)\tPrec@1 94.531 (94.115)\tPrec@5 100.000 (99.890)\t\n",
            "TRAINING - Epoch: [52][180/390]\tTime 0.060 (0.058)\tData 0.007 (0.005)\tLoss 0.2036 (0.1670)\tPrec@1 93.750 (94.095)\tPrec@5 100.000 (99.892)\t\n",
            "TRAINING - Epoch: [52][190/390]\tTime 0.064 (0.058)\tData 0.013 (0.005)\tLoss 0.1291 (0.1664)\tPrec@1 93.750 (94.110)\tPrec@5 100.000 (99.898)\t\n",
            "TRAINING - Epoch: [52][200/390]\tTime 0.061 (0.058)\tData 0.012 (0.005)\tLoss 0.1469 (0.1666)\tPrec@1 92.188 (94.119)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [52][210/390]\tTime 0.063 (0.058)\tData 0.002 (0.005)\tLoss 0.1407 (0.1657)\tPrec@1 93.750 (94.113)\tPrec@5 100.000 (99.900)\t\n",
            "TRAINING - Epoch: [52][220/390]\tTime 0.046 (0.058)\tData 0.000 (0.005)\tLoss 0.1987 (0.1665)\tPrec@1 91.406 (94.079)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [52][230/390]\tTime 0.072 (0.058)\tData 0.003 (0.005)\tLoss 0.2000 (0.1667)\tPrec@1 92.969 (94.081)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [52][240/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2338 (0.1673)\tPrec@1 90.625 (94.061)\tPrec@5 100.000 (99.906)\t\n",
            "TRAINING - Epoch: [52][250/390]\tTime 0.056 (0.057)\tData 0.003 (0.004)\tLoss 0.1966 (0.1683)\tPrec@1 94.531 (94.008)\tPrec@5 100.000 (99.910)\t\n",
            "TRAINING - Epoch: [52][260/390]\tTime 0.052 (0.057)\tData 0.004 (0.004)\tLoss 0.2558 (0.1691)\tPrec@1 93.750 (93.977)\tPrec@5 99.219 (99.910)\t\n",
            "TRAINING - Epoch: [52][270/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.1424 (0.1692)\tPrec@1 96.094 (94.001)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [52][280/390]\tTime 0.057 (0.057)\tData 0.010 (0.004)\tLoss 0.2185 (0.1689)\tPrec@1 92.188 (94.017)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [52][290/390]\tTime 0.065 (0.057)\tData 0.013 (0.004)\tLoss 0.1646 (0.1688)\tPrec@1 93.750 (94.027)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [52][300/390]\tTime 0.055 (0.057)\tData 0.006 (0.004)\tLoss 0.1196 (0.1686)\tPrec@1 96.094 (94.036)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [52][310/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.1714 (0.1688)\tPrec@1 95.312 (94.016)\tPrec@5 100.000 (99.910)\t\n",
            "TRAINING - Epoch: [52][320/390]\tTime 0.059 (0.057)\tData 0.010 (0.004)\tLoss 0.1531 (0.1687)\tPrec@1 93.750 (94.020)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [52][330/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2055 (0.1689)\tPrec@1 92.969 (94.003)\tPrec@5 100.000 (99.915)\t\n",
            "TRAINING - Epoch: [52][340/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1354 (0.1694)\tPrec@1 96.094 (93.988)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [52][350/390]\tTime 0.065 (0.057)\tData 0.009 (0.004)\tLoss 0.1536 (0.1697)\tPrec@1 92.969 (93.959)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [52][360/390]\tTime 0.059 (0.057)\tData 0.008 (0.004)\tLoss 0.2145 (0.1700)\tPrec@1 92.188 (93.932)\tPrec@5 100.000 (99.911)\t\n",
            "TRAINING - Epoch: [52][370/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2076 (0.1706)\tPrec@1 90.625 (93.904)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [52][380/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2546 (0.1712)\tPrec@1 93.750 (93.885)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [52][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.2032 (0.1720)\tPrec@1 92.188 (93.858)\tPrec@5 100.000 (99.910)\t\n",
            "EVALUATING - Epoch: [52][0/79]\tTime 0.211 (0.211)\tData 0.170 (0.170)\tLoss 0.4198 (0.4198)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [52][10/79]\tTime 0.035 (0.057)\tData 0.007 (0.026)\tLoss 0.3989 (0.4774)\tPrec@1 85.938 (85.795)\tPrec@5 98.438 (99.432)\t\n",
            "EVALUATING - Epoch: [52][20/79]\tTime 0.032 (0.043)\tData 0.001 (0.015)\tLoss 0.5119 (0.5040)\tPrec@1 85.938 (85.640)\tPrec@5 99.219 (99.293)\t\n",
            "EVALUATING - Epoch: [52][30/79]\tTime 0.027 (0.041)\tData 0.000 (0.012)\tLoss 0.3615 (0.5137)\tPrec@1 87.500 (85.585)\tPrec@5 100.000 (99.269)\t\n",
            "EVALUATING - Epoch: [52][40/79]\tTime 0.038 (0.038)\tData 0.007 (0.010)\tLoss 0.5570 (0.5053)\tPrec@1 83.594 (85.842)\tPrec@5 98.438 (99.295)\t\n",
            "EVALUATING - Epoch: [52][50/79]\tTime 0.023 (0.035)\tData 0.007 (0.009)\tLoss 0.4726 (0.4903)\tPrec@1 85.156 (86.244)\tPrec@5 99.219 (99.357)\t\n",
            "EVALUATING - Epoch: [52][60/79]\tTime 0.015 (0.035)\tData 0.000 (0.008)\tLoss 0.4434 (0.4899)\tPrec@1 88.281 (86.386)\tPrec@5 100.000 (99.347)\t\n",
            "EVALUATING - Epoch: [52][70/79]\tTime 0.020 (0.034)\tData 0.006 (0.007)\tLoss 0.3836 (0.4888)\tPrec@1 86.719 (86.268)\tPrec@5 100.000 (99.351)\t\n",
            "EVALUATING - Epoch: [52][78/79]\tTime 0.006 (0.032)\tData 0.000 (0.007)\tLoss 0.5038 (0.4876)\tPrec@1 93.750 (86.330)\tPrec@5 100.000 (99.380)\t\n",
            "\n",
            "Results - Epoch: 53\n",
            "Training Loss 0.1720 \tTraining Prec@1 93.858 \tTraining Prec@5 99.910 \tValidation Loss 0.4876 \tValidation Prec@1 86.330 \tValidation Prec@5 99.380 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 54\n",
            "\n",
            "TRAINING - Epoch: [53][0/390]\tTime 0.383 (0.383)\tData 0.282 (0.282)\tLoss 0.1983 (0.1983)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [53][10/390]\tTime 0.067 (0.090)\tData 0.011 (0.030)\tLoss 0.1187 (0.1817)\tPrec@1 94.531 (93.608)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [53][20/390]\tTime 0.066 (0.075)\tData 0.007 (0.018)\tLoss 0.0996 (0.1751)\tPrec@1 96.875 (93.936)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [53][30/390]\tTime 0.059 (0.069)\tData 0.007 (0.013)\tLoss 0.1166 (0.1728)\tPrec@1 96.875 (94.002)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [53][40/390]\tTime 0.055 (0.066)\tData 0.000 (0.011)\tLoss 0.1407 (0.1703)\tPrec@1 96.094 (94.093)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [53][50/390]\tTime 0.053 (0.064)\tData 0.005 (0.010)\tLoss 0.2353 (0.1707)\tPrec@1 92.188 (94.148)\tPrec@5 99.219 (99.923)\t\n",
            "TRAINING - Epoch: [53][60/390]\tTime 0.051 (0.062)\tData 0.000 (0.008)\tLoss 0.1289 (0.1648)\tPrec@1 93.750 (94.326)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [53][70/390]\tTime 0.075 (0.062)\tData 0.019 (0.008)\tLoss 0.1682 (0.1667)\tPrec@1 92.969 (94.190)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [53][80/390]\tTime 0.054 (0.061)\tData 0.006 (0.008)\tLoss 0.1816 (0.1650)\tPrec@1 91.406 (94.194)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [53][90/390]\tTime 0.046 (0.060)\tData 0.000 (0.007)\tLoss 0.1076 (0.1630)\tPrec@1 96.875 (94.222)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [53][100/390]\tTime 0.051 (0.060)\tData 0.003 (0.007)\tLoss 0.1897 (0.1628)\tPrec@1 91.406 (94.284)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [53][110/390]\tTime 0.050 (0.060)\tData 0.000 (0.007)\tLoss 0.3137 (0.1641)\tPrec@1 89.844 (94.250)\tPrec@5 99.219 (99.930)\t\n",
            "TRAINING - Epoch: [53][120/390]\tTime 0.051 (0.059)\tData 0.000 (0.006)\tLoss 0.1973 (0.1645)\tPrec@1 92.188 (94.196)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [53][130/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.1272 (0.1640)\tPrec@1 95.312 (94.185)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [53][140/390]\tTime 0.060 (0.059)\tData 0.000 (0.006)\tLoss 0.1173 (0.1649)\tPrec@1 95.312 (94.193)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [53][150/390]\tTime 0.069 (0.059)\tData 0.006 (0.005)\tLoss 0.1933 (0.1653)\tPrec@1 92.969 (94.190)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [53][160/390]\tTime 0.071 (0.058)\tData 0.004 (0.005)\tLoss 0.1187 (0.1649)\tPrec@1 96.094 (94.235)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [53][170/390]\tTime 0.054 (0.058)\tData 0.000 (0.005)\tLoss 0.2208 (0.1653)\tPrec@1 89.844 (94.193)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [53][180/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1709 (0.1657)\tPrec@1 92.969 (94.151)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [53][190/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1582 (0.1672)\tPrec@1 93.750 (94.110)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [53][200/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.2292 (0.1669)\tPrec@1 91.406 (94.115)\tPrec@5 99.219 (99.922)\t\n",
            "TRAINING - Epoch: [53][210/390]\tTime 0.055 (0.058)\tData 0.007 (0.005)\tLoss 0.3016 (0.1683)\tPrec@1 91.406 (94.043)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [53][220/390]\tTime 0.060 (0.058)\tData 0.007 (0.005)\tLoss 0.2003 (0.1690)\tPrec@1 91.406 (94.029)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [53][230/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2365 (0.1695)\tPrec@1 91.406 (94.014)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [53][240/390]\tTime 0.071 (0.058)\tData 0.017 (0.005)\tLoss 0.1762 (0.1716)\tPrec@1 93.750 (93.957)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [53][250/390]\tTime 0.049 (0.057)\tData 0.002 (0.005)\tLoss 0.0765 (0.1714)\tPrec@1 97.656 (93.977)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [53][260/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.1209 (0.1716)\tPrec@1 96.875 (93.974)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [53][270/390]\tTime 0.070 (0.057)\tData 0.011 (0.005)\tLoss 0.1252 (0.1724)\tPrec@1 96.094 (93.952)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [53][280/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.1758 (0.1710)\tPrec@1 92.969 (93.992)\tPrec@5 100.000 (99.925)\t\n",
            "TRAINING - Epoch: [53][290/390]\tTime 0.055 (0.057)\tData 0.000 (0.005)\tLoss 0.1717 (0.1719)\tPrec@1 92.188 (93.962)\tPrec@5 100.000 (99.925)\t\n",
            "TRAINING - Epoch: [53][300/390]\tTime 0.056 (0.057)\tData 0.007 (0.005)\tLoss 0.2071 (0.1720)\tPrec@1 92.969 (93.973)\tPrec@5 100.000 (99.925)\t\n",
            "TRAINING - Epoch: [53][310/390]\tTime 0.066 (0.057)\tData 0.007 (0.005)\tLoss 0.1215 (0.1715)\tPrec@1 95.312 (93.999)\tPrec@5 100.000 (99.925)\t\n",
            "TRAINING - Epoch: [53][320/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.1835 (0.1715)\tPrec@1 92.969 (94.001)\tPrec@5 100.000 (99.925)\t\n",
            "TRAINING - Epoch: [53][330/390]\tTime 0.054 (0.057)\tData 0.006 (0.005)\tLoss 0.1881 (0.1720)\tPrec@1 93.750 (93.977)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [53][340/390]\tTime 0.052 (0.057)\tData 0.001 (0.005)\tLoss 0.2067 (0.1719)\tPrec@1 91.406 (93.975)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [53][350/390]\tTime 0.056 (0.057)\tData 0.009 (0.005)\tLoss 0.1380 (0.1730)\tPrec@1 95.312 (93.926)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [53][360/390]\tTime 0.087 (0.057)\tData 0.007 (0.005)\tLoss 0.1774 (0.1731)\tPrec@1 91.406 (93.919)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [53][370/390]\tTime 0.054 (0.057)\tData 0.008 (0.005)\tLoss 0.1538 (0.1739)\tPrec@1 96.094 (93.889)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [53][380/390]\tTime 0.055 (0.057)\tData 0.007 (0.005)\tLoss 0.1554 (0.1740)\tPrec@1 93.750 (93.861)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [53][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.005)\tLoss 0.2493 (0.1744)\tPrec@1 89.844 (93.836)\tPrec@5 99.219 (99.930)\t\n",
            "EVALUATING - Epoch: [53][0/79]\tTime 0.193 (0.193)\tData 0.162 (0.162)\tLoss 0.2879 (0.2879)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [53][10/79]\tTime 0.022 (0.053)\tData 0.000 (0.021)\tLoss 0.3238 (0.3834)\tPrec@1 89.844 (87.926)\tPrec@5 99.219 (99.503)\t\n",
            "EVALUATING - Epoch: [53][20/79]\tTime 0.041 (0.043)\tData 0.009 (0.014)\tLoss 0.5211 (0.4079)\tPrec@1 88.281 (87.984)\tPrec@5 100.000 (99.442)\t\n",
            "EVALUATING - Epoch: [53][30/79]\tTime 0.021 (0.039)\tData 0.001 (0.012)\tLoss 0.3070 (0.4108)\tPrec@1 91.406 (87.979)\tPrec@5 100.000 (99.446)\t\n",
            "EVALUATING - Epoch: [53][40/79]\tTime 0.028 (0.037)\tData 0.002 (0.011)\tLoss 0.4721 (0.4080)\tPrec@1 84.375 (87.900)\tPrec@5 99.219 (99.466)\t\n",
            "EVALUATING - Epoch: [53][50/79]\tTime 0.038 (0.035)\tData 0.008 (0.010)\tLoss 0.3067 (0.4072)\tPrec@1 87.500 (87.898)\tPrec@5 100.000 (99.540)\t\n",
            "EVALUATING - Epoch: [53][60/79]\tTime 0.027 (0.034)\tData 0.001 (0.009)\tLoss 0.3304 (0.4052)\tPrec@1 91.406 (87.807)\tPrec@5 100.000 (99.526)\t\n",
            "EVALUATING - Epoch: [53][70/79]\tTime 0.026 (0.034)\tData 0.001 (0.008)\tLoss 0.2770 (0.4032)\tPrec@1 92.969 (87.676)\tPrec@5 100.000 (99.582)\t\n",
            "EVALUATING - Epoch: [53][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.4230 (0.4021)\tPrec@1 87.500 (87.800)\tPrec@5 100.000 (99.560)\t\n",
            "\n",
            "Results - Epoch: 54\n",
            "Training Loss 0.1744 \tTraining Prec@1 93.836 \tTraining Prec@5 99.930 \tValidation Loss 0.4021 \tValidation Prec@1 87.800 \tValidation Prec@5 99.560 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 55\n",
            "\n",
            "TRAINING - Epoch: [54][0/390]\tTime 0.325 (0.325)\tData 0.189 (0.189)\tLoss 0.1495 (0.1495)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [54][10/390]\tTime 0.066 (0.088)\tData 0.006 (0.019)\tLoss 0.1016 (0.1493)\tPrec@1 96.875 (94.815)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [54][20/390]\tTime 0.057 (0.074)\tData 0.011 (0.012)\tLoss 0.0401 (0.1415)\tPrec@1 99.219 (95.126)\tPrec@5 100.000 (99.888)\t\n",
            "TRAINING - Epoch: [54][30/390]\tTime 0.054 (0.068)\tData 0.006 (0.010)\tLoss 0.2007 (0.1437)\tPrec@1 94.531 (95.086)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [54][40/390]\tTime 0.055 (0.065)\tData 0.007 (0.009)\tLoss 0.1415 (0.1450)\tPrec@1 95.312 (95.084)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [54][50/390]\tTime 0.049 (0.063)\tData 0.000 (0.007)\tLoss 0.2137 (0.1475)\tPrec@1 91.406 (94.991)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [54][60/390]\tTime 0.060 (0.063)\tData 0.007 (0.007)\tLoss 0.1370 (0.1519)\tPrec@1 96.875 (94.787)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [54][70/390]\tTime 0.050 (0.062)\tData 0.000 (0.006)\tLoss 0.1399 (0.1529)\tPrec@1 94.531 (94.652)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [54][80/390]\tTime 0.050 (0.061)\tData 0.000 (0.006)\tLoss 0.1474 (0.1547)\tPrec@1 96.094 (94.637)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [54][90/390]\tTime 0.082 (0.061)\tData 0.007 (0.005)\tLoss 0.1120 (0.1554)\tPrec@1 94.531 (94.626)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [54][100/390]\tTime 0.053 (0.060)\tData 0.000 (0.005)\tLoss 0.1355 (0.1551)\tPrec@1 95.312 (94.647)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [54][110/390]\tTime 0.050 (0.060)\tData 0.000 (0.005)\tLoss 0.1100 (0.1557)\tPrec@1 95.312 (94.602)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [54][120/390]\tTime 0.048 (0.060)\tData 0.000 (0.005)\tLoss 0.0887 (0.1565)\tPrec@1 96.875 (94.583)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [54][130/390]\tTime 0.057 (0.060)\tData 0.007 (0.005)\tLoss 0.1401 (0.1584)\tPrec@1 95.312 (94.495)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [54][140/390]\tTime 0.053 (0.059)\tData 0.000 (0.005)\tLoss 0.1472 (0.1601)\tPrec@1 94.531 (94.437)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [54][150/390]\tTime 0.064 (0.059)\tData 0.009 (0.005)\tLoss 0.2029 (0.1608)\tPrec@1 94.531 (94.417)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [54][160/390]\tTime 0.052 (0.059)\tData 0.000 (0.005)\tLoss 0.1053 (0.1605)\tPrec@1 96.094 (94.429)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [54][170/390]\tTime 0.072 (0.059)\tData 0.013 (0.005)\tLoss 0.2100 (0.1606)\tPrec@1 90.625 (94.458)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [54][180/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1944 (0.1615)\tPrec@1 93.750 (94.436)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [54][190/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.1162 (0.1611)\tPrec@1 95.312 (94.417)\tPrec@5 99.219 (99.930)\t\n",
            "TRAINING - Epoch: [54][200/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.2092 (0.1615)\tPrec@1 93.750 (94.407)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [54][210/390]\tTime 0.061 (0.058)\tData 0.008 (0.004)\tLoss 0.1979 (0.1620)\tPrec@1 92.188 (94.361)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [54][220/390]\tTime 0.060 (0.058)\tData 0.007 (0.004)\tLoss 0.1814 (0.1625)\tPrec@1 92.969 (94.351)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [54][230/390]\tTime 0.050 (0.058)\tData 0.000 (0.004)\tLoss 0.2142 (0.1647)\tPrec@1 92.969 (94.271)\tPrec@5 100.000 (99.932)\t\n",
            "TRAINING - Epoch: [54][240/390]\tTime 0.057 (0.058)\tData 0.009 (0.004)\tLoss 0.1713 (0.1654)\tPrec@1 93.750 (94.239)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [54][250/390]\tTime 0.055 (0.058)\tData 0.007 (0.004)\tLoss 0.3001 (0.1664)\tPrec@1 90.625 (94.192)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [54][260/390]\tTime 0.047 (0.058)\tData 0.000 (0.004)\tLoss 0.1850 (0.1682)\tPrec@1 92.969 (94.127)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [54][270/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2241 (0.1690)\tPrec@1 92.969 (94.110)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [54][280/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2339 (0.1704)\tPrec@1 92.969 (94.061)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [54][290/390]\tTime 0.061 (0.057)\tData 0.009 (0.004)\tLoss 0.1987 (0.1714)\tPrec@1 92.969 (94.018)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [54][300/390]\tTime 0.060 (0.057)\tData 0.006 (0.004)\tLoss 0.1452 (0.1714)\tPrec@1 94.531 (94.017)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [54][310/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1345 (0.1708)\tPrec@1 95.312 (94.019)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [54][320/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2210 (0.1712)\tPrec@1 92.188 (93.976)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [54][330/390]\tTime 0.058 (0.057)\tData 0.007 (0.004)\tLoss 0.2308 (0.1715)\tPrec@1 92.188 (93.979)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [54][340/390]\tTime 0.055 (0.057)\tData 0.005 (0.004)\tLoss 0.1932 (0.1720)\tPrec@1 93.750 (93.975)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [54][350/390]\tTime 0.067 (0.057)\tData 0.000 (0.004)\tLoss 0.1624 (0.1721)\tPrec@1 96.094 (93.953)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [54][360/390]\tTime 0.049 (0.057)\tData 0.001 (0.004)\tLoss 0.0979 (0.1720)\tPrec@1 96.875 (93.960)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [54][370/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1339 (0.1719)\tPrec@1 96.094 (93.958)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [54][380/390]\tTime 0.052 (0.057)\tData 0.004 (0.004)\tLoss 0.0871 (0.1714)\tPrec@1 96.094 (93.978)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [54][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1108 (0.1714)\tPrec@1 95.312 (93.962)\tPrec@5 100.000 (99.930)\t\n",
            "EVALUATING - Epoch: [54][0/79]\tTime 0.278 (0.278)\tData 0.246 (0.246)\tLoss 0.3277 (0.3277)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [54][10/79]\tTime 0.043 (0.054)\tData 0.000 (0.027)\tLoss 0.3850 (0.3999)\tPrec@1 88.281 (87.784)\tPrec@5 99.219 (99.432)\t\n",
            "EVALUATING - Epoch: [54][20/79]\tTime 0.044 (0.042)\tData 0.004 (0.016)\tLoss 0.3942 (0.4080)\tPrec@1 89.062 (87.984)\tPrec@5 97.656 (99.182)\t\n",
            "EVALUATING - Epoch: [54][30/79]\tTime 0.042 (0.038)\tData 0.007 (0.012)\tLoss 0.2441 (0.4140)\tPrec@1 92.188 (88.231)\tPrec@5 100.000 (99.244)\t\n",
            "EVALUATING - Epoch: [54][40/79]\tTime 0.017 (0.036)\tData 0.000 (0.010)\tLoss 0.4061 (0.4109)\tPrec@1 85.938 (88.167)\tPrec@5 100.000 (99.333)\t\n",
            "EVALUATING - Epoch: [54][50/79]\tTime 0.047 (0.035)\tData 0.005 (0.009)\tLoss 0.4260 (0.3980)\tPrec@1 88.281 (88.404)\tPrec@5 100.000 (99.433)\t\n",
            "EVALUATING - Epoch: [54][60/79]\tTime 0.043 (0.035)\tData 0.009 (0.008)\tLoss 0.2943 (0.3944)\tPrec@1 90.625 (88.461)\tPrec@5 100.000 (99.398)\t\n",
            "EVALUATING - Epoch: [54][70/79]\tTime 0.020 (0.034)\tData 0.005 (0.007)\tLoss 0.2781 (0.3922)\tPrec@1 91.406 (88.457)\tPrec@5 100.000 (99.428)\t\n",
            "EVALUATING - Epoch: [54][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.0882 (0.3869)\tPrec@1 93.750 (88.510)\tPrec@5 100.000 (99.460)\t\n",
            "\n",
            "Results - Epoch: 55\n",
            "Training Loss 0.1714 \tTraining Prec@1 93.962 \tTraining Prec@5 99.930 \tValidation Loss 0.3869 \tValidation Prec@1 88.510 \tValidation Prec@5 99.460 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 56\n",
            "\n",
            "TRAINING - Epoch: [55][0/390]\tTime 0.413 (0.413)\tData 0.284 (0.284)\tLoss 0.1753 (0.1753)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [55][10/390]\tTime 0.049 (0.090)\tData 0.002 (0.030)\tLoss 0.1582 (0.1872)\tPrec@1 95.312 (93.750)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [55][20/390]\tTime 0.047 (0.074)\tData 0.000 (0.018)\tLoss 0.2683 (0.1808)\tPrec@1 89.844 (94.048)\tPrec@5 99.219 (99.888)\t\n",
            "TRAINING - Epoch: [55][30/390]\tTime 0.056 (0.068)\tData 0.007 (0.014)\tLoss 0.0950 (0.1671)\tPrec@1 96.875 (94.380)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [55][40/390]\tTime 0.061 (0.065)\tData 0.000 (0.011)\tLoss 0.1211 (0.1662)\tPrec@1 98.438 (94.398)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [55][50/390]\tTime 0.046 (0.064)\tData 0.000 (0.009)\tLoss 0.1903 (0.1641)\tPrec@1 94.531 (94.577)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [55][60/390]\tTime 0.058 (0.063)\tData 0.011 (0.008)\tLoss 0.2610 (0.1668)\tPrec@1 90.625 (94.416)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [55][70/390]\tTime 0.050 (0.062)\tData 0.000 (0.008)\tLoss 0.2093 (0.1654)\tPrec@1 89.844 (94.322)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [55][80/390]\tTime 0.058 (0.061)\tData 0.008 (0.007)\tLoss 0.1127 (0.1640)\tPrec@1 96.094 (94.425)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [55][90/390]\tTime 0.051 (0.061)\tData 0.000 (0.007)\tLoss 0.2346 (0.1628)\tPrec@1 91.406 (94.411)\tPrec@5 100.000 (99.966)\t\n",
            "TRAINING - Epoch: [55][100/390]\tTime 0.065 (0.061)\tData 0.010 (0.007)\tLoss 0.1318 (0.1621)\tPrec@1 95.312 (94.423)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [55][110/390]\tTime 0.058 (0.061)\tData 0.007 (0.006)\tLoss 0.1696 (0.1619)\tPrec@1 96.094 (94.426)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [55][120/390]\tTime 0.050 (0.061)\tData 0.000 (0.006)\tLoss 0.1735 (0.1620)\tPrec@1 93.750 (94.402)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [55][130/390]\tTime 0.050 (0.060)\tData 0.000 (0.006)\tLoss 0.0998 (0.1601)\tPrec@1 96.094 (94.495)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [55][140/390]\tTime 0.049 (0.060)\tData 0.000 (0.006)\tLoss 0.1867 (0.1608)\tPrec@1 93.750 (94.454)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [55][150/390]\tTime 0.057 (0.060)\tData 0.008 (0.005)\tLoss 0.1288 (0.1616)\tPrec@1 94.531 (94.402)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [55][160/390]\tTime 0.054 (0.060)\tData 0.004 (0.005)\tLoss 0.1738 (0.1620)\tPrec@1 92.188 (94.405)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [55][170/390]\tTime 0.057 (0.059)\tData 0.000 (0.005)\tLoss 0.2150 (0.1614)\tPrec@1 93.750 (94.454)\tPrec@5 100.000 (99.941)\t\n",
            "TRAINING - Epoch: [55][180/390]\tTime 0.055 (0.059)\tData 0.007 (0.005)\tLoss 0.2046 (0.1626)\tPrec@1 94.531 (94.462)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [55][190/390]\tTime 0.059 (0.059)\tData 0.007 (0.005)\tLoss 0.1460 (0.1624)\tPrec@1 94.531 (94.466)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [55][200/390]\tTime 0.059 (0.059)\tData 0.010 (0.005)\tLoss 0.2124 (0.1627)\tPrec@1 92.188 (94.454)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [55][210/390]\tTime 0.050 (0.059)\tData 0.000 (0.005)\tLoss 0.0934 (0.1618)\tPrec@1 96.875 (94.479)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [55][220/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.1283 (0.1619)\tPrec@1 93.750 (94.450)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [55][230/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.1318 (0.1619)\tPrec@1 94.531 (94.453)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [55][240/390]\tTime 0.076 (0.058)\tData 0.012 (0.005)\tLoss 0.2098 (0.1625)\tPrec@1 92.188 (94.418)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [55][250/390]\tTime 0.072 (0.059)\tData 0.009 (0.005)\tLoss 0.2468 (0.1633)\tPrec@1 92.969 (94.376)\tPrec@5 100.000 (99.941)\t\n",
            "TRAINING - Epoch: [55][260/390]\tTime 0.060 (0.058)\tData 0.009 (0.005)\tLoss 0.2016 (0.1643)\tPrec@1 94.531 (94.319)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [55][270/390]\tTime 0.063 (0.058)\tData 0.000 (0.005)\tLoss 0.1400 (0.1637)\tPrec@1 93.750 (94.321)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [55][280/390]\tTime 0.047 (0.058)\tData 0.000 (0.004)\tLoss 0.3120 (0.1649)\tPrec@1 91.406 (94.278)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [55][290/390]\tTime 0.053 (0.058)\tData 0.000 (0.004)\tLoss 0.1961 (0.1648)\tPrec@1 92.188 (94.260)\tPrec@5 99.219 (99.936)\t\n",
            "TRAINING - Epoch: [55][300/390]\tTime 0.054 (0.058)\tData 0.002 (0.004)\tLoss 0.1246 (0.1646)\tPrec@1 94.531 (94.264)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [55][310/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.1536 (0.1660)\tPrec@1 92.969 (94.232)\tPrec@5 100.000 (99.932)\t\n",
            "TRAINING - Epoch: [55][320/390]\tTime 0.055 (0.058)\tData 0.000 (0.004)\tLoss 0.2181 (0.1672)\tPrec@1 92.188 (94.169)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [55][330/390]\tTime 0.054 (0.058)\tData 0.000 (0.004)\tLoss 0.2134 (0.1679)\tPrec@1 92.188 (94.130)\tPrec@5 100.000 (99.932)\t\n",
            "TRAINING - Epoch: [55][340/390]\tTime 0.048 (0.058)\tData 0.000 (0.004)\tLoss 0.1836 (0.1686)\tPrec@1 90.625 (94.105)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [55][350/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.2464 (0.1693)\tPrec@1 92.188 (94.073)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [55][360/390]\tTime 0.064 (0.057)\tData 0.000 (0.004)\tLoss 0.1962 (0.1695)\tPrec@1 92.188 (94.068)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [55][370/390]\tTime 0.071 (0.057)\tData 0.004 (0.004)\tLoss 0.2372 (0.1697)\tPrec@1 92.188 (94.066)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [55][380/390]\tTime 0.057 (0.057)\tData 0.009 (0.004)\tLoss 0.2894 (0.1708)\tPrec@1 89.844 (94.043)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [55][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.2015 (0.1712)\tPrec@1 92.188 (94.024)\tPrec@5 100.000 (99.924)\t\n",
            "EVALUATING - Epoch: [55][0/79]\tTime 0.267 (0.267)\tData 0.213 (0.213)\tLoss 0.3689 (0.3689)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [55][10/79]\tTime 0.024 (0.053)\tData 0.005 (0.021)\tLoss 0.3246 (0.3965)\tPrec@1 87.500 (87.287)\tPrec@5 100.000 (99.574)\t\n",
            "EVALUATING - Epoch: [55][20/79]\tTime 0.012 (0.042)\tData 0.000 (0.014)\tLoss 0.4003 (0.4059)\tPrec@1 84.375 (86.868)\tPrec@5 99.219 (99.516)\t\n",
            "EVALUATING - Epoch: [55][30/79]\tTime 0.054 (0.038)\tData 0.000 (0.011)\tLoss 0.3183 (0.4009)\tPrec@1 90.625 (87.097)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [55][40/79]\tTime 0.043 (0.037)\tData 0.003 (0.009)\tLoss 0.3502 (0.3970)\tPrec@1 86.719 (87.081)\tPrec@5 100.000 (99.600)\t\n",
            "EVALUATING - Epoch: [55][50/79]\tTime 0.012 (0.035)\tData 0.000 (0.008)\tLoss 0.4322 (0.3925)\tPrec@1 89.844 (87.301)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [55][60/79]\tTime 0.044 (0.035)\tData 0.002 (0.007)\tLoss 0.4524 (0.3925)\tPrec@1 85.938 (87.449)\tPrec@5 99.219 (99.641)\t\n",
            "EVALUATING - Epoch: [55][70/79]\tTime 0.020 (0.035)\tData 0.006 (0.008)\tLoss 0.3336 (0.3916)\tPrec@1 89.844 (87.522)\tPrec@5 100.000 (99.626)\t\n",
            "EVALUATING - Epoch: [55][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.1381 (0.3910)\tPrec@1 93.750 (87.590)\tPrec@5 100.000 (99.640)\t\n",
            "\n",
            "Results - Epoch: 56\n",
            "Training Loss 0.1712 \tTraining Prec@1 94.024 \tTraining Prec@5 99.924 \tValidation Loss 0.3910 \tValidation Prec@1 87.590 \tValidation Prec@5 99.640 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 57\n",
            "\n",
            "TRAINING - Epoch: [56][0/390]\tTime 0.412 (0.412)\tData 0.303 (0.303)\tLoss 0.1404 (0.1404)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [56][10/390]\tTime 0.048 (0.089)\tData 0.000 (0.032)\tLoss 0.1526 (0.1835)\tPrec@1 94.531 (93.253)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [56][20/390]\tTime 0.056 (0.073)\tData 0.008 (0.018)\tLoss 0.2234 (0.1740)\tPrec@1 90.625 (93.601)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [56][30/390]\tTime 0.052 (0.067)\tData 0.000 (0.013)\tLoss 0.1251 (0.1663)\tPrec@1 95.312 (93.901)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [56][40/390]\tTime 0.054 (0.064)\tData 0.006 (0.011)\tLoss 0.2453 (0.1654)\tPrec@1 92.969 (94.036)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [56][50/390]\tTime 0.061 (0.062)\tData 0.000 (0.009)\tLoss 0.2762 (0.1673)\tPrec@1 90.625 (93.934)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [56][60/390]\tTime 0.051 (0.061)\tData 0.000 (0.008)\tLoss 0.2176 (0.1656)\tPrec@1 92.969 (93.981)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [56][70/390]\tTime 0.056 (0.060)\tData 0.007 (0.007)\tLoss 0.2147 (0.1687)\tPrec@1 90.625 (93.860)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [56][80/390]\tTime 0.065 (0.060)\tData 0.008 (0.007)\tLoss 0.2180 (0.1689)\tPrec@1 93.750 (93.866)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [56][90/390]\tTime 0.057 (0.060)\tData 0.000 (0.006)\tLoss 0.1164 (0.1690)\tPrec@1 96.875 (93.905)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [56][100/390]\tTime 0.069 (0.059)\tData 0.011 (0.006)\tLoss 0.1597 (0.1687)\tPrec@1 93.750 (93.967)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [56][110/390]\tTime 0.046 (0.059)\tData 0.000 (0.006)\tLoss 0.1661 (0.1673)\tPrec@1 92.969 (94.003)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [56][120/390]\tTime 0.055 (0.059)\tData 0.000 (0.006)\tLoss 0.1544 (0.1648)\tPrec@1 92.969 (94.137)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [56][130/390]\tTime 0.072 (0.059)\tData 0.006 (0.005)\tLoss 0.1403 (0.1636)\tPrec@1 95.312 (94.173)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [56][140/390]\tTime 0.070 (0.059)\tData 0.006 (0.005)\tLoss 0.0924 (0.1619)\tPrec@1 96.094 (94.249)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [56][150/390]\tTime 0.076 (0.059)\tData 0.012 (0.005)\tLoss 0.1111 (0.1602)\tPrec@1 96.094 (94.293)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [56][160/390]\tTime 0.059 (0.059)\tData 0.007 (0.005)\tLoss 0.1098 (0.1597)\tPrec@1 95.312 (94.327)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [56][170/390]\tTime 0.056 (0.059)\tData 0.009 (0.005)\tLoss 0.1797 (0.1602)\tPrec@1 92.969 (94.275)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [56][180/390]\tTime 0.053 (0.059)\tData 0.001 (0.005)\tLoss 0.1877 (0.1612)\tPrec@1 92.969 (94.281)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [56][190/390]\tTime 0.062 (0.058)\tData 0.007 (0.005)\tLoss 0.1117 (0.1606)\tPrec@1 96.094 (94.327)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [56][200/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1351 (0.1625)\tPrec@1 96.094 (94.259)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [56][210/390]\tTime 0.054 (0.058)\tData 0.007 (0.005)\tLoss 0.1868 (0.1648)\tPrec@1 93.750 (94.172)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [56][220/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.2440 (0.1659)\tPrec@1 88.281 (94.121)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [56][230/390]\tTime 0.055 (0.058)\tData 0.006 (0.005)\tLoss 0.1901 (0.1668)\tPrec@1 95.312 (94.108)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [56][240/390]\tTime 0.070 (0.058)\tData 0.000 (0.005)\tLoss 0.2101 (0.1673)\tPrec@1 94.531 (94.107)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [56][250/390]\tTime 0.066 (0.058)\tData 0.013 (0.005)\tLoss 0.1228 (0.1677)\tPrec@1 93.750 (94.095)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [56][260/390]\tTime 0.073 (0.058)\tData 0.000 (0.005)\tLoss 0.1555 (0.1673)\tPrec@1 94.531 (94.112)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [56][270/390]\tTime 0.053 (0.057)\tData 0.000 (0.005)\tLoss 0.1058 (0.1671)\tPrec@1 96.875 (94.116)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [56][280/390]\tTime 0.049 (0.057)\tData 0.002 (0.004)\tLoss 0.1236 (0.1662)\tPrec@1 95.312 (94.150)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [56][290/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.1715 (0.1670)\tPrec@1 94.531 (94.153)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [56][300/390]\tTime 0.057 (0.057)\tData 0.006 (0.004)\tLoss 0.0978 (0.1666)\tPrec@1 96.875 (94.152)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [56][310/390]\tTime 0.051 (0.057)\tData 0.003 (0.004)\tLoss 0.1240 (0.1664)\tPrec@1 95.312 (94.162)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [56][320/390]\tTime 0.062 (0.057)\tData 0.017 (0.004)\tLoss 0.2389 (0.1660)\tPrec@1 92.188 (94.171)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [56][330/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.1571 (0.1661)\tPrec@1 94.531 (94.154)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [56][340/390]\tTime 0.050 (0.057)\tData 0.003 (0.004)\tLoss 0.1289 (0.1666)\tPrec@1 94.531 (94.142)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [56][350/390]\tTime 0.056 (0.057)\tData 0.000 (0.004)\tLoss 0.2468 (0.1673)\tPrec@1 92.188 (94.108)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [56][360/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.3821 (0.1692)\tPrec@1 85.156 (94.046)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [56][370/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.1314 (0.1694)\tPrec@1 94.531 (94.041)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [56][380/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.2389 (0.1699)\tPrec@1 92.969 (94.029)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [56][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1399 (0.1695)\tPrec@1 95.312 (94.030)\tPrec@5 100.000 (99.936)\t\n",
            "EVALUATING - Epoch: [56][0/79]\tTime 0.249 (0.249)\tData 0.206 (0.206)\tLoss 0.2063 (0.2063)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [56][10/79]\tTime 0.035 (0.056)\tData 0.007 (0.026)\tLoss 0.4523 (0.3411)\tPrec@1 87.500 (89.347)\tPrec@5 100.000 (99.716)\t\n",
            "EVALUATING - Epoch: [56][20/79]\tTime 0.044 (0.045)\tData 0.009 (0.017)\tLoss 0.3276 (0.3814)\tPrec@1 89.844 (88.802)\tPrec@5 98.438 (99.516)\t\n",
            "EVALUATING - Epoch: [56][30/79]\tTime 0.024 (0.039)\tData 0.004 (0.013)\tLoss 0.3528 (0.3775)\tPrec@1 89.844 (88.861)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [56][40/79]\tTime 0.031 (0.037)\tData 0.001 (0.011)\tLoss 0.5366 (0.3798)\tPrec@1 79.688 (88.758)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [56][50/79]\tTime 0.031 (0.035)\tData 0.013 (0.010)\tLoss 0.4604 (0.3742)\tPrec@1 83.594 (88.848)\tPrec@5 100.000 (99.556)\t\n",
            "EVALUATING - Epoch: [56][60/79]\tTime 0.030 (0.035)\tData 0.004 (0.009)\tLoss 0.3280 (0.3767)\tPrec@1 91.406 (88.858)\tPrec@5 99.219 (99.539)\t\n",
            "EVALUATING - Epoch: [56][70/79]\tTime 0.047 (0.034)\tData 0.028 (0.009)\tLoss 0.2304 (0.3733)\tPrec@1 89.844 (88.776)\tPrec@5 100.000 (99.593)\t\n",
            "EVALUATING - Epoch: [56][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.008)\tLoss 0.2166 (0.3718)\tPrec@1 87.500 (88.880)\tPrec@5 100.000 (99.600)\t\n",
            "\n",
            "Results - Epoch: 57\n",
            "Training Loss 0.1695 \tTraining Prec@1 94.030 \tTraining Prec@5 99.936 \tValidation Loss 0.3718 \tValidation Prec@1 88.880 \tValidation Prec@5 99.600 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 58\n",
            "\n",
            "TRAINING - Epoch: [57][0/390]\tTime 0.364 (0.364)\tData 0.274 (0.274)\tLoss 0.1002 (0.1002)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [57][10/390]\tTime 0.047 (0.086)\tData 0.000 (0.028)\tLoss 0.1624 (0.1548)\tPrec@1 92.188 (93.892)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [57][20/390]\tTime 0.049 (0.072)\tData 0.000 (0.016)\tLoss 0.1323 (0.1490)\tPrec@1 94.531 (94.308)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [57][30/390]\tTime 0.046 (0.067)\tData 0.000 (0.012)\tLoss 0.1564 (0.1550)\tPrec@1 92.969 (94.153)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [57][40/390]\tTime 0.049 (0.064)\tData 0.002 (0.010)\tLoss 0.1327 (0.1584)\tPrec@1 95.312 (94.131)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [57][50/390]\tTime 0.046 (0.062)\tData 0.000 (0.009)\tLoss 0.1110 (0.1607)\tPrec@1 95.312 (93.964)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [57][60/390]\tTime 0.057 (0.061)\tData 0.007 (0.008)\tLoss 0.1453 (0.1624)\tPrec@1 92.969 (93.968)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [57][70/390]\tTime 0.047 (0.061)\tData 0.000 (0.008)\tLoss 0.2869 (0.1640)\tPrec@1 89.844 (93.992)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [57][80/390]\tTime 0.057 (0.060)\tData 0.000 (0.007)\tLoss 0.0666 (0.1616)\tPrec@1 98.438 (94.068)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [57][90/390]\tTime 0.049 (0.060)\tData 0.000 (0.007)\tLoss 0.1612 (0.1632)\tPrec@1 94.531 (94.050)\tPrec@5 100.000 (99.966)\t\n",
            "TRAINING - Epoch: [57][100/390]\tTime 0.063 (0.060)\tData 0.000 (0.006)\tLoss 0.1134 (0.1640)\tPrec@1 96.094 (94.005)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [57][110/390]\tTime 0.059 (0.060)\tData 0.008 (0.006)\tLoss 0.1601 (0.1638)\tPrec@1 92.188 (94.010)\tPrec@5 100.000 (99.965)\t\n",
            "TRAINING - Epoch: [57][120/390]\tTime 0.057 (0.059)\tData 0.007 (0.006)\tLoss 0.2526 (0.1652)\tPrec@1 90.625 (93.982)\tPrec@5 100.000 (99.968)\t\n",
            "TRAINING - Epoch: [57][130/390]\tTime 0.050 (0.059)\tData 0.000 (0.006)\tLoss 0.2046 (0.1642)\tPrec@1 91.406 (93.995)\tPrec@5 100.000 (99.964)\t\n",
            "TRAINING - Epoch: [57][140/390]\tTime 0.050 (0.059)\tData 0.001 (0.006)\tLoss 0.1462 (0.1655)\tPrec@1 94.531 (93.961)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [57][150/390]\tTime 0.049 (0.058)\tData 0.000 (0.006)\tLoss 0.1138 (0.1652)\tPrec@1 96.094 (94.009)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [57][160/390]\tTime 0.054 (0.058)\tData 0.000 (0.006)\tLoss 0.1343 (0.1671)\tPrec@1 93.750 (93.930)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [57][170/390]\tTime 0.046 (0.058)\tData 0.000 (0.005)\tLoss 0.0742 (0.1683)\tPrec@1 97.656 (93.901)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [57][180/390]\tTime 0.059 (0.058)\tData 0.008 (0.005)\tLoss 0.2446 (0.1689)\tPrec@1 94.531 (93.931)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [57][190/390]\tTime 0.070 (0.058)\tData 0.015 (0.005)\tLoss 0.2091 (0.1690)\tPrec@1 94.531 (93.950)\tPrec@5 99.219 (99.943)\t\n",
            "TRAINING - Epoch: [57][200/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.2900 (0.1693)\tPrec@1 90.625 (93.952)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [57][210/390]\tTime 0.054 (0.057)\tData 0.006 (0.005)\tLoss 0.1130 (0.1691)\tPrec@1 97.656 (93.972)\tPrec@5 100.000 (99.941)\t\n",
            "TRAINING - Epoch: [57][220/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.1745 (0.1689)\tPrec@1 93.750 (93.987)\tPrec@5 99.219 (99.940)\t\n",
            "TRAINING - Epoch: [57][230/390]\tTime 0.067 (0.057)\tData 0.014 (0.005)\tLoss 0.1952 (0.1685)\tPrec@1 93.750 (94.010)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [57][240/390]\tTime 0.054 (0.057)\tData 0.008 (0.005)\tLoss 0.1105 (0.1683)\tPrec@1 96.094 (94.035)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [57][250/390]\tTime 0.055 (0.057)\tData 0.008 (0.005)\tLoss 0.2384 (0.1693)\tPrec@1 91.406 (93.993)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [57][260/390]\tTime 0.063 (0.057)\tData 0.000 (0.005)\tLoss 0.1328 (0.1689)\tPrec@1 94.531 (94.031)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [57][270/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.1657 (0.1685)\tPrec@1 93.750 (94.035)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [57][280/390]\tTime 0.064 (0.057)\tData 0.007 (0.005)\tLoss 0.2033 (0.1690)\tPrec@1 95.312 (94.039)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [57][290/390]\tTime 0.065 (0.057)\tData 0.006 (0.005)\tLoss 0.2087 (0.1686)\tPrec@1 92.188 (94.059)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [57][300/390]\tTime 0.074 (0.057)\tData 0.007 (0.005)\tLoss 0.1853 (0.1694)\tPrec@1 91.406 (94.025)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [57][310/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.2076 (0.1691)\tPrec@1 94.531 (94.046)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [57][320/390]\tTime 0.055 (0.057)\tData 0.008 (0.005)\tLoss 0.1756 (0.1687)\tPrec@1 94.531 (94.071)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [57][330/390]\tTime 0.054 (0.057)\tData 0.006 (0.005)\tLoss 0.1690 (0.1686)\tPrec@1 95.312 (94.071)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [57][340/390]\tTime 0.056 (0.057)\tData 0.011 (0.005)\tLoss 0.1236 (0.1685)\tPrec@1 95.312 (94.082)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [57][350/390]\tTime 0.052 (0.057)\tData 0.000 (0.005)\tLoss 0.1558 (0.1688)\tPrec@1 93.750 (94.066)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [57][360/390]\tTime 0.055 (0.057)\tData 0.000 (0.005)\tLoss 0.1554 (0.1693)\tPrec@1 96.094 (94.079)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [57][370/390]\tTime 0.054 (0.057)\tData 0.000 (0.005)\tLoss 0.1850 (0.1696)\tPrec@1 90.625 (94.032)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [57][380/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.1862 (0.1702)\tPrec@1 93.750 (93.994)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [57][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1888 (0.1700)\tPrec@1 93.750 (93.996)\tPrec@5 100.000 (99.942)\t\n",
            "EVALUATING - Epoch: [57][0/79]\tTime 0.205 (0.205)\tData 0.173 (0.173)\tLoss 0.3187 (0.3187)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [57][10/79]\tTime 0.033 (0.054)\tData 0.005 (0.022)\tLoss 0.2239 (0.3597)\tPrec@1 92.969 (88.139)\tPrec@5 100.000 (99.645)\t\n",
            "EVALUATING - Epoch: [57][20/79]\tTime 0.049 (0.042)\tData 0.014 (0.014)\tLoss 0.3974 (0.4030)\tPrec@1 85.938 (88.318)\tPrec@5 100.000 (99.554)\t\n",
            "EVALUATING - Epoch: [57][30/79]\tTime 0.036 (0.038)\tData 0.005 (0.011)\tLoss 0.2923 (0.4039)\tPrec@1 91.406 (87.979)\tPrec@5 100.000 (99.521)\t\n",
            "EVALUATING - Epoch: [57][40/79]\tTime 0.035 (0.037)\tData 0.002 (0.010)\tLoss 0.5045 (0.3994)\tPrec@1 84.375 (88.167)\tPrec@5 100.000 (99.543)\t\n",
            "EVALUATING - Epoch: [57][50/79]\tTime 0.028 (0.034)\tData 0.005 (0.009)\tLoss 0.2812 (0.3865)\tPrec@1 92.969 (88.572)\tPrec@5 100.000 (99.586)\t\n",
            "EVALUATING - Epoch: [57][60/79]\tTime 0.033 (0.034)\tData 0.001 (0.008)\tLoss 0.3423 (0.3870)\tPrec@1 90.625 (88.576)\tPrec@5 100.000 (99.590)\t\n",
            "EVALUATING - Epoch: [57][70/79]\tTime 0.053 (0.034)\tData 0.005 (0.007)\tLoss 0.3184 (0.3840)\tPrec@1 91.406 (88.567)\tPrec@5 100.000 (99.615)\t\n",
            "EVALUATING - Epoch: [57][78/79]\tTime 0.006 (0.031)\tData 0.000 (0.007)\tLoss 0.1920 (0.3812)\tPrec@1 93.750 (88.650)\tPrec@5 100.000 (99.640)\t\n",
            "\n",
            "Results - Epoch: 58\n",
            "Training Loss 0.1700 \tTraining Prec@1 93.996 \tTraining Prec@5 99.942 \tValidation Loss 0.3812 \tValidation Prec@1 88.650 \tValidation Prec@5 99.640 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 59\n",
            "\n",
            "TRAINING - Epoch: [58][0/390]\tTime 0.359 (0.359)\tData 0.276 (0.276)\tLoss 0.1656 (0.1656)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [58][10/390]\tTime 0.046 (0.087)\tData 0.000 (0.028)\tLoss 0.1256 (0.1428)\tPrec@1 94.531 (95.170)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [58][20/390]\tTime 0.047 (0.073)\tData 0.000 (0.016)\tLoss 0.1422 (0.1382)\tPrec@1 95.312 (95.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [58][30/390]\tTime 0.047 (0.067)\tData 0.000 (0.012)\tLoss 0.1194 (0.1425)\tPrec@1 96.094 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [58][40/390]\tTime 0.052 (0.065)\tData 0.002 (0.010)\tLoss 0.1474 (0.1429)\tPrec@1 95.312 (95.236)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [58][50/390]\tTime 0.050 (0.063)\tData 0.000 (0.008)\tLoss 0.1617 (0.1416)\tPrec@1 93.750 (95.205)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [58][60/390]\tTime 0.046 (0.062)\tData 0.000 (0.008)\tLoss 0.1776 (0.1437)\tPrec@1 92.188 (95.172)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [58][70/390]\tTime 0.058 (0.061)\tData 0.003 (0.007)\tLoss 0.1669 (0.1428)\tPrec@1 94.531 (95.169)\tPrec@5 99.219 (99.956)\t\n",
            "TRAINING - Epoch: [58][80/390]\tTime 0.056 (0.061)\tData 0.007 (0.007)\tLoss 0.1302 (0.1431)\tPrec@1 95.312 (95.206)\tPrec@5 100.000 (99.952)\t\n",
            "TRAINING - Epoch: [58][90/390]\tTime 0.057 (0.060)\tData 0.010 (0.006)\tLoss 0.1223 (0.1436)\tPrec@1 96.875 (95.184)\tPrec@5 99.219 (99.940)\t\n",
            "TRAINING - Epoch: [58][100/390]\tTime 0.056 (0.060)\tData 0.007 (0.006)\tLoss 0.1970 (0.1443)\tPrec@1 92.188 (95.111)\tPrec@5 99.219 (99.923)\t\n",
            "TRAINING - Epoch: [58][110/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.1776 (0.1453)\tPrec@1 93.750 (95.073)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [58][120/390]\tTime 0.060 (0.059)\tData 0.001 (0.006)\tLoss 0.1244 (0.1469)\tPrec@1 96.094 (95.015)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [58][130/390]\tTime 0.074 (0.059)\tData 0.007 (0.006)\tLoss 0.2340 (0.1480)\tPrec@1 93.750 (94.955)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [58][140/390]\tTime 0.046 (0.059)\tData 0.000 (0.005)\tLoss 0.1678 (0.1501)\tPrec@1 95.312 (94.830)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [58][150/390]\tTime 0.051 (0.058)\tData 0.000 (0.005)\tLoss 0.1826 (0.1508)\tPrec@1 94.531 (94.837)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [58][160/390]\tTime 0.053 (0.058)\tData 0.000 (0.005)\tLoss 0.0953 (0.1531)\tPrec@1 96.875 (94.774)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [58][170/390]\tTime 0.067 (0.058)\tData 0.007 (0.005)\tLoss 0.1454 (0.1535)\tPrec@1 93.750 (94.755)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [58][180/390]\tTime 0.064 (0.058)\tData 0.009 (0.005)\tLoss 0.1652 (0.1536)\tPrec@1 93.750 (94.725)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [58][190/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2193 (0.1550)\tPrec@1 92.969 (94.654)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [58][200/390]\tTime 0.056 (0.058)\tData 0.005 (0.005)\tLoss 0.1647 (0.1556)\tPrec@1 95.312 (94.632)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [58][210/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2631 (0.1574)\tPrec@1 92.969 (94.620)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [58][220/390]\tTime 0.058 (0.058)\tData 0.000 (0.005)\tLoss 0.1803 (0.1580)\tPrec@1 95.312 (94.577)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [58][230/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.2145 (0.1583)\tPrec@1 93.750 (94.572)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [58][240/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.1659 (0.1573)\tPrec@1 95.312 (94.586)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [58][250/390]\tTime 0.051 (0.057)\tData 0.000 (0.005)\tLoss 0.1392 (0.1568)\tPrec@1 93.750 (94.603)\tPrec@5 99.219 (99.938)\t\n",
            "TRAINING - Epoch: [58][260/390]\tTime 0.053 (0.057)\tData 0.000 (0.005)\tLoss 0.2242 (0.1576)\tPrec@1 90.625 (94.561)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [58][270/390]\tTime 0.064 (0.057)\tData 0.000 (0.005)\tLoss 0.2211 (0.1573)\tPrec@1 92.969 (94.600)\tPrec@5 99.219 (99.937)\t\n",
            "TRAINING - Epoch: [58][280/390]\tTime 0.051 (0.057)\tData 0.002 (0.004)\tLoss 0.2979 (0.1585)\tPrec@1 90.625 (94.526)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [58][290/390]\tTime 0.066 (0.057)\tData 0.007 (0.005)\tLoss 0.1684 (0.1590)\tPrec@1 92.969 (94.502)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [58][300/390]\tTime 0.065 (0.057)\tData 0.007 (0.004)\tLoss 0.2402 (0.1594)\tPrec@1 93.750 (94.492)\tPrec@5 99.219 (99.933)\t\n",
            "TRAINING - Epoch: [58][310/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.1674 (0.1590)\tPrec@1 92.969 (94.504)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [58][320/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.1078 (0.1585)\tPrec@1 96.094 (94.536)\tPrec@5 100.000 (99.932)\t\n",
            "TRAINING - Epoch: [58][330/390]\tTime 0.065 (0.057)\tData 0.007 (0.004)\tLoss 0.1486 (0.1589)\tPrec@1 96.094 (94.529)\tPrec@5 100.000 (99.932)\t\n",
            "TRAINING - Epoch: [58][340/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1466 (0.1598)\tPrec@1 92.188 (94.490)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [58][350/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1095 (0.1602)\tPrec@1 97.656 (94.480)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [58][360/390]\tTime 0.054 (0.057)\tData 0.000 (0.004)\tLoss 0.2609 (0.1613)\tPrec@1 91.406 (94.430)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [58][370/390]\tTime 0.056 (0.057)\tData 0.007 (0.004)\tLoss 0.1572 (0.1630)\tPrec@1 95.312 (94.367)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [58][380/390]\tTime 0.058 (0.057)\tData 0.009 (0.004)\tLoss 0.2760 (0.1647)\tPrec@1 91.406 (94.308)\tPrec@5 98.438 (99.928)\t\n",
            "TRAINING - Epoch: [58][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.1637 (0.1656)\tPrec@1 96.094 (94.275)\tPrec@5 99.219 (99.926)\t\n",
            "EVALUATING - Epoch: [58][0/79]\tTime 0.212 (0.212)\tData 0.177 (0.177)\tLoss 0.4330 (0.4330)\tPrec@1 85.938 (85.938)\tPrec@5 98.438 (98.438)\t\n",
            "EVALUATING - Epoch: [58][10/79]\tTime 0.041 (0.057)\tData 0.001 (0.023)\tLoss 0.2990 (0.4105)\tPrec@1 89.844 (86.932)\tPrec@5 100.000 (99.503)\t\n",
            "EVALUATING - Epoch: [58][20/79]\tTime 0.030 (0.043)\tData 0.000 (0.014)\tLoss 0.5197 (0.4224)\tPrec@1 85.938 (87.016)\tPrec@5 98.438 (99.516)\t\n",
            "EVALUATING - Epoch: [58][30/79]\tTime 0.026 (0.040)\tData 0.006 (0.011)\tLoss 0.4127 (0.4163)\tPrec@1 87.500 (87.450)\tPrec@5 100.000 (99.471)\t\n",
            "EVALUATING - Epoch: [58][40/79]\tTime 0.022 (0.037)\tData 0.003 (0.010)\tLoss 0.3872 (0.4024)\tPrec@1 85.938 (87.671)\tPrec@5 100.000 (99.581)\t\n",
            "EVALUATING - Epoch: [58][50/79]\tTime 0.043 (0.037)\tData 0.007 (0.010)\tLoss 0.4366 (0.4066)\tPrec@1 87.500 (87.837)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [58][60/79]\tTime 0.029 (0.036)\tData 0.002 (0.009)\tLoss 0.3833 (0.3999)\tPrec@1 89.844 (87.974)\tPrec@5 100.000 (99.693)\t\n",
            "EVALUATING - Epoch: [58][70/79]\tTime 0.014 (0.035)\tData 0.000 (0.008)\tLoss 0.3659 (0.3991)\tPrec@1 91.406 (88.039)\tPrec@5 99.219 (99.648)\t\n",
            "EVALUATING - Epoch: [58][78/79]\tTime 0.005 (0.033)\tData 0.000 (0.007)\tLoss 0.4878 (0.3954)\tPrec@1 87.500 (88.130)\tPrec@5 100.000 (99.660)\t\n",
            "\n",
            "Results - Epoch: 59\n",
            "Training Loss 0.1656 \tTraining Prec@1 94.275 \tTraining Prec@5 99.926 \tValidation Loss 0.3954 \tValidation Prec@1 88.130 \tValidation Prec@5 99.660 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 60\n",
            "\n",
            "TRAINING - Epoch: [59][0/390]\tTime 0.277 (0.277)\tData 0.186 (0.186)\tLoss 0.1286 (0.1286)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [59][10/390]\tTime 0.055 (0.089)\tData 0.009 (0.024)\tLoss 0.1996 (0.1556)\tPrec@1 95.312 (94.389)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [59][20/390]\tTime 0.057 (0.072)\tData 0.000 (0.014)\tLoss 0.2262 (0.1716)\tPrec@1 93.750 (93.899)\tPrec@5 99.219 (99.851)\t\n",
            "TRAINING - Epoch: [59][30/390]\tTime 0.068 (0.068)\tData 0.009 (0.011)\tLoss 0.1751 (0.1675)\tPrec@1 93.750 (94.279)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [59][40/390]\tTime 0.052 (0.065)\tData 0.000 (0.009)\tLoss 0.1553 (0.1629)\tPrec@1 92.969 (94.226)\tPrec@5 100.000 (99.886)\t\n",
            "TRAINING - Epoch: [59][50/390]\tTime 0.057 (0.063)\tData 0.007 (0.008)\tLoss 0.1341 (0.1614)\tPrec@1 95.312 (94.118)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [59][60/390]\tTime 0.073 (0.062)\tData 0.008 (0.007)\tLoss 0.2125 (0.1609)\tPrec@1 94.531 (94.249)\tPrec@5 99.219 (99.910)\t\n",
            "TRAINING - Epoch: [59][70/390]\tTime 0.049 (0.061)\tData 0.000 (0.007)\tLoss 0.0941 (0.1557)\tPrec@1 96.875 (94.421)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [59][80/390]\tTime 0.087 (0.061)\tData 0.009 (0.006)\tLoss 0.1633 (0.1530)\tPrec@1 95.312 (94.531)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [59][90/390]\tTime 0.052 (0.060)\tData 0.000 (0.006)\tLoss 0.2091 (0.1551)\tPrec@1 91.406 (94.411)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [59][100/390]\tTime 0.048 (0.060)\tData 0.000 (0.006)\tLoss 0.1160 (0.1553)\tPrec@1 94.531 (94.384)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [59][110/390]\tTime 0.051 (0.059)\tData 0.004 (0.005)\tLoss 0.1624 (0.1553)\tPrec@1 92.969 (94.398)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [59][120/390]\tTime 0.054 (0.059)\tData 0.000 (0.005)\tLoss 0.2127 (0.1546)\tPrec@1 92.969 (94.434)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [59][130/390]\tTime 0.055 (0.059)\tData 0.000 (0.005)\tLoss 0.1709 (0.1555)\tPrec@1 93.750 (94.412)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [59][140/390]\tTime 0.067 (0.058)\tData 0.000 (0.005)\tLoss 0.1580 (0.1555)\tPrec@1 95.312 (94.470)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [59][150/390]\tTime 0.074 (0.058)\tData 0.007 (0.005)\tLoss 0.1732 (0.1563)\tPrec@1 95.312 (94.454)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [59][160/390]\tTime 0.059 (0.058)\tData 0.007 (0.005)\tLoss 0.1373 (0.1563)\tPrec@1 93.750 (94.444)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [59][170/390]\tTime 0.050 (0.058)\tData 0.002 (0.005)\tLoss 0.1293 (0.1561)\tPrec@1 95.312 (94.412)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [59][180/390]\tTime 0.052 (0.058)\tData 0.000 (0.004)\tLoss 0.1927 (0.1554)\tPrec@1 93.750 (94.436)\tPrec@5 100.000 (99.927)\t\n",
            "TRAINING - Epoch: [59][190/390]\tTime 0.066 (0.058)\tData 0.007 (0.004)\tLoss 0.1592 (0.1566)\tPrec@1 93.750 (94.421)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [59][200/390]\tTime 0.046 (0.058)\tData 0.000 (0.004)\tLoss 0.1134 (0.1565)\tPrec@1 96.094 (94.442)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [59][210/390]\tTime 0.053 (0.058)\tData 0.000 (0.004)\tLoss 0.0702 (0.1559)\tPrec@1 98.438 (94.494)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [59][220/390]\tTime 0.047 (0.058)\tData 0.000 (0.004)\tLoss 0.1736 (0.1559)\tPrec@1 92.969 (94.475)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [59][230/390]\tTime 0.049 (0.058)\tData 0.000 (0.004)\tLoss 0.1317 (0.1572)\tPrec@1 95.312 (94.426)\tPrec@5 100.000 (99.915)\t\n",
            "TRAINING - Epoch: [59][240/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.2765 (0.1581)\tPrec@1 88.281 (94.415)\tPrec@5 100.000 (99.919)\t\n",
            "TRAINING - Epoch: [59][250/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1593 (0.1592)\tPrec@1 94.531 (94.366)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [59][260/390]\tTime 0.056 (0.057)\tData 0.000 (0.004)\tLoss 0.1798 (0.1590)\tPrec@1 93.750 (94.382)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [59][270/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.0953 (0.1587)\tPrec@1 96.094 (94.378)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [59][280/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.2435 (0.1593)\tPrec@1 90.625 (94.334)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [59][290/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.1706 (0.1596)\tPrec@1 93.750 (94.346)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [59][300/390]\tTime 0.049 (0.057)\tData 0.002 (0.004)\tLoss 0.1626 (0.1593)\tPrec@1 92.969 (94.347)\tPrec@5 100.000 (99.920)\t\n",
            "TRAINING - Epoch: [59][310/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1261 (0.1593)\tPrec@1 94.531 (94.338)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [59][320/390]\tTime 0.065 (0.057)\tData 0.011 (0.004)\tLoss 0.1631 (0.1603)\tPrec@1 92.969 (94.298)\tPrec@5 100.000 (99.920)\t\n",
            "TRAINING - Epoch: [59][330/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.1398 (0.1602)\tPrec@1 96.094 (94.298)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [59][340/390]\tTime 0.049 (0.057)\tData 0.003 (0.004)\tLoss 0.1300 (0.1600)\tPrec@1 94.531 (94.304)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [59][350/390]\tTime 0.058 (0.057)\tData 0.009 (0.004)\tLoss 0.1101 (0.1594)\tPrec@1 96.875 (94.331)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [59][360/390]\tTime 0.075 (0.057)\tData 0.007 (0.004)\tLoss 0.1556 (0.1599)\tPrec@1 93.750 (94.313)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [59][370/390]\tTime 0.057 (0.057)\tData 0.000 (0.004)\tLoss 0.1055 (0.1598)\tPrec@1 97.656 (94.329)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [59][380/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.1360 (0.1595)\tPrec@1 96.094 (94.341)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [59][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.1207 (0.1596)\tPrec@1 95.312 (94.321)\tPrec@5 100.000 (99.928)\t\n",
            "EVALUATING - Epoch: [59][0/79]\tTime 0.216 (0.216)\tData 0.179 (0.179)\tLoss 0.3598 (0.3598)\tPrec@1 89.062 (89.062)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [59][10/79]\tTime 0.027 (0.055)\tData 0.002 (0.025)\tLoss 0.3564 (0.3557)\tPrec@1 89.062 (88.778)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [59][20/79]\tTime 0.031 (0.043)\tData 0.000 (0.015)\tLoss 0.4772 (0.3902)\tPrec@1 85.156 (88.244)\tPrec@5 99.219 (99.665)\t\n",
            "EVALUATING - Epoch: [59][30/79]\tTime 0.037 (0.039)\tData 0.009 (0.012)\tLoss 0.2519 (0.3916)\tPrec@1 89.062 (88.054)\tPrec@5 100.000 (99.597)\t\n",
            "EVALUATING - Epoch: [59][40/79]\tTime 0.015 (0.037)\tData 0.000 (0.010)\tLoss 0.5102 (0.3835)\tPrec@1 85.938 (88.377)\tPrec@5 99.219 (99.638)\t\n",
            "EVALUATING - Epoch: [59][50/79]\tTime 0.028 (0.036)\tData 0.013 (0.009)\tLoss 0.3720 (0.3782)\tPrec@1 89.844 (88.542)\tPrec@5 100.000 (99.678)\t\n",
            "EVALUATING - Epoch: [59][60/79]\tTime 0.026 (0.035)\tData 0.007 (0.009)\tLoss 0.3854 (0.3730)\tPrec@1 87.500 (88.781)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [59][70/79]\tTime 0.058 (0.034)\tData 0.005 (0.008)\tLoss 0.2823 (0.3698)\tPrec@1 91.406 (88.655)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [59][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.3359 (0.3706)\tPrec@1 93.750 (88.770)\tPrec@5 100.000 (99.720)\t\n",
            "\n",
            "Results - Epoch: 60\n",
            "Training Loss 0.1596 \tTraining Prec@1 94.321 \tTraining Prec@5 99.928 \tValidation Loss 0.3706 \tValidation Prec@1 88.770 \tValidation Prec@5 99.720 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 61\n",
            "\n",
            "TRAINING - Epoch: [60][0/390]\tTime 0.401 (0.401)\tData 0.290 (0.290)\tLoss 0.2158 (0.2158)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [60][10/390]\tTime 0.046 (0.087)\tData 0.000 (0.029)\tLoss 0.2681 (0.1621)\tPrec@1 91.406 (94.318)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [60][20/390]\tTime 0.053 (0.073)\tData 0.004 (0.018)\tLoss 0.1165 (0.1591)\tPrec@1 96.875 (94.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [60][30/390]\tTime 0.059 (0.067)\tData 0.011 (0.013)\tLoss 0.0940 (0.1528)\tPrec@1 94.531 (94.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [60][40/390]\tTime 0.049 (0.065)\tData 0.000 (0.011)\tLoss 0.1188 (0.1556)\tPrec@1 94.531 (94.303)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [60][50/390]\tTime 0.049 (0.063)\tData 0.000 (0.009)\tLoss 0.1366 (0.1596)\tPrec@1 94.531 (94.240)\tPrec@5 100.000 (99.985)\t\n",
            "TRAINING - Epoch: [60][60/390]\tTime 0.054 (0.062)\tData 0.000 (0.009)\tLoss 0.1480 (0.1590)\tPrec@1 95.312 (94.365)\tPrec@5 100.000 (99.987)\t\n",
            "TRAINING - Epoch: [60][70/390]\tTime 0.073 (0.061)\tData 0.010 (0.008)\tLoss 0.1705 (0.1607)\tPrec@1 95.312 (94.344)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [60][80/390]\tTime 0.048 (0.060)\tData 0.000 (0.007)\tLoss 0.2228 (0.1624)\tPrec@1 90.625 (94.261)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [60][90/390]\tTime 0.059 (0.060)\tData 0.000 (0.007)\tLoss 0.1857 (0.1612)\tPrec@1 93.750 (94.239)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [60][100/390]\tTime 0.047 (0.059)\tData 0.000 (0.006)\tLoss 0.1186 (0.1609)\tPrec@1 94.531 (94.276)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [60][110/390]\tTime 0.046 (0.059)\tData 0.000 (0.006)\tLoss 0.2264 (0.1603)\tPrec@1 92.969 (94.313)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [60][120/390]\tTime 0.069 (0.059)\tData 0.010 (0.006)\tLoss 0.1445 (0.1590)\tPrec@1 92.969 (94.370)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [60][130/390]\tTime 0.071 (0.059)\tData 0.006 (0.006)\tLoss 0.1111 (0.1580)\tPrec@1 94.531 (94.400)\tPrec@5 100.000 (99.952)\t\n",
            "TRAINING - Epoch: [60][140/390]\tTime 0.074 (0.059)\tData 0.000 (0.006)\tLoss 0.1474 (0.1562)\tPrec@1 94.531 (94.426)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [60][150/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.1706 (0.1570)\tPrec@1 92.969 (94.392)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [60][160/390]\tTime 0.056 (0.059)\tData 0.006 (0.005)\tLoss 0.1429 (0.1582)\tPrec@1 94.531 (94.361)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [60][170/390]\tTime 0.055 (0.059)\tData 0.007 (0.005)\tLoss 0.2030 (0.1593)\tPrec@1 92.969 (94.326)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [60][180/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 0.2554 (0.1605)\tPrec@1 92.188 (94.315)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [60][190/390]\tTime 0.059 (0.059)\tData 0.000 (0.005)\tLoss 0.1298 (0.1602)\tPrec@1 93.750 (94.314)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [60][200/390]\tTime 0.046 (0.058)\tData 0.000 (0.005)\tLoss 0.1445 (0.1607)\tPrec@1 94.531 (94.294)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [60][210/390]\tTime 0.051 (0.058)\tData 0.004 (0.005)\tLoss 0.2380 (0.1619)\tPrec@1 91.406 (94.228)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [60][220/390]\tTime 0.054 (0.058)\tData 0.006 (0.005)\tLoss 0.1885 (0.1623)\tPrec@1 92.969 (94.227)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [60][230/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.0884 (0.1619)\tPrec@1 96.875 (94.247)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [60][240/390]\tTime 0.046 (0.058)\tData 0.000 (0.005)\tLoss 0.2638 (0.1625)\tPrec@1 89.062 (94.233)\tPrec@5 99.219 (99.938)\t\n",
            "TRAINING - Epoch: [60][250/390]\tTime 0.059 (0.058)\tData 0.000 (0.005)\tLoss 0.1374 (0.1627)\tPrec@1 94.531 (94.254)\tPrec@5 100.000 (99.941)\t\n",
            "TRAINING - Epoch: [60][260/390]\tTime 0.068 (0.058)\tData 0.006 (0.005)\tLoss 0.1016 (0.1643)\tPrec@1 96.094 (94.220)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [60][270/390]\tTime 0.079 (0.058)\tData 0.000 (0.005)\tLoss 0.1499 (0.1637)\tPrec@1 94.531 (94.223)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [60][280/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.1632 (0.1637)\tPrec@1 93.750 (94.217)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [60][290/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2130 (0.1639)\tPrec@1 89.062 (94.185)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [60][300/390]\tTime 0.052 (0.058)\tData 0.006 (0.004)\tLoss 0.0908 (0.1636)\tPrec@1 96.875 (94.196)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [60][310/390]\tTime 0.065 (0.058)\tData 0.007 (0.004)\tLoss 0.2077 (0.1633)\tPrec@1 92.188 (94.202)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [60][320/390]\tTime 0.051 (0.058)\tData 0.000 (0.004)\tLoss 0.2268 (0.1642)\tPrec@1 91.406 (94.173)\tPrec@5 99.219 (99.939)\t\n",
            "TRAINING - Epoch: [60][330/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.2803 (0.1646)\tPrec@1 92.188 (94.170)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [60][340/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.1426 (0.1648)\tPrec@1 93.750 (94.156)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [60][350/390]\tTime 0.062 (0.057)\tData 0.007 (0.004)\tLoss 0.1102 (0.1646)\tPrec@1 96.875 (94.164)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [60][360/390]\tTime 0.068 (0.058)\tData 0.008 (0.004)\tLoss 0.1641 (0.1645)\tPrec@1 93.750 (94.166)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [60][370/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2987 (0.1642)\tPrec@1 89.844 (94.186)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [60][380/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.1377 (0.1640)\tPrec@1 94.531 (94.187)\tPrec@5 100.000 (99.932)\t\n",
            "TRAINING - Epoch: [60][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1686 (0.1639)\tPrec@1 94.531 (94.165)\tPrec@5 100.000 (99.934)\t\n",
            "EVALUATING - Epoch: [60][0/79]\tTime 0.187 (0.187)\tData 0.159 (0.159)\tLoss 0.3142 (0.3142)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [60][10/79]\tTime 0.032 (0.058)\tData 0.009 (0.025)\tLoss 0.3727 (0.3746)\tPrec@1 90.625 (89.062)\tPrec@5 100.000 (99.716)\t\n",
            "EVALUATING - Epoch: [60][20/79]\tTime 0.056 (0.044)\tData 0.009 (0.016)\tLoss 0.4157 (0.4285)\tPrec@1 88.281 (88.244)\tPrec@5 100.000 (99.330)\t\n",
            "EVALUATING - Epoch: [60][30/79]\tTime 0.036 (0.039)\tData 0.008 (0.012)\tLoss 0.3934 (0.4190)\tPrec@1 92.188 (88.508)\tPrec@5 100.000 (99.471)\t\n",
            "EVALUATING - Epoch: [60][40/79]\tTime 0.034 (0.037)\tData 0.008 (0.011)\tLoss 0.3821 (0.4061)\tPrec@1 85.938 (88.586)\tPrec@5 100.000 (99.543)\t\n",
            "EVALUATING - Epoch: [60][50/79]\tTime 0.027 (0.034)\tData 0.010 (0.009)\tLoss 0.4786 (0.3971)\tPrec@1 89.844 (88.787)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [60][60/79]\tTime 0.030 (0.034)\tData 0.012 (0.009)\tLoss 0.4008 (0.3878)\tPrec@1 89.844 (88.909)\tPrec@5 99.219 (99.629)\t\n",
            "EVALUATING - Epoch: [60][70/79]\tTime 0.026 (0.032)\tData 0.000 (0.008)\tLoss 0.3753 (0.3889)\tPrec@1 90.625 (88.743)\tPrec@5 100.000 (99.659)\t\n",
            "EVALUATING - Epoch: [60][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.5045 (0.3872)\tPrec@1 93.750 (88.710)\tPrec@5 100.000 (99.660)\t\n",
            "\n",
            "Results - Epoch: 61\n",
            "Training Loss 0.1639 \tTraining Prec@1 94.165 \tTraining Prec@5 99.934 \tValidation Loss 0.3872 \tValidation Prec@1 88.710 \tValidation Prec@5 99.660 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 62\n",
            "\n",
            "TRAINING - Epoch: [61][0/390]\tTime 0.391 (0.391)\tData 0.280 (0.280)\tLoss 0.1303 (0.1303)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [61][10/390]\tTime 0.052 (0.088)\tData 0.006 (0.028)\tLoss 0.1684 (0.1611)\tPrec@1 92.969 (94.389)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [61][20/390]\tTime 0.064 (0.073)\tData 0.009 (0.017)\tLoss 0.1416 (0.1397)\tPrec@1 95.312 (95.164)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [61][30/390]\tTime 0.059 (0.067)\tData 0.000 (0.012)\tLoss 0.1911 (0.1423)\tPrec@1 92.188 (95.010)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [61][40/390]\tTime 0.050 (0.064)\tData 0.000 (0.010)\tLoss 0.1445 (0.1435)\tPrec@1 92.969 (94.970)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [61][50/390]\tTime 0.061 (0.062)\tData 0.007 (0.008)\tLoss 0.0931 (0.1437)\tPrec@1 96.875 (95.037)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [61][60/390]\tTime 0.050 (0.061)\tData 0.000 (0.008)\tLoss 0.1206 (0.1411)\tPrec@1 96.094 (95.005)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [61][70/390]\tTime 0.049 (0.061)\tData 0.000 (0.007)\tLoss 0.1231 (0.1375)\tPrec@1 93.750 (95.092)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [61][80/390]\tTime 0.050 (0.060)\tData 0.000 (0.007)\tLoss 0.2013 (0.1395)\tPrec@1 92.188 (94.985)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [61][90/390]\tTime 0.052 (0.059)\tData 0.000 (0.006)\tLoss 0.2683 (0.1391)\tPrec@1 89.844 (94.952)\tPrec@5 99.219 (99.974)\t\n",
            "TRAINING - Epoch: [61][100/390]\tTime 0.050 (0.059)\tData 0.003 (0.006)\tLoss 0.1626 (0.1426)\tPrec@1 95.312 (94.910)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [61][110/390]\tTime 0.069 (0.059)\tData 0.007 (0.006)\tLoss 0.1823 (0.1440)\tPrec@1 92.969 (94.855)\tPrec@5 100.000 (99.965)\t\n",
            "TRAINING - Epoch: [61][120/390]\tTime 0.056 (0.059)\tData 0.007 (0.006)\tLoss 0.1654 (0.1469)\tPrec@1 96.094 (94.770)\tPrec@5 99.219 (99.955)\t\n",
            "TRAINING - Epoch: [61][130/390]\tTime 0.051 (0.058)\tData 0.000 (0.006)\tLoss 0.1789 (0.1498)\tPrec@1 95.312 (94.704)\tPrec@5 100.000 (99.952)\t\n",
            "TRAINING - Epoch: [61][140/390]\tTime 0.060 (0.058)\tData 0.007 (0.006)\tLoss 0.1996 (0.1490)\tPrec@1 94.531 (94.714)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [61][150/390]\tTime 0.048 (0.058)\tData 0.000 (0.006)\tLoss 0.1752 (0.1494)\tPrec@1 92.969 (94.666)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [61][160/390]\tTime 0.064 (0.058)\tData 0.007 (0.005)\tLoss 0.2315 (0.1501)\tPrec@1 92.188 (94.628)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [61][170/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1448 (0.1499)\tPrec@1 95.312 (94.632)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [61][180/390]\tTime 0.057 (0.058)\tData 0.007 (0.005)\tLoss 0.0698 (0.1502)\tPrec@1 97.656 (94.587)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [61][190/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.2224 (0.1517)\tPrec@1 93.750 (94.523)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [61][200/390]\tTime 0.060 (0.057)\tData 0.002 (0.005)\tLoss 0.1447 (0.1547)\tPrec@1 96.094 (94.411)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [61][210/390]\tTime 0.062 (0.057)\tData 0.006 (0.005)\tLoss 0.1285 (0.1544)\tPrec@1 92.969 (94.416)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [61][220/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.1246 (0.1549)\tPrec@1 96.094 (94.393)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [61][230/390]\tTime 0.060 (0.057)\tData 0.007 (0.005)\tLoss 0.2837 (0.1565)\tPrec@1 91.406 (94.359)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [61][240/390]\tTime 0.062 (0.057)\tData 0.000 (0.005)\tLoss 0.1337 (0.1576)\tPrec@1 95.312 (94.327)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [61][250/390]\tTime 0.049 (0.057)\tData 0.000 (0.005)\tLoss 0.2636 (0.1581)\tPrec@1 95.312 (94.332)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [61][260/390]\tTime 0.052 (0.057)\tData 0.000 (0.005)\tLoss 0.1482 (0.1581)\tPrec@1 93.750 (94.349)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [61][270/390]\tTime 0.052 (0.057)\tData 0.000 (0.005)\tLoss 0.1128 (0.1585)\tPrec@1 96.875 (94.341)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [61][280/390]\tTime 0.082 (0.057)\tData 0.007 (0.005)\tLoss 0.2590 (0.1592)\tPrec@1 91.406 (94.306)\tPrec@5 99.219 (99.956)\t\n",
            "TRAINING - Epoch: [61][290/390]\tTime 0.068 (0.057)\tData 0.013 (0.005)\tLoss 0.1938 (0.1605)\tPrec@1 92.969 (94.276)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [61][300/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.1194 (0.1611)\tPrec@1 96.875 (94.277)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [61][310/390]\tTime 0.058 (0.057)\tData 0.001 (0.004)\tLoss 0.2145 (0.1619)\tPrec@1 93.750 (94.278)\tPrec@5 99.219 (99.947)\t\n",
            "TRAINING - Epoch: [61][320/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1125 (0.1617)\tPrec@1 94.531 (94.273)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [61][330/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2018 (0.1623)\tPrec@1 92.969 (94.267)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [61][340/390]\tTime 0.061 (0.057)\tData 0.007 (0.004)\tLoss 0.2003 (0.1635)\tPrec@1 90.625 (94.213)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [61][350/390]\tTime 0.066 (0.057)\tData 0.011 (0.004)\tLoss 0.1947 (0.1639)\tPrec@1 92.969 (94.186)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [61][360/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.1903 (0.1645)\tPrec@1 93.750 (94.157)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [61][370/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.1492 (0.1652)\tPrec@1 94.531 (94.135)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [61][380/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.1065 (0.1664)\tPrec@1 96.875 (94.113)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [61][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.1788 (0.1661)\tPrec@1 93.750 (94.119)\tPrec@5 100.000 (99.948)\t\n",
            "EVALUATING - Epoch: [61][0/79]\tTime 0.280 (0.280)\tData 0.250 (0.250)\tLoss 0.3013 (0.3013)\tPrec@1 91.406 (91.406)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [61][10/79]\tTime 0.028 (0.053)\tData 0.004 (0.028)\tLoss 0.3619 (0.4051)\tPrec@1 90.625 (88.494)\tPrec@5 100.000 (99.716)\t\n",
            "EVALUATING - Epoch: [61][20/79]\tTime 0.022 (0.042)\tData 0.005 (0.017)\tLoss 0.3801 (0.4165)\tPrec@1 86.719 (88.318)\tPrec@5 99.219 (99.479)\t\n",
            "EVALUATING - Epoch: [61][30/79]\tTime 0.024 (0.038)\tData 0.001 (0.014)\tLoss 0.2651 (0.4163)\tPrec@1 89.844 (88.155)\tPrec@5 100.000 (99.496)\t\n",
            "EVALUATING - Epoch: [61][40/79]\tTime 0.038 (0.037)\tData 0.018 (0.012)\tLoss 0.5690 (0.4135)\tPrec@1 82.812 (88.072)\tPrec@5 100.000 (99.466)\t\n",
            "EVALUATING - Epoch: [61][50/79]\tTime 0.014 (0.035)\tData 0.000 (0.011)\tLoss 0.4868 (0.4156)\tPrec@1 85.156 (88.051)\tPrec@5 99.219 (99.525)\t\n",
            "EVALUATING - Epoch: [61][60/79]\tTime 0.034 (0.034)\tData 0.000 (0.010)\tLoss 0.3402 (0.4139)\tPrec@1 90.625 (87.961)\tPrec@5 100.000 (99.501)\t\n",
            "EVALUATING - Epoch: [61][70/79]\tTime 0.032 (0.033)\tData 0.006 (0.009)\tLoss 0.2718 (0.4167)\tPrec@1 91.406 (87.819)\tPrec@5 100.000 (99.505)\t\n",
            "EVALUATING - Epoch: [61][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.008)\tLoss 0.1110 (0.4124)\tPrec@1 93.750 (87.880)\tPrec@5 100.000 (99.540)\t\n",
            "\n",
            "Results - Epoch: 62\n",
            "Training Loss 0.1661 \tTraining Prec@1 94.119 \tTraining Prec@5 99.948 \tValidation Loss 0.4124 \tValidation Prec@1 87.880 \tValidation Prec@5 99.540 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 63\n",
            "\n",
            "TRAINING - Epoch: [62][0/390]\tTime 0.265 (0.265)\tData 0.181 (0.181)\tLoss 0.0954 (0.0954)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [62][10/390]\tTime 0.047 (0.087)\tData 0.000 (0.023)\tLoss 0.1269 (0.1226)\tPrec@1 96.094 (96.307)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [62][20/390]\tTime 0.061 (0.072)\tData 0.000 (0.013)\tLoss 0.0765 (0.1375)\tPrec@1 96.875 (95.275)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [62][30/390]\tTime 0.048 (0.066)\tData 0.000 (0.010)\tLoss 0.0775 (0.1398)\tPrec@1 98.438 (95.338)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [62][40/390]\tTime 0.051 (0.063)\tData 0.000 (0.008)\tLoss 0.1963 (0.1431)\tPrec@1 93.750 (95.084)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [62][50/390]\tTime 0.064 (0.062)\tData 0.012 (0.007)\tLoss 0.1123 (0.1415)\tPrec@1 96.094 (94.991)\tPrec@5 100.000 (99.985)\t\n",
            "TRAINING - Epoch: [62][60/390]\tTime 0.053 (0.061)\tData 0.006 (0.007)\tLoss 0.1795 (0.1433)\tPrec@1 91.406 (94.736)\tPrec@5 100.000 (99.987)\t\n",
            "TRAINING - Epoch: [62][70/390]\tTime 0.048 (0.060)\tData 0.000 (0.006)\tLoss 0.2266 (0.1426)\tPrec@1 92.188 (94.751)\tPrec@5 100.000 (99.989)\t\n",
            "TRAINING - Epoch: [62][80/390]\tTime 0.064 (0.059)\tData 0.007 (0.006)\tLoss 0.1152 (0.1447)\tPrec@1 96.875 (94.628)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [62][90/390]\tTime 0.053 (0.059)\tData 0.006 (0.006)\tLoss 0.1288 (0.1446)\tPrec@1 94.531 (94.651)\tPrec@5 100.000 (99.983)\t\n",
            "TRAINING - Epoch: [62][100/390]\tTime 0.046 (0.058)\tData 0.000 (0.005)\tLoss 0.2073 (0.1469)\tPrec@1 92.188 (94.601)\tPrec@5 100.000 (99.985)\t\n",
            "TRAINING - Epoch: [62][110/390]\tTime 0.055 (0.058)\tData 0.007 (0.005)\tLoss 0.1880 (0.1481)\tPrec@1 94.531 (94.616)\tPrec@5 100.000 (99.979)\t\n",
            "TRAINING - Epoch: [62][120/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1428 (0.1474)\tPrec@1 95.312 (94.667)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [62][130/390]\tTime 0.069 (0.058)\tData 0.007 (0.005)\tLoss 0.1980 (0.1473)\tPrec@1 92.969 (94.645)\tPrec@5 100.000 (99.976)\t\n",
            "TRAINING - Epoch: [62][140/390]\tTime 0.056 (0.058)\tData 0.007 (0.005)\tLoss 0.0641 (0.1472)\tPrec@1 98.438 (94.714)\tPrec@5 100.000 (99.972)\t\n",
            "TRAINING - Epoch: [62][150/390]\tTime 0.059 (0.058)\tData 0.009 (0.005)\tLoss 0.2252 (0.1482)\tPrec@1 90.625 (94.671)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [62][160/390]\tTime 0.058 (0.058)\tData 0.009 (0.005)\tLoss 0.2054 (0.1488)\tPrec@1 93.750 (94.672)\tPrec@5 100.000 (99.971)\t\n",
            "TRAINING - Epoch: [62][170/390]\tTime 0.055 (0.057)\tData 0.008 (0.005)\tLoss 0.1638 (0.1484)\tPrec@1 94.531 (94.691)\tPrec@5 100.000 (99.973)\t\n",
            "TRAINING - Epoch: [62][180/390]\tTime 0.063 (0.057)\tData 0.007 (0.005)\tLoss 0.2432 (0.1491)\tPrec@1 94.531 (94.669)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [62][190/390]\tTime 0.050 (0.057)\tData 0.000 (0.005)\tLoss 0.0913 (0.1497)\tPrec@1 96.094 (94.638)\tPrec@5 100.000 (99.971)\t\n",
            "TRAINING - Epoch: [62][200/390]\tTime 0.051 (0.057)\tData 0.000 (0.005)\tLoss 0.0767 (0.1509)\tPrec@1 96.875 (94.558)\tPrec@5 100.000 (99.973)\t\n",
            "TRAINING - Epoch: [62][210/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.2809 (0.1511)\tPrec@1 91.406 (94.568)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [62][220/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.1524 (0.1521)\tPrec@1 94.531 (94.560)\tPrec@5 100.000 (99.968)\t\n",
            "TRAINING - Epoch: [62][230/390]\tTime 0.059 (0.057)\tData 0.000 (0.004)\tLoss 0.1700 (0.1531)\tPrec@1 95.312 (94.528)\tPrec@5 100.000 (99.970)\t\n",
            "TRAINING - Epoch: [62][240/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1627 (0.1537)\tPrec@1 95.312 (94.509)\tPrec@5 100.000 (99.968)\t\n",
            "TRAINING - Epoch: [62][250/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.2315 (0.1547)\tPrec@1 91.406 (94.488)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [62][260/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.1142 (0.1550)\tPrec@1 94.531 (94.456)\tPrec@5 100.000 (99.964)\t\n",
            "TRAINING - Epoch: [62][270/390]\tTime 0.065 (0.057)\tData 0.011 (0.004)\tLoss 0.1518 (0.1555)\tPrec@1 93.750 (94.433)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [62][280/390]\tTime 0.058 (0.057)\tData 0.008 (0.004)\tLoss 0.1862 (0.1573)\tPrec@1 92.969 (94.384)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [62][290/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.1389 (0.1571)\tPrec@1 94.531 (94.397)\tPrec@5 100.000 (99.960)\t\n",
            "TRAINING - Epoch: [62][300/390]\tTime 0.061 (0.057)\tData 0.010 (0.004)\tLoss 0.1206 (0.1578)\tPrec@1 95.312 (94.378)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [62][310/390]\tTime 0.056 (0.057)\tData 0.008 (0.004)\tLoss 0.2623 (0.1589)\tPrec@1 90.625 (94.333)\tPrec@5 100.000 (99.960)\t\n",
            "TRAINING - Epoch: [62][320/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.2623 (0.1592)\tPrec@1 92.188 (94.322)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [62][330/390]\tTime 0.054 (0.057)\tData 0.000 (0.004)\tLoss 0.1701 (0.1590)\tPrec@1 93.750 (94.331)\tPrec@5 100.000 (99.960)\t\n",
            "TRAINING - Epoch: [62][340/390]\tTime 0.058 (0.057)\tData 0.000 (0.004)\tLoss 0.1771 (0.1587)\tPrec@1 94.531 (94.346)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [62][350/390]\tTime 0.052 (0.057)\tData 0.004 (0.004)\tLoss 0.1267 (0.1595)\tPrec@1 94.531 (94.324)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [62][360/390]\tTime 0.060 (0.057)\tData 0.011 (0.004)\tLoss 0.1811 (0.1599)\tPrec@1 92.969 (94.298)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [62][370/390]\tTime 0.056 (0.057)\tData 0.006 (0.004)\tLoss 0.3017 (0.1606)\tPrec@1 88.281 (94.287)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [62][380/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.1690 (0.1606)\tPrec@1 92.969 (94.310)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [62][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.1577 (0.1608)\tPrec@1 95.312 (94.303)\tPrec@5 100.000 (99.960)\t\n",
            "EVALUATING - Epoch: [62][0/79]\tTime 0.252 (0.252)\tData 0.219 (0.219)\tLoss 0.4584 (0.4584)\tPrec@1 84.375 (84.375)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [62][10/79]\tTime 0.030 (0.051)\tData 0.000 (0.023)\tLoss 0.5061 (0.4715)\tPrec@1 82.812 (85.724)\tPrec@5 99.219 (99.077)\t\n",
            "EVALUATING - Epoch: [62][20/79]\tTime 0.019 (0.042)\tData 0.001 (0.014)\tLoss 0.4930 (0.5048)\tPrec@1 85.938 (85.714)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [62][30/79]\tTime 0.043 (0.040)\tData 0.007 (0.012)\tLoss 0.3404 (0.4899)\tPrec@1 85.938 (85.938)\tPrec@5 100.000 (99.168)\t\n",
            "EVALUATING - Epoch: [62][40/79]\tTime 0.026 (0.037)\tData 0.005 (0.010)\tLoss 0.6074 (0.4901)\tPrec@1 84.375 (85.785)\tPrec@5 100.000 (99.238)\t\n",
            "EVALUATING - Epoch: [62][50/79]\tTime 0.032 (0.036)\tData 0.010 (0.009)\tLoss 0.3165 (0.4830)\tPrec@1 90.625 (86.091)\tPrec@5 100.000 (99.326)\t\n",
            "EVALUATING - Epoch: [62][60/79]\tTime 0.029 (0.035)\tData 0.005 (0.008)\tLoss 0.5855 (0.4899)\tPrec@1 87.500 (86.091)\tPrec@5 99.219 (99.347)\t\n",
            "EVALUATING - Epoch: [62][70/79]\tTime 0.030 (0.034)\tData 0.000 (0.007)\tLoss 0.4034 (0.4969)\tPrec@1 88.281 (85.960)\tPrec@5 100.000 (99.362)\t\n",
            "EVALUATING - Epoch: [62][78/79]\tTime 0.006 (0.032)\tData 0.000 (0.007)\tLoss 0.1532 (0.4940)\tPrec@1 93.750 (86.100)\tPrec@5 100.000 (99.360)\t\n",
            "\n",
            "Results - Epoch: 63\n",
            "Training Loss 0.1608 \tTraining Prec@1 94.303 \tTraining Prec@5 99.960 \tValidation Loss 0.4940 \tValidation Prec@1 86.100 \tValidation Prec@5 99.360 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 64\n",
            "\n",
            "TRAINING - Epoch: [63][0/390]\tTime 0.327 (0.327)\tData 0.201 (0.201)\tLoss 0.1655 (0.1655)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [63][10/390]\tTime 0.056 (0.090)\tData 0.007 (0.023)\tLoss 0.1504 (0.1400)\tPrec@1 94.531 (95.526)\tPrec@5 99.219 (99.858)\t\n",
            "TRAINING - Epoch: [63][20/390]\tTime 0.067 (0.074)\tData 0.010 (0.015)\tLoss 0.1137 (0.1381)\tPrec@1 94.531 (95.536)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [63][30/390]\tTime 0.054 (0.068)\tData 0.007 (0.011)\tLoss 0.1722 (0.1417)\tPrec@1 92.969 (95.237)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [63][40/390]\tTime 0.048 (0.065)\tData 0.000 (0.010)\tLoss 0.0923 (0.1396)\tPrec@1 97.656 (95.160)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [63][50/390]\tTime 0.066 (0.063)\tData 0.013 (0.009)\tLoss 0.2653 (0.1439)\tPrec@1 91.406 (95.083)\tPrec@5 99.219 (99.939)\t\n",
            "TRAINING - Epoch: [63][60/390]\tTime 0.054 (0.062)\tData 0.000 (0.008)\tLoss 0.0982 (0.1416)\tPrec@1 97.656 (95.223)\tPrec@5 99.219 (99.923)\t\n",
            "TRAINING - Epoch: [63][70/390]\tTime 0.048 (0.061)\tData 0.000 (0.007)\tLoss 0.3309 (0.1447)\tPrec@1 89.844 (95.114)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [63][80/390]\tTime 0.059 (0.060)\tData 0.007 (0.007)\tLoss 0.1067 (0.1431)\tPrec@1 96.875 (95.129)\tPrec@5 100.000 (99.932)\t\n",
            "TRAINING - Epoch: [63][90/390]\tTime 0.051 (0.060)\tData 0.000 (0.006)\tLoss 0.1364 (0.1409)\tPrec@1 94.531 (95.201)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [63][100/390]\tTime 0.065 (0.060)\tData 0.000 (0.006)\tLoss 0.1583 (0.1410)\tPrec@1 95.312 (95.227)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [63][110/390]\tTime 0.054 (0.059)\tData 0.006 (0.006)\tLoss 0.1245 (0.1418)\tPrec@1 96.094 (95.172)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [63][120/390]\tTime 0.069 (0.059)\tData 0.006 (0.006)\tLoss 0.1734 (0.1432)\tPrec@1 94.531 (95.099)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [63][130/390]\tTime 0.051 (0.059)\tData 0.004 (0.006)\tLoss 0.2086 (0.1461)\tPrec@1 92.969 (94.943)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [63][140/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.1240 (0.1477)\tPrec@1 96.094 (94.869)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [63][150/390]\tTime 0.059 (0.058)\tData 0.010 (0.005)\tLoss 0.0805 (0.1482)\tPrec@1 96.875 (94.821)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [63][160/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.2122 (0.1488)\tPrec@1 91.406 (94.822)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [63][170/390]\tTime 0.059 (0.058)\tData 0.007 (0.005)\tLoss 0.1774 (0.1501)\tPrec@1 92.188 (94.773)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [63][180/390]\tTime 0.054 (0.057)\tData 0.000 (0.005)\tLoss 0.1910 (0.1526)\tPrec@1 92.969 (94.682)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [63][190/390]\tTime 0.062 (0.057)\tData 0.007 (0.005)\tLoss 0.1511 (0.1534)\tPrec@1 96.094 (94.629)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [63][200/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.1568 (0.1552)\tPrec@1 95.312 (94.605)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [63][210/390]\tTime 0.062 (0.057)\tData 0.000 (0.005)\tLoss 0.2228 (0.1566)\tPrec@1 92.969 (94.565)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [63][220/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.0902 (0.1563)\tPrec@1 97.656 (94.584)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [63][230/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.1218 (0.1570)\tPrec@1 95.312 (94.548)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [63][240/390]\tTime 0.055 (0.057)\tData 0.000 (0.005)\tLoss 0.2062 (0.1579)\tPrec@1 93.750 (94.512)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [63][250/390]\tTime 0.055 (0.057)\tData 0.000 (0.004)\tLoss 0.2026 (0.1585)\tPrec@1 92.969 (94.460)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [63][260/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1639 (0.1589)\tPrec@1 95.312 (94.447)\tPrec@5 99.219 (99.949)\t\n",
            "TRAINING - Epoch: [63][270/390]\tTime 0.054 (0.057)\tData 0.007 (0.004)\tLoss 0.2572 (0.1597)\tPrec@1 92.969 (94.427)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [63][280/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.1555 (0.1604)\tPrec@1 94.531 (94.387)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [63][290/390]\tTime 0.060 (0.057)\tData 0.012 (0.004)\tLoss 0.1190 (0.1613)\tPrec@1 93.750 (94.338)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [63][300/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.1398 (0.1618)\tPrec@1 95.312 (94.298)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [63][310/390]\tTime 0.059 (0.056)\tData 0.007 (0.004)\tLoss 0.1426 (0.1631)\tPrec@1 92.969 (94.283)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [63][320/390]\tTime 0.053 (0.056)\tData 0.000 (0.004)\tLoss 0.1808 (0.1637)\tPrec@1 92.969 (94.254)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [63][330/390]\tTime 0.052 (0.056)\tData 0.000 (0.004)\tLoss 0.2916 (0.1641)\tPrec@1 88.281 (94.229)\tPrec@5 99.219 (99.953)\t\n",
            "TRAINING - Epoch: [63][340/390]\tTime 0.065 (0.056)\tData 0.006 (0.004)\tLoss 0.1215 (0.1640)\tPrec@1 96.094 (94.233)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [63][350/390]\tTime 0.054 (0.056)\tData 0.007 (0.004)\tLoss 0.0737 (0.1640)\tPrec@1 99.219 (94.237)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [63][360/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.2602 (0.1645)\tPrec@1 89.844 (94.220)\tPrec@5 99.219 (99.948)\t\n",
            "TRAINING - Epoch: [63][370/390]\tTime 0.050 (0.056)\tData 0.000 (0.004)\tLoss 0.1221 (0.1643)\tPrec@1 96.094 (94.226)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [63][380/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.1524 (0.1646)\tPrec@1 97.656 (94.218)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [63][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.1096 (0.1644)\tPrec@1 96.875 (94.233)\tPrec@5 100.000 (99.946)\t\n",
            "EVALUATING - Epoch: [63][0/79]\tTime 0.255 (0.255)\tData 0.219 (0.219)\tLoss 0.3386 (0.3386)\tPrec@1 85.938 (85.938)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [63][10/79]\tTime 0.021 (0.052)\tData 0.000 (0.025)\tLoss 0.2572 (0.3557)\tPrec@1 92.969 (89.134)\tPrec@5 99.219 (99.645)\t\n",
            "EVALUATING - Epoch: [63][20/79]\tTime 0.012 (0.040)\tData 0.000 (0.015)\tLoss 0.4137 (0.3700)\tPrec@1 87.500 (89.435)\tPrec@5 100.000 (99.591)\t\n",
            "EVALUATING - Epoch: [63][30/79]\tTime 0.034 (0.037)\tData 0.007 (0.013)\tLoss 0.2368 (0.3708)\tPrec@1 92.969 (89.516)\tPrec@5 100.000 (99.521)\t\n",
            "EVALUATING - Epoch: [63][40/79]\tTime 0.022 (0.036)\tData 0.000 (0.010)\tLoss 0.2898 (0.3726)\tPrec@1 91.406 (89.367)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [63][50/79]\tTime 0.027 (0.034)\tData 0.000 (0.009)\tLoss 0.4083 (0.3681)\tPrec@1 88.281 (89.537)\tPrec@5 100.000 (99.571)\t\n",
            "EVALUATING - Epoch: [63][60/79]\tTime 0.032 (0.033)\tData 0.005 (0.009)\tLoss 0.2644 (0.3728)\tPrec@1 90.625 (89.344)\tPrec@5 99.219 (99.552)\t\n",
            "EVALUATING - Epoch: [63][70/79]\tTime 0.044 (0.033)\tData 0.008 (0.008)\tLoss 0.2823 (0.3728)\tPrec@1 90.625 (89.107)\tPrec@5 100.000 (99.582)\t\n",
            "EVALUATING - Epoch: [63][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.5006 (0.3722)\tPrec@1 93.750 (89.160)\tPrec@5 100.000 (99.580)\t\n",
            "\n",
            "Results - Epoch: 64\n",
            "Training Loss 0.1644 \tTraining Prec@1 94.233 \tTraining Prec@5 99.946 \tValidation Loss 0.3722 \tValidation Prec@1 89.160 \tValidation Prec@5 99.580 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 65\n",
            "\n",
            "TRAINING - Epoch: [64][0/390]\tTime 0.353 (0.353)\tData 0.271 (0.271)\tLoss 0.1744 (0.1744)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [64][10/390]\tTime 0.048 (0.086)\tData 0.000 (0.027)\tLoss 0.2201 (0.1393)\tPrec@1 92.188 (95.170)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [64][20/390]\tTime 0.057 (0.071)\tData 0.010 (0.016)\tLoss 0.0983 (0.1362)\tPrec@1 96.875 (95.387)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [64][30/390]\tTime 0.047 (0.066)\tData 0.000 (0.012)\tLoss 0.0794 (0.1390)\tPrec@1 98.438 (95.287)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [64][40/390]\tTime 0.059 (0.063)\tData 0.007 (0.010)\tLoss 0.1940 (0.1372)\tPrec@1 93.750 (95.179)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [64][50/390]\tTime 0.048 (0.062)\tData 0.000 (0.009)\tLoss 0.2267 (0.1387)\tPrec@1 92.969 (95.098)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [64][60/390]\tTime 0.049 (0.060)\tData 0.000 (0.008)\tLoss 0.0888 (0.1357)\tPrec@1 96.875 (95.300)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [64][70/390]\tTime 0.064 (0.060)\tData 0.000 (0.007)\tLoss 0.1111 (0.1331)\tPrec@1 94.531 (95.312)\tPrec@5 100.000 (99.967)\t\n",
            "TRAINING - Epoch: [64][80/390]\tTime 0.047 (0.059)\tData 0.000 (0.007)\tLoss 0.1390 (0.1357)\tPrec@1 95.312 (95.255)\tPrec@5 100.000 (99.971)\t\n",
            "TRAINING - Epoch: [64][90/390]\tTime 0.057 (0.059)\tData 0.006 (0.006)\tLoss 0.0600 (0.1321)\tPrec@1 97.656 (95.373)\tPrec@5 100.000 (99.966)\t\n",
            "TRAINING - Epoch: [64][100/390]\tTime 0.054 (0.059)\tData 0.007 (0.006)\tLoss 0.0930 (0.1318)\tPrec@1 96.875 (95.336)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [64][110/390]\tTime 0.054 (0.058)\tData 0.006 (0.006)\tLoss 0.1337 (0.1331)\tPrec@1 96.094 (95.305)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [64][120/390]\tTime 0.050 (0.059)\tData 0.000 (0.006)\tLoss 0.2012 (0.1327)\tPrec@1 96.094 (95.377)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [64][130/390]\tTime 0.053 (0.059)\tData 0.000 (0.006)\tLoss 0.2305 (0.1366)\tPrec@1 90.625 (95.235)\tPrec@5 100.000 (99.952)\t\n",
            "TRAINING - Epoch: [64][140/390]\tTime 0.050 (0.059)\tData 0.000 (0.005)\tLoss 0.2025 (0.1409)\tPrec@1 91.406 (95.069)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [64][150/390]\tTime 0.056 (0.058)\tData 0.000 (0.005)\tLoss 0.2507 (0.1427)\tPrec@1 91.406 (95.002)\tPrec@5 99.219 (99.943)\t\n",
            "TRAINING - Epoch: [64][160/390]\tTime 0.055 (0.058)\tData 0.000 (0.005)\tLoss 0.1151 (0.1460)\tPrec@1 97.656 (94.890)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [64][170/390]\tTime 0.054 (0.058)\tData 0.000 (0.005)\tLoss 0.2200 (0.1467)\tPrec@1 91.406 (94.874)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [64][180/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2161 (0.1466)\tPrec@1 90.625 (94.864)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [64][190/390]\tTime 0.055 (0.058)\tData 0.007 (0.005)\tLoss 0.1062 (0.1470)\tPrec@1 96.094 (94.842)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [64][200/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.2706 (0.1479)\tPrec@1 93.750 (94.815)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [64][210/390]\tTime 0.069 (0.058)\tData 0.000 (0.004)\tLoss 0.2270 (0.1487)\tPrec@1 89.844 (94.776)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [64][220/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.0843 (0.1495)\tPrec@1 96.094 (94.754)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [64][230/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.0925 (0.1498)\tPrec@1 95.312 (94.734)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [64][240/390]\tTime 0.059 (0.057)\tData 0.008 (0.004)\tLoss 0.1237 (0.1505)\tPrec@1 96.094 (94.706)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [64][250/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1552 (0.1512)\tPrec@1 94.531 (94.668)\tPrec@5 100.000 (99.941)\t\n",
            "TRAINING - Epoch: [64][260/390]\tTime 0.054 (0.057)\tData 0.007 (0.004)\tLoss 0.1958 (0.1520)\tPrec@1 92.969 (94.657)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [64][270/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.1401 (0.1529)\tPrec@1 93.750 (94.632)\tPrec@5 99.219 (99.937)\t\n",
            "TRAINING - Epoch: [64][280/390]\tTime 0.061 (0.057)\tData 0.007 (0.004)\tLoss 0.2144 (0.1533)\tPrec@1 92.188 (94.617)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [64][290/390]\tTime 0.050 (0.057)\tData 0.003 (0.004)\tLoss 0.1608 (0.1543)\tPrec@1 93.750 (94.577)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [64][300/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.2255 (0.1552)\tPrec@1 89.844 (94.536)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [64][310/390]\tTime 0.065 (0.057)\tData 0.007 (0.004)\tLoss 0.1195 (0.1552)\tPrec@1 97.656 (94.556)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [64][320/390]\tTime 0.055 (0.057)\tData 0.009 (0.004)\tLoss 0.1165 (0.1558)\tPrec@1 96.094 (94.541)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [64][330/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1566 (0.1559)\tPrec@1 94.531 (94.548)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [64][340/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.1161 (0.1559)\tPrec@1 95.312 (94.547)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [64][350/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1317 (0.1561)\tPrec@1 94.531 (94.540)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [64][360/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.0960 (0.1560)\tPrec@1 96.094 (94.542)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [64][370/390]\tTime 0.054 (0.057)\tData 0.006 (0.004)\tLoss 0.1692 (0.1563)\tPrec@1 96.094 (94.531)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [64][380/390]\tTime 0.050 (0.057)\tData 0.004 (0.004)\tLoss 0.0934 (0.1566)\tPrec@1 96.875 (94.519)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [64][389/390]\tTime 0.043 (0.056)\tData 0.000 (0.004)\tLoss 0.1215 (0.1567)\tPrec@1 93.750 (94.507)\tPrec@5 100.000 (99.936)\t\n",
            "EVALUATING - Epoch: [64][0/79]\tTime 0.236 (0.236)\tData 0.195 (0.195)\tLoss 0.3792 (0.3792)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [64][10/79]\tTime 0.018 (0.055)\tData 0.000 (0.023)\tLoss 0.3046 (0.4085)\tPrec@1 89.844 (87.855)\tPrec@5 100.000 (99.574)\t\n",
            "EVALUATING - Epoch: [64][20/79]\tTime 0.012 (0.043)\tData 0.000 (0.015)\tLoss 0.3247 (0.4098)\tPrec@1 90.625 (88.095)\tPrec@5 100.000 (99.628)\t\n",
            "EVALUATING - Epoch: [64][30/79]\tTime 0.042 (0.040)\tData 0.012 (0.012)\tLoss 0.2672 (0.4199)\tPrec@1 92.969 (88.180)\tPrec@5 100.000 (99.496)\t\n",
            "EVALUATING - Epoch: [64][40/79]\tTime 0.033 (0.036)\tData 0.005 (0.010)\tLoss 0.5379 (0.4102)\tPrec@1 79.688 (88.224)\tPrec@5 100.000 (99.466)\t\n",
            "EVALUATING - Epoch: [64][50/79]\tTime 0.041 (0.035)\tData 0.005 (0.009)\tLoss 0.4743 (0.4054)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.449)\t\n",
            "EVALUATING - Epoch: [64][60/79]\tTime 0.034 (0.035)\tData 0.008 (0.008)\tLoss 0.4822 (0.4086)\tPrec@1 88.281 (88.384)\tPrec@5 99.219 (99.436)\t\n",
            "EVALUATING - Epoch: [64][70/79]\tTime 0.041 (0.034)\tData 0.003 (0.007)\tLoss 0.3036 (0.4099)\tPrec@1 95.312 (88.325)\tPrec@5 100.000 (99.494)\t\n",
            "EVALUATING - Epoch: [64][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.006)\tLoss 0.5675 (0.4078)\tPrec@1 93.750 (88.430)\tPrec@5 100.000 (99.510)\t\n",
            "\n",
            "Results - Epoch: 65\n",
            "Training Loss 0.1567 \tTraining Prec@1 94.507 \tTraining Prec@5 99.936 \tValidation Loss 0.4078 \tValidation Prec@1 88.430 \tValidation Prec@5 99.510 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 66\n",
            "\n",
            "TRAINING - Epoch: [65][0/390]\tTime 0.351 (0.351)\tData 0.213 (0.213)\tLoss 0.1061 (0.1061)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [65][10/390]\tTime 0.056 (0.090)\tData 0.006 (0.022)\tLoss 0.1390 (0.1500)\tPrec@1 96.094 (94.886)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [65][20/390]\tTime 0.053 (0.073)\tData 0.000 (0.012)\tLoss 0.1342 (0.1375)\tPrec@1 95.312 (95.499)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [65][30/390]\tTime 0.048 (0.068)\tData 0.000 (0.010)\tLoss 0.0874 (0.1385)\tPrec@1 95.312 (95.413)\tPrec@5 100.000 (99.924)\t\n",
            "TRAINING - Epoch: [65][40/390]\tTime 0.058 (0.065)\tData 0.007 (0.008)\tLoss 0.1567 (0.1356)\tPrec@1 93.750 (95.522)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [65][50/390]\tTime 0.053 (0.064)\tData 0.000 (0.007)\tLoss 0.1354 (0.1333)\tPrec@1 96.094 (95.619)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [65][60/390]\tTime 0.060 (0.063)\tData 0.007 (0.007)\tLoss 0.1481 (0.1376)\tPrec@1 95.312 (95.479)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [65][70/390]\tTime 0.069 (0.062)\tData 0.000 (0.006)\tLoss 0.1469 (0.1397)\tPrec@1 92.969 (95.324)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [65][80/390]\tTime 0.048 (0.061)\tData 0.000 (0.006)\tLoss 0.1336 (0.1373)\tPrec@1 92.969 (95.322)\tPrec@5 100.000 (99.952)\t\n",
            "TRAINING - Epoch: [65][90/390]\tTime 0.048 (0.060)\tData 0.000 (0.006)\tLoss 0.1353 (0.1388)\tPrec@1 93.750 (95.270)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [65][100/390]\tTime 0.046 (0.060)\tData 0.000 (0.005)\tLoss 0.1329 (0.1408)\tPrec@1 95.312 (95.158)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [65][110/390]\tTime 0.061 (0.060)\tData 0.012 (0.005)\tLoss 0.1200 (0.1415)\tPrec@1 96.875 (95.122)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [65][120/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.2205 (0.1448)\tPrec@1 90.625 (94.944)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [65][130/390]\tTime 0.074 (0.059)\tData 0.011 (0.005)\tLoss 0.1752 (0.1468)\tPrec@1 91.406 (94.853)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [65][140/390]\tTime 0.048 (0.059)\tData 0.000 (0.005)\tLoss 0.2319 (0.1475)\tPrec@1 91.406 (94.858)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [65][150/390]\tTime 0.058 (0.059)\tData 0.009 (0.005)\tLoss 0.1288 (0.1491)\tPrec@1 94.531 (94.837)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [65][160/390]\tTime 0.059 (0.059)\tData 0.000 (0.005)\tLoss 0.1278 (0.1501)\tPrec@1 96.094 (94.803)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [65][170/390]\tTime 0.051 (0.059)\tData 0.003 (0.005)\tLoss 0.3067 (0.1509)\tPrec@1 87.500 (94.783)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [65][180/390]\tTime 0.059 (0.059)\tData 0.000 (0.005)\tLoss 0.0969 (0.1506)\tPrec@1 96.094 (94.795)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [65][190/390]\tTime 0.049 (0.058)\tData 0.003 (0.004)\tLoss 0.1536 (0.1511)\tPrec@1 92.969 (94.748)\tPrec@5 99.219 (99.951)\t\n",
            "TRAINING - Epoch: [65][200/390]\tTime 0.069 (0.058)\tData 0.003 (0.004)\tLoss 0.2056 (0.1522)\tPrec@1 95.312 (94.714)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [65][210/390]\tTime 0.055 (0.058)\tData 0.007 (0.004)\tLoss 0.1268 (0.1532)\tPrec@1 96.094 (94.668)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [65][220/390]\tTime 0.064 (0.058)\tData 0.008 (0.004)\tLoss 0.1767 (0.1541)\tPrec@1 94.531 (94.648)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [65][230/390]\tTime 0.056 (0.058)\tData 0.008 (0.004)\tLoss 0.2199 (0.1541)\tPrec@1 93.750 (94.639)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [65][240/390]\tTime 0.051 (0.058)\tData 0.002 (0.004)\tLoss 0.0671 (0.1551)\tPrec@1 97.656 (94.625)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [65][250/390]\tTime 0.053 (0.057)\tData 0.005 (0.004)\tLoss 0.1395 (0.1555)\tPrec@1 95.312 (94.603)\tPrec@5 99.219 (99.938)\t\n",
            "TRAINING - Epoch: [65][260/390]\tTime 0.055 (0.057)\tData 0.000 (0.004)\tLoss 0.1527 (0.1570)\tPrec@1 94.531 (94.564)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [65][270/390]\tTime 0.066 (0.057)\tData 0.000 (0.004)\tLoss 0.2944 (0.1593)\tPrec@1 90.625 (94.485)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [65][280/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.1785 (0.1598)\tPrec@1 95.312 (94.470)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [65][290/390]\tTime 0.060 (0.057)\tData 0.011 (0.004)\tLoss 0.1843 (0.1608)\tPrec@1 93.750 (94.448)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [65][300/390]\tTime 0.072 (0.057)\tData 0.010 (0.004)\tLoss 0.1329 (0.1613)\tPrec@1 93.750 (94.399)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [65][310/390]\tTime 0.064 (0.058)\tData 0.007 (0.004)\tLoss 0.1263 (0.1615)\tPrec@1 96.094 (94.388)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [65][320/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1787 (0.1617)\tPrec@1 93.750 (94.383)\tPrec@5 100.000 (99.925)\t\n",
            "TRAINING - Epoch: [65][330/390]\tTime 0.052 (0.057)\tData 0.000 (0.004)\tLoss 0.1093 (0.1616)\tPrec@1 96.875 (94.406)\tPrec@5 99.219 (99.924)\t\n",
            "TRAINING - Epoch: [65][340/390]\tTime 0.051 (0.057)\tData 0.004 (0.004)\tLoss 0.2036 (0.1611)\tPrec@1 92.188 (94.426)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [65][350/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.1670 (0.1607)\tPrec@1 96.094 (94.449)\tPrec@5 100.000 (99.920)\t\n",
            "TRAINING - Epoch: [65][360/390]\tTime 0.055 (0.057)\tData 0.000 (0.004)\tLoss 0.1044 (0.1600)\tPrec@1 96.875 (94.456)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [65][370/390]\tTime 0.052 (0.057)\tData 0.006 (0.004)\tLoss 0.1110 (0.1599)\tPrec@1 95.312 (94.453)\tPrec@5 100.000 (99.920)\t\n",
            "TRAINING - Epoch: [65][380/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.0913 (0.1597)\tPrec@1 96.875 (94.451)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [65][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1574 (0.1599)\tPrec@1 92.969 (94.441)\tPrec@5 100.000 (99.924)\t\n",
            "EVALUATING - Epoch: [65][0/79]\tTime 0.236 (0.236)\tData 0.176 (0.176)\tLoss 0.4276 (0.4276)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [65][10/79]\tTime 0.029 (0.052)\tData 0.002 (0.023)\tLoss 0.2508 (0.3582)\tPrec@1 92.969 (89.560)\tPrec@5 100.000 (99.929)\t\n",
            "EVALUATING - Epoch: [65][20/79]\tTime 0.036 (0.042)\tData 0.007 (0.014)\tLoss 0.3636 (0.3992)\tPrec@1 89.844 (89.062)\tPrec@5 100.000 (99.628)\t\n",
            "EVALUATING - Epoch: [65][30/79]\tTime 0.013 (0.039)\tData 0.000 (0.012)\tLoss 0.3225 (0.3965)\tPrec@1 91.406 (89.012)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [65][40/79]\tTime 0.036 (0.037)\tData 0.000 (0.010)\tLoss 0.4709 (0.3871)\tPrec@1 85.938 (89.082)\tPrec@5 100.000 (99.638)\t\n",
            "EVALUATING - Epoch: [65][50/79]\tTime 0.033 (0.035)\tData 0.006 (0.009)\tLoss 0.5121 (0.3810)\tPrec@1 86.719 (89.093)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [65][60/79]\tTime 0.021 (0.034)\tData 0.000 (0.008)\tLoss 0.2908 (0.3847)\tPrec@1 92.969 (88.973)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [65][70/79]\tTime 0.015 (0.033)\tData 0.000 (0.008)\tLoss 0.2841 (0.3858)\tPrec@1 95.312 (89.029)\tPrec@5 100.000 (99.637)\t\n",
            "EVALUATING - Epoch: [65][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.3938 (0.3850)\tPrec@1 93.750 (89.110)\tPrec@5 100.000 (99.640)\t\n",
            "\n",
            "Results - Epoch: 66\n",
            "Training Loss 0.1599 \tTraining Prec@1 94.441 \tTraining Prec@5 99.924 \tValidation Loss 0.3850 \tValidation Prec@1 89.110 \tValidation Prec@5 99.640 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 67\n",
            "\n",
            "TRAINING - Epoch: [66][0/390]\tTime 0.417 (0.417)\tData 0.287 (0.287)\tLoss 0.2086 (0.2086)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [66][10/390]\tTime 0.047 (0.089)\tData 0.000 (0.028)\tLoss 0.1927 (0.1678)\tPrec@1 91.406 (94.105)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [66][20/390]\tTime 0.063 (0.072)\tData 0.011 (0.017)\tLoss 0.1193 (0.1559)\tPrec@1 94.531 (94.345)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [66][30/390]\tTime 0.048 (0.067)\tData 0.000 (0.012)\tLoss 0.1133 (0.1572)\tPrec@1 96.094 (94.355)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [66][40/390]\tTime 0.076 (0.064)\tData 0.005 (0.010)\tLoss 0.1205 (0.1562)\tPrec@1 95.312 (94.531)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [66][50/390]\tTime 0.049 (0.062)\tData 0.000 (0.009)\tLoss 0.1561 (0.1538)\tPrec@1 93.750 (94.654)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [66][60/390]\tTime 0.050 (0.062)\tData 0.001 (0.008)\tLoss 0.1807 (0.1471)\tPrec@1 93.750 (94.941)\tPrec@5 99.219 (99.936)\t\n",
            "TRAINING - Epoch: [66][70/390]\tTime 0.047 (0.060)\tData 0.000 (0.007)\tLoss 0.1118 (0.1434)\tPrec@1 96.094 (94.982)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [66][80/390]\tTime 0.049 (0.060)\tData 0.000 (0.006)\tLoss 0.1001 (0.1441)\tPrec@1 96.875 (94.956)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [66][90/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.1144 (0.1463)\tPrec@1 96.094 (94.926)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [66][100/390]\tTime 0.046 (0.059)\tData 0.000 (0.006)\tLoss 0.1367 (0.1444)\tPrec@1 96.094 (94.995)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [66][110/390]\tTime 0.056 (0.059)\tData 0.007 (0.005)\tLoss 0.1631 (0.1454)\tPrec@1 95.312 (95.003)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [66][120/390]\tTime 0.076 (0.059)\tData 0.000 (0.005)\tLoss 0.1455 (0.1461)\tPrec@1 95.312 (94.990)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [66][130/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.2201 (0.1470)\tPrec@1 89.844 (94.883)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [66][140/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1683 (0.1482)\tPrec@1 91.406 (94.825)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [66][150/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.1060 (0.1481)\tPrec@1 97.656 (94.837)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [66][160/390]\tTime 0.054 (0.058)\tData 0.000 (0.005)\tLoss 0.1662 (0.1496)\tPrec@1 92.969 (94.793)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [66][170/390]\tTime 0.064 (0.058)\tData 0.007 (0.005)\tLoss 0.2043 (0.1493)\tPrec@1 93.750 (94.769)\tPrec@5 99.219 (99.959)\t\n",
            "TRAINING - Epoch: [66][180/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1387 (0.1487)\tPrec@1 96.094 (94.773)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [66][190/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1547 (0.1496)\tPrec@1 93.750 (94.711)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [66][200/390]\tTime 0.052 (0.057)\tData 0.000 (0.005)\tLoss 0.1857 (0.1490)\tPrec@1 94.531 (94.764)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [66][210/390]\tTime 0.046 (0.057)\tData 0.000 (0.005)\tLoss 0.1139 (0.1487)\tPrec@1 98.438 (94.768)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [66][220/390]\tTime 0.056 (0.057)\tData 0.006 (0.005)\tLoss 0.2565 (0.1491)\tPrec@1 91.406 (94.768)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [66][230/390]\tTime 0.055 (0.057)\tData 0.000 (0.005)\tLoss 0.1331 (0.1486)\tPrec@1 94.531 (94.778)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [66][240/390]\tTime 0.053 (0.057)\tData 0.000 (0.005)\tLoss 0.1548 (0.1479)\tPrec@1 94.531 (94.774)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [66][250/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1309 (0.1478)\tPrec@1 94.531 (94.765)\tPrec@5 100.000 (99.960)\t\n",
            "TRAINING - Epoch: [66][260/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.1530 (0.1475)\tPrec@1 94.531 (94.768)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [66][270/390]\tTime 0.055 (0.057)\tData 0.006 (0.004)\tLoss 0.0921 (0.1475)\tPrec@1 94.531 (94.756)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [66][280/390]\tTime 0.083 (0.057)\tData 0.000 (0.004)\tLoss 0.0831 (0.1471)\tPrec@1 96.094 (94.770)\tPrec@5 100.000 (99.964)\t\n",
            "TRAINING - Epoch: [66][290/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.1706 (0.1481)\tPrec@1 94.531 (94.746)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [66][300/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.1146 (0.1483)\tPrec@1 96.875 (94.726)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [66][310/390]\tTime 0.047 (0.057)\tData 0.000 (0.004)\tLoss 0.1512 (0.1493)\tPrec@1 95.312 (94.672)\tPrec@5 100.000 (99.960)\t\n",
            "TRAINING - Epoch: [66][320/390]\tTime 0.064 (0.057)\tData 0.008 (0.004)\tLoss 0.2348 (0.1502)\tPrec@1 92.188 (94.651)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [66][330/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.2215 (0.1511)\tPrec@1 94.531 (94.614)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [66][340/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.1552 (0.1513)\tPrec@1 93.750 (94.602)\tPrec@5 100.000 (99.952)\t\n",
            "TRAINING - Epoch: [66][350/390]\tTime 0.054 (0.057)\tData 0.007 (0.004)\tLoss 0.1479 (0.1516)\tPrec@1 94.531 (94.582)\tPrec@5 99.219 (99.949)\t\n",
            "TRAINING - Epoch: [66][360/390]\tTime 0.048 (0.056)\tData 0.000 (0.004)\tLoss 0.0985 (0.1514)\tPrec@1 96.094 (94.598)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [66][370/390]\tTime 0.070 (0.056)\tData 0.002 (0.004)\tLoss 0.1934 (0.1527)\tPrec@1 93.750 (94.567)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [66][380/390]\tTime 0.049 (0.056)\tData 0.000 (0.004)\tLoss 0.2498 (0.1537)\tPrec@1 91.406 (94.515)\tPrec@5 99.219 (99.945)\t\n",
            "TRAINING - Epoch: [66][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.0987 (0.1538)\tPrec@1 96.094 (94.499)\tPrec@5 100.000 (99.944)\t\n",
            "EVALUATING - Epoch: [66][0/79]\tTime 0.287 (0.287)\tData 0.258 (0.258)\tLoss 0.4054 (0.4054)\tPrec@1 86.719 (86.719)\tPrec@5 98.438 (98.438)\t\n",
            "EVALUATING - Epoch: [66][10/79]\tTime 0.036 (0.054)\tData 0.005 (0.027)\tLoss 0.3079 (0.3418)\tPrec@1 85.938 (88.778)\tPrec@5 99.219 (99.574)\t\n",
            "EVALUATING - Epoch: [66][20/79]\tTime 0.026 (0.042)\tData 0.009 (0.018)\tLoss 0.5010 (0.4057)\tPrec@1 85.938 (88.021)\tPrec@5 97.656 (99.256)\t\n",
            "EVALUATING - Epoch: [66][30/79]\tTime 0.041 (0.040)\tData 0.002 (0.014)\tLoss 0.3508 (0.4159)\tPrec@1 87.500 (88.130)\tPrec@5 100.000 (99.219)\t\n",
            "EVALUATING - Epoch: [66][40/79]\tTime 0.027 (0.038)\tData 0.001 (0.011)\tLoss 0.3944 (0.4150)\tPrec@1 87.500 (88.281)\tPrec@5 99.219 (99.181)\t\n",
            "EVALUATING - Epoch: [66][50/79]\tTime 0.014 (0.036)\tData 0.001 (0.009)\tLoss 0.3375 (0.4119)\tPrec@1 91.406 (88.297)\tPrec@5 100.000 (99.311)\t\n",
            "EVALUATING - Epoch: [66][60/79]\tTime 0.044 (0.035)\tData 0.007 (0.009)\tLoss 0.2778 (0.4069)\tPrec@1 86.719 (88.307)\tPrec@5 100.000 (99.308)\t\n",
            "EVALUATING - Epoch: [66][70/79]\tTime 0.017 (0.035)\tData 0.000 (0.008)\tLoss 0.3761 (0.4097)\tPrec@1 89.844 (88.193)\tPrec@5 100.000 (99.340)\t\n",
            "EVALUATING - Epoch: [66][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.7494 (0.4019)\tPrec@1 87.500 (88.310)\tPrec@5 100.000 (99.370)\t\n",
            "\n",
            "Results - Epoch: 67\n",
            "Training Loss 0.1538 \tTraining Prec@1 94.499 \tTraining Prec@5 99.944 \tValidation Loss 0.4019 \tValidation Prec@1 88.310 \tValidation Prec@5 99.370 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 68\n",
            "\n",
            "TRAINING - Epoch: [67][0/390]\tTime 0.279 (0.279)\tData 0.177 (0.177)\tLoss 0.2007 (0.2007)\tPrec@1 93.750 (93.750)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [67][10/390]\tTime 0.047 (0.088)\tData 0.000 (0.021)\tLoss 0.1000 (0.1566)\tPrec@1 96.094 (94.389)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [67][20/390]\tTime 0.047 (0.073)\tData 0.000 (0.013)\tLoss 0.1045 (0.1495)\tPrec@1 96.094 (94.792)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [67][30/390]\tTime 0.048 (0.068)\tData 0.000 (0.010)\tLoss 0.1233 (0.1402)\tPrec@1 96.094 (95.111)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [67][40/390]\tTime 0.059 (0.065)\tData 0.007 (0.009)\tLoss 0.1669 (0.1473)\tPrec@1 95.312 (95.065)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [67][50/390]\tTime 0.069 (0.064)\tData 0.006 (0.007)\tLoss 0.1110 (0.1425)\tPrec@1 96.094 (95.113)\tPrec@5 100.000 (99.923)\t\n",
            "TRAINING - Epoch: [67][60/390]\tTime 0.062 (0.062)\tData 0.007 (0.007)\tLoss 0.1834 (0.1423)\tPrec@1 93.750 (95.005)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [67][70/390]\tTime 0.051 (0.061)\tData 0.000 (0.006)\tLoss 0.0782 (0.1387)\tPrec@1 97.656 (95.092)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [67][80/390]\tTime 0.062 (0.060)\tData 0.007 (0.006)\tLoss 0.1213 (0.1359)\tPrec@1 95.312 (95.197)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [67][90/390]\tTime 0.066 (0.060)\tData 0.013 (0.006)\tLoss 0.2091 (0.1394)\tPrec@1 92.188 (95.072)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [67][100/390]\tTime 0.046 (0.059)\tData 0.000 (0.006)\tLoss 0.1708 (0.1405)\tPrec@1 94.531 (95.042)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [67][110/390]\tTime 0.052 (0.059)\tData 0.000 (0.005)\tLoss 0.2946 (0.1430)\tPrec@1 91.406 (94.954)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [67][120/390]\tTime 0.047 (0.059)\tData 0.000 (0.005)\tLoss 0.1801 (0.1450)\tPrec@1 96.094 (94.944)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [67][130/390]\tTime 0.049 (0.059)\tData 0.000 (0.005)\tLoss 0.0796 (0.1469)\tPrec@1 96.875 (94.907)\tPrec@5 100.000 (99.917)\t\n",
            "TRAINING - Epoch: [67][140/390]\tTime 0.047 (0.058)\tData 0.000 (0.005)\tLoss 0.1792 (0.1465)\tPrec@1 93.750 (94.902)\tPrec@5 100.000 (99.922)\t\n",
            "TRAINING - Epoch: [67][150/390]\tTime 0.054 (0.058)\tData 0.006 (0.005)\tLoss 0.1159 (0.1485)\tPrec@1 96.875 (94.847)\tPrec@5 100.000 (99.928)\t\n",
            "TRAINING - Epoch: [67][160/390]\tTime 0.057 (0.058)\tData 0.007 (0.005)\tLoss 0.1294 (0.1504)\tPrec@1 94.531 (94.750)\tPrec@5 100.000 (99.932)\t\n",
            "TRAINING - Epoch: [67][170/390]\tTime 0.049 (0.058)\tData 0.000 (0.005)\tLoss 0.1149 (0.1504)\tPrec@1 96.094 (94.755)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [67][180/390]\tTime 0.071 (0.058)\tData 0.011 (0.005)\tLoss 0.1163 (0.1498)\tPrec@1 94.531 (94.764)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [67][190/390]\tTime 0.057 (0.058)\tData 0.011 (0.005)\tLoss 0.1643 (0.1496)\tPrec@1 93.750 (94.764)\tPrec@5 100.000 (99.930)\t\n",
            "TRAINING - Epoch: [67][200/390]\tTime 0.052 (0.058)\tData 0.000 (0.005)\tLoss 0.0877 (0.1492)\tPrec@1 96.875 (94.792)\tPrec@5 100.000 (99.934)\t\n",
            "TRAINING - Epoch: [67][210/390]\tTime 0.055 (0.058)\tData 0.000 (0.004)\tLoss 0.2239 (0.1500)\tPrec@1 91.406 (94.757)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [67][220/390]\tTime 0.055 (0.057)\tData 0.000 (0.004)\tLoss 0.0944 (0.1514)\tPrec@1 96.094 (94.708)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [67][230/390]\tTime 0.066 (0.057)\tData 0.001 (0.004)\tLoss 0.0886 (0.1515)\tPrec@1 97.656 (94.710)\tPrec@5 100.000 (99.936)\t\n",
            "TRAINING - Epoch: [67][240/390]\tTime 0.059 (0.057)\tData 0.008 (0.004)\tLoss 0.1793 (0.1511)\tPrec@1 92.969 (94.732)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [67][250/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.1189 (0.1515)\tPrec@1 97.656 (94.737)\tPrec@5 100.000 (99.941)\t\n",
            "TRAINING - Epoch: [67][260/390]\tTime 0.060 (0.057)\tData 0.007 (0.004)\tLoss 0.1173 (0.1516)\tPrec@1 94.531 (94.726)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [67][270/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.1367 (0.1516)\tPrec@1 93.750 (94.730)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [67][280/390]\tTime 0.053 (0.057)\tData 0.006 (0.004)\tLoss 0.0788 (0.1511)\tPrec@1 98.438 (94.756)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [67][290/390]\tTime 0.065 (0.057)\tData 0.007 (0.004)\tLoss 0.1275 (0.1516)\tPrec@1 94.531 (94.725)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [67][300/390]\tTime 0.058 (0.057)\tData 0.000 (0.004)\tLoss 0.1450 (0.1516)\tPrec@1 96.094 (94.734)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [67][310/390]\tTime 0.084 (0.057)\tData 0.001 (0.004)\tLoss 0.1493 (0.1525)\tPrec@1 94.531 (94.710)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [67][320/390]\tTime 0.051 (0.057)\tData 0.004 (0.004)\tLoss 0.1125 (0.1530)\tPrec@1 96.094 (94.694)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [67][330/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.1172 (0.1535)\tPrec@1 96.875 (94.666)\tPrec@5 100.000 (99.946)\t\n",
            "TRAINING - Epoch: [67][340/390]\tTime 0.067 (0.057)\tData 0.007 (0.004)\tLoss 0.1348 (0.1540)\tPrec@1 93.750 (94.644)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [67][350/390]\tTime 0.051 (0.057)\tData 0.000 (0.004)\tLoss 0.0915 (0.1546)\tPrec@1 97.656 (94.629)\tPrec@5 100.000 (99.940)\t\n",
            "TRAINING - Epoch: [67][360/390]\tTime 0.060 (0.057)\tData 0.012 (0.004)\tLoss 0.2087 (0.1549)\tPrec@1 89.062 (94.598)\tPrec@5 100.000 (99.942)\t\n",
            "TRAINING - Epoch: [67][370/390]\tTime 0.070 (0.057)\tData 0.000 (0.004)\tLoss 0.1350 (0.1548)\tPrec@1 94.531 (94.603)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [67][380/390]\tTime 0.056 (0.057)\tData 0.000 (0.004)\tLoss 0.0972 (0.1549)\tPrec@1 96.875 (94.589)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [67][389/390]\tTime 0.040 (0.056)\tData 0.000 (0.004)\tLoss 0.2756 (0.1555)\tPrec@1 92.188 (94.579)\tPrec@5 99.219 (99.936)\t\n",
            "EVALUATING - Epoch: [67][0/79]\tTime 0.269 (0.269)\tData 0.234 (0.234)\tLoss 0.4065 (0.4065)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [67][10/79]\tTime 0.029 (0.057)\tData 0.009 (0.025)\tLoss 0.3920 (0.4169)\tPrec@1 88.281 (87.926)\tPrec@5 99.219 (99.432)\t\n",
            "EVALUATING - Epoch: [67][20/79]\tTime 0.012 (0.044)\tData 0.000 (0.016)\tLoss 0.4719 (0.4335)\tPrec@1 88.281 (87.574)\tPrec@5 100.000 (99.293)\t\n",
            "EVALUATING - Epoch: [67][30/79]\tTime 0.043 (0.037)\tData 0.005 (0.011)\tLoss 0.3812 (0.4274)\tPrec@1 89.844 (87.853)\tPrec@5 100.000 (99.395)\t\n",
            "EVALUATING - Epoch: [67][40/79]\tTime 0.033 (0.037)\tData 0.001 (0.009)\tLoss 0.5003 (0.4124)\tPrec@1 83.594 (87.862)\tPrec@5 99.219 (99.409)\t\n",
            "EVALUATING - Epoch: [67][50/79]\tTime 0.012 (0.036)\tData 0.000 (0.008)\tLoss 0.3601 (0.4076)\tPrec@1 89.844 (88.036)\tPrec@5 100.000 (99.479)\t\n",
            "EVALUATING - Epoch: [67][60/79]\tTime 0.024 (0.034)\tData 0.009 (0.007)\tLoss 0.1603 (0.3978)\tPrec@1 92.188 (88.307)\tPrec@5 100.000 (99.539)\t\n",
            "EVALUATING - Epoch: [67][70/79]\tTime 0.039 (0.034)\tData 0.007 (0.007)\tLoss 0.3601 (0.3982)\tPrec@1 89.844 (88.160)\tPrec@5 100.000 (99.593)\t\n",
            "EVALUATING - Epoch: [67][78/79]\tTime 0.006 (0.031)\tData 0.000 (0.007)\tLoss 0.2766 (0.3931)\tPrec@1 93.750 (88.300)\tPrec@5 100.000 (99.610)\t\n",
            "\n",
            "Results - Epoch: 68\n",
            "Training Loss 0.1555 \tTraining Prec@1 94.579 \tTraining Prec@5 99.936 \tValidation Loss 0.3931 \tValidation Prec@1 88.300 \tValidation Prec@5 99.610 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 69\n",
            "\n",
            "TRAINING - Epoch: [68][0/390]\tTime 0.376 (0.376)\tData 0.251 (0.251)\tLoss 0.1699 (0.1699)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [68][10/390]\tTime 0.048 (0.089)\tData 0.000 (0.026)\tLoss 0.1269 (0.1327)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [68][20/390]\tTime 0.067 (0.075)\tData 0.007 (0.015)\tLoss 0.0573 (0.1305)\tPrec@1 98.438 (95.424)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [68][30/390]\tTime 0.057 (0.069)\tData 0.007 (0.012)\tLoss 0.1471 (0.1346)\tPrec@1 95.312 (95.186)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [68][40/390]\tTime 0.047 (0.066)\tData 0.000 (0.010)\tLoss 0.2230 (0.1412)\tPrec@1 91.406 (94.893)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [68][50/390]\tTime 0.059 (0.064)\tData 0.000 (0.009)\tLoss 0.1067 (0.1398)\tPrec@1 96.875 (94.960)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [68][60/390]\tTime 0.049 (0.062)\tData 0.000 (0.008)\tLoss 0.1492 (0.1423)\tPrec@1 96.094 (94.954)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [68][70/390]\tTime 0.048 (0.061)\tData 0.000 (0.007)\tLoss 0.1782 (0.1385)\tPrec@1 95.312 (95.070)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [68][80/390]\tTime 0.057 (0.061)\tData 0.007 (0.007)\tLoss 0.1034 (0.1384)\tPrec@1 97.656 (95.110)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [68][90/390]\tTime 0.056 (0.060)\tData 0.008 (0.007)\tLoss 0.0887 (0.1395)\tPrec@1 96.094 (95.003)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [68][100/390]\tTime 0.047 (0.060)\tData 0.000 (0.006)\tLoss 0.1061 (0.1423)\tPrec@1 96.875 (94.918)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [68][110/390]\tTime 0.053 (0.060)\tData 0.000 (0.006)\tLoss 0.1868 (0.1426)\tPrec@1 92.969 (94.918)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [68][120/390]\tTime 0.058 (0.060)\tData 0.009 (0.006)\tLoss 0.1599 (0.1429)\tPrec@1 92.188 (94.925)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [68][130/390]\tTime 0.052 (0.060)\tData 0.000 (0.006)\tLoss 0.0697 (0.1435)\tPrec@1 96.875 (94.949)\tPrec@5 100.000 (99.952)\t\n",
            "TRAINING - Epoch: [68][140/390]\tTime 0.050 (0.060)\tData 0.000 (0.006)\tLoss 0.1047 (0.1412)\tPrec@1 96.094 (95.013)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [68][150/390]\tTime 0.063 (0.060)\tData 0.009 (0.006)\tLoss 0.1486 (0.1423)\tPrec@1 93.750 (94.997)\tPrec@5 99.219 (99.943)\t\n",
            "TRAINING - Epoch: [68][160/390]\tTime 0.056 (0.060)\tData 0.007 (0.006)\tLoss 0.1111 (0.1422)\tPrec@1 96.875 (94.987)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [68][170/390]\tTime 0.066 (0.059)\tData 0.007 (0.006)\tLoss 0.1188 (0.1430)\tPrec@1 96.875 (94.970)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [68][180/390]\tTime 0.056 (0.059)\tData 0.002 (0.005)\tLoss 0.1129 (0.1432)\tPrec@1 96.094 (94.967)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [68][190/390]\tTime 0.049 (0.059)\tData 0.000 (0.005)\tLoss 0.2279 (0.1438)\tPrec@1 91.406 (94.965)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [68][200/390]\tTime 0.068 (0.059)\tData 0.013 (0.005)\tLoss 0.1021 (0.1440)\tPrec@1 96.094 (94.955)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [68][210/390]\tTime 0.059 (0.059)\tData 0.007 (0.005)\tLoss 0.1594 (0.1439)\tPrec@1 92.969 (94.939)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [68][220/390]\tTime 0.052 (0.059)\tData 0.000 (0.005)\tLoss 0.1337 (0.1437)\tPrec@1 96.094 (94.955)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [68][230/390]\tTime 0.056 (0.059)\tData 0.007 (0.005)\tLoss 0.1317 (0.1435)\tPrec@1 96.875 (94.920)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [68][240/390]\tTime 0.054 (0.058)\tData 0.006 (0.005)\tLoss 0.1171 (0.1432)\tPrec@1 94.531 (94.949)\tPrec@5 100.000 (99.951)\t\n",
            "TRAINING - Epoch: [68][250/390]\tTime 0.062 (0.058)\tData 0.013 (0.005)\tLoss 0.1204 (0.1438)\tPrec@1 96.875 (94.930)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [68][260/390]\tTime 0.046 (0.058)\tData 0.000 (0.005)\tLoss 0.0519 (0.1449)\tPrec@1 98.438 (94.884)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [68][270/390]\tTime 0.069 (0.058)\tData 0.011 (0.005)\tLoss 0.1368 (0.1450)\tPrec@1 93.750 (94.880)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [68][280/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.2865 (0.1461)\tPrec@1 92.188 (94.834)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [68][290/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1863 (0.1474)\tPrec@1 94.531 (94.805)\tPrec@5 99.219 (99.946)\t\n",
            "TRAINING - Epoch: [68][300/390]\tTime 0.048 (0.058)\tData 0.000 (0.005)\tLoss 0.1571 (0.1476)\tPrec@1 94.531 (94.804)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [68][310/390]\tTime 0.056 (0.058)\tData 0.007 (0.005)\tLoss 0.2142 (0.1484)\tPrec@1 90.625 (94.790)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [68][320/390]\tTime 0.058 (0.058)\tData 0.006 (0.004)\tLoss 0.2221 (0.1489)\tPrec@1 93.750 (94.779)\tPrec@5 99.219 (99.946)\t\n",
            "TRAINING - Epoch: [68][330/390]\tTime 0.050 (0.058)\tData 0.000 (0.004)\tLoss 0.1415 (0.1491)\tPrec@1 94.531 (94.763)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [68][340/390]\tTime 0.046 (0.057)\tData 0.000 (0.004)\tLoss 0.1037 (0.1488)\tPrec@1 94.531 (94.779)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [68][350/390]\tTime 0.067 (0.057)\tData 0.012 (0.004)\tLoss 0.1707 (0.1480)\tPrec@1 92.188 (94.794)\tPrec@5 99.219 (99.942)\t\n",
            "TRAINING - Epoch: [68][360/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.1577 (0.1482)\tPrec@1 94.531 (94.791)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [68][370/390]\tTime 0.066 (0.057)\tData 0.008 (0.004)\tLoss 0.1421 (0.1486)\tPrec@1 92.188 (94.776)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [68][380/390]\tTime 0.058 (0.057)\tData 0.006 (0.004)\tLoss 0.1686 (0.1486)\tPrec@1 96.094 (94.777)\tPrec@5 100.000 (99.945)\t\n",
            "TRAINING - Epoch: [68][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1523 (0.1492)\tPrec@1 95.312 (94.762)\tPrec@5 100.000 (99.944)\t\n",
            "EVALUATING - Epoch: [68][0/79]\tTime 0.208 (0.208)\tData 0.180 (0.180)\tLoss 0.3504 (0.3504)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [68][10/79]\tTime 0.020 (0.052)\tData 0.004 (0.027)\tLoss 0.3441 (0.3390)\tPrec@1 92.188 (89.489)\tPrec@5 100.000 (99.929)\t\n",
            "EVALUATING - Epoch: [68][20/79]\tTime 0.043 (0.041)\tData 0.004 (0.016)\tLoss 0.4418 (0.3976)\tPrec@1 87.500 (88.579)\tPrec@5 98.438 (99.554)\t\n",
            "EVALUATING - Epoch: [68][30/79]\tTime 0.024 (0.038)\tData 0.004 (0.012)\tLoss 0.2421 (0.3871)\tPrec@1 92.969 (88.836)\tPrec@5 100.000 (99.496)\t\n",
            "EVALUATING - Epoch: [68][40/79]\tTime 0.034 (0.038)\tData 0.006 (0.011)\tLoss 0.3998 (0.3818)\tPrec@1 86.719 (89.024)\tPrec@5 98.438 (99.486)\t\n",
            "EVALUATING - Epoch: [68][50/79]\tTime 0.042 (0.036)\tData 0.000 (0.010)\tLoss 0.3975 (0.3808)\tPrec@1 87.500 (89.154)\tPrec@5 100.000 (99.571)\t\n",
            "EVALUATING - Epoch: [68][60/79]\tTime 0.043 (0.036)\tData 0.005 (0.009)\tLoss 0.3684 (0.3779)\tPrec@1 88.281 (89.178)\tPrec@5 100.000 (99.590)\t\n",
            "EVALUATING - Epoch: [68][70/79]\tTime 0.032 (0.035)\tData 0.000 (0.008)\tLoss 0.2221 (0.3786)\tPrec@1 93.750 (89.140)\tPrec@5 100.000 (99.604)\t\n",
            "EVALUATING - Epoch: [68][78/79]\tTime 0.005 (0.032)\tData 0.000 (0.007)\tLoss 0.0814 (0.3795)\tPrec@1 93.750 (89.020)\tPrec@5 100.000 (99.610)\t\n",
            "\n",
            "Results - Epoch: 69\n",
            "Training Loss 0.1492 \tTraining Prec@1 94.762 \tTraining Prec@5 99.944 \tValidation Loss 0.3795 \tValidation Prec@1 89.020 \tValidation Prec@5 99.610 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 70\n",
            "\n",
            "TRAINING - Epoch: [69][0/390]\tTime 0.389 (0.389)\tData 0.270 (0.270)\tLoss 0.1273 (0.1273)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [69][10/390]\tTime 0.063 (0.088)\tData 0.007 (0.028)\tLoss 0.0924 (0.1342)\tPrec@1 96.875 (95.739)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [69][20/390]\tTime 0.056 (0.072)\tData 0.006 (0.017)\tLoss 0.0780 (0.1441)\tPrec@1 97.656 (95.015)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [69][30/390]\tTime 0.059 (0.066)\tData 0.007 (0.013)\tLoss 0.1767 (0.1384)\tPrec@1 93.750 (95.086)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [69][40/390]\tTime 0.047 (0.064)\tData 0.000 (0.010)\tLoss 0.1157 (0.1329)\tPrec@1 96.094 (95.370)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [69][50/390]\tTime 0.058 (0.062)\tData 0.003 (0.009)\tLoss 0.1400 (0.1323)\tPrec@1 93.750 (95.236)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [69][60/390]\tTime 0.052 (0.062)\tData 0.004 (0.008)\tLoss 0.1669 (0.1340)\tPrec@1 93.750 (95.197)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [69][70/390]\tTime 0.068 (0.061)\tData 0.000 (0.007)\tLoss 0.1716 (0.1364)\tPrec@1 96.094 (95.158)\tPrec@5 100.000 (99.967)\t\n",
            "TRAINING - Epoch: [69][80/390]\tTime 0.046 (0.060)\tData 0.000 (0.007)\tLoss 0.1343 (0.1393)\tPrec@1 96.875 (95.033)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [69][90/390]\tTime 0.048 (0.059)\tData 0.000 (0.006)\tLoss 0.0523 (0.1426)\tPrec@1 97.656 (94.935)\tPrec@5 100.000 (99.966)\t\n",
            "TRAINING - Epoch: [69][100/390]\tTime 0.075 (0.059)\tData 0.001 (0.006)\tLoss 0.0616 (0.1406)\tPrec@1 97.656 (94.988)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [69][110/390]\tTime 0.046 (0.059)\tData 0.000 (0.006)\tLoss 0.1587 (0.1407)\tPrec@1 95.312 (95.052)\tPrec@5 99.219 (99.965)\t\n",
            "TRAINING - Epoch: [69][120/390]\tTime 0.065 (0.059)\tData 0.008 (0.006)\tLoss 0.1983 (0.1403)\tPrec@1 92.188 (95.028)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [69][130/390]\tTime 0.053 (0.059)\tData 0.005 (0.006)\tLoss 0.1528 (0.1411)\tPrec@1 92.969 (95.026)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [69][140/390]\tTime 0.057 (0.058)\tData 0.002 (0.006)\tLoss 0.1382 (0.1424)\tPrec@1 96.094 (94.986)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [69][150/390]\tTime 0.070 (0.058)\tData 0.006 (0.005)\tLoss 0.1536 (0.1433)\tPrec@1 95.312 (94.904)\tPrec@5 100.000 (99.964)\t\n",
            "TRAINING - Epoch: [69][160/390]\tTime 0.088 (0.058)\tData 0.000 (0.005)\tLoss 0.1788 (0.1462)\tPrec@1 92.969 (94.827)\tPrec@5 100.000 (99.966)\t\n",
            "TRAINING - Epoch: [69][170/390]\tTime 0.046 (0.058)\tData 0.000 (0.005)\tLoss 0.1794 (0.1462)\tPrec@1 93.750 (94.837)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [69][180/390]\tTime 0.054 (0.058)\tData 0.006 (0.005)\tLoss 0.2147 (0.1475)\tPrec@1 92.969 (94.803)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [69][190/390]\tTime 0.053 (0.058)\tData 0.005 (0.005)\tLoss 0.1272 (0.1472)\tPrec@1 93.750 (94.789)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [69][200/390]\tTime 0.062 (0.058)\tData 0.000 (0.005)\tLoss 0.2028 (0.1487)\tPrec@1 94.531 (94.745)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [69][210/390]\tTime 0.050 (0.058)\tData 0.000 (0.005)\tLoss 0.1992 (0.1489)\tPrec@1 92.969 (94.724)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [69][220/390]\tTime 0.048 (0.057)\tData 0.000 (0.005)\tLoss 0.1426 (0.1482)\tPrec@1 94.531 (94.726)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [69][230/390]\tTime 0.062 (0.057)\tData 0.007 (0.005)\tLoss 0.1404 (0.1480)\tPrec@1 94.531 (94.738)\tPrec@5 100.000 (99.959)\t\n",
            "TRAINING - Epoch: [69][240/390]\tTime 0.053 (0.057)\tData 0.000 (0.005)\tLoss 0.1149 (0.1481)\tPrec@1 95.312 (94.713)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [69][250/390]\tTime 0.071 (0.057)\tData 0.000 (0.004)\tLoss 0.0951 (0.1483)\tPrec@1 96.094 (94.749)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [69][260/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.0904 (0.1481)\tPrec@1 96.094 (94.762)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [69][270/390]\tTime 0.066 (0.057)\tData 0.012 (0.004)\tLoss 0.0819 (0.1474)\tPrec@1 96.094 (94.771)\tPrec@5 100.000 (99.960)\t\n",
            "TRAINING - Epoch: [69][280/390]\tTime 0.053 (0.057)\tData 0.000 (0.004)\tLoss 0.1004 (0.1474)\tPrec@1 96.094 (94.773)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [69][290/390]\tTime 0.063 (0.057)\tData 0.007 (0.004)\tLoss 0.1564 (0.1478)\tPrec@1 92.969 (94.746)\tPrec@5 100.000 (99.952)\t\n",
            "TRAINING - Epoch: [69][300/390]\tTime 0.050 (0.057)\tData 0.000 (0.004)\tLoss 0.1671 (0.1493)\tPrec@1 91.406 (94.690)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [69][310/390]\tTime 0.049 (0.057)\tData 0.000 (0.004)\tLoss 0.1988 (0.1492)\tPrec@1 92.188 (94.692)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [69][320/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.0862 (0.1501)\tPrec@1 98.438 (94.687)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [69][330/390]\tTime 0.059 (0.057)\tData 0.006 (0.004)\tLoss 0.2173 (0.1504)\tPrec@1 93.750 (94.682)\tPrec@5 100.000 (99.955)\t\n",
            "TRAINING - Epoch: [69][340/390]\tTime 0.058 (0.057)\tData 0.000 (0.004)\tLoss 0.1281 (0.1502)\tPrec@1 94.531 (94.678)\tPrec@5 99.219 (99.950)\t\n",
            "TRAINING - Epoch: [69][350/390]\tTime 0.055 (0.057)\tData 0.007 (0.004)\tLoss 0.1344 (0.1505)\tPrec@1 95.312 (94.663)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [69][360/390]\tTime 0.048 (0.057)\tData 0.000 (0.004)\tLoss 0.1694 (0.1507)\tPrec@1 94.531 (94.646)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [69][370/390]\tTime 0.057 (0.057)\tData 0.010 (0.004)\tLoss 0.2448 (0.1510)\tPrec@1 91.406 (94.645)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [69][380/390]\tTime 0.057 (0.057)\tData 0.007 (0.004)\tLoss 0.1652 (0.1508)\tPrec@1 92.188 (94.654)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [69][389/390]\tTime 0.040 (0.057)\tData 0.000 (0.004)\tLoss 0.1433 (0.1507)\tPrec@1 94.531 (94.659)\tPrec@5 100.000 (99.950)\t\n",
            "EVALUATING - Epoch: [69][0/79]\tTime 0.183 (0.183)\tData 0.160 (0.160)\tLoss 0.3382 (0.3382)\tPrec@1 91.406 (91.406)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [69][10/79]\tTime 0.031 (0.056)\tData 0.005 (0.027)\tLoss 0.4221 (0.3715)\tPrec@1 89.844 (89.205)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [69][20/79]\tTime 0.024 (0.042)\tData 0.005 (0.016)\tLoss 0.4794 (0.4036)\tPrec@1 88.281 (89.062)\tPrec@5 98.438 (99.554)\t\n",
            "EVALUATING - Epoch: [69][30/79]\tTime 0.049 (0.039)\tData 0.019 (0.012)\tLoss 0.3299 (0.3987)\tPrec@1 90.625 (88.936)\tPrec@5 100.000 (99.597)\t\n",
            "EVALUATING - Epoch: [69][40/79]\tTime 0.031 (0.037)\tData 0.000 (0.010)\tLoss 0.3958 (0.3943)\tPrec@1 89.062 (89.253)\tPrec@5 98.438 (99.562)\t\n",
            "EVALUATING - Epoch: [69][50/79]\tTime 0.009 (0.035)\tData 0.000 (0.009)\tLoss 0.4269 (0.3859)\tPrec@1 90.625 (89.369)\tPrec@5 99.219 (99.602)\t\n",
            "EVALUATING - Epoch: [69][60/79]\tTime 0.037 (0.035)\tData 0.011 (0.008)\tLoss 0.4556 (0.3769)\tPrec@1 89.062 (89.408)\tPrec@5 99.219 (99.590)\t\n",
            "EVALUATING - Epoch: [69][70/79]\tTime 0.040 (0.034)\tData 0.014 (0.008)\tLoss 0.3890 (0.3804)\tPrec@1 89.062 (89.217)\tPrec@5 100.000 (99.593)\t\n",
            "EVALUATING - Epoch: [69][78/79]\tTime 0.005 (0.031)\tData 0.000 (0.007)\tLoss 0.3568 (0.3836)\tPrec@1 81.250 (89.090)\tPrec@5 100.000 (99.610)\t\n",
            "\n",
            "Results - Epoch: 70\n",
            "Training Loss 0.1507 \tTraining Prec@1 94.659 \tTraining Prec@5 99.950 \tValidation Loss 0.3836 \tValidation Prec@1 89.090 \tValidation Prec@5 99.610 \t\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A1raN73lki9",
        "outputId": "b16e4912-e5f5-48cf-a79b-e4743f4aab81"
      },
      "source": [
        "!python main.py --dataset cifar10 --model resnet --workers 4 --model-config \"{'depth': 20}\" -b 128 --epochs 350 --save resnet20-p100-v2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "TRAINING - Epoch: [260][370/390]\tTime 0.027 (0.044)\tData 0.000 (0.005)\tLoss 0.0207 (0.0172)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [260][380/390]\tTime 0.040 (0.044)\tData 0.003 (0.005)\tLoss 0.0446 (0.0173)\tPrec@1 97.656 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [260][389/390]\tTime 0.017 (0.043)\tData 0.000 (0.004)\tLoss 0.0060 (0.0174)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [260][0/79]\tTime 0.182 (0.182)\tData 0.165 (0.165)\tLoss 0.2967 (0.2967)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [260][10/79]\tTime 0.060 (0.045)\tData 0.054 (0.033)\tLoss 0.2655 (0.3664)\tPrec@1 91.406 (92.401)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [260][20/79]\tTime 0.024 (0.037)\tData 0.001 (0.025)\tLoss 0.5534 (0.4115)\tPrec@1 89.844 (91.555)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [260][30/79]\tTime 0.019 (0.033)\tData 0.005 (0.021)\tLoss 0.0993 (0.3974)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [260][40/79]\tTime 0.021 (0.033)\tData 0.001 (0.021)\tLoss 0.2420 (0.3989)\tPrec@1 89.844 (91.787)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [260][50/79]\tTime 0.025 (0.032)\tData 0.010 (0.019)\tLoss 0.4226 (0.3917)\tPrec@1 90.625 (91.774)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [260][60/79]\tTime 0.025 (0.031)\tData 0.000 (0.019)\tLoss 0.6421 (0.3969)\tPrec@1 92.188 (91.675)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [260][70/79]\tTime 0.028 (0.030)\tData 0.015 (0.018)\tLoss 0.4065 (0.3894)\tPrec@1 89.062 (91.637)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [260][78/79]\tTime 0.003 (0.028)\tData 0.000 (0.017)\tLoss 0.2491 (0.3866)\tPrec@1 93.750 (91.640)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 261\n",
            "Training Loss 0.0174 \tTraining Prec@1 99.505 \tTraining Prec@5 100.000 \tValidation Loss 0.3866 \tValidation Prec@1 91.640 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 262\n",
            "\n",
            "TRAINING - Epoch: [261][0/390]\tTime 0.320 (0.320)\tData 0.271 (0.271)\tLoss 0.0073 (0.0073)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][10/390]\tTime 0.046 (0.069)\tData 0.005 (0.028)\tLoss 0.0149 (0.0181)\tPrec@1 99.219 (99.361)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][20/390]\tTime 0.049 (0.058)\tData 0.012 (0.016)\tLoss 0.0104 (0.0214)\tPrec@1 100.000 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][30/390]\tTime 0.055 (0.051)\tData 0.005 (0.011)\tLoss 0.0081 (0.0189)\tPrec@1 100.000 (99.320)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][40/390]\tTime 0.052 (0.050)\tData 0.001 (0.010)\tLoss 0.0161 (0.0184)\tPrec@1 99.219 (99.333)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][50/390]\tTime 0.046 (0.048)\tData 0.011 (0.009)\tLoss 0.0089 (0.0177)\tPrec@1 99.219 (99.387)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][60/390]\tTime 0.038 (0.047)\tData 0.010 (0.009)\tLoss 0.0037 (0.0178)\tPrec@1 100.000 (99.398)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][70/390]\tTime 0.045 (0.046)\tData 0.004 (0.009)\tLoss 0.0298 (0.0174)\tPrec@1 99.219 (99.428)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][80/390]\tTime 0.056 (0.046)\tData 0.007 (0.009)\tLoss 0.0144 (0.0167)\tPrec@1 99.219 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][90/390]\tTime 0.039 (0.046)\tData 0.000 (0.008)\tLoss 0.0212 (0.0166)\tPrec@1 99.219 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][100/390]\tTime 0.043 (0.046)\tData 0.001 (0.007)\tLoss 0.0182 (0.0164)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][110/390]\tTime 0.035 (0.046)\tData 0.004 (0.007)\tLoss 0.0083 (0.0161)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][120/390]\tTime 0.033 (0.045)\tData 0.002 (0.007)\tLoss 0.0033 (0.0166)\tPrec@1 100.000 (99.477)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][130/390]\tTime 0.041 (0.045)\tData 0.000 (0.007)\tLoss 0.0204 (0.0166)\tPrec@1 99.219 (99.463)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][140/390]\tTime 0.035 (0.045)\tData 0.000 (0.006)\tLoss 0.0503 (0.0169)\tPrec@1 98.438 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][150/390]\tTime 0.036 (0.044)\tData 0.000 (0.006)\tLoss 0.0248 (0.0169)\tPrec@1 99.219 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][160/390]\tTime 0.040 (0.044)\tData 0.000 (0.006)\tLoss 0.0100 (0.0166)\tPrec@1 99.219 (99.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][170/390]\tTime 0.034 (0.044)\tData 0.002 (0.006)\tLoss 0.0145 (0.0165)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][180/390]\tTime 0.045 (0.044)\tData 0.005 (0.006)\tLoss 0.0138 (0.0166)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][190/390]\tTime 0.041 (0.044)\tData 0.002 (0.006)\tLoss 0.0037 (0.0165)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][200/390]\tTime 0.039 (0.044)\tData 0.005 (0.006)\tLoss 0.0205 (0.0169)\tPrec@1 99.219 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][210/390]\tTime 0.050 (0.044)\tData 0.001 (0.006)\tLoss 0.0146 (0.0169)\tPrec@1 99.219 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][220/390]\tTime 0.050 (0.044)\tData 0.000 (0.005)\tLoss 0.0202 (0.0169)\tPrec@1 99.219 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][230/390]\tTime 0.057 (0.044)\tData 0.002 (0.005)\tLoss 0.0041 (0.0167)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][240/390]\tTime 0.052 (0.044)\tData 0.001 (0.005)\tLoss 0.0033 (0.0165)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][250/390]\tTime 0.039 (0.044)\tData 0.000 (0.005)\tLoss 0.0117 (0.0163)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][260/390]\tTime 0.036 (0.044)\tData 0.000 (0.005)\tLoss 0.0043 (0.0163)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][270/390]\tTime 0.060 (0.044)\tData 0.025 (0.005)\tLoss 0.0108 (0.0162)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][280/390]\tTime 0.048 (0.044)\tData 0.007 (0.005)\tLoss 0.0290 (0.0162)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][290/390]\tTime 0.042 (0.044)\tData 0.005 (0.005)\tLoss 0.0074 (0.0163)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][300/390]\tTime 0.042 (0.044)\tData 0.005 (0.006)\tLoss 0.0056 (0.0163)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][310/390]\tTime 0.042 (0.044)\tData 0.016 (0.006)\tLoss 0.0058 (0.0163)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][320/390]\tTime 0.048 (0.044)\tData 0.011 (0.006)\tLoss 0.0462 (0.0165)\tPrec@1 98.438 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][330/390]\tTime 0.030 (0.044)\tData 0.000 (0.006)\tLoss 0.0080 (0.0164)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][340/390]\tTime 0.037 (0.044)\tData 0.000 (0.006)\tLoss 0.0124 (0.0163)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][350/390]\tTime 0.059 (0.044)\tData 0.014 (0.006)\tLoss 0.0193 (0.0163)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][360/390]\tTime 0.058 (0.044)\tData 0.014 (0.006)\tLoss 0.0094 (0.0163)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][370/390]\tTime 0.046 (0.044)\tData 0.005 (0.006)\tLoss 0.0108 (0.0163)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][380/390]\tTime 0.041 (0.044)\tData 0.005 (0.006)\tLoss 0.0079 (0.0162)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [261][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.006)\tLoss 0.0114 (0.0162)\tPrec@1 99.219 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [261][0/79]\tTime 0.231 (0.231)\tData 0.217 (0.217)\tLoss 0.2720 (0.2720)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [261][10/79]\tTime 0.020 (0.042)\tData 0.005 (0.030)\tLoss 0.2558 (0.3690)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [261][20/79]\tTime 0.062 (0.036)\tData 0.056 (0.024)\tLoss 0.5029 (0.4053)\tPrec@1 89.844 (91.555)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [261][30/79]\tTime 0.012 (0.032)\tData 0.006 (0.019)\tLoss 0.1061 (0.3930)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [261][40/79]\tTime 0.032 (0.031)\tData 0.026 (0.019)\tLoss 0.2379 (0.3955)\tPrec@1 91.406 (91.825)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [261][50/79]\tTime 0.014 (0.031)\tData 0.004 (0.018)\tLoss 0.4459 (0.3880)\tPrec@1 89.844 (91.774)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [261][60/79]\tTime 0.005 (0.030)\tData 0.000 (0.018)\tLoss 0.6433 (0.3937)\tPrec@1 92.969 (91.688)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [261][70/79]\tTime 0.014 (0.030)\tData 0.000 (0.018)\tLoss 0.3898 (0.3859)\tPrec@1 89.844 (91.648)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [261][78/79]\tTime 0.003 (0.028)\tData 0.000 (0.017)\tLoss 0.2713 (0.3828)\tPrec@1 93.750 (91.700)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 262\n",
            "Training Loss 0.0162 \tTraining Prec@1 99.563 \tTraining Prec@5 100.000 \tValidation Loss 0.3828 \tValidation Prec@1 91.700 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 263\n",
            "\n",
            "TRAINING - Epoch: [262][0/390]\tTime 0.284 (0.284)\tData 0.238 (0.238)\tLoss 0.0170 (0.0170)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][10/390]\tTime 0.053 (0.067)\tData 0.005 (0.027)\tLoss 0.0162 (0.0126)\tPrec@1 99.219 (99.787)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][20/390]\tTime 0.044 (0.054)\tData 0.021 (0.016)\tLoss 0.0383 (0.0158)\tPrec@1 97.656 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][30/390]\tTime 0.050 (0.051)\tData 0.006 (0.014)\tLoss 0.0091 (0.0161)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][40/390]\tTime 0.028 (0.049)\tData 0.000 (0.011)\tLoss 0.0154 (0.0162)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][50/390]\tTime 0.042 (0.048)\tData 0.003 (0.010)\tLoss 0.0150 (0.0159)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][60/390]\tTime 0.045 (0.047)\tData 0.020 (0.009)\tLoss 0.0071 (0.0165)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][70/390]\tTime 0.038 (0.047)\tData 0.005 (0.009)\tLoss 0.0060 (0.0161)\tPrec@1 100.000 (99.593)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][80/390]\tTime 0.046 (0.046)\tData 0.005 (0.008)\tLoss 0.0049 (0.0162)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][90/390]\tTime 0.047 (0.045)\tData 0.004 (0.007)\tLoss 0.0045 (0.0159)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][100/390]\tTime 0.040 (0.045)\tData 0.005 (0.007)\tLoss 0.0113 (0.0161)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][110/390]\tTime 0.038 (0.045)\tData 0.005 (0.007)\tLoss 0.0083 (0.0158)\tPrec@1 100.000 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][120/390]\tTime 0.060 (0.045)\tData 0.013 (0.006)\tLoss 0.0264 (0.0161)\tPrec@1 98.438 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][130/390]\tTime 0.058 (0.044)\tData 0.000 (0.006)\tLoss 0.0437 (0.0163)\tPrec@1 98.438 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][140/390]\tTime 0.045 (0.044)\tData 0.002 (0.006)\tLoss 0.0297 (0.0163)\tPrec@1 98.438 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][150/390]\tTime 0.034 (0.044)\tData 0.000 (0.006)\tLoss 0.0180 (0.0164)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][160/390]\tTime 0.037 (0.044)\tData 0.005 (0.006)\tLoss 0.0211 (0.0167)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][170/390]\tTime 0.041 (0.044)\tData 0.004 (0.006)\tLoss 0.0055 (0.0168)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][180/390]\tTime 0.051 (0.044)\tData 0.010 (0.006)\tLoss 0.0118 (0.0166)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][190/390]\tTime 0.043 (0.044)\tData 0.001 (0.006)\tLoss 0.0148 (0.0167)\tPrec@1 100.000 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][200/390]\tTime 0.037 (0.044)\tData 0.005 (0.006)\tLoss 0.0074 (0.0168)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][210/390]\tTime 0.036 (0.044)\tData 0.002 (0.006)\tLoss 0.0096 (0.0168)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][220/390]\tTime 0.049 (0.044)\tData 0.000 (0.006)\tLoss 0.0108 (0.0166)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][230/390]\tTime 0.045 (0.044)\tData 0.007 (0.006)\tLoss 0.0126 (0.0167)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][240/390]\tTime 0.036 (0.044)\tData 0.010 (0.006)\tLoss 0.0228 (0.0168)\tPrec@1 99.219 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][250/390]\tTime 0.035 (0.044)\tData 0.004 (0.006)\tLoss 0.0220 (0.0170)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][260/390]\tTime 0.040 (0.044)\tData 0.006 (0.006)\tLoss 0.0221 (0.0170)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][270/390]\tTime 0.045 (0.044)\tData 0.001 (0.006)\tLoss 0.0152 (0.0168)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][280/390]\tTime 0.037 (0.044)\tData 0.001 (0.006)\tLoss 0.0058 (0.0166)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][290/390]\tTime 0.026 (0.044)\tData 0.000 (0.006)\tLoss 0.0052 (0.0165)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][300/390]\tTime 0.044 (0.044)\tData 0.001 (0.006)\tLoss 0.0448 (0.0166)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][310/390]\tTime 0.040 (0.043)\tData 0.004 (0.006)\tLoss 0.0125 (0.0167)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][320/390]\tTime 0.027 (0.043)\tData 0.000 (0.005)\tLoss 0.0230 (0.0168)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][330/390]\tTime 0.042 (0.043)\tData 0.004 (0.005)\tLoss 0.0235 (0.0168)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][340/390]\tTime 0.050 (0.043)\tData 0.010 (0.005)\tLoss 0.0112 (0.0169)\tPrec@1 99.219 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][350/390]\tTime 0.044 (0.043)\tData 0.000 (0.005)\tLoss 0.0087 (0.0168)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][360/390]\tTime 0.029 (0.043)\tData 0.000 (0.005)\tLoss 0.0200 (0.0168)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][370/390]\tTime 0.049 (0.043)\tData 0.003 (0.005)\tLoss 0.0264 (0.0167)\tPrec@1 98.438 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][380/390]\tTime 0.035 (0.043)\tData 0.007 (0.005)\tLoss 0.0485 (0.0168)\tPrec@1 96.875 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [262][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.005)\tLoss 0.0043 (0.0167)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [262][0/79]\tTime 0.264 (0.264)\tData 0.248 (0.248)\tLoss 0.2791 (0.2791)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [262][10/79]\tTime 0.029 (0.050)\tData 0.000 (0.034)\tLoss 0.2735 (0.3695)\tPrec@1 91.406 (92.116)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [262][20/79]\tTime 0.064 (0.040)\tData 0.059 (0.026)\tLoss 0.5227 (0.4078)\tPrec@1 91.406 (91.592)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [262][30/79]\tTime 0.011 (0.035)\tData 0.005 (0.021)\tLoss 0.0933 (0.3931)\tPrec@1 97.656 (92.061)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [262][40/79]\tTime 0.023 (0.034)\tData 0.018 (0.021)\tLoss 0.2352 (0.3958)\tPrec@1 90.625 (91.959)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [262][50/79]\tTime 0.012 (0.031)\tData 0.000 (0.019)\tLoss 0.4456 (0.3895)\tPrec@1 89.844 (91.866)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [262][60/79]\tTime 0.030 (0.031)\tData 0.024 (0.019)\tLoss 0.6364 (0.3952)\tPrec@1 93.750 (91.816)\tPrec@5 100.000 (99.629)\t\n",
            "EVALUATING - Epoch: [262][70/79]\tTime 0.022 (0.030)\tData 0.000 (0.019)\tLoss 0.4125 (0.3879)\tPrec@1 90.625 (91.791)\tPrec@5 100.000 (99.670)\t\n",
            "EVALUATING - Epoch: [262][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2753 (0.3850)\tPrec@1 93.750 (91.800)\tPrec@5 100.000 (99.670)\t\n",
            "\n",
            "Results - Epoch: 263\n",
            "Training Loss 0.0167 \tTraining Prec@1 99.551 \tTraining Prec@5 100.000 \tValidation Loss 0.3850 \tValidation Prec@1 91.800 \tValidation Prec@5 99.670 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 264\n",
            "\n",
            "TRAINING - Epoch: [263][0/390]\tTime 0.337 (0.337)\tData 0.291 (0.291)\tLoss 0.0235 (0.0235)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][10/390]\tTime 0.033 (0.069)\tData 0.001 (0.034)\tLoss 0.0361 (0.0144)\tPrec@1 98.438 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][20/390]\tTime 0.044 (0.057)\tData 0.002 (0.020)\tLoss 0.0108 (0.0136)\tPrec@1 100.000 (99.740)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][30/390]\tTime 0.040 (0.050)\tData 0.004 (0.015)\tLoss 0.0313 (0.0143)\tPrec@1 98.438 (99.647)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][40/390]\tTime 0.048 (0.049)\tData 0.017 (0.014)\tLoss 0.0070 (0.0141)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][50/390]\tTime 0.035 (0.049)\tData 0.002 (0.012)\tLoss 0.0313 (0.0151)\tPrec@1 99.219 (99.632)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][60/390]\tTime 0.046 (0.048)\tData 0.009 (0.011)\tLoss 0.0260 (0.0146)\tPrec@1 98.438 (99.641)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][70/390]\tTime 0.050 (0.048)\tData 0.006 (0.011)\tLoss 0.0058 (0.0150)\tPrec@1 100.000 (99.604)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][80/390]\tTime 0.055 (0.048)\tData 0.010 (0.010)\tLoss 0.0198 (0.0159)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][90/390]\tTime 0.034 (0.047)\tData 0.002 (0.010)\tLoss 0.0131 (0.0155)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][100/390]\tTime 0.054 (0.047)\tData 0.004 (0.009)\tLoss 0.0154 (0.0158)\tPrec@1 99.219 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][110/390]\tTime 0.045 (0.046)\tData 0.008 (0.009)\tLoss 0.0150 (0.0155)\tPrec@1 99.219 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][120/390]\tTime 0.032 (0.046)\tData 0.004 (0.009)\tLoss 0.0057 (0.0156)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][130/390]\tTime 0.030 (0.046)\tData 0.000 (0.008)\tLoss 0.0101 (0.0156)\tPrec@1 100.000 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][140/390]\tTime 0.038 (0.046)\tData 0.002 (0.008)\tLoss 0.0086 (0.0163)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][150/390]\tTime 0.021 (0.045)\tData 0.000 (0.008)\tLoss 0.0110 (0.0163)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][160/390]\tTime 0.047 (0.045)\tData 0.002 (0.008)\tLoss 0.0318 (0.0163)\tPrec@1 98.438 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][170/390]\tTime 0.062 (0.046)\tData 0.012 (0.007)\tLoss 0.0261 (0.0161)\tPrec@1 98.438 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][180/390]\tTime 0.047 (0.045)\tData 0.014 (0.007)\tLoss 0.0085 (0.0163)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][190/390]\tTime 0.046 (0.045)\tData 0.003 (0.007)\tLoss 0.0249 (0.0165)\tPrec@1 98.438 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][200/390]\tTime 0.043 (0.045)\tData 0.001 (0.007)\tLoss 0.0205 (0.0165)\tPrec@1 99.219 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][210/390]\tTime 0.047 (0.045)\tData 0.000 (0.007)\tLoss 0.0165 (0.0165)\tPrec@1 98.438 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][220/390]\tTime 0.043 (0.045)\tData 0.004 (0.007)\tLoss 0.0072 (0.0165)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][230/390]\tTime 0.041 (0.045)\tData 0.004 (0.007)\tLoss 0.0047 (0.0163)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][240/390]\tTime 0.039 (0.045)\tData 0.001 (0.007)\tLoss 0.0014 (0.0163)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][250/390]\tTime 0.040 (0.045)\tData 0.003 (0.006)\tLoss 0.0207 (0.0165)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][260/390]\tTime 0.054 (0.045)\tData 0.005 (0.006)\tLoss 0.0123 (0.0165)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][270/390]\tTime 0.043 (0.045)\tData 0.002 (0.006)\tLoss 0.0043 (0.0165)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][280/390]\tTime 0.049 (0.045)\tData 0.006 (0.006)\tLoss 0.0399 (0.0164)\tPrec@1 98.438 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][290/390]\tTime 0.038 (0.045)\tData 0.001 (0.006)\tLoss 0.0450 (0.0166)\tPrec@1 98.438 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][300/390]\tTime 0.046 (0.045)\tData 0.004 (0.006)\tLoss 0.0054 (0.0166)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][310/390]\tTime 0.033 (0.045)\tData 0.000 (0.006)\tLoss 0.0174 (0.0167)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][320/390]\tTime 0.039 (0.045)\tData 0.000 (0.006)\tLoss 0.0124 (0.0166)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][330/390]\tTime 0.037 (0.045)\tData 0.006 (0.006)\tLoss 0.0093 (0.0168)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][340/390]\tTime 0.051 (0.045)\tData 0.000 (0.006)\tLoss 0.0041 (0.0168)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][350/390]\tTime 0.047 (0.044)\tData 0.002 (0.006)\tLoss 0.0247 (0.0167)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][360/390]\tTime 0.037 (0.044)\tData 0.005 (0.006)\tLoss 0.0249 (0.0167)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][370/390]\tTime 0.045 (0.044)\tData 0.003 (0.006)\tLoss 0.0410 (0.0168)\tPrec@1 98.438 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][380/390]\tTime 0.048 (0.044)\tData 0.000 (0.006)\tLoss 0.0090 (0.0167)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [263][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0160 (0.0166)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [263][0/79]\tTime 0.246 (0.246)\tData 0.239 (0.239)\tLoss 0.2884 (0.2884)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [263][10/79]\tTime 0.020 (0.044)\tData 0.000 (0.031)\tLoss 0.2676 (0.3666)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [263][20/79]\tTime 0.021 (0.036)\tData 0.005 (0.024)\tLoss 0.5345 (0.4098)\tPrec@1 89.844 (91.592)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [263][30/79]\tTime 0.031 (0.034)\tData 0.000 (0.022)\tLoss 0.0972 (0.3962)\tPrec@1 97.656 (91.935)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [263][40/79]\tTime 0.019 (0.031)\tData 0.004 (0.020)\tLoss 0.2416 (0.3985)\tPrec@1 90.625 (91.806)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [263][50/79]\tTime 0.018 (0.031)\tData 0.006 (0.020)\tLoss 0.4372 (0.3918)\tPrec@1 90.625 (91.713)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [263][60/79]\tTime 0.045 (0.030)\tData 0.012 (0.019)\tLoss 0.6450 (0.3972)\tPrec@1 92.969 (91.650)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [263][70/79]\tTime 0.012 (0.030)\tData 0.006 (0.019)\tLoss 0.4109 (0.3899)\tPrec@1 89.062 (91.604)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [263][78/79]\tTime 0.003 (0.028)\tData 0.000 (0.018)\tLoss 0.2541 (0.3871)\tPrec@1 93.750 (91.630)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 264\n",
            "Training Loss 0.0166 \tTraining Prec@1 99.545 \tTraining Prec@5 100.000 \tValidation Loss 0.3871 \tValidation Prec@1 91.630 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 265\n",
            "\n",
            "TRAINING - Epoch: [264][0/390]\tTime 0.281 (0.281)\tData 0.239 (0.239)\tLoss 0.0089 (0.0089)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][10/390]\tTime 0.035 (0.067)\tData 0.001 (0.026)\tLoss 0.0164 (0.0219)\tPrec@1 100.000 (99.361)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][20/390]\tTime 0.039 (0.055)\tData 0.004 (0.015)\tLoss 0.0168 (0.0162)\tPrec@1 99.219 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][30/390]\tTime 0.040 (0.051)\tData 0.004 (0.012)\tLoss 0.0078 (0.0169)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][40/390]\tTime 0.049 (0.049)\tData 0.001 (0.011)\tLoss 0.0103 (0.0179)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][50/390]\tTime 0.037 (0.047)\tData 0.007 (0.009)\tLoss 0.0084 (0.0174)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][60/390]\tTime 0.025 (0.046)\tData 0.005 (0.008)\tLoss 0.0119 (0.0174)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][70/390]\tTime 0.039 (0.046)\tData 0.000 (0.009)\tLoss 0.0034 (0.0170)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][80/390]\tTime 0.047 (0.046)\tData 0.007 (0.008)\tLoss 0.0172 (0.0170)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][90/390]\tTime 0.034 (0.046)\tData 0.001 (0.007)\tLoss 0.0089 (0.0171)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][100/390]\tTime 0.036 (0.046)\tData 0.000 (0.007)\tLoss 0.0187 (0.0170)\tPrec@1 99.219 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][110/390]\tTime 0.040 (0.046)\tData 0.013 (0.007)\tLoss 0.0141 (0.0168)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][120/390]\tTime 0.051 (0.046)\tData 0.008 (0.007)\tLoss 0.0077 (0.0167)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][130/390]\tTime 0.024 (0.046)\tData 0.000 (0.007)\tLoss 0.0145 (0.0168)\tPrec@1 100.000 (99.589)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][140/390]\tTime 0.046 (0.046)\tData 0.005 (0.006)\tLoss 0.0237 (0.0169)\tPrec@1 99.219 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][150/390]\tTime 0.038 (0.045)\tData 0.001 (0.006)\tLoss 0.0054 (0.0171)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][160/390]\tTime 0.050 (0.045)\tData 0.001 (0.006)\tLoss 0.0232 (0.0172)\tPrec@1 99.219 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][170/390]\tTime 0.037 (0.045)\tData 0.000 (0.006)\tLoss 0.0117 (0.0177)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][180/390]\tTime 0.036 (0.045)\tData 0.007 (0.006)\tLoss 0.0176 (0.0177)\tPrec@1 99.219 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][190/390]\tTime 0.031 (0.045)\tData 0.001 (0.005)\tLoss 0.0326 (0.0179)\tPrec@1 99.219 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][200/390]\tTime 0.051 (0.045)\tData 0.001 (0.005)\tLoss 0.0067 (0.0176)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][210/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0092 (0.0177)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][220/390]\tTime 0.047 (0.045)\tData 0.000 (0.005)\tLoss 0.0098 (0.0180)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][230/390]\tTime 0.034 (0.044)\tData 0.001 (0.005)\tLoss 0.0229 (0.0178)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][240/390]\tTime 0.039 (0.044)\tData 0.000 (0.005)\tLoss 0.0103 (0.0177)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][250/390]\tTime 0.045 (0.044)\tData 0.005 (0.005)\tLoss 0.0071 (0.0176)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][260/390]\tTime 0.070 (0.044)\tData 0.037 (0.005)\tLoss 0.0111 (0.0175)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][270/390]\tTime 0.040 (0.044)\tData 0.009 (0.005)\tLoss 0.0149 (0.0174)\tPrec@1 99.219 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][280/390]\tTime 0.045 (0.044)\tData 0.005 (0.005)\tLoss 0.0152 (0.0175)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][290/390]\tTime 0.040 (0.044)\tData 0.003 (0.005)\tLoss 0.0129 (0.0174)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][300/390]\tTime 0.038 (0.044)\tData 0.005 (0.005)\tLoss 0.0059 (0.0174)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][310/390]\tTime 0.040 (0.044)\tData 0.000 (0.005)\tLoss 0.0117 (0.0176)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][320/390]\tTime 0.045 (0.044)\tData 0.000 (0.005)\tLoss 0.0106 (0.0176)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][330/390]\tTime 0.031 (0.044)\tData 0.000 (0.005)\tLoss 0.0162 (0.0177)\tPrec@1 99.219 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][340/390]\tTime 0.031 (0.044)\tData 0.001 (0.005)\tLoss 0.0184 (0.0176)\tPrec@1 99.219 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][350/390]\tTime 0.030 (0.044)\tData 0.000 (0.005)\tLoss 0.0082 (0.0176)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][360/390]\tTime 0.032 (0.044)\tData 0.000 (0.005)\tLoss 0.0242 (0.0177)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][370/390]\tTime 0.055 (0.044)\tData 0.007 (0.005)\tLoss 0.0144 (0.0176)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][380/390]\tTime 0.041 (0.044)\tData 0.004 (0.005)\tLoss 0.0236 (0.0176)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [264][389/390]\tTime 0.019 (0.044)\tData 0.000 (0.005)\tLoss 0.0053 (0.0174)\tPrec@1 100.000 (99.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [264][0/79]\tTime 0.228 (0.228)\tData 0.203 (0.203)\tLoss 0.2926 (0.2926)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [264][10/79]\tTime 0.036 (0.042)\tData 0.030 (0.032)\tLoss 0.2606 (0.3665)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [264][20/79]\tTime 0.047 (0.037)\tData 0.041 (0.027)\tLoss 0.5369 (0.4092)\tPrec@1 89.844 (91.592)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [264][30/79]\tTime 0.035 (0.034)\tData 0.023 (0.024)\tLoss 0.0963 (0.3954)\tPrec@1 97.656 (91.809)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [264][40/79]\tTime 0.013 (0.032)\tData 0.000 (0.022)\tLoss 0.2444 (0.3968)\tPrec@1 91.406 (91.806)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [264][50/79]\tTime 0.049 (0.032)\tData 0.044 (0.021)\tLoss 0.4331 (0.3899)\tPrec@1 90.625 (91.728)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [264][60/79]\tTime 0.021 (0.031)\tData 0.005 (0.019)\tLoss 0.6339 (0.3952)\tPrec@1 92.969 (91.662)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [264][70/79]\tTime 0.068 (0.031)\tData 0.061 (0.019)\tLoss 0.4039 (0.3877)\tPrec@1 89.844 (91.626)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [264][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2700 (0.3853)\tPrec@1 93.750 (91.610)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 265\n",
            "Training Loss 0.0174 \tTraining Prec@1 99.531 \tTraining Prec@5 100.000 \tValidation Loss 0.3853 \tValidation Prec@1 91.610 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 266\n",
            "\n",
            "TRAINING - Epoch: [265][0/390]\tTime 0.228 (0.228)\tData 0.187 (0.187)\tLoss 0.0244 (0.0244)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][10/390]\tTime 0.039 (0.070)\tData 0.000 (0.030)\tLoss 0.0202 (0.0142)\tPrec@1 99.219 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][20/390]\tTime 0.046 (0.058)\tData 0.006 (0.017)\tLoss 0.0168 (0.0172)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][30/390]\tTime 0.042 (0.054)\tData 0.000 (0.013)\tLoss 0.0048 (0.0163)\tPrec@1 100.000 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][40/390]\tTime 0.049 (0.051)\tData 0.005 (0.010)\tLoss 0.0132 (0.0159)\tPrec@1 100.000 (99.676)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][50/390]\tTime 0.043 (0.048)\tData 0.005 (0.009)\tLoss 0.0149 (0.0153)\tPrec@1 99.219 (99.694)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][60/390]\tTime 0.047 (0.048)\tData 0.003 (0.008)\tLoss 0.0172 (0.0164)\tPrec@1 99.219 (99.629)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][70/390]\tTime 0.036 (0.047)\tData 0.001 (0.008)\tLoss 0.0217 (0.0168)\tPrec@1 99.219 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][80/390]\tTime 0.044 (0.046)\tData 0.001 (0.007)\tLoss 0.0171 (0.0171)\tPrec@1 99.219 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][90/390]\tTime 0.031 (0.046)\tData 0.003 (0.007)\tLoss 0.0299 (0.0169)\tPrec@1 98.438 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][100/390]\tTime 0.043 (0.046)\tData 0.005 (0.006)\tLoss 0.0835 (0.0185)\tPrec@1 96.094 (99.466)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][110/390]\tTime 0.044 (0.045)\tData 0.008 (0.006)\tLoss 0.0067 (0.0182)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][120/390]\tTime 0.038 (0.045)\tData 0.005 (0.006)\tLoss 0.0106 (0.0182)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][130/390]\tTime 0.040 (0.045)\tData 0.001 (0.006)\tLoss 0.0127 (0.0179)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][140/390]\tTime 0.039 (0.045)\tData 0.002 (0.006)\tLoss 0.0097 (0.0175)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][150/390]\tTime 0.054 (0.045)\tData 0.002 (0.006)\tLoss 0.0023 (0.0173)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][160/390]\tTime 0.034 (0.045)\tData 0.003 (0.006)\tLoss 0.0278 (0.0175)\tPrec@1 99.219 (99.515)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][170/390]\tTime 0.037 (0.044)\tData 0.007 (0.005)\tLoss 0.0056 (0.0175)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][180/390]\tTime 0.036 (0.045)\tData 0.001 (0.006)\tLoss 0.0252 (0.0173)\tPrec@1 98.438 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][190/390]\tTime 0.039 (0.045)\tData 0.010 (0.006)\tLoss 0.0048 (0.0172)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][200/390]\tTime 0.021 (0.044)\tData 0.000 (0.006)\tLoss 0.0079 (0.0171)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][210/390]\tTime 0.029 (0.044)\tData 0.000 (0.005)\tLoss 0.0297 (0.0171)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][220/390]\tTime 0.053 (0.044)\tData 0.023 (0.006)\tLoss 0.0160 (0.0172)\tPrec@1 99.219 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][230/390]\tTime 0.040 (0.044)\tData 0.000 (0.006)\tLoss 0.0190 (0.0171)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][240/390]\tTime 0.050 (0.044)\tData 0.000 (0.006)\tLoss 0.0059 (0.0171)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][250/390]\tTime 0.044 (0.044)\tData 0.005 (0.006)\tLoss 0.0119 (0.0171)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][260/390]\tTime 0.055 (0.044)\tData 0.011 (0.006)\tLoss 0.0423 (0.0171)\tPrec@1 98.438 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][270/390]\tTime 0.052 (0.044)\tData 0.002 (0.006)\tLoss 0.0087 (0.0170)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][280/390]\tTime 0.072 (0.044)\tData 0.035 (0.006)\tLoss 0.0101 (0.0169)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][290/390]\tTime 0.043 (0.044)\tData 0.004 (0.006)\tLoss 0.0325 (0.0171)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][300/390]\tTime 0.055 (0.044)\tData 0.013 (0.006)\tLoss 0.0114 (0.0171)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][310/390]\tTime 0.041 (0.044)\tData 0.002 (0.006)\tLoss 0.0076 (0.0171)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][320/390]\tTime 0.053 (0.044)\tData 0.013 (0.006)\tLoss 0.0336 (0.0171)\tPrec@1 98.438 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][330/390]\tTime 0.038 (0.044)\tData 0.000 (0.006)\tLoss 0.0291 (0.0170)\tPrec@1 98.438 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][340/390]\tTime 0.048 (0.044)\tData 0.005 (0.006)\tLoss 0.0401 (0.0170)\tPrec@1 97.656 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][350/390]\tTime 0.060 (0.044)\tData 0.006 (0.006)\tLoss 0.0057 (0.0170)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][360/390]\tTime 0.037 (0.044)\tData 0.005 (0.005)\tLoss 0.0120 (0.0169)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][370/390]\tTime 0.044 (0.044)\tData 0.006 (0.006)\tLoss 0.0108 (0.0170)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][380/390]\tTime 0.032 (0.043)\tData 0.010 (0.006)\tLoss 0.0201 (0.0170)\tPrec@1 99.219 (99.532)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [265][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.005)\tLoss 0.0048 (0.0171)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [265][0/79]\tTime 0.165 (0.165)\tData 0.156 (0.156)\tLoss 0.2920 (0.2920)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [265][10/79]\tTime 0.016 (0.042)\tData 0.000 (0.030)\tLoss 0.2661 (0.3700)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [265][20/79]\tTime 0.019 (0.033)\tData 0.005 (0.022)\tLoss 0.5217 (0.4085)\tPrec@1 89.844 (91.629)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [265][30/79]\tTime 0.052 (0.031)\tData 0.046 (0.020)\tLoss 0.0996 (0.3961)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [265][40/79]\tTime 0.015 (0.030)\tData 0.000 (0.018)\tLoss 0.2494 (0.3975)\tPrec@1 89.844 (91.864)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [265][50/79]\tTime 0.039 (0.029)\tData 0.033 (0.018)\tLoss 0.4306 (0.3906)\tPrec@1 90.625 (91.774)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [265][60/79]\tTime 0.059 (0.030)\tData 0.047 (0.018)\tLoss 0.6400 (0.3958)\tPrec@1 92.969 (91.650)\tPrec@5 99.219 (99.680)\t\n",
            "EVALUATING - Epoch: [265][70/79]\tTime 0.028 (0.029)\tData 0.007 (0.018)\tLoss 0.3933 (0.3881)\tPrec@1 89.844 (91.593)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [265][78/79]\tTime 0.003 (0.028)\tData 0.000 (0.017)\tLoss 0.2399 (0.3849)\tPrec@1 93.750 (91.570)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 266\n",
            "Training Loss 0.0171 \tTraining Prec@1 99.537 \tTraining Prec@5 100.000 \tValidation Loss 0.3849 \tValidation Prec@1 91.570 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 267\n",
            "\n",
            "TRAINING - Epoch: [266][0/390]\tTime 0.249 (0.249)\tData 0.190 (0.190)\tLoss 0.0203 (0.0203)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][10/390]\tTime 0.034 (0.063)\tData 0.004 (0.029)\tLoss 0.0162 (0.0163)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][20/390]\tTime 0.055 (0.055)\tData 0.011 (0.020)\tLoss 0.0210 (0.0169)\tPrec@1 99.219 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][30/390]\tTime 0.036 (0.051)\tData 0.005 (0.016)\tLoss 0.0090 (0.0164)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][40/390]\tTime 0.050 (0.049)\tData 0.000 (0.013)\tLoss 0.0100 (0.0164)\tPrec@1 100.000 (99.638)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][50/390]\tTime 0.042 (0.048)\tData 0.000 (0.011)\tLoss 0.0239 (0.0165)\tPrec@1 99.219 (99.648)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][60/390]\tTime 0.044 (0.046)\tData 0.001 (0.010)\tLoss 0.0080 (0.0187)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][70/390]\tTime 0.033 (0.046)\tData 0.000 (0.009)\tLoss 0.0453 (0.0191)\tPrec@1 98.438 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][80/390]\tTime 0.046 (0.045)\tData 0.001 (0.009)\tLoss 0.0133 (0.0207)\tPrec@1 100.000 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][90/390]\tTime 0.052 (0.045)\tData 0.011 (0.008)\tLoss 0.0223 (0.0202)\tPrec@1 99.219 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][100/390]\tTime 0.038 (0.045)\tData 0.000 (0.008)\tLoss 0.0114 (0.0199)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][110/390]\tTime 0.043 (0.045)\tData 0.001 (0.008)\tLoss 0.0182 (0.0193)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][120/390]\tTime 0.034 (0.044)\tData 0.000 (0.007)\tLoss 0.0218 (0.0187)\tPrec@1 99.219 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][130/390]\tTime 0.052 (0.044)\tData 0.008 (0.007)\tLoss 0.0196 (0.0184)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][140/390]\tTime 0.050 (0.044)\tData 0.004 (0.007)\tLoss 0.0085 (0.0181)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][150/390]\tTime 0.039 (0.044)\tData 0.002 (0.007)\tLoss 0.0200 (0.0181)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][160/390]\tTime 0.044 (0.044)\tData 0.000 (0.006)\tLoss 0.0205 (0.0182)\tPrec@1 99.219 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][170/390]\tTime 0.042 (0.044)\tData 0.000 (0.006)\tLoss 0.0108 (0.0183)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][180/390]\tTime 0.046 (0.044)\tData 0.000 (0.006)\tLoss 0.0117 (0.0184)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][190/390]\tTime 0.037 (0.044)\tData 0.001 (0.006)\tLoss 0.0118 (0.0183)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][200/390]\tTime 0.033 (0.044)\tData 0.001 (0.006)\tLoss 0.0084 (0.0185)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][210/390]\tTime 0.042 (0.044)\tData 0.004 (0.006)\tLoss 0.0439 (0.0188)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][220/390]\tTime 0.050 (0.044)\tData 0.001 (0.006)\tLoss 0.0398 (0.0189)\tPrec@1 98.438 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][230/390]\tTime 0.054 (0.044)\tData 0.000 (0.006)\tLoss 0.0235 (0.0189)\tPrec@1 100.000 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][240/390]\tTime 0.034 (0.044)\tData 0.000 (0.006)\tLoss 0.0072 (0.0192)\tPrec@1 100.000 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][250/390]\tTime 0.045 (0.044)\tData 0.001 (0.006)\tLoss 0.0052 (0.0192)\tPrec@1 100.000 (99.480)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][260/390]\tTime 0.043 (0.044)\tData 0.002 (0.006)\tLoss 0.0090 (0.0191)\tPrec@1 100.000 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][270/390]\tTime 0.043 (0.044)\tData 0.009 (0.006)\tLoss 0.0272 (0.0190)\tPrec@1 98.438 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][280/390]\tTime 0.045 (0.044)\tData 0.009 (0.006)\tLoss 0.0176 (0.0190)\tPrec@1 99.219 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][290/390]\tTime 0.052 (0.044)\tData 0.022 (0.006)\tLoss 0.0174 (0.0189)\tPrec@1 99.219 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][300/390]\tTime 0.051 (0.044)\tData 0.000 (0.006)\tLoss 0.0042 (0.0189)\tPrec@1 100.000 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][310/390]\tTime 0.036 (0.044)\tData 0.001 (0.005)\tLoss 0.0058 (0.0187)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][320/390]\tTime 0.050 (0.044)\tData 0.006 (0.005)\tLoss 0.0161 (0.0187)\tPrec@1 100.000 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][330/390]\tTime 0.033 (0.044)\tData 0.003 (0.005)\tLoss 0.0186 (0.0188)\tPrec@1 98.438 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][340/390]\tTime 0.042 (0.044)\tData 0.002 (0.005)\tLoss 0.0304 (0.0188)\tPrec@1 98.438 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][350/390]\tTime 0.049 (0.044)\tData 0.005 (0.005)\tLoss 0.0083 (0.0187)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][360/390]\tTime 0.037 (0.044)\tData 0.001 (0.005)\tLoss 0.0088 (0.0187)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][370/390]\tTime 0.053 (0.044)\tData 0.007 (0.005)\tLoss 0.0317 (0.0186)\tPrec@1 98.438 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][380/390]\tTime 0.049 (0.044)\tData 0.006 (0.005)\tLoss 0.0254 (0.0187)\tPrec@1 99.219 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [266][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.005)\tLoss 0.0179 (0.0186)\tPrec@1 99.219 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [266][0/79]\tTime 0.174 (0.174)\tData 0.165 (0.165)\tLoss 0.2828 (0.2828)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [266][10/79]\tTime 0.024 (0.045)\tData 0.006 (0.034)\tLoss 0.2645 (0.3722)\tPrec@1 91.406 (92.401)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [266][20/79]\tTime 0.019 (0.036)\tData 0.005 (0.024)\tLoss 0.5318 (0.4104)\tPrec@1 89.844 (91.741)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [266][30/79]\tTime 0.011 (0.034)\tData 0.000 (0.022)\tLoss 0.0929 (0.3980)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [266][40/79]\tTime 0.041 (0.033)\tData 0.000 (0.020)\tLoss 0.2410 (0.3996)\tPrec@1 89.844 (91.845)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [266][50/79]\tTime 0.053 (0.032)\tData 0.048 (0.019)\tLoss 0.4476 (0.3925)\tPrec@1 90.625 (91.759)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [266][60/79]\tTime 0.020 (0.031)\tData 0.005 (0.017)\tLoss 0.6410 (0.3975)\tPrec@1 92.969 (91.688)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [266][70/79]\tTime 0.028 (0.030)\tData 0.022 (0.017)\tLoss 0.3969 (0.3892)\tPrec@1 90.625 (91.670)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [266][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.016)\tLoss 0.2363 (0.3860)\tPrec@1 93.750 (91.670)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 267\n",
            "Training Loss 0.0186 \tTraining Prec@1 99.495 \tTraining Prec@5 100.000 \tValidation Loss 0.3860 \tValidation Prec@1 91.670 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 268\n",
            "\n",
            "TRAINING - Epoch: [267][0/390]\tTime 0.310 (0.310)\tData 0.249 (0.249)\tLoss 0.0188 (0.0188)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][10/390]\tTime 0.029 (0.065)\tData 0.000 (0.027)\tLoss 0.0078 (0.0160)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][20/390]\tTime 0.045 (0.054)\tData 0.012 (0.016)\tLoss 0.0337 (0.0158)\tPrec@1 98.438 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][30/390]\tTime 0.030 (0.052)\tData 0.000 (0.013)\tLoss 0.0538 (0.0167)\tPrec@1 98.438 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][40/390]\tTime 0.044 (0.050)\tData 0.005 (0.011)\tLoss 0.0146 (0.0158)\tPrec@1 99.219 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][50/390]\tTime 0.049 (0.049)\tData 0.006 (0.009)\tLoss 0.0093 (0.0158)\tPrec@1 100.000 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][60/390]\tTime 0.047 (0.047)\tData 0.011 (0.008)\tLoss 0.0177 (0.0164)\tPrec@1 99.219 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][70/390]\tTime 0.052 (0.047)\tData 0.001 (0.008)\tLoss 0.0181 (0.0171)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][80/390]\tTime 0.031 (0.046)\tData 0.000 (0.007)\tLoss 0.0064 (0.0171)\tPrec@1 100.000 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][90/390]\tTime 0.052 (0.046)\tData 0.001 (0.006)\tLoss 0.0073 (0.0174)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][100/390]\tTime 0.045 (0.045)\tData 0.007 (0.006)\tLoss 0.0269 (0.0175)\tPrec@1 98.438 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][110/390]\tTime 0.034 (0.045)\tData 0.006 (0.006)\tLoss 0.0157 (0.0171)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][120/390]\tTime 0.038 (0.045)\tData 0.000 (0.006)\tLoss 0.0070 (0.0175)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][130/390]\tTime 0.044 (0.045)\tData 0.004 (0.006)\tLoss 0.0100 (0.0173)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][140/390]\tTime 0.038 (0.045)\tData 0.000 (0.005)\tLoss 0.0242 (0.0172)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][150/390]\tTime 0.050 (0.045)\tData 0.007 (0.005)\tLoss 0.0168 (0.0172)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][160/390]\tTime 0.034 (0.045)\tData 0.007 (0.005)\tLoss 0.0302 (0.0171)\tPrec@1 98.438 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][170/390]\tTime 0.049 (0.044)\tData 0.013 (0.005)\tLoss 0.0189 (0.0172)\tPrec@1 99.219 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][180/390]\tTime 0.046 (0.044)\tData 0.008 (0.006)\tLoss 0.0248 (0.0171)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][190/390]\tTime 0.035 (0.044)\tData 0.005 (0.006)\tLoss 0.0058 (0.0169)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][200/390]\tTime 0.043 (0.044)\tData 0.005 (0.006)\tLoss 0.0099 (0.0168)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][210/390]\tTime 0.035 (0.044)\tData 0.001 (0.005)\tLoss 0.0253 (0.0165)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][220/390]\tTime 0.048 (0.044)\tData 0.010 (0.006)\tLoss 0.0110 (0.0165)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][230/390]\tTime 0.039 (0.044)\tData 0.002 (0.006)\tLoss 0.0160 (0.0165)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][240/390]\tTime 0.041 (0.044)\tData 0.000 (0.006)\tLoss 0.0068 (0.0164)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][250/390]\tTime 0.050 (0.044)\tData 0.007 (0.006)\tLoss 0.0049 (0.0165)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][260/390]\tTime 0.050 (0.044)\tData 0.011 (0.006)\tLoss 0.0309 (0.0166)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][270/390]\tTime 0.055 (0.044)\tData 0.008 (0.006)\tLoss 0.0310 (0.0166)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][280/390]\tTime 0.042 (0.044)\tData 0.004 (0.006)\tLoss 0.0044 (0.0167)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][290/390]\tTime 0.032 (0.044)\tData 0.000 (0.006)\tLoss 0.0084 (0.0166)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][300/390]\tTime 0.045 (0.044)\tData 0.003 (0.006)\tLoss 0.0114 (0.0168)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][310/390]\tTime 0.021 (0.044)\tData 0.000 (0.006)\tLoss 0.0081 (0.0168)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][320/390]\tTime 0.034 (0.044)\tData 0.004 (0.006)\tLoss 0.0088 (0.0167)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][330/390]\tTime 0.053 (0.044)\tData 0.007 (0.005)\tLoss 0.0312 (0.0167)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][340/390]\tTime 0.048 (0.044)\tData 0.012 (0.005)\tLoss 0.0143 (0.0166)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][350/390]\tTime 0.045 (0.044)\tData 0.000 (0.005)\tLoss 0.0025 (0.0166)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][360/390]\tTime 0.029 (0.043)\tData 0.000 (0.005)\tLoss 0.0069 (0.0166)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][370/390]\tTime 0.049 (0.043)\tData 0.023 (0.005)\tLoss 0.0089 (0.0166)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][380/390]\tTime 0.030 (0.044)\tData 0.000 (0.006)\tLoss 0.0100 (0.0166)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [267][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.006)\tLoss 0.0308 (0.0168)\tPrec@1 98.438 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [267][0/79]\tTime 0.233 (0.233)\tData 0.220 (0.220)\tLoss 0.2826 (0.2826)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [267][10/79]\tTime 0.015 (0.043)\tData 0.000 (0.031)\tLoss 0.2682 (0.3698)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [267][20/79]\tTime 0.058 (0.036)\tData 0.052 (0.024)\tLoss 0.5352 (0.4128)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [267][30/79]\tTime 0.017 (0.032)\tData 0.003 (0.022)\tLoss 0.0957 (0.3994)\tPrec@1 97.656 (91.986)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [267][40/79]\tTime 0.032 (0.031)\tData 0.026 (0.020)\tLoss 0.2408 (0.4011)\tPrec@1 89.844 (91.864)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [267][50/79]\tTime 0.022 (0.031)\tData 0.006 (0.019)\tLoss 0.4529 (0.3938)\tPrec@1 90.625 (91.774)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [267][60/79]\tTime 0.049 (0.031)\tData 0.032 (0.019)\tLoss 0.6457 (0.3985)\tPrec@1 92.969 (91.714)\tPrec@5 99.219 (99.654)\t\n",
            "EVALUATING - Epoch: [267][70/79]\tTime 0.020 (0.030)\tData 0.005 (0.018)\tLoss 0.3973 (0.3904)\tPrec@1 89.062 (91.626)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [267][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2525 (0.3872)\tPrec@1 93.750 (91.650)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 268\n",
            "Training Loss 0.0168 \tTraining Prec@1 99.541 \tTraining Prec@5 100.000 \tValidation Loss 0.3872 \tValidation Prec@1 91.650 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 269\n",
            "\n",
            "TRAINING - Epoch: [268][0/390]\tTime 0.325 (0.325)\tData 0.277 (0.277)\tLoss 0.0189 (0.0189)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][10/390]\tTime 0.046 (0.066)\tData 0.005 (0.029)\tLoss 0.0046 (0.0183)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][20/390]\tTime 0.048 (0.057)\tData 0.003 (0.017)\tLoss 0.0091 (0.0161)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][30/390]\tTime 0.054 (0.053)\tData 0.000 (0.012)\tLoss 0.0084 (0.0175)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][40/390]\tTime 0.030 (0.051)\tData 0.000 (0.010)\tLoss 0.0222 (0.0166)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][50/390]\tTime 0.028 (0.049)\tData 0.000 (0.009)\tLoss 0.0299 (0.0169)\tPrec@1 98.438 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][60/390]\tTime 0.042 (0.049)\tData 0.007 (0.009)\tLoss 0.0067 (0.0156)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][70/390]\tTime 0.038 (0.048)\tData 0.006 (0.008)\tLoss 0.0050 (0.0157)\tPrec@1 100.000 (99.593)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][80/390]\tTime 0.050 (0.048)\tData 0.002 (0.008)\tLoss 0.0093 (0.0157)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][90/390]\tTime 0.050 (0.048)\tData 0.001 (0.007)\tLoss 0.0058 (0.0162)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][100/390]\tTime 0.051 (0.048)\tData 0.007 (0.006)\tLoss 0.0043 (0.0163)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][110/390]\tTime 0.047 (0.047)\tData 0.001 (0.006)\tLoss 0.0156 (0.0167)\tPrec@1 99.219 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][120/390]\tTime 0.044 (0.047)\tData 0.013 (0.006)\tLoss 0.0222 (0.0168)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][130/390]\tTime 0.037 (0.046)\tData 0.001 (0.006)\tLoss 0.0284 (0.0167)\tPrec@1 99.219 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][140/390]\tTime 0.053 (0.046)\tData 0.001 (0.005)\tLoss 0.0062 (0.0166)\tPrec@1 100.000 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][150/390]\tTime 0.045 (0.046)\tData 0.001 (0.005)\tLoss 0.0071 (0.0169)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][160/390]\tTime 0.048 (0.046)\tData 0.005 (0.005)\tLoss 0.0134 (0.0170)\tPrec@1 99.219 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][170/390]\tTime 0.045 (0.046)\tData 0.008 (0.005)\tLoss 0.0082 (0.0167)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][180/390]\tTime 0.035 (0.046)\tData 0.002 (0.005)\tLoss 0.0098 (0.0169)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][190/390]\tTime 0.038 (0.046)\tData 0.002 (0.005)\tLoss 0.0258 (0.0169)\tPrec@1 99.219 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][200/390]\tTime 0.054 (0.046)\tData 0.007 (0.005)\tLoss 0.0539 (0.0172)\tPrec@1 97.656 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][210/390]\tTime 0.039 (0.046)\tData 0.000 (0.005)\tLoss 0.0168 (0.0174)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][220/390]\tTime 0.035 (0.046)\tData 0.000 (0.005)\tLoss 0.0104 (0.0174)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][230/390]\tTime 0.033 (0.045)\tData 0.000 (0.005)\tLoss 0.0102 (0.0172)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][240/390]\tTime 0.028 (0.045)\tData 0.000 (0.005)\tLoss 0.0294 (0.0173)\tPrec@1 99.219 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][250/390]\tTime 0.042 (0.045)\tData 0.002 (0.005)\tLoss 0.0303 (0.0173)\tPrec@1 98.438 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][260/390]\tTime 0.036 (0.045)\tData 0.000 (0.005)\tLoss 0.0214 (0.0172)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][270/390]\tTime 0.050 (0.045)\tData 0.008 (0.005)\tLoss 0.0164 (0.0170)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][280/390]\tTime 0.027 (0.045)\tData 0.000 (0.005)\tLoss 0.0149 (0.0170)\tPrec@1 99.219 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][290/390]\tTime 0.039 (0.045)\tData 0.003 (0.005)\tLoss 0.0051 (0.0169)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][300/390]\tTime 0.036 (0.044)\tData 0.000 (0.005)\tLoss 0.0108 (0.0169)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][310/390]\tTime 0.036 (0.044)\tData 0.003 (0.005)\tLoss 0.0064 (0.0169)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][320/390]\tTime 0.050 (0.044)\tData 0.008 (0.005)\tLoss 0.0146 (0.0169)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][330/390]\tTime 0.031 (0.044)\tData 0.007 (0.005)\tLoss 0.0146 (0.0171)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][340/390]\tTime 0.040 (0.044)\tData 0.001 (0.005)\tLoss 0.0139 (0.0170)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][350/390]\tTime 0.044 (0.044)\tData 0.009 (0.005)\tLoss 0.0108 (0.0170)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][360/390]\tTime 0.047 (0.044)\tData 0.015 (0.005)\tLoss 0.0313 (0.0169)\tPrec@1 98.438 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][370/390]\tTime 0.035 (0.044)\tData 0.000 (0.005)\tLoss 0.0066 (0.0171)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][380/390]\tTime 0.035 (0.044)\tData 0.001 (0.005)\tLoss 0.0263 (0.0171)\tPrec@1 98.438 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [268][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0192 (0.0172)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [268][0/79]\tTime 0.249 (0.249)\tData 0.234 (0.234)\tLoss 0.2910 (0.2910)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [268][10/79]\tTime 0.016 (0.044)\tData 0.010 (0.033)\tLoss 0.2587 (0.3689)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [268][20/79]\tTime 0.019 (0.037)\tData 0.003 (0.025)\tLoss 0.5354 (0.4102)\tPrec@1 89.844 (91.555)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [268][30/79]\tTime 0.059 (0.035)\tData 0.053 (0.023)\tLoss 0.0979 (0.3975)\tPrec@1 97.656 (91.835)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [268][40/79]\tTime 0.015 (0.032)\tData 0.000 (0.020)\tLoss 0.2518 (0.3987)\tPrec@1 89.844 (91.749)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [268][50/79]\tTime 0.043 (0.031)\tData 0.036 (0.019)\tLoss 0.4379 (0.3913)\tPrec@1 89.844 (91.805)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [268][60/79]\tTime 0.021 (0.030)\tData 0.005 (0.018)\tLoss 0.6375 (0.3964)\tPrec@1 92.969 (91.726)\tPrec@5 99.219 (99.680)\t\n",
            "EVALUATING - Epoch: [268][70/79]\tTime 0.059 (0.030)\tData 0.052 (0.018)\tLoss 0.3940 (0.3884)\tPrec@1 89.844 (91.648)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [268][78/79]\tTime 0.003 (0.028)\tData 0.000 (0.017)\tLoss 0.2481 (0.3854)\tPrec@1 93.750 (91.650)\tPrec@5 100.000 (99.720)\t\n",
            "\n",
            "Results - Epoch: 269\n",
            "Training Loss 0.0172 \tTraining Prec@1 99.537 \tTraining Prec@5 100.000 \tValidation Loss 0.3854 \tValidation Prec@1 91.650 \tValidation Prec@5 99.720 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 270\n",
            "\n",
            "TRAINING - Epoch: [269][0/390]\tTime 0.304 (0.304)\tData 0.243 (0.243)\tLoss 0.0167 (0.0167)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][10/390]\tTime 0.045 (0.070)\tData 0.003 (0.025)\tLoss 0.0063 (0.0169)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][20/390]\tTime 0.044 (0.058)\tData 0.000 (0.014)\tLoss 0.0218 (0.0173)\tPrec@1 99.219 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][30/390]\tTime 0.055 (0.053)\tData 0.000 (0.010)\tLoss 0.0197 (0.0173)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][40/390]\tTime 0.046 (0.052)\tData 0.000 (0.008)\tLoss 0.0180 (0.0168)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][50/390]\tTime 0.036 (0.050)\tData 0.007 (0.007)\tLoss 0.0405 (0.0176)\tPrec@1 99.219 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][60/390]\tTime 0.042 (0.049)\tData 0.006 (0.007)\tLoss 0.0343 (0.0182)\tPrec@1 98.438 (99.462)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][70/390]\tTime 0.053 (0.048)\tData 0.006 (0.006)\tLoss 0.0258 (0.0185)\tPrec@1 99.219 (99.450)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][80/390]\tTime 0.048 (0.048)\tData 0.001 (0.006)\tLoss 0.0167 (0.0183)\tPrec@1 100.000 (99.460)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][90/390]\tTime 0.029 (0.048)\tData 0.000 (0.006)\tLoss 0.0102 (0.0178)\tPrec@1 100.000 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][100/390]\tTime 0.039 (0.047)\tData 0.002 (0.005)\tLoss 0.0053 (0.0174)\tPrec@1 100.000 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][110/390]\tTime 0.048 (0.046)\tData 0.004 (0.005)\tLoss 0.0189 (0.0170)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][120/390]\tTime 0.054 (0.046)\tData 0.004 (0.005)\tLoss 0.0201 (0.0168)\tPrec@1 99.219 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][130/390]\tTime 0.044 (0.046)\tData 0.000 (0.005)\tLoss 0.0108 (0.0169)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][140/390]\tTime 0.042 (0.046)\tData 0.005 (0.005)\tLoss 0.0094 (0.0168)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][150/390]\tTime 0.048 (0.046)\tData 0.005 (0.005)\tLoss 0.0389 (0.0175)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][160/390]\tTime 0.033 (0.046)\tData 0.003 (0.005)\tLoss 0.0197 (0.0173)\tPrec@1 98.438 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][170/390]\tTime 0.043 (0.045)\tData 0.009 (0.005)\tLoss 0.0094 (0.0173)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][180/390]\tTime 0.036 (0.045)\tData 0.006 (0.005)\tLoss 0.0087 (0.0168)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][190/390]\tTime 0.047 (0.045)\tData 0.000 (0.005)\tLoss 0.0261 (0.0170)\tPrec@1 99.219 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][200/390]\tTime 0.041 (0.045)\tData 0.006 (0.005)\tLoss 0.0139 (0.0172)\tPrec@1 99.219 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][210/390]\tTime 0.036 (0.045)\tData 0.007 (0.005)\tLoss 0.0185 (0.0172)\tPrec@1 99.219 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][220/390]\tTime 0.048 (0.045)\tData 0.000 (0.005)\tLoss 0.0049 (0.0174)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [269][230/390]\tTime 0.037 (0.045)\tData 0.000 (0.005)\tLoss 0.0488 (0.0177)\tPrec@1 99.219 (99.513)\tPrec@5 99.219 (99.997)\t\n",
            "TRAINING - Epoch: [269][240/390]\tTime 0.039 (0.045)\tData 0.002 (0.005)\tLoss 0.0104 (0.0178)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [269][250/390]\tTime 0.033 (0.045)\tData 0.000 (0.005)\tLoss 0.0122 (0.0176)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [269][260/390]\tTime 0.043 (0.044)\tData 0.000 (0.004)\tLoss 0.0261 (0.0176)\tPrec@1 98.438 (99.515)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [269][270/390]\tTime 0.048 (0.045)\tData 0.005 (0.005)\tLoss 0.0109 (0.0175)\tPrec@1 99.219 (99.521)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [269][280/390]\tTime 0.043 (0.044)\tData 0.002 (0.004)\tLoss 0.0180 (0.0175)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [269][290/390]\tTime 0.034 (0.044)\tData 0.005 (0.004)\tLoss 0.0140 (0.0175)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [269][300/390]\tTime 0.039 (0.044)\tData 0.003 (0.004)\tLoss 0.0361 (0.0176)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [269][310/390]\tTime 0.070 (0.044)\tData 0.003 (0.004)\tLoss 0.0034 (0.0176)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [269][320/390]\tTime 0.040 (0.044)\tData 0.001 (0.004)\tLoss 0.0141 (0.0174)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [269][330/390]\tTime 0.042 (0.044)\tData 0.005 (0.004)\tLoss 0.0244 (0.0174)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [269][340/390]\tTime 0.048 (0.044)\tData 0.000 (0.004)\tLoss 0.0127 (0.0173)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [269][350/390]\tTime 0.054 (0.044)\tData 0.012 (0.004)\tLoss 0.0170 (0.0174)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [269][360/390]\tTime 0.042 (0.044)\tData 0.000 (0.004)\tLoss 0.0060 (0.0175)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [269][370/390]\tTime 0.033 (0.044)\tData 0.001 (0.004)\tLoss 0.0182 (0.0174)\tPrec@1 99.219 (99.522)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [269][380/390]\tTime 0.045 (0.044)\tData 0.003 (0.004)\tLoss 0.0078 (0.0173)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [269][389/390]\tTime 0.019 (0.044)\tData 0.000 (0.004)\tLoss 0.0189 (0.0174)\tPrec@1 100.000 (99.531)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [269][0/79]\tTime 0.266 (0.266)\tData 0.251 (0.251)\tLoss 0.2976 (0.2976)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [269][10/79]\tTime 0.018 (0.044)\tData 0.007 (0.034)\tLoss 0.2703 (0.3717)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [269][20/79]\tTime 0.016 (0.037)\tData 0.000 (0.027)\tLoss 0.5350 (0.4121)\tPrec@1 89.844 (91.518)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [269][30/79]\tTime 0.056 (0.036)\tData 0.050 (0.026)\tLoss 0.0944 (0.3986)\tPrec@1 97.656 (91.860)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [269][40/79]\tTime 0.027 (0.034)\tData 0.001 (0.024)\tLoss 0.2504 (0.3993)\tPrec@1 90.625 (91.806)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [269][50/79]\tTime 0.018 (0.033)\tData 0.000 (0.022)\tLoss 0.4190 (0.3923)\tPrec@1 90.625 (91.774)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [269][60/79]\tTime 0.009 (0.031)\tData 0.000 (0.021)\tLoss 0.6392 (0.3969)\tPrec@1 92.969 (91.714)\tPrec@5 99.219 (99.641)\t\n",
            "EVALUATING - Epoch: [269][70/79]\tTime 0.047 (0.031)\tData 0.041 (0.021)\tLoss 0.4025 (0.3890)\tPrec@1 89.062 (91.670)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [269][78/79]\tTime 0.002 (0.030)\tData 0.000 (0.020)\tLoss 0.2421 (0.3861)\tPrec@1 93.750 (91.710)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 270\n",
            "Training Loss 0.0174 \tTraining Prec@1 99.531 \tTraining Prec@5 99.998 \tValidation Loss 0.3861 \tValidation Prec@1 91.710 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 271\n",
            "\n",
            "TRAINING - Epoch: [270][0/390]\tTime 0.233 (0.233)\tData 0.191 (0.191)\tLoss 0.0314 (0.0314)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][10/390]\tTime 0.048 (0.068)\tData 0.001 (0.028)\tLoss 0.0105 (0.0177)\tPrec@1 100.000 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][20/390]\tTime 0.054 (0.057)\tData 0.002 (0.016)\tLoss 0.0186 (0.0166)\tPrec@1 99.219 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][30/390]\tTime 0.044 (0.052)\tData 0.001 (0.012)\tLoss 0.0120 (0.0157)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][40/390]\tTime 0.040 (0.050)\tData 0.000 (0.010)\tLoss 0.0297 (0.0178)\tPrec@1 98.438 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][50/390]\tTime 0.030 (0.049)\tData 0.002 (0.008)\tLoss 0.0052 (0.0184)\tPrec@1 100.000 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][60/390]\tTime 0.050 (0.048)\tData 0.002 (0.008)\tLoss 0.0150 (0.0177)\tPrec@1 100.000 (99.629)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][70/390]\tTime 0.034 (0.047)\tData 0.000 (0.007)\tLoss 0.0081 (0.0185)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][80/390]\tTime 0.034 (0.046)\tData 0.002 (0.006)\tLoss 0.0075 (0.0190)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][90/390]\tTime 0.038 (0.047)\tData 0.000 (0.007)\tLoss 0.0061 (0.0188)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][100/390]\tTime 0.061 (0.046)\tData 0.002 (0.006)\tLoss 0.0053 (0.0189)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][110/390]\tTime 0.041 (0.046)\tData 0.000 (0.006)\tLoss 0.0159 (0.0190)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][120/390]\tTime 0.046 (0.046)\tData 0.002 (0.006)\tLoss 0.0201 (0.0188)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][130/390]\tTime 0.054 (0.046)\tData 0.005 (0.006)\tLoss 0.0225 (0.0187)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][140/390]\tTime 0.043 (0.046)\tData 0.009 (0.006)\tLoss 0.0028 (0.0184)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][150/390]\tTime 0.045 (0.046)\tData 0.001 (0.005)\tLoss 0.0111 (0.0185)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][160/390]\tTime 0.043 (0.046)\tData 0.005 (0.005)\tLoss 0.0335 (0.0185)\tPrec@1 99.219 (99.515)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][170/390]\tTime 0.042 (0.045)\tData 0.004 (0.005)\tLoss 0.0072 (0.0182)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][180/390]\tTime 0.033 (0.045)\tData 0.000 (0.005)\tLoss 0.0071 (0.0179)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][190/390]\tTime 0.034 (0.045)\tData 0.006 (0.005)\tLoss 0.0165 (0.0177)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][200/390]\tTime 0.046 (0.045)\tData 0.014 (0.005)\tLoss 0.0398 (0.0178)\tPrec@1 98.438 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][210/390]\tTime 0.038 (0.045)\tData 0.010 (0.005)\tLoss 0.0166 (0.0175)\tPrec@1 99.219 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][220/390]\tTime 0.040 (0.045)\tData 0.003 (0.005)\tLoss 0.0091 (0.0172)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][230/390]\tTime 0.045 (0.045)\tData 0.001 (0.005)\tLoss 0.0238 (0.0173)\tPrec@1 99.219 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][240/390]\tTime 0.032 (0.045)\tData 0.001 (0.005)\tLoss 0.0152 (0.0172)\tPrec@1 99.219 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][250/390]\tTime 0.034 (0.045)\tData 0.005 (0.005)\tLoss 0.0215 (0.0173)\tPrec@1 99.219 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][260/390]\tTime 0.056 (0.045)\tData 0.008 (0.005)\tLoss 0.0121 (0.0171)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][270/390]\tTime 0.042 (0.045)\tData 0.007 (0.005)\tLoss 0.0132 (0.0173)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][280/390]\tTime 0.044 (0.045)\tData 0.006 (0.005)\tLoss 0.0136 (0.0171)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][290/390]\tTime 0.051 (0.045)\tData 0.005 (0.005)\tLoss 0.0038 (0.0174)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][300/390]\tTime 0.040 (0.045)\tData 0.005 (0.005)\tLoss 0.0201 (0.0174)\tPrec@1 99.219 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][310/390]\tTime 0.035 (0.045)\tData 0.001 (0.005)\tLoss 0.0133 (0.0174)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][320/390]\tTime 0.038 (0.045)\tData 0.001 (0.005)\tLoss 0.0202 (0.0174)\tPrec@1 98.438 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][330/390]\tTime 0.044 (0.045)\tData 0.000 (0.005)\tLoss 0.0132 (0.0173)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][340/390]\tTime 0.042 (0.045)\tData 0.005 (0.005)\tLoss 0.0246 (0.0172)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][350/390]\tTime 0.042 (0.045)\tData 0.004 (0.005)\tLoss 0.0206 (0.0174)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][360/390]\tTime 0.049 (0.045)\tData 0.000 (0.005)\tLoss 0.0087 (0.0172)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][370/390]\tTime 0.036 (0.045)\tData 0.003 (0.004)\tLoss 0.0116 (0.0174)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][380/390]\tTime 0.050 (0.044)\tData 0.001 (0.004)\tLoss 0.0135 (0.0175)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [270][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.004)\tLoss 0.0078 (0.0175)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [270][0/79]\tTime 0.188 (0.188)\tData 0.168 (0.168)\tLoss 0.2913 (0.2913)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [270][10/79]\tTime 0.082 (0.050)\tData 0.076 (0.040)\tLoss 0.2472 (0.3689)\tPrec@1 90.625 (91.832)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [270][20/79]\tTime 0.034 (0.039)\tData 0.008 (0.027)\tLoss 0.5039 (0.4096)\tPrec@1 90.625 (91.332)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [270][30/79]\tTime 0.048 (0.036)\tData 0.039 (0.024)\tLoss 0.1021 (0.3954)\tPrec@1 97.656 (91.809)\tPrec@5 100.000 (99.597)\t\n",
            "EVALUATING - Epoch: [270][40/79]\tTime 0.015 (0.033)\tData 0.004 (0.020)\tLoss 0.2342 (0.3959)\tPrec@1 91.406 (91.787)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [270][50/79]\tTime 0.060 (0.032)\tData 0.054 (0.020)\tLoss 0.4448 (0.3887)\tPrec@1 90.625 (91.743)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [270][60/79]\tTime 0.015 (0.031)\tData 0.000 (0.019)\tLoss 0.6522 (0.3931)\tPrec@1 92.188 (91.688)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [270][70/79]\tTime 0.073 (0.031)\tData 0.067 (0.019)\tLoss 0.4056 (0.3856)\tPrec@1 89.844 (91.692)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [270][78/79]\tTime 0.002 (0.029)\tData 0.000 (0.017)\tLoss 0.2996 (0.3828)\tPrec@1 93.750 (91.740)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 271\n",
            "Training Loss 0.0175 \tTraining Prec@1 99.525 \tTraining Prec@5 100.000 \tValidation Loss 0.3828 \tValidation Prec@1 91.740 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 272\n",
            "\n",
            "TRAINING - Epoch: [271][0/390]\tTime 0.322 (0.322)\tData 0.278 (0.278)\tLoss 0.0095 (0.0095)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][10/390]\tTime 0.047 (0.073)\tData 0.002 (0.029)\tLoss 0.0095 (0.0180)\tPrec@1 100.000 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][20/390]\tTime 0.044 (0.058)\tData 0.013 (0.017)\tLoss 0.0178 (0.0176)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][30/390]\tTime 0.049 (0.055)\tData 0.002 (0.014)\tLoss 0.0253 (0.0183)\tPrec@1 99.219 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][40/390]\tTime 0.042 (0.052)\tData 0.005 (0.012)\tLoss 0.0099 (0.0179)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][50/390]\tTime 0.053 (0.050)\tData 0.002 (0.010)\tLoss 0.0194 (0.0189)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][60/390]\tTime 0.037 (0.049)\tData 0.005 (0.009)\tLoss 0.0073 (0.0187)\tPrec@1 100.000 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][70/390]\tTime 0.043 (0.048)\tData 0.000 (0.008)\tLoss 0.0135 (0.0194)\tPrec@1 99.219 (99.439)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][80/390]\tTime 0.034 (0.048)\tData 0.007 (0.009)\tLoss 0.0115 (0.0192)\tPrec@1 100.000 (99.460)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][90/390]\tTime 0.072 (0.048)\tData 0.000 (0.008)\tLoss 0.0055 (0.0184)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][100/390]\tTime 0.051 (0.047)\tData 0.001 (0.008)\tLoss 0.0144 (0.0181)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][110/390]\tTime 0.040 (0.047)\tData 0.005 (0.008)\tLoss 0.0065 (0.0179)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][120/390]\tTime 0.036 (0.046)\tData 0.001 (0.007)\tLoss 0.0052 (0.0176)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][130/390]\tTime 0.037 (0.046)\tData 0.002 (0.007)\tLoss 0.0070 (0.0178)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][140/390]\tTime 0.043 (0.046)\tData 0.003 (0.007)\tLoss 0.0135 (0.0183)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][150/390]\tTime 0.051 (0.046)\tData 0.008 (0.007)\tLoss 0.0215 (0.0185)\tPrec@1 99.219 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][160/390]\tTime 0.038 (0.046)\tData 0.000 (0.007)\tLoss 0.0238 (0.0186)\tPrec@1 99.219 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][170/390]\tTime 0.063 (0.046)\tData 0.008 (0.006)\tLoss 0.0125 (0.0187)\tPrec@1 100.000 (99.484)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][180/390]\tTime 0.024 (0.046)\tData 0.000 (0.006)\tLoss 0.0057 (0.0189)\tPrec@1 100.000 (99.482)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][190/390]\tTime 0.056 (0.046)\tData 0.005 (0.006)\tLoss 0.0082 (0.0188)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][200/390]\tTime 0.033 (0.046)\tData 0.008 (0.006)\tLoss 0.0126 (0.0190)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][210/390]\tTime 0.037 (0.046)\tData 0.003 (0.006)\tLoss 0.0048 (0.0187)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][220/390]\tTime 0.037 (0.046)\tData 0.000 (0.006)\tLoss 0.0299 (0.0184)\tPrec@1 98.438 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][230/390]\tTime 0.048 (0.046)\tData 0.005 (0.006)\tLoss 0.0149 (0.0182)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][240/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0508 (0.0182)\tPrec@1 98.438 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][250/390]\tTime 0.040 (0.046)\tData 0.000 (0.006)\tLoss 0.0193 (0.0183)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][260/390]\tTime 0.057 (0.046)\tData 0.007 (0.006)\tLoss 0.0034 (0.0182)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][270/390]\tTime 0.042 (0.046)\tData 0.001 (0.006)\tLoss 0.0106 (0.0180)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][280/390]\tTime 0.044 (0.046)\tData 0.000 (0.006)\tLoss 0.0080 (0.0181)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][290/390]\tTime 0.042 (0.046)\tData 0.003 (0.006)\tLoss 0.0060 (0.0179)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][300/390]\tTime 0.067 (0.046)\tData 0.006 (0.006)\tLoss 0.0262 (0.0178)\tPrec@1 99.219 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][310/390]\tTime 0.042 (0.046)\tData 0.010 (0.006)\tLoss 0.0453 (0.0181)\tPrec@1 98.438 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][320/390]\tTime 0.048 (0.046)\tData 0.001 (0.005)\tLoss 0.0236 (0.0180)\tPrec@1 99.219 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][330/390]\tTime 0.034 (0.046)\tData 0.005 (0.005)\tLoss 0.0155 (0.0179)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][340/390]\tTime 0.047 (0.046)\tData 0.001 (0.005)\tLoss 0.0272 (0.0180)\tPrec@1 99.219 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][350/390]\tTime 0.041 (0.046)\tData 0.012 (0.005)\tLoss 0.0079 (0.0179)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][360/390]\tTime 0.046 (0.046)\tData 0.006 (0.005)\tLoss 0.0184 (0.0179)\tPrec@1 98.438 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][370/390]\tTime 0.046 (0.046)\tData 0.014 (0.005)\tLoss 0.0268 (0.0178)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][380/390]\tTime 0.062 (0.046)\tData 0.006 (0.005)\tLoss 0.0205 (0.0177)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [271][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0046 (0.0177)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [271][0/79]\tTime 0.183 (0.183)\tData 0.167 (0.167)\tLoss 0.2967 (0.2967)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [271][10/79]\tTime 0.018 (0.046)\tData 0.013 (0.035)\tLoss 0.2561 (0.3700)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [271][20/79]\tTime 0.016 (0.036)\tData 0.010 (0.027)\tLoss 0.5184 (0.4090)\tPrec@1 89.844 (91.667)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [271][30/79]\tTime 0.015 (0.034)\tData 0.000 (0.023)\tLoss 0.1076 (0.3957)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [271][40/79]\tTime 0.018 (0.032)\tData 0.003 (0.020)\tLoss 0.2460 (0.3972)\tPrec@1 90.625 (91.864)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [271][50/79]\tTime 0.019 (0.032)\tData 0.000 (0.020)\tLoss 0.4207 (0.3903)\tPrec@1 91.406 (91.774)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [271][60/79]\tTime 0.017 (0.031)\tData 0.002 (0.018)\tLoss 0.6445 (0.3947)\tPrec@1 92.969 (91.752)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [271][70/79]\tTime 0.011 (0.030)\tData 0.003 (0.017)\tLoss 0.4075 (0.3876)\tPrec@1 89.062 (91.714)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [271][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.016)\tLoss 0.2550 (0.3850)\tPrec@1 93.750 (91.730)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 272\n",
            "Training Loss 0.0177 \tTraining Prec@1 99.525 \tTraining Prec@5 100.000 \tValidation Loss 0.3850 \tValidation Prec@1 91.730 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 273\n",
            "\n",
            "TRAINING - Epoch: [272][0/390]\tTime 0.219 (0.219)\tData 0.180 (0.180)\tLoss 0.0173 (0.0173)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][10/390]\tTime 0.034 (0.065)\tData 0.002 (0.033)\tLoss 0.0140 (0.0127)\tPrec@1 99.219 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][20/390]\tTime 0.036 (0.055)\tData 0.000 (0.019)\tLoss 0.0094 (0.0148)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][30/390]\tTime 0.036 (0.051)\tData 0.001 (0.014)\tLoss 0.0154 (0.0148)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][40/390]\tTime 0.035 (0.050)\tData 0.000 (0.011)\tLoss 0.0042 (0.0141)\tPrec@1 100.000 (99.695)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][50/390]\tTime 0.043 (0.048)\tData 0.000 (0.010)\tLoss 0.0093 (0.0150)\tPrec@1 100.000 (99.648)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][60/390]\tTime 0.040 (0.047)\tData 0.001 (0.009)\tLoss 0.0484 (0.0157)\tPrec@1 98.438 (99.641)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][70/390]\tTime 0.058 (0.048)\tData 0.002 (0.008)\tLoss 0.0181 (0.0149)\tPrec@1 99.219 (99.670)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][80/390]\tTime 0.049 (0.047)\tData 0.005 (0.007)\tLoss 0.0079 (0.0160)\tPrec@1 100.000 (99.605)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][90/390]\tTime 0.045 (0.047)\tData 0.000 (0.007)\tLoss 0.0157 (0.0163)\tPrec@1 99.219 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][100/390]\tTime 0.027 (0.046)\tData 0.000 (0.006)\tLoss 0.0174 (0.0163)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][110/390]\tTime 0.055 (0.046)\tData 0.007 (0.006)\tLoss 0.0134 (0.0167)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][120/390]\tTime 0.049 (0.046)\tData 0.007 (0.006)\tLoss 0.0241 (0.0167)\tPrec@1 99.219 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][130/390]\tTime 0.023 (0.046)\tData 0.000 (0.006)\tLoss 0.0293 (0.0165)\tPrec@1 98.438 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][140/390]\tTime 0.028 (0.045)\tData 0.000 (0.006)\tLoss 0.0168 (0.0166)\tPrec@1 99.219 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][150/390]\tTime 0.049 (0.045)\tData 0.007 (0.005)\tLoss 0.0172 (0.0167)\tPrec@1 99.219 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][160/390]\tTime 0.043 (0.045)\tData 0.001 (0.005)\tLoss 0.0289 (0.0172)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][170/390]\tTime 0.035 (0.045)\tData 0.000 (0.005)\tLoss 0.0128 (0.0168)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][180/390]\tTime 0.034 (0.045)\tData 0.002 (0.005)\tLoss 0.0156 (0.0168)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][190/390]\tTime 0.035 (0.045)\tData 0.006 (0.005)\tLoss 0.0105 (0.0165)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][200/390]\tTime 0.039 (0.045)\tData 0.009 (0.005)\tLoss 0.0242 (0.0165)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][210/390]\tTime 0.035 (0.045)\tData 0.000 (0.005)\tLoss 0.0157 (0.0164)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][220/390]\tTime 0.043 (0.045)\tData 0.005 (0.005)\tLoss 0.0069 (0.0165)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][230/390]\tTime 0.048 (0.045)\tData 0.004 (0.005)\tLoss 0.0307 (0.0164)\tPrec@1 99.219 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][240/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0162 (0.0165)\tPrec@1 99.219 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][250/390]\tTime 0.038 (0.045)\tData 0.005 (0.005)\tLoss 0.0342 (0.0165)\tPrec@1 97.656 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][260/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0028 (0.0166)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][270/390]\tTime 0.065 (0.045)\tData 0.003 (0.005)\tLoss 0.0184 (0.0167)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][280/390]\tTime 0.047 (0.045)\tData 0.008 (0.005)\tLoss 0.0260 (0.0166)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][290/390]\tTime 0.046 (0.045)\tData 0.000 (0.005)\tLoss 0.0167 (0.0167)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][300/390]\tTime 0.033 (0.045)\tData 0.000 (0.005)\tLoss 0.0184 (0.0167)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][310/390]\tTime 0.057 (0.045)\tData 0.009 (0.005)\tLoss 0.0223 (0.0167)\tPrec@1 98.438 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][320/390]\tTime 0.041 (0.045)\tData 0.000 (0.005)\tLoss 0.0331 (0.0168)\tPrec@1 98.438 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][330/390]\tTime 0.037 (0.045)\tData 0.007 (0.005)\tLoss 0.0069 (0.0167)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][340/390]\tTime 0.039 (0.045)\tData 0.000 (0.005)\tLoss 0.0235 (0.0168)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][350/390]\tTime 0.043 (0.044)\tData 0.000 (0.005)\tLoss 0.0065 (0.0168)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][360/390]\tTime 0.054 (0.044)\tData 0.008 (0.005)\tLoss 0.0382 (0.0168)\tPrec@1 98.438 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][370/390]\tTime 0.051 (0.044)\tData 0.000 (0.005)\tLoss 0.0128 (0.0166)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][380/390]\tTime 0.038 (0.044)\tData 0.000 (0.005)\tLoss 0.0159 (0.0167)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [272][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0201 (0.0167)\tPrec@1 98.438 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [272][0/79]\tTime 0.239 (0.239)\tData 0.218 (0.218)\tLoss 0.2979 (0.2979)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [272][10/79]\tTime 0.016 (0.044)\tData 0.011 (0.032)\tLoss 0.2488 (0.3730)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [272][20/79]\tTime 0.020 (0.036)\tData 0.010 (0.024)\tLoss 0.5335 (0.4127)\tPrec@1 89.844 (91.629)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [272][30/79]\tTime 0.019 (0.034)\tData 0.001 (0.023)\tLoss 0.0987 (0.4009)\tPrec@1 97.656 (91.885)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [272][40/79]\tTime 0.034 (0.032)\tData 0.008 (0.020)\tLoss 0.2479 (0.4014)\tPrec@1 89.844 (91.806)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [272][50/79]\tTime 0.009 (0.032)\tData 0.000 (0.021)\tLoss 0.4290 (0.3931)\tPrec@1 90.625 (91.774)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [272][60/79]\tTime 0.016 (0.031)\tData 0.000 (0.019)\tLoss 0.6469 (0.3975)\tPrec@1 92.969 (91.752)\tPrec@5 100.000 (99.693)\t\n",
            "EVALUATING - Epoch: [272][70/79]\tTime 0.017 (0.031)\tData 0.006 (0.019)\tLoss 0.3928 (0.3895)\tPrec@1 89.844 (91.725)\tPrec@5 100.000 (99.725)\t\n",
            "EVALUATING - Epoch: [272][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2439 (0.3865)\tPrec@1 93.750 (91.760)\tPrec@5 100.000 (99.730)\t\n",
            "\n",
            "Results - Epoch: 273\n",
            "Training Loss 0.0167 \tTraining Prec@1 99.543 \tTraining Prec@5 100.000 \tValidation Loss 0.3865 \tValidation Prec@1 91.760 \tValidation Prec@5 99.730 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 274\n",
            "\n",
            "TRAINING - Epoch: [273][0/390]\tTime 0.328 (0.328)\tData 0.266 (0.266)\tLoss 0.0363 (0.0363)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][10/390]\tTime 0.033 (0.069)\tData 0.000 (0.028)\tLoss 0.0100 (0.0215)\tPrec@1 100.000 (99.290)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][20/390]\tTime 0.049 (0.057)\tData 0.005 (0.016)\tLoss 0.0243 (0.0201)\tPrec@1 99.219 (99.293)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][30/390]\tTime 0.052 (0.054)\tData 0.003 (0.012)\tLoss 0.0275 (0.0199)\tPrec@1 99.219 (99.320)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][40/390]\tTime 0.045 (0.051)\tData 0.004 (0.010)\tLoss 0.0186 (0.0198)\tPrec@1 98.438 (99.333)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][50/390]\tTime 0.030 (0.049)\tData 0.000 (0.009)\tLoss 0.0110 (0.0188)\tPrec@1 100.000 (99.403)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][60/390]\tTime 0.046 (0.048)\tData 0.003 (0.008)\tLoss 0.0116 (0.0182)\tPrec@1 100.000 (99.436)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][70/390]\tTime 0.052 (0.049)\tData 0.000 (0.007)\tLoss 0.0184 (0.0177)\tPrec@1 99.219 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][80/390]\tTime 0.033 (0.048)\tData 0.001 (0.007)\tLoss 0.0393 (0.0176)\tPrec@1 99.219 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][90/390]\tTime 0.051 (0.047)\tData 0.004 (0.007)\tLoss 0.0248 (0.0183)\tPrec@1 100.000 (99.442)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][100/390]\tTime 0.068 (0.047)\tData 0.036 (0.007)\tLoss 0.0210 (0.0180)\tPrec@1 99.219 (99.451)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][110/390]\tTime 0.050 (0.047)\tData 0.002 (0.007)\tLoss 0.0084 (0.0174)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][120/390]\tTime 0.034 (0.047)\tData 0.004 (0.006)\tLoss 0.0067 (0.0177)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][130/390]\tTime 0.031 (0.046)\tData 0.007 (0.006)\tLoss 0.0036 (0.0176)\tPrec@1 100.000 (99.487)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][140/390]\tTime 0.034 (0.046)\tData 0.006 (0.006)\tLoss 0.0232 (0.0178)\tPrec@1 99.219 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][150/390]\tTime 0.040 (0.046)\tData 0.009 (0.006)\tLoss 0.0061 (0.0177)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][160/390]\tTime 0.048 (0.046)\tData 0.006 (0.006)\tLoss 0.0225 (0.0178)\tPrec@1 98.438 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][170/390]\tTime 0.049 (0.046)\tData 0.000 (0.006)\tLoss 0.0225 (0.0179)\tPrec@1 98.438 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][180/390]\tTime 0.041 (0.046)\tData 0.011 (0.006)\tLoss 0.0176 (0.0180)\tPrec@1 100.000 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][190/390]\tTime 0.029 (0.046)\tData 0.001 (0.006)\tLoss 0.0139 (0.0181)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][200/390]\tTime 0.041 (0.046)\tData 0.016 (0.006)\tLoss 0.0109 (0.0178)\tPrec@1 99.219 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][210/390]\tTime 0.055 (0.046)\tData 0.013 (0.006)\tLoss 0.0196 (0.0176)\tPrec@1 99.219 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][220/390]\tTime 0.036 (0.046)\tData 0.005 (0.006)\tLoss 0.0181 (0.0181)\tPrec@1 99.219 (99.456)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][230/390]\tTime 0.045 (0.046)\tData 0.004 (0.006)\tLoss 0.0122 (0.0183)\tPrec@1 99.219 (99.445)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][240/390]\tTime 0.036 (0.046)\tData 0.000 (0.006)\tLoss 0.0084 (0.0185)\tPrec@1 100.000 (99.446)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][250/390]\tTime 0.029 (0.045)\tData 0.000 (0.006)\tLoss 0.0054 (0.0185)\tPrec@1 100.000 (99.434)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][260/390]\tTime 0.046 (0.045)\tData 0.003 (0.006)\tLoss 0.0367 (0.0186)\tPrec@1 98.438 (99.437)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][270/390]\tTime 0.041 (0.045)\tData 0.000 (0.006)\tLoss 0.0050 (0.0187)\tPrec@1 100.000 (99.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][280/390]\tTime 0.043 (0.045)\tData 0.005 (0.006)\tLoss 0.0251 (0.0185)\tPrec@1 100.000 (99.450)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][290/390]\tTime 0.050 (0.045)\tData 0.005 (0.006)\tLoss 0.0075 (0.0184)\tPrec@1 100.000 (99.452)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][300/390]\tTime 0.035 (0.045)\tData 0.000 (0.006)\tLoss 0.0334 (0.0184)\tPrec@1 98.438 (99.450)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][310/390]\tTime 0.039 (0.045)\tData 0.005 (0.006)\tLoss 0.0227 (0.0185)\tPrec@1 99.219 (99.445)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][320/390]\tTime 0.050 (0.045)\tData 0.005 (0.006)\tLoss 0.0366 (0.0186)\tPrec@1 98.438 (99.440)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][330/390]\tTime 0.048 (0.045)\tData 0.019 (0.006)\tLoss 0.0075 (0.0186)\tPrec@1 100.000 (99.443)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][340/390]\tTime 0.039 (0.045)\tData 0.010 (0.006)\tLoss 0.0389 (0.0186)\tPrec@1 97.656 (99.446)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][350/390]\tTime 0.040 (0.045)\tData 0.000 (0.006)\tLoss 0.0208 (0.0184)\tPrec@1 100.000 (99.455)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][360/390]\tTime 0.051 (0.045)\tData 0.008 (0.006)\tLoss 0.0148 (0.0185)\tPrec@1 100.000 (99.461)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][370/390]\tTime 0.054 (0.045)\tData 0.019 (0.006)\tLoss 0.0075 (0.0185)\tPrec@1 100.000 (99.455)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][380/390]\tTime 0.038 (0.045)\tData 0.002 (0.006)\tLoss 0.0354 (0.0188)\tPrec@1 98.438 (99.440)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [273][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.006)\tLoss 0.0173 (0.0189)\tPrec@1 99.219 (99.431)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [273][0/79]\tTime 0.246 (0.246)\tData 0.232 (0.232)\tLoss 0.2790 (0.2790)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [273][10/79]\tTime 0.031 (0.044)\tData 0.025 (0.034)\tLoss 0.2594 (0.3661)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [273][20/79]\tTime 0.037 (0.037)\tData 0.031 (0.027)\tLoss 0.5195 (0.4073)\tPrec@1 89.844 (91.518)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [273][30/79]\tTime 0.079 (0.035)\tData 0.071 (0.026)\tLoss 0.1010 (0.3951)\tPrec@1 97.656 (91.835)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [273][40/79]\tTime 0.028 (0.033)\tData 0.009 (0.023)\tLoss 0.2427 (0.3975)\tPrec@1 91.406 (91.825)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [273][50/79]\tTime 0.029 (0.033)\tData 0.023 (0.021)\tLoss 0.4301 (0.3901)\tPrec@1 90.625 (91.789)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [273][60/79]\tTime 0.019 (0.031)\tData 0.002 (0.019)\tLoss 0.6477 (0.3954)\tPrec@1 92.969 (91.714)\tPrec@5 99.219 (99.641)\t\n",
            "EVALUATING - Epoch: [273][70/79]\tTime 0.019 (0.031)\tData 0.004 (0.019)\tLoss 0.3815 (0.3870)\tPrec@1 90.625 (91.692)\tPrec@5 100.000 (99.670)\t\n",
            "EVALUATING - Epoch: [273][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.018)\tLoss 0.2294 (0.3838)\tPrec@1 93.750 (91.690)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 274\n",
            "Training Loss 0.0189 \tTraining Prec@1 99.431 \tTraining Prec@5 100.000 \tValidation Loss 0.3838 \tValidation Prec@1 91.690 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 275\n",
            "\n",
            "TRAINING - Epoch: [274][0/390]\tTime 0.332 (0.332)\tData 0.284 (0.284)\tLoss 0.0164 (0.0164)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][10/390]\tTime 0.046 (0.068)\tData 0.000 (0.029)\tLoss 0.0118 (0.0161)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][20/390]\tTime 0.043 (0.056)\tData 0.000 (0.016)\tLoss 0.0166 (0.0203)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][30/390]\tTime 0.043 (0.052)\tData 0.007 (0.013)\tLoss 0.0176 (0.0210)\tPrec@1 99.219 (99.420)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][40/390]\tTime 0.036 (0.049)\tData 0.001 (0.010)\tLoss 0.0147 (0.0221)\tPrec@1 99.219 (99.314)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][50/390]\tTime 0.033 (0.048)\tData 0.005 (0.009)\tLoss 0.0118 (0.0209)\tPrec@1 99.219 (99.341)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][60/390]\tTime 0.043 (0.048)\tData 0.004 (0.008)\tLoss 0.0206 (0.0209)\tPrec@1 99.219 (99.372)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][70/390]\tTime 0.058 (0.048)\tData 0.009 (0.008)\tLoss 0.0155 (0.0195)\tPrec@1 99.219 (99.428)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][80/390]\tTime 0.028 (0.047)\tData 0.000 (0.007)\tLoss 0.0095 (0.0196)\tPrec@1 100.000 (99.431)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][90/390]\tTime 0.044 (0.046)\tData 0.000 (0.007)\tLoss 0.0107 (0.0194)\tPrec@1 100.000 (99.425)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][100/390]\tTime 0.042 (0.046)\tData 0.015 (0.007)\tLoss 0.0143 (0.0190)\tPrec@1 100.000 (99.443)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][110/390]\tTime 0.033 (0.046)\tData 0.004 (0.006)\tLoss 0.0074 (0.0190)\tPrec@1 100.000 (99.444)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][120/390]\tTime 0.099 (0.046)\tData 0.069 (0.007)\tLoss 0.0143 (0.0188)\tPrec@1 100.000 (99.451)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][130/390]\tTime 0.042 (0.045)\tData 0.003 (0.007)\tLoss 0.0094 (0.0184)\tPrec@1 100.000 (99.463)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][140/390]\tTime 0.037 (0.045)\tData 0.000 (0.007)\tLoss 0.0095 (0.0181)\tPrec@1 100.000 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][150/390]\tTime 0.033 (0.045)\tData 0.000 (0.007)\tLoss 0.0061 (0.0181)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][160/390]\tTime 0.033 (0.045)\tData 0.004 (0.007)\tLoss 0.0056 (0.0178)\tPrec@1 100.000 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][170/390]\tTime 0.055 (0.045)\tData 0.020 (0.007)\tLoss 0.0058 (0.0174)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][180/390]\tTime 0.027 (0.045)\tData 0.000 (0.006)\tLoss 0.0193 (0.0175)\tPrec@1 99.219 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][190/390]\tTime 0.040 (0.045)\tData 0.003 (0.007)\tLoss 0.0107 (0.0179)\tPrec@1 100.000 (99.460)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][200/390]\tTime 0.060 (0.045)\tData 0.000 (0.006)\tLoss 0.0134 (0.0177)\tPrec@1 100.000 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][210/390]\tTime 0.039 (0.045)\tData 0.006 (0.006)\tLoss 0.0186 (0.0178)\tPrec@1 99.219 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][220/390]\tTime 0.045 (0.045)\tData 0.004 (0.006)\tLoss 0.0061 (0.0175)\tPrec@1 100.000 (99.487)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][230/390]\tTime 0.031 (0.045)\tData 0.000 (0.006)\tLoss 0.0119 (0.0174)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][240/390]\tTime 0.044 (0.045)\tData 0.004 (0.006)\tLoss 0.0165 (0.0173)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][250/390]\tTime 0.040 (0.045)\tData 0.000 (0.006)\tLoss 0.0064 (0.0170)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][260/390]\tTime 0.031 (0.045)\tData 0.000 (0.006)\tLoss 0.0157 (0.0169)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][270/390]\tTime 0.050 (0.044)\tData 0.007 (0.006)\tLoss 0.0255 (0.0171)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][280/390]\tTime 0.067 (0.045)\tData 0.005 (0.006)\tLoss 0.0098 (0.0170)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][290/390]\tTime 0.050 (0.045)\tData 0.006 (0.006)\tLoss 0.0136 (0.0170)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][300/390]\tTime 0.050 (0.045)\tData 0.000 (0.006)\tLoss 0.0393 (0.0172)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][310/390]\tTime 0.036 (0.045)\tData 0.000 (0.006)\tLoss 0.0164 (0.0172)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][320/390]\tTime 0.046 (0.044)\tData 0.012 (0.006)\tLoss 0.0323 (0.0173)\tPrec@1 98.438 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][330/390]\tTime 0.056 (0.045)\tData 0.007 (0.006)\tLoss 0.0257 (0.0174)\tPrec@1 98.438 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][340/390]\tTime 0.028 (0.044)\tData 0.000 (0.006)\tLoss 0.0095 (0.0173)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][350/390]\tTime 0.044 (0.044)\tData 0.011 (0.006)\tLoss 0.0212 (0.0173)\tPrec@1 99.219 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][360/390]\tTime 0.050 (0.044)\tData 0.004 (0.006)\tLoss 0.0120 (0.0172)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][370/390]\tTime 0.033 (0.044)\tData 0.000 (0.006)\tLoss 0.0035 (0.0172)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][380/390]\tTime 0.052 (0.044)\tData 0.003 (0.006)\tLoss 0.0205 (0.0171)\tPrec@1 99.219 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [274][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.006)\tLoss 0.0076 (0.0170)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [274][0/79]\tTime 0.298 (0.298)\tData 0.279 (0.279)\tLoss 0.2787 (0.2787)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [274][10/79]\tTime 0.018 (0.049)\tData 0.004 (0.035)\tLoss 0.2774 (0.3750)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [274][20/79]\tTime 0.033 (0.040)\tData 0.027 (0.025)\tLoss 0.5353 (0.4126)\tPrec@1 89.844 (91.555)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [274][30/79]\tTime 0.030 (0.035)\tData 0.000 (0.021)\tLoss 0.0909 (0.3985)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [274][40/79]\tTime 0.059 (0.033)\tData 0.053 (0.019)\tLoss 0.2488 (0.4008)\tPrec@1 91.406 (91.825)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [274][50/79]\tTime 0.020 (0.031)\tData 0.005 (0.018)\tLoss 0.4367 (0.3934)\tPrec@1 91.406 (91.759)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [274][60/79]\tTime 0.025 (0.031)\tData 0.020 (0.019)\tLoss 0.6350 (0.3984)\tPrec@1 92.969 (91.701)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [274][70/79]\tTime 0.015 (0.030)\tData 0.000 (0.018)\tLoss 0.3913 (0.3898)\tPrec@1 89.062 (91.659)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [274][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2431 (0.3869)\tPrec@1 93.750 (91.680)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 275\n",
            "Training Loss 0.0170 \tTraining Prec@1 99.527 \tTraining Prec@5 100.000 \tValidation Loss 0.3869 \tValidation Prec@1 91.680 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 276\n",
            "\n",
            "TRAINING - Epoch: [275][0/390]\tTime 0.395 (0.395)\tData 0.340 (0.340)\tLoss 0.0067 (0.0067)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][10/390]\tTime 0.055 (0.075)\tData 0.016 (0.036)\tLoss 0.0340 (0.0266)\tPrec@1 98.438 (99.148)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][20/390]\tTime 0.052 (0.058)\tData 0.003 (0.020)\tLoss 0.0639 (0.0241)\tPrec@1 97.656 (99.293)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][30/390]\tTime 0.041 (0.053)\tData 0.000 (0.015)\tLoss 0.0056 (0.0228)\tPrec@1 100.000 (99.345)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][40/390]\tTime 0.040 (0.051)\tData 0.007 (0.012)\tLoss 0.0128 (0.0210)\tPrec@1 99.219 (99.428)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][50/390]\tTime 0.042 (0.049)\tData 0.001 (0.010)\tLoss 0.0067 (0.0205)\tPrec@1 100.000 (99.433)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][60/390]\tTime 0.035 (0.051)\tData 0.004 (0.012)\tLoss 0.0161 (0.0195)\tPrec@1 99.219 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][70/390]\tTime 0.033 (0.050)\tData 0.000 (0.011)\tLoss 0.0082 (0.0184)\tPrec@1 100.000 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][80/390]\tTime 0.040 (0.049)\tData 0.001 (0.010)\tLoss 0.0101 (0.0180)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][90/390]\tTime 0.206 (0.050)\tData 0.181 (0.012)\tLoss 0.0201 (0.0181)\tPrec@1 99.219 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][100/390]\tTime 0.049 (0.049)\tData 0.016 (0.011)\tLoss 0.0062 (0.0184)\tPrec@1 100.000 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][110/390]\tTime 0.046 (0.049)\tData 0.010 (0.010)\tLoss 0.0085 (0.0184)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][120/390]\tTime 0.044 (0.048)\tData 0.001 (0.010)\tLoss 0.0197 (0.0186)\tPrec@1 99.219 (99.458)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][130/390]\tTime 0.048 (0.048)\tData 0.011 (0.010)\tLoss 0.0094 (0.0184)\tPrec@1 100.000 (99.463)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][140/390]\tTime 0.032 (0.048)\tData 0.000 (0.010)\tLoss 0.0118 (0.0183)\tPrec@1 100.000 (99.485)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][150/390]\tTime 0.033 (0.048)\tData 0.000 (0.009)\tLoss 0.0094 (0.0181)\tPrec@1 100.000 (99.477)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][160/390]\tTime 0.045 (0.048)\tData 0.007 (0.010)\tLoss 0.0411 (0.0181)\tPrec@1 98.438 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][170/390]\tTime 0.045 (0.047)\tData 0.000 (0.010)\tLoss 0.0111 (0.0180)\tPrec@1 100.000 (99.484)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][180/390]\tTime 0.044 (0.047)\tData 0.006 (0.009)\tLoss 0.0137 (0.0178)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][190/390]\tTime 0.036 (0.047)\tData 0.000 (0.009)\tLoss 0.0142 (0.0176)\tPrec@1 99.219 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][200/390]\tTime 0.051 (0.047)\tData 0.000 (0.009)\tLoss 0.0103 (0.0176)\tPrec@1 100.000 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][210/390]\tTime 0.046 (0.047)\tData 0.000 (0.009)\tLoss 0.0349 (0.0176)\tPrec@1 98.438 (99.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][220/390]\tTime 0.063 (0.047)\tData 0.005 (0.008)\tLoss 0.0129 (0.0175)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][230/390]\tTime 0.035 (0.047)\tData 0.001 (0.008)\tLoss 0.0050 (0.0176)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][240/390]\tTime 0.031 (0.046)\tData 0.003 (0.008)\tLoss 0.0024 (0.0175)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][250/390]\tTime 0.049 (0.046)\tData 0.000 (0.008)\tLoss 0.0243 (0.0176)\tPrec@1 99.219 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][260/390]\tTime 0.040 (0.046)\tData 0.003 (0.007)\tLoss 0.0069 (0.0178)\tPrec@1 100.000 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][270/390]\tTime 0.043 (0.046)\tData 0.000 (0.007)\tLoss 0.0245 (0.0178)\tPrec@1 99.219 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][280/390]\tTime 0.045 (0.046)\tData 0.001 (0.007)\tLoss 0.0106 (0.0178)\tPrec@1 100.000 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][290/390]\tTime 0.034 (0.046)\tData 0.000 (0.007)\tLoss 0.0136 (0.0179)\tPrec@1 100.000 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][300/390]\tTime 0.054 (0.046)\tData 0.007 (0.007)\tLoss 0.0177 (0.0181)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][310/390]\tTime 0.034 (0.046)\tData 0.000 (0.007)\tLoss 0.0120 (0.0180)\tPrec@1 100.000 (99.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][320/390]\tTime 0.047 (0.045)\tData 0.004 (0.007)\tLoss 0.0207 (0.0179)\tPrec@1 98.438 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][330/390]\tTime 0.040 (0.045)\tData 0.000 (0.007)\tLoss 0.0250 (0.0180)\tPrec@1 99.219 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][340/390]\tTime 0.034 (0.045)\tData 0.002 (0.007)\tLoss 0.0137 (0.0181)\tPrec@1 100.000 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][350/390]\tTime 0.040 (0.045)\tData 0.005 (0.006)\tLoss 0.0033 (0.0181)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][360/390]\tTime 0.038 (0.045)\tData 0.000 (0.006)\tLoss 0.0138 (0.0179)\tPrec@1 99.219 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][370/390]\tTime 0.043 (0.045)\tData 0.005 (0.007)\tLoss 0.0292 (0.0181)\tPrec@1 99.219 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][380/390]\tTime 0.036 (0.045)\tData 0.006 (0.007)\tLoss 0.0049 (0.0180)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [275][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.007)\tLoss 0.0138 (0.0180)\tPrec@1 99.219 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [275][0/79]\tTime 0.180 (0.180)\tData 0.172 (0.172)\tLoss 0.2826 (0.2826)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [275][10/79]\tTime 0.016 (0.044)\tData 0.001 (0.032)\tLoss 0.2779 (0.3720)\tPrec@1 91.406 (92.401)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [275][20/79]\tTime 0.010 (0.034)\tData 0.005 (0.023)\tLoss 0.5307 (0.4118)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [275][30/79]\tTime 0.011 (0.037)\tData 0.005 (0.026)\tLoss 0.0896 (0.3982)\tPrec@1 97.656 (91.986)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [275][40/79]\tTime 0.018 (0.035)\tData 0.000 (0.024)\tLoss 0.2525 (0.4003)\tPrec@1 89.844 (91.902)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [275][50/79]\tTime 0.019 (0.033)\tData 0.002 (0.021)\tLoss 0.4473 (0.3935)\tPrec@1 91.406 (91.835)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [275][60/79]\tTime 0.020 (0.031)\tData 0.000 (0.019)\tLoss 0.6402 (0.3983)\tPrec@1 92.969 (91.765)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [275][70/79]\tTime 0.141 (0.033)\tData 0.134 (0.021)\tLoss 0.3925 (0.3898)\tPrec@1 89.844 (91.692)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [275][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.019)\tLoss 0.2357 (0.3866)\tPrec@1 93.750 (91.680)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 276\n",
            "Training Loss 0.0180 \tTraining Prec@1 99.497 \tTraining Prec@5 100.000 \tValidation Loss 0.3866 \tValidation Prec@1 91.680 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 277\n",
            "\n",
            "TRAINING - Epoch: [276][0/390]\tTime 0.227 (0.227)\tData 0.188 (0.188)\tLoss 0.0128 (0.0128)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][10/390]\tTime 0.039 (0.071)\tData 0.000 (0.029)\tLoss 0.0305 (0.0225)\tPrec@1 99.219 (99.361)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][20/390]\tTime 0.032 (0.057)\tData 0.005 (0.016)\tLoss 0.0215 (0.0203)\tPrec@1 99.219 (99.368)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][30/390]\tTime 0.045 (0.052)\tData 0.001 (0.013)\tLoss 0.0114 (0.0201)\tPrec@1 100.000 (99.370)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][40/390]\tTime 0.033 (0.049)\tData 0.000 (0.011)\tLoss 0.0344 (0.0180)\tPrec@1 98.438 (99.466)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][50/390]\tTime 0.044 (0.048)\tData 0.003 (0.009)\tLoss 0.0346 (0.0192)\tPrec@1 97.656 (99.449)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][60/390]\tTime 0.034 (0.048)\tData 0.004 (0.009)\tLoss 0.0102 (0.0195)\tPrec@1 100.000 (99.424)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][70/390]\tTime 0.050 (0.047)\tData 0.001 (0.008)\tLoss 0.0077 (0.0184)\tPrec@1 100.000 (99.461)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][80/390]\tTime 0.045 (0.047)\tData 0.003 (0.007)\tLoss 0.0085 (0.0183)\tPrec@1 100.000 (99.441)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][90/390]\tTime 0.042 (0.046)\tData 0.000 (0.007)\tLoss 0.0400 (0.0184)\tPrec@1 97.656 (99.433)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][100/390]\tTime 0.047 (0.045)\tData 0.005 (0.006)\tLoss 0.0354 (0.0181)\tPrec@1 97.656 (99.443)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][110/390]\tTime 0.044 (0.045)\tData 0.002 (0.006)\tLoss 0.0086 (0.0177)\tPrec@1 100.000 (99.458)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][120/390]\tTime 0.054 (0.045)\tData 0.002 (0.006)\tLoss 0.0388 (0.0181)\tPrec@1 98.438 (99.419)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][130/390]\tTime 0.051 (0.045)\tData 0.006 (0.006)\tLoss 0.0046 (0.0178)\tPrec@1 100.000 (99.445)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][140/390]\tTime 0.035 (0.045)\tData 0.003 (0.006)\tLoss 0.0392 (0.0179)\tPrec@1 99.219 (99.451)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][150/390]\tTime 0.057 (0.045)\tData 0.001 (0.006)\tLoss 0.0102 (0.0176)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][160/390]\tTime 0.039 (0.045)\tData 0.015 (0.005)\tLoss 0.0098 (0.0176)\tPrec@1 100.000 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][170/390]\tTime 0.046 (0.045)\tData 0.011 (0.006)\tLoss 0.0235 (0.0174)\tPrec@1 99.219 (99.484)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][180/390]\tTime 0.048 (0.045)\tData 0.004 (0.006)\tLoss 0.0106 (0.0172)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][190/390]\tTime 0.037 (0.045)\tData 0.000 (0.006)\tLoss 0.0220 (0.0171)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][200/390]\tTime 0.040 (0.045)\tData 0.003 (0.006)\tLoss 0.0164 (0.0172)\tPrec@1 99.219 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][210/390]\tTime 0.044 (0.045)\tData 0.000 (0.006)\tLoss 0.0390 (0.0175)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][220/390]\tTime 0.055 (0.045)\tData 0.003 (0.005)\tLoss 0.0182 (0.0175)\tPrec@1 99.219 (99.487)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][230/390]\tTime 0.044 (0.045)\tData 0.011 (0.005)\tLoss 0.0160 (0.0175)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][240/390]\tTime 0.029 (0.045)\tData 0.001 (0.005)\tLoss 0.0252 (0.0174)\tPrec@1 99.219 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][250/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0096 (0.0172)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][260/390]\tTime 0.042 (0.045)\tData 0.004 (0.005)\tLoss 0.0169 (0.0170)\tPrec@1 99.219 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][270/390]\tTime 0.052 (0.045)\tData 0.001 (0.005)\tLoss 0.0136 (0.0168)\tPrec@1 99.219 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][280/390]\tTime 0.038 (0.045)\tData 0.007 (0.005)\tLoss 0.0072 (0.0168)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][290/390]\tTime 0.038 (0.045)\tData 0.000 (0.005)\tLoss 0.0150 (0.0168)\tPrec@1 99.219 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][300/390]\tTime 0.036 (0.045)\tData 0.007 (0.005)\tLoss 0.0151 (0.0170)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][310/390]\tTime 0.037 (0.044)\tData 0.010 (0.005)\tLoss 0.0160 (0.0170)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][320/390]\tTime 0.034 (0.044)\tData 0.005 (0.005)\tLoss 0.0218 (0.0170)\tPrec@1 99.219 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][330/390]\tTime 0.059 (0.044)\tData 0.000 (0.005)\tLoss 0.0047 (0.0170)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][340/390]\tTime 0.029 (0.044)\tData 0.000 (0.005)\tLoss 0.0497 (0.0170)\tPrec@1 99.219 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][350/390]\tTime 0.044 (0.044)\tData 0.000 (0.005)\tLoss 0.0129 (0.0169)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][360/390]\tTime 0.048 (0.044)\tData 0.000 (0.005)\tLoss 0.0056 (0.0167)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][370/390]\tTime 0.038 (0.044)\tData 0.006 (0.005)\tLoss 0.0311 (0.0168)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][380/390]\tTime 0.038 (0.044)\tData 0.005 (0.005)\tLoss 0.0070 (0.0168)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [276][389/390]\tTime 0.019 (0.044)\tData 0.000 (0.005)\tLoss 0.0138 (0.0168)\tPrec@1 99.219 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [276][0/79]\tTime 0.243 (0.243)\tData 0.227 (0.227)\tLoss 0.3014 (0.3014)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [276][10/79]\tTime 0.056 (0.042)\tData 0.050 (0.033)\tLoss 0.2568 (0.3717)\tPrec@1 91.406 (92.045)\tPrec@5 100.000 (99.716)\t\n",
            "EVALUATING - Epoch: [276][20/79]\tTime 0.076 (0.036)\tData 0.071 (0.027)\tLoss 0.5328 (0.4119)\tPrec@1 89.844 (91.406)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [276][30/79]\tTime 0.016 (0.032)\tData 0.000 (0.022)\tLoss 0.0989 (0.3971)\tPrec@1 97.656 (91.784)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [276][40/79]\tTime 0.026 (0.031)\tData 0.021 (0.021)\tLoss 0.2514 (0.3986)\tPrec@1 89.844 (91.673)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [276][50/79]\tTime 0.017 (0.030)\tData 0.011 (0.020)\tLoss 0.4321 (0.3910)\tPrec@1 89.844 (91.621)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [276][60/79]\tTime 0.014 (0.030)\tData 0.001 (0.020)\tLoss 0.6462 (0.3961)\tPrec@1 92.188 (91.586)\tPrec@5 100.000 (99.667)\t\n",
            "EVALUATING - Epoch: [276][70/79]\tTime 0.020 (0.029)\tData 0.010 (0.019)\tLoss 0.4195 (0.3891)\tPrec@1 89.844 (91.560)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [276][78/79]\tTime 0.002 (0.028)\tData 0.000 (0.018)\tLoss 0.2744 (0.3864)\tPrec@1 93.750 (91.620)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 277\n",
            "Training Loss 0.0168 \tTraining Prec@1 99.525 \tTraining Prec@5 100.000 \tValidation Loss 0.3864 \tValidation Prec@1 91.620 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 278\n",
            "\n",
            "TRAINING - Epoch: [277][0/390]\tTime 0.348 (0.348)\tData 0.288 (0.288)\tLoss 0.0087 (0.0087)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][10/390]\tTime 0.034 (0.072)\tData 0.000 (0.030)\tLoss 0.0099 (0.0202)\tPrec@1 100.000 (99.361)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][20/390]\tTime 0.054 (0.058)\tData 0.005 (0.018)\tLoss 0.0282 (0.0192)\tPrec@1 98.438 (99.405)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][30/390]\tTime 0.031 (0.052)\tData 0.000 (0.012)\tLoss 0.0044 (0.0172)\tPrec@1 100.000 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][40/390]\tTime 0.037 (0.050)\tData 0.001 (0.010)\tLoss 0.0158 (0.0187)\tPrec@1 99.219 (99.428)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][50/390]\tTime 0.035 (0.048)\tData 0.000 (0.009)\tLoss 0.0037 (0.0179)\tPrec@1 100.000 (99.464)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][60/390]\tTime 0.040 (0.047)\tData 0.001 (0.008)\tLoss 0.0258 (0.0173)\tPrec@1 99.219 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][70/390]\tTime 0.053 (0.047)\tData 0.000 (0.007)\tLoss 0.0146 (0.0178)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][80/390]\tTime 0.040 (0.047)\tData 0.000 (0.006)\tLoss 0.0062 (0.0177)\tPrec@1 100.000 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][90/390]\tTime 0.057 (0.046)\tData 0.001 (0.006)\tLoss 0.0148 (0.0182)\tPrec@1 100.000 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][100/390]\tTime 0.031 (0.046)\tData 0.004 (0.006)\tLoss 0.0064 (0.0178)\tPrec@1 100.000 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][110/390]\tTime 0.032 (0.046)\tData 0.000 (0.006)\tLoss 0.0052 (0.0183)\tPrec@1 100.000 (99.465)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][120/390]\tTime 0.029 (0.045)\tData 0.000 (0.006)\tLoss 0.0255 (0.0181)\tPrec@1 99.219 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][130/390]\tTime 0.055 (0.045)\tData 0.005 (0.006)\tLoss 0.0057 (0.0177)\tPrec@1 100.000 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][140/390]\tTime 0.043 (0.045)\tData 0.005 (0.005)\tLoss 0.0132 (0.0176)\tPrec@1 99.219 (99.474)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][150/390]\tTime 0.043 (0.045)\tData 0.004 (0.005)\tLoss 0.0057 (0.0174)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][160/390]\tTime 0.048 (0.045)\tData 0.000 (0.005)\tLoss 0.0065 (0.0174)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][170/390]\tTime 0.033 (0.045)\tData 0.006 (0.005)\tLoss 0.0140 (0.0176)\tPrec@1 99.219 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][180/390]\tTime 0.055 (0.045)\tData 0.008 (0.005)\tLoss 0.0070 (0.0176)\tPrec@1 100.000 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][190/390]\tTime 0.056 (0.045)\tData 0.008 (0.005)\tLoss 0.0075 (0.0174)\tPrec@1 100.000 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][200/390]\tTime 0.049 (0.045)\tData 0.005 (0.005)\tLoss 0.0334 (0.0177)\tPrec@1 98.438 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][210/390]\tTime 0.045 (0.045)\tData 0.000 (0.005)\tLoss 0.0277 (0.0176)\tPrec@1 99.219 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][220/390]\tTime 0.116 (0.045)\tData 0.080 (0.005)\tLoss 0.0477 (0.0174)\tPrec@1 97.656 (99.487)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][230/390]\tTime 0.042 (0.045)\tData 0.005 (0.005)\tLoss 0.0168 (0.0175)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][240/390]\tTime 0.044 (0.045)\tData 0.010 (0.005)\tLoss 0.0053 (0.0174)\tPrec@1 100.000 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][250/390]\tTime 0.034 (0.044)\tData 0.002 (0.005)\tLoss 0.0071 (0.0173)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][260/390]\tTime 0.043 (0.045)\tData 0.000 (0.005)\tLoss 0.0191 (0.0173)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][270/390]\tTime 0.040 (0.044)\tData 0.001 (0.005)\tLoss 0.0072 (0.0173)\tPrec@1 100.000 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][280/390]\tTime 0.054 (0.044)\tData 0.011 (0.005)\tLoss 0.0069 (0.0172)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][290/390]\tTime 0.047 (0.044)\tData 0.005 (0.005)\tLoss 0.0113 (0.0173)\tPrec@1 100.000 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][300/390]\tTime 0.045 (0.044)\tData 0.009 (0.005)\tLoss 0.0091 (0.0173)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][310/390]\tTime 0.060 (0.044)\tData 0.009 (0.005)\tLoss 0.0223 (0.0174)\tPrec@1 99.219 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][320/390]\tTime 0.088 (0.044)\tData 0.045 (0.005)\tLoss 0.0185 (0.0172)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][330/390]\tTime 0.040 (0.044)\tData 0.000 (0.005)\tLoss 0.0039 (0.0170)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][340/390]\tTime 0.059 (0.044)\tData 0.034 (0.005)\tLoss 0.0109 (0.0171)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][350/390]\tTime 0.029 (0.044)\tData 0.000 (0.005)\tLoss 0.0272 (0.0171)\tPrec@1 99.219 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][360/390]\tTime 0.056 (0.044)\tData 0.027 (0.005)\tLoss 0.0196 (0.0170)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][370/390]\tTime 0.039 (0.044)\tData 0.000 (0.005)\tLoss 0.0420 (0.0170)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][380/390]\tTime 0.077 (0.044)\tData 0.047 (0.006)\tLoss 0.0052 (0.0169)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [277][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0155 (0.0169)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [277][0/79]\tTime 0.256 (0.256)\tData 0.234 (0.234)\tLoss 0.2848 (0.2848)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [277][10/79]\tTime 0.018 (0.043)\tData 0.005 (0.027)\tLoss 0.2514 (0.3713)\tPrec@1 91.406 (92.472)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [277][20/79]\tTime 0.058 (0.039)\tData 0.050 (0.023)\tLoss 0.5216 (0.4097)\tPrec@1 89.844 (91.592)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [277][30/79]\tTime 0.026 (0.034)\tData 0.006 (0.019)\tLoss 0.1007 (0.3968)\tPrec@1 97.656 (92.011)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [277][40/79]\tTime 0.077 (0.034)\tData 0.071 (0.019)\tLoss 0.2494 (0.3987)\tPrec@1 90.625 (91.940)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [277][50/79]\tTime 0.011 (0.031)\tData 0.005 (0.017)\tLoss 0.4468 (0.3912)\tPrec@1 89.844 (91.866)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [277][60/79]\tTime 0.019 (0.031)\tData 0.009 (0.018)\tLoss 0.6436 (0.3957)\tPrec@1 92.969 (91.752)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [277][70/79]\tTime 0.014 (0.030)\tData 0.000 (0.017)\tLoss 0.3973 (0.3877)\tPrec@1 89.844 (91.714)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [277][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.016)\tLoss 0.2485 (0.3846)\tPrec@1 93.750 (91.730)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 278\n",
            "Training Loss 0.0169 \tTraining Prec@1 99.529 \tTraining Prec@5 100.000 \tValidation Loss 0.3846 \tValidation Prec@1 91.730 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 279\n",
            "\n",
            "TRAINING - Epoch: [278][0/390]\tTime 0.357 (0.357)\tData 0.316 (0.316)\tLoss 0.0314 (0.0314)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][10/390]\tTime 0.042 (0.072)\tData 0.000 (0.032)\tLoss 0.0062 (0.0203)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][20/390]\tTime 0.067 (0.058)\tData 0.034 (0.020)\tLoss 0.0232 (0.0201)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][30/390]\tTime 0.042 (0.053)\tData 0.005 (0.016)\tLoss 0.0083 (0.0188)\tPrec@1 100.000 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][40/390]\tTime 0.056 (0.051)\tData 0.020 (0.014)\tLoss 0.0177 (0.0177)\tPrec@1 99.219 (99.638)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][50/390]\tTime 0.031 (0.050)\tData 0.001 (0.012)\tLoss 0.0337 (0.0167)\tPrec@1 99.219 (99.663)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][60/390]\tTime 0.034 (0.049)\tData 0.005 (0.011)\tLoss 0.0169 (0.0176)\tPrec@1 100.000 (99.654)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][70/390]\tTime 0.059 (0.048)\tData 0.000 (0.010)\tLoss 0.0134 (0.0169)\tPrec@1 99.219 (99.659)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][80/390]\tTime 0.045 (0.048)\tData 0.007 (0.009)\tLoss 0.0118 (0.0167)\tPrec@1 100.000 (99.672)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][90/390]\tTime 0.052 (0.049)\tData 0.006 (0.009)\tLoss 0.0255 (0.0165)\tPrec@1 99.219 (99.665)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][100/390]\tTime 0.038 (0.048)\tData 0.004 (0.008)\tLoss 0.0024 (0.0163)\tPrec@1 100.000 (99.652)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][110/390]\tTime 0.040 (0.048)\tData 0.000 (0.008)\tLoss 0.0321 (0.0165)\tPrec@1 99.219 (99.641)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][120/390]\tTime 0.041 (0.047)\tData 0.009 (0.007)\tLoss 0.0168 (0.0166)\tPrec@1 100.000 (99.651)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][130/390]\tTime 0.058 (0.047)\tData 0.005 (0.008)\tLoss 0.0085 (0.0164)\tPrec@1 100.000 (99.672)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][140/390]\tTime 0.039 (0.046)\tData 0.000 (0.007)\tLoss 0.0137 (0.0166)\tPrec@1 99.219 (99.656)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][150/390]\tTime 0.053 (0.046)\tData 0.014 (0.007)\tLoss 0.0055 (0.0164)\tPrec@1 100.000 (99.643)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][160/390]\tTime 0.048 (0.046)\tData 0.000 (0.007)\tLoss 0.0151 (0.0163)\tPrec@1 100.000 (99.646)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][170/390]\tTime 0.041 (0.046)\tData 0.000 (0.007)\tLoss 0.0070 (0.0162)\tPrec@1 100.000 (99.644)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][180/390]\tTime 0.051 (0.046)\tData 0.001 (0.007)\tLoss 0.0053 (0.0162)\tPrec@1 100.000 (99.633)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][190/390]\tTime 0.056 (0.045)\tData 0.000 (0.007)\tLoss 0.0061 (0.0165)\tPrec@1 100.000 (99.624)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][200/390]\tTime 0.042 (0.045)\tData 0.001 (0.006)\tLoss 0.0142 (0.0164)\tPrec@1 100.000 (99.619)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][210/390]\tTime 0.050 (0.045)\tData 0.022 (0.006)\tLoss 0.0073 (0.0164)\tPrec@1 100.000 (99.626)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][220/390]\tTime 0.041 (0.045)\tData 0.004 (0.006)\tLoss 0.0250 (0.0166)\tPrec@1 99.219 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][230/390]\tTime 0.046 (0.045)\tData 0.001 (0.006)\tLoss 0.0126 (0.0169)\tPrec@1 100.000 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][240/390]\tTime 0.037 (0.045)\tData 0.007 (0.006)\tLoss 0.0117 (0.0170)\tPrec@1 100.000 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][250/390]\tTime 0.048 (0.045)\tData 0.018 (0.006)\tLoss 0.0121 (0.0171)\tPrec@1 100.000 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][260/390]\tTime 0.043 (0.045)\tData 0.001 (0.006)\tLoss 0.0174 (0.0172)\tPrec@1 99.219 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][270/390]\tTime 0.042 (0.045)\tData 0.006 (0.006)\tLoss 0.0199 (0.0174)\tPrec@1 99.219 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][280/390]\tTime 0.041 (0.045)\tData 0.004 (0.006)\tLoss 0.0084 (0.0173)\tPrec@1 100.000 (99.580)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][290/390]\tTime 0.047 (0.045)\tData 0.005 (0.006)\tLoss 0.0179 (0.0173)\tPrec@1 100.000 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][300/390]\tTime 0.053 (0.045)\tData 0.011 (0.006)\tLoss 0.0124 (0.0174)\tPrec@1 99.219 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][310/390]\tTime 0.032 (0.045)\tData 0.001 (0.006)\tLoss 0.0603 (0.0176)\tPrec@1 97.656 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][320/390]\tTime 0.032 (0.045)\tData 0.000 (0.006)\tLoss 0.0117 (0.0174)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][330/390]\tTime 0.048 (0.045)\tData 0.000 (0.006)\tLoss 0.0116 (0.0174)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][340/390]\tTime 0.044 (0.045)\tData 0.009 (0.006)\tLoss 0.0327 (0.0173)\tPrec@1 98.438 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][350/390]\tTime 0.043 (0.044)\tData 0.001 (0.006)\tLoss 0.0264 (0.0173)\tPrec@1 98.438 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][360/390]\tTime 0.038 (0.044)\tData 0.008 (0.006)\tLoss 0.0131 (0.0172)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][370/390]\tTime 0.041 (0.044)\tData 0.001 (0.006)\tLoss 0.0098 (0.0173)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][380/390]\tTime 0.031 (0.044)\tData 0.000 (0.006)\tLoss 0.0122 (0.0172)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [278][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0171 (0.0172)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [278][0/79]\tTime 0.259 (0.259)\tData 0.243 (0.243)\tLoss 0.2824 (0.2824)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [278][10/79]\tTime 0.018 (0.041)\tData 0.012 (0.030)\tLoss 0.2551 (0.3664)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [278][20/79]\tTime 0.043 (0.035)\tData 0.037 (0.025)\tLoss 0.5226 (0.4060)\tPrec@1 89.844 (91.555)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [278][30/79]\tTime 0.021 (0.032)\tData 0.008 (0.022)\tLoss 0.0996 (0.3933)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [278][40/79]\tTime 0.012 (0.031)\tData 0.006 (0.020)\tLoss 0.2434 (0.3951)\tPrec@1 91.406 (91.864)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [278][50/79]\tTime 0.019 (0.032)\tData 0.004 (0.021)\tLoss 0.4231 (0.3880)\tPrec@1 90.625 (91.850)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [278][60/79]\tTime 0.021 (0.032)\tData 0.008 (0.020)\tLoss 0.6414 (0.3934)\tPrec@1 92.969 (91.765)\tPrec@5 99.219 (99.641)\t\n",
            "EVALUATING - Epoch: [278][70/79]\tTime 0.018 (0.031)\tData 0.001 (0.020)\tLoss 0.3838 (0.3855)\tPrec@1 89.844 (91.725)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [278][78/79]\tTime 0.002 (0.029)\tData 0.000 (0.018)\tLoss 0.2376 (0.3826)\tPrec@1 93.750 (91.720)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 279\n",
            "Training Loss 0.0172 \tTraining Prec@1 99.553 \tTraining Prec@5 99.998 \tValidation Loss 0.3826 \tValidation Prec@1 91.720 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 280\n",
            "\n",
            "TRAINING - Epoch: [279][0/390]\tTime 0.335 (0.335)\tData 0.292 (0.292)\tLoss 0.0423 (0.0423)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][10/390]\tTime 0.047 (0.070)\tData 0.003 (0.031)\tLoss 0.0111 (0.0231)\tPrec@1 100.000 (99.148)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][20/390]\tTime 0.032 (0.058)\tData 0.000 (0.018)\tLoss 0.0165 (0.0183)\tPrec@1 99.219 (99.405)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][30/390]\tTime 0.027 (0.052)\tData 0.007 (0.014)\tLoss 0.0078 (0.0168)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][40/390]\tTime 0.053 (0.050)\tData 0.023 (0.012)\tLoss 0.0158 (0.0168)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][50/390]\tTime 0.039 (0.049)\tData 0.005 (0.011)\tLoss 0.0214 (0.0166)\tPrec@1 99.219 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][60/390]\tTime 0.035 (0.048)\tData 0.000 (0.010)\tLoss 0.0038 (0.0162)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][70/390]\tTime 0.047 (0.047)\tData 0.000 (0.009)\tLoss 0.0131 (0.0161)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][80/390]\tTime 0.030 (0.046)\tData 0.000 (0.008)\tLoss 0.0064 (0.0159)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][90/390]\tTime 0.058 (0.046)\tData 0.005 (0.008)\tLoss 0.0276 (0.0163)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][100/390]\tTime 0.052 (0.046)\tData 0.000 (0.008)\tLoss 0.0458 (0.0170)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][110/390]\tTime 0.042 (0.046)\tData 0.004 (0.007)\tLoss 0.0210 (0.0175)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][120/390]\tTime 0.043 (0.045)\tData 0.005 (0.007)\tLoss 0.0251 (0.0176)\tPrec@1 99.219 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][130/390]\tTime 0.052 (0.045)\tData 0.005 (0.006)\tLoss 0.0038 (0.0174)\tPrec@1 100.000 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][140/390]\tTime 0.034 (0.045)\tData 0.000 (0.006)\tLoss 0.0038 (0.0178)\tPrec@1 100.000 (99.446)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][150/390]\tTime 0.050 (0.045)\tData 0.024 (0.006)\tLoss 0.0326 (0.0176)\tPrec@1 98.438 (99.462)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][160/390]\tTime 0.053 (0.045)\tData 0.006 (0.006)\tLoss 0.0185 (0.0176)\tPrec@1 99.219 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][170/390]\tTime 0.030 (0.045)\tData 0.006 (0.006)\tLoss 0.0120 (0.0175)\tPrec@1 100.000 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][180/390]\tTime 0.022 (0.045)\tData 0.000 (0.006)\tLoss 0.0251 (0.0173)\tPrec@1 99.219 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][190/390]\tTime 0.037 (0.045)\tData 0.004 (0.006)\tLoss 0.0163 (0.0174)\tPrec@1 99.219 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][200/390]\tTime 0.042 (0.045)\tData 0.000 (0.006)\tLoss 0.0227 (0.0173)\tPrec@1 99.219 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][210/390]\tTime 0.038 (0.045)\tData 0.004 (0.006)\tLoss 0.0188 (0.0172)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][220/390]\tTime 0.039 (0.045)\tData 0.001 (0.006)\tLoss 0.0152 (0.0171)\tPrec@1 99.219 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][230/390]\tTime 0.039 (0.045)\tData 0.000 (0.006)\tLoss 0.0150 (0.0171)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][240/390]\tTime 0.040 (0.044)\tData 0.001 (0.005)\tLoss 0.0081 (0.0171)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][250/390]\tTime 0.037 (0.045)\tData 0.007 (0.005)\tLoss 0.0028 (0.0170)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][260/390]\tTime 0.043 (0.045)\tData 0.001 (0.005)\tLoss 0.0180 (0.0172)\tPrec@1 99.219 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][270/390]\tTime 0.023 (0.044)\tData 0.000 (0.005)\tLoss 0.0125 (0.0174)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][280/390]\tTime 0.029 (0.044)\tData 0.000 (0.005)\tLoss 0.0240 (0.0173)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][290/390]\tTime 0.040 (0.044)\tData 0.010 (0.005)\tLoss 0.0231 (0.0173)\tPrec@1 99.219 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][300/390]\tTime 0.035 (0.044)\tData 0.000 (0.005)\tLoss 0.0163 (0.0175)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][310/390]\tTime 0.032 (0.044)\tData 0.000 (0.005)\tLoss 0.0129 (0.0176)\tPrec@1 99.219 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][320/390]\tTime 0.039 (0.044)\tData 0.005 (0.005)\tLoss 0.0055 (0.0176)\tPrec@1 100.000 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][330/390]\tTime 0.039 (0.044)\tData 0.003 (0.005)\tLoss 0.0429 (0.0176)\tPrec@1 98.438 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][340/390]\tTime 0.048 (0.044)\tData 0.002 (0.005)\tLoss 0.0157 (0.0174)\tPrec@1 99.219 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][350/390]\tTime 0.038 (0.044)\tData 0.005 (0.005)\tLoss 0.0090 (0.0174)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][360/390]\tTime 0.061 (0.044)\tData 0.001 (0.005)\tLoss 0.0138 (0.0173)\tPrec@1 100.000 (99.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][370/390]\tTime 0.030 (0.044)\tData 0.002 (0.005)\tLoss 0.0391 (0.0172)\tPrec@1 98.438 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][380/390]\tTime 0.035 (0.044)\tData 0.006 (0.005)\tLoss 0.0152 (0.0172)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [279][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0090 (0.0172)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [279][0/79]\tTime 0.206 (0.206)\tData 0.192 (0.192)\tLoss 0.2878 (0.2878)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [279][10/79]\tTime 0.076 (0.047)\tData 0.070 (0.036)\tLoss 0.2506 (0.3687)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.716)\t\n",
            "EVALUATING - Epoch: [279][20/79]\tTime 0.015 (0.038)\tData 0.003 (0.027)\tLoss 0.5244 (0.4113)\tPrec@1 89.844 (91.667)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [279][30/79]\tTime 0.080 (0.035)\tData 0.063 (0.024)\tLoss 0.1004 (0.3979)\tPrec@1 97.656 (92.011)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [279][40/79]\tTime 0.012 (0.032)\tData 0.004 (0.022)\tLoss 0.2404 (0.3992)\tPrec@1 91.406 (91.959)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [279][50/79]\tTime 0.036 (0.032)\tData 0.026 (0.021)\tLoss 0.4433 (0.3922)\tPrec@1 90.625 (91.866)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [279][60/79]\tTime 0.017 (0.032)\tData 0.003 (0.021)\tLoss 0.6523 (0.3968)\tPrec@1 92.969 (91.803)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [279][70/79]\tTime 0.022 (0.031)\tData 0.004 (0.020)\tLoss 0.4026 (0.3893)\tPrec@1 90.625 (91.780)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [279][78/79]\tTime 0.002 (0.029)\tData 0.000 (0.019)\tLoss 0.2915 (0.3863)\tPrec@1 93.750 (91.830)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 280\n",
            "Training Loss 0.0172 \tTraining Prec@1 99.513 \tTraining Prec@5 100.000 \tValidation Loss 0.3863 \tValidation Prec@1 91.830 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 281\n",
            "\n",
            "TRAINING - Epoch: [280][0/390]\tTime 0.251 (0.251)\tData 0.198 (0.198)\tLoss 0.0220 (0.0220)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][10/390]\tTime 0.044 (0.069)\tData 0.002 (0.027)\tLoss 0.0080 (0.0171)\tPrec@1 100.000 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][20/390]\tTime 0.059 (0.057)\tData 0.002 (0.015)\tLoss 0.0354 (0.0188)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][30/390]\tTime 0.048 (0.054)\tData 0.003 (0.011)\tLoss 0.0087 (0.0172)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][40/390]\tTime 0.041 (0.051)\tData 0.005 (0.009)\tLoss 0.0034 (0.0161)\tPrec@1 100.000 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][50/390]\tTime 0.040 (0.049)\tData 0.012 (0.008)\tLoss 0.0172 (0.0163)\tPrec@1 99.219 (99.617)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][60/390]\tTime 0.036 (0.048)\tData 0.002 (0.007)\tLoss 0.0023 (0.0163)\tPrec@1 100.000 (99.616)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][70/390]\tTime 0.035 (0.047)\tData 0.000 (0.006)\tLoss 0.0110 (0.0159)\tPrec@1 100.000 (99.626)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][80/390]\tTime 0.024 (0.047)\tData 0.004 (0.006)\tLoss 0.0344 (0.0162)\tPrec@1 99.219 (99.624)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][90/390]\tTime 0.036 (0.046)\tData 0.000 (0.006)\tLoss 0.0160 (0.0168)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][100/390]\tTime 0.044 (0.046)\tData 0.002 (0.006)\tLoss 0.0087 (0.0167)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][110/390]\tTime 0.037 (0.046)\tData 0.002 (0.005)\tLoss 0.0163 (0.0164)\tPrec@1 100.000 (99.620)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][120/390]\tTime 0.036 (0.046)\tData 0.003 (0.005)\tLoss 0.0114 (0.0162)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][130/390]\tTime 0.043 (0.045)\tData 0.000 (0.005)\tLoss 0.0063 (0.0159)\tPrec@1 100.000 (99.624)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][140/390]\tTime 0.031 (0.045)\tData 0.000 (0.005)\tLoss 0.0250 (0.0165)\tPrec@1 99.219 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][150/390]\tTime 0.027 (0.045)\tData 0.000 (0.005)\tLoss 0.0161 (0.0166)\tPrec@1 99.219 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [280][160/390]\tTime 0.051 (0.045)\tData 0.012 (0.005)\tLoss 0.0213 (0.0166)\tPrec@1 99.219 (99.583)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [280][170/390]\tTime 0.035 (0.045)\tData 0.000 (0.005)\tLoss 0.0179 (0.0164)\tPrec@1 100.000 (99.598)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [280][180/390]\tTime 0.035 (0.044)\tData 0.003 (0.005)\tLoss 0.0066 (0.0161)\tPrec@1 100.000 (99.603)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [280][190/390]\tTime 0.040 (0.044)\tData 0.010 (0.005)\tLoss 0.0241 (0.0162)\tPrec@1 99.219 (99.595)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [280][200/390]\tTime 0.038 (0.044)\tData 0.006 (0.005)\tLoss 0.0169 (0.0161)\tPrec@1 99.219 (99.596)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [280][210/390]\tTime 0.041 (0.045)\tData 0.000 (0.005)\tLoss 0.0154 (0.0162)\tPrec@1 99.219 (99.585)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [280][220/390]\tTime 0.034 (0.044)\tData 0.000 (0.005)\tLoss 0.0212 (0.0162)\tPrec@1 99.219 (99.579)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [280][230/390]\tTime 0.038 (0.044)\tData 0.000 (0.005)\tLoss 0.0270 (0.0163)\tPrec@1 99.219 (99.574)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [280][240/390]\tTime 0.048 (0.044)\tData 0.005 (0.005)\tLoss 0.0223 (0.0165)\tPrec@1 99.219 (99.559)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [280][250/390]\tTime 0.048 (0.044)\tData 0.002 (0.005)\tLoss 0.0039 (0.0165)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [280][260/390]\tTime 0.053 (0.045)\tData 0.000 (0.005)\tLoss 0.0140 (0.0165)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [280][270/390]\tTime 0.035 (0.044)\tData 0.003 (0.005)\tLoss 0.0104 (0.0165)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [280][280/390]\tTime 0.045 (0.044)\tData 0.005 (0.005)\tLoss 0.0195 (0.0165)\tPrec@1 98.438 (99.555)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [280][290/390]\tTime 0.046 (0.044)\tData 0.003 (0.005)\tLoss 0.0297 (0.0165)\tPrec@1 99.219 (99.557)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [280][300/390]\tTime 0.051 (0.044)\tData 0.003 (0.005)\tLoss 0.0094 (0.0163)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [280][310/390]\tTime 0.046 (0.044)\tData 0.005 (0.005)\tLoss 0.0074 (0.0162)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [280][320/390]\tTime 0.038 (0.044)\tData 0.005 (0.005)\tLoss 0.0231 (0.0165)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [280][330/390]\tTime 0.034 (0.044)\tData 0.001 (0.005)\tLoss 0.0096 (0.0164)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [280][340/390]\tTime 0.040 (0.044)\tData 0.001 (0.005)\tLoss 0.0080 (0.0163)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [280][350/390]\tTime 0.037 (0.044)\tData 0.006 (0.005)\tLoss 0.0573 (0.0165)\tPrec@1 99.219 (99.548)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [280][360/390]\tTime 0.041 (0.044)\tData 0.000 (0.005)\tLoss 0.0183 (0.0164)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [280][370/390]\tTime 0.039 (0.044)\tData 0.004 (0.005)\tLoss 0.0144 (0.0165)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [280][380/390]\tTime 0.047 (0.044)\tData 0.001 (0.005)\tLoss 0.0098 (0.0166)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [280][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.005)\tLoss 0.0090 (0.0166)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [280][0/79]\tTime 0.187 (0.187)\tData 0.171 (0.171)\tLoss 0.2887 (0.2887)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [280][10/79]\tTime 0.028 (0.043)\tData 0.022 (0.030)\tLoss 0.2614 (0.3734)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [280][20/79]\tTime 0.017 (0.034)\tData 0.000 (0.022)\tLoss 0.5221 (0.4118)\tPrec@1 89.844 (91.741)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [280][30/79]\tTime 0.020 (0.032)\tData 0.011 (0.020)\tLoss 0.1015 (0.3985)\tPrec@1 97.656 (92.011)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [280][40/79]\tTime 0.015 (0.031)\tData 0.000 (0.019)\tLoss 0.2451 (0.3995)\tPrec@1 89.844 (91.883)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [280][50/79]\tTime 0.087 (0.031)\tData 0.073 (0.019)\tLoss 0.4294 (0.3926)\tPrec@1 91.406 (91.774)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [280][60/79]\tTime 0.020 (0.029)\tData 0.005 (0.018)\tLoss 0.6466 (0.3972)\tPrec@1 92.969 (91.701)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [280][70/79]\tTime 0.021 (0.030)\tData 0.000 (0.019)\tLoss 0.4069 (0.3895)\tPrec@1 89.062 (91.648)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [280][78/79]\tTime 0.003 (0.028)\tData 0.000 (0.017)\tLoss 0.2483 (0.3866)\tPrec@1 93.750 (91.640)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 281\n",
            "Training Loss 0.0166 \tTraining Prec@1 99.543 \tTraining Prec@5 99.998 \tValidation Loss 0.3866 \tValidation Prec@1 91.640 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 282\n",
            "\n",
            "TRAINING - Epoch: [281][0/390]\tTime 0.345 (0.345)\tData 0.303 (0.303)\tLoss 0.0096 (0.0096)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][10/390]\tTime 0.030 (0.070)\tData 0.001 (0.031)\tLoss 0.0227 (0.0136)\tPrec@1 99.219 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][20/390]\tTime 0.067 (0.057)\tData 0.033 (0.020)\tLoss 0.0119 (0.0182)\tPrec@1 100.000 (99.442)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][30/390]\tTime 0.046 (0.053)\tData 0.005 (0.015)\tLoss 0.0115 (0.0181)\tPrec@1 99.219 (99.370)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][40/390]\tTime 0.044 (0.051)\tData 0.001 (0.012)\tLoss 0.0118 (0.0177)\tPrec@1 99.219 (99.466)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][50/390]\tTime 0.039 (0.049)\tData 0.000 (0.010)\tLoss 0.0094 (0.0168)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][60/390]\tTime 0.043 (0.048)\tData 0.005 (0.009)\tLoss 0.0278 (0.0171)\tPrec@1 99.219 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][70/390]\tTime 0.036 (0.047)\tData 0.001 (0.008)\tLoss 0.0215 (0.0166)\tPrec@1 99.219 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][80/390]\tTime 0.056 (0.047)\tData 0.008 (0.008)\tLoss 0.0086 (0.0169)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][90/390]\tTime 0.035 (0.047)\tData 0.001 (0.007)\tLoss 0.0320 (0.0173)\tPrec@1 98.438 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][100/390]\tTime 0.046 (0.046)\tData 0.005 (0.007)\tLoss 0.0139 (0.0171)\tPrec@1 99.219 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][110/390]\tTime 0.035 (0.046)\tData 0.005 (0.006)\tLoss 0.0198 (0.0173)\tPrec@1 98.438 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][120/390]\tTime 0.051 (0.045)\tData 0.005 (0.006)\tLoss 0.0294 (0.0174)\tPrec@1 98.438 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][130/390]\tTime 0.036 (0.045)\tData 0.005 (0.006)\tLoss 0.0048 (0.0171)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][140/390]\tTime 0.037 (0.045)\tData 0.005 (0.006)\tLoss 0.0039 (0.0170)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][150/390]\tTime 0.040 (0.045)\tData 0.001 (0.006)\tLoss 0.0113 (0.0170)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][160/390]\tTime 0.048 (0.045)\tData 0.001 (0.006)\tLoss 0.0037 (0.0169)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][170/390]\tTime 0.064 (0.045)\tData 0.031 (0.006)\tLoss 0.0510 (0.0172)\tPrec@1 96.875 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][180/390]\tTime 0.056 (0.045)\tData 0.011 (0.006)\tLoss 0.0048 (0.0172)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][190/390]\tTime 0.037 (0.045)\tData 0.000 (0.005)\tLoss 0.0106 (0.0172)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][200/390]\tTime 0.038 (0.045)\tData 0.007 (0.005)\tLoss 0.0078 (0.0170)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][210/390]\tTime 0.043 (0.044)\tData 0.005 (0.005)\tLoss 0.0061 (0.0172)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][220/390]\tTime 0.047 (0.044)\tData 0.005 (0.005)\tLoss 0.0466 (0.0173)\tPrec@1 96.875 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][230/390]\tTime 0.042 (0.044)\tData 0.005 (0.005)\tLoss 0.0515 (0.0174)\tPrec@1 98.438 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][240/390]\tTime 0.042 (0.045)\tData 0.007 (0.005)\tLoss 0.0235 (0.0175)\tPrec@1 98.438 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][250/390]\tTime 0.027 (0.044)\tData 0.000 (0.005)\tLoss 0.0347 (0.0177)\tPrec@1 98.438 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][260/390]\tTime 0.041 (0.044)\tData 0.000 (0.005)\tLoss 0.0250 (0.0180)\tPrec@1 99.219 (99.467)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][270/390]\tTime 0.037 (0.044)\tData 0.000 (0.005)\tLoss 0.0172 (0.0180)\tPrec@1 100.000 (99.464)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][280/390]\tTime 0.046 (0.044)\tData 0.008 (0.005)\tLoss 0.0280 (0.0181)\tPrec@1 99.219 (99.452)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][290/390]\tTime 0.047 (0.044)\tData 0.005 (0.005)\tLoss 0.0403 (0.0181)\tPrec@1 99.219 (99.460)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][300/390]\tTime 0.038 (0.044)\tData 0.005 (0.005)\tLoss 0.0379 (0.0180)\tPrec@1 96.875 (99.458)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][310/390]\tTime 0.048 (0.044)\tData 0.005 (0.005)\tLoss 0.0110 (0.0180)\tPrec@1 99.219 (99.457)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][320/390]\tTime 0.033 (0.044)\tData 0.000 (0.005)\tLoss 0.0149 (0.0180)\tPrec@1 100.000 (99.465)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][330/390]\tTime 0.048 (0.044)\tData 0.005 (0.005)\tLoss 0.0217 (0.0179)\tPrec@1 99.219 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][340/390]\tTime 0.032 (0.044)\tData 0.000 (0.005)\tLoss 0.0400 (0.0180)\tPrec@1 98.438 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][350/390]\tTime 0.046 (0.044)\tData 0.000 (0.005)\tLoss 0.0131 (0.0180)\tPrec@1 99.219 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][360/390]\tTime 0.044 (0.044)\tData 0.010 (0.005)\tLoss 0.0274 (0.0179)\tPrec@1 99.219 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][370/390]\tTime 0.034 (0.044)\tData 0.000 (0.005)\tLoss 0.0043 (0.0178)\tPrec@1 100.000 (99.482)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][380/390]\tTime 0.030 (0.044)\tData 0.002 (0.005)\tLoss 0.0292 (0.0178)\tPrec@1 99.219 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [281][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0241 (0.0178)\tPrec@1 98.438 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [281][0/79]\tTime 0.231 (0.231)\tData 0.218 (0.218)\tLoss 0.2919 (0.2919)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [281][10/79]\tTime 0.024 (0.044)\tData 0.004 (0.032)\tLoss 0.2581 (0.3660)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [281][20/79]\tTime 0.049 (0.037)\tData 0.000 (0.023)\tLoss 0.5470 (0.4099)\tPrec@1 90.625 (91.704)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [281][30/79]\tTime 0.013 (0.035)\tData 0.001 (0.021)\tLoss 0.0937 (0.3968)\tPrec@1 97.656 (91.986)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [281][40/79]\tTime 0.053 (0.033)\tData 0.002 (0.019)\tLoss 0.2482 (0.3981)\tPrec@1 89.844 (91.845)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [281][50/79]\tTime 0.039 (0.032)\tData 0.033 (0.019)\tLoss 0.4127 (0.3911)\tPrec@1 89.844 (91.820)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [281][60/79]\tTime 0.011 (0.030)\tData 0.005 (0.017)\tLoss 0.6314 (0.3965)\tPrec@1 92.969 (91.701)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [281][70/79]\tTime 0.036 (0.030)\tData 0.030 (0.017)\tLoss 0.4108 (0.3896)\tPrec@1 89.062 (91.648)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [281][78/79]\tTime 0.002 (0.028)\tData 0.000 (0.016)\tLoss 0.2546 (0.3872)\tPrec@1 93.750 (91.660)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 282\n",
            "Training Loss 0.0178 \tTraining Prec@1 99.481 \tTraining Prec@5 100.000 \tValidation Loss 0.3872 \tValidation Prec@1 91.660 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 283\n",
            "\n",
            "TRAINING - Epoch: [282][0/390]\tTime 0.342 (0.342)\tData 0.286 (0.286)\tLoss 0.0216 (0.0216)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][10/390]\tTime 0.034 (0.066)\tData 0.004 (0.029)\tLoss 0.0082 (0.0195)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][20/390]\tTime 0.041 (0.055)\tData 0.013 (0.017)\tLoss 0.0073 (0.0164)\tPrec@1 100.000 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][30/390]\tTime 0.038 (0.051)\tData 0.001 (0.014)\tLoss 0.0068 (0.0158)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][40/390]\tTime 0.046 (0.049)\tData 0.018 (0.011)\tLoss 0.0120 (0.0146)\tPrec@1 100.000 (99.695)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][50/390]\tTime 0.046 (0.048)\tData 0.000 (0.010)\tLoss 0.0164 (0.0144)\tPrec@1 99.219 (99.709)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][60/390]\tTime 0.066 (0.047)\tData 0.031 (0.009)\tLoss 0.0063 (0.0141)\tPrec@1 100.000 (99.718)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][70/390]\tTime 0.040 (0.047)\tData 0.001 (0.008)\tLoss 0.0245 (0.0153)\tPrec@1 99.219 (99.659)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][80/390]\tTime 0.041 (0.046)\tData 0.002 (0.008)\tLoss 0.0123 (0.0154)\tPrec@1 100.000 (99.624)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][90/390]\tTime 0.050 (0.046)\tData 0.001 (0.007)\tLoss 0.0220 (0.0161)\tPrec@1 99.219 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][100/390]\tTime 0.042 (0.045)\tData 0.012 (0.007)\tLoss 0.0226 (0.0170)\tPrec@1 99.219 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][110/390]\tTime 0.048 (0.045)\tData 0.005 (0.007)\tLoss 0.0095 (0.0175)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][120/390]\tTime 0.042 (0.045)\tData 0.005 (0.006)\tLoss 0.0245 (0.0176)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][130/390]\tTime 0.048 (0.045)\tData 0.004 (0.006)\tLoss 0.0134 (0.0175)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][140/390]\tTime 0.036 (0.045)\tData 0.001 (0.006)\tLoss 0.0342 (0.0176)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][150/390]\tTime 0.050 (0.044)\tData 0.011 (0.006)\tLoss 0.0224 (0.0178)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][160/390]\tTime 0.038 (0.044)\tData 0.000 (0.006)\tLoss 0.0060 (0.0179)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][170/390]\tTime 0.041 (0.044)\tData 0.007 (0.005)\tLoss 0.0292 (0.0180)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][180/390]\tTime 0.049 (0.044)\tData 0.007 (0.005)\tLoss 0.0155 (0.0180)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][190/390]\tTime 0.051 (0.044)\tData 0.000 (0.005)\tLoss 0.0264 (0.0177)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][200/390]\tTime 0.047 (0.044)\tData 0.005 (0.005)\tLoss 0.0486 (0.0179)\tPrec@1 97.656 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][210/390]\tTime 0.037 (0.044)\tData 0.007 (0.005)\tLoss 0.0255 (0.0179)\tPrec@1 98.438 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][220/390]\tTime 0.043 (0.044)\tData 0.000 (0.005)\tLoss 0.0063 (0.0181)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][230/390]\tTime 0.037 (0.044)\tData 0.000 (0.005)\tLoss 0.0175 (0.0181)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][240/390]\tTime 0.044 (0.044)\tData 0.002 (0.005)\tLoss 0.0244 (0.0179)\tPrec@1 99.219 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][250/390]\tTime 0.034 (0.044)\tData 0.000 (0.005)\tLoss 0.0214 (0.0178)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][260/390]\tTime 0.045 (0.044)\tData 0.000 (0.005)\tLoss 0.0038 (0.0176)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][270/390]\tTime 0.045 (0.043)\tData 0.001 (0.004)\tLoss 0.0046 (0.0175)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][280/390]\tTime 0.037 (0.043)\tData 0.000 (0.004)\tLoss 0.0162 (0.0176)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][290/390]\tTime 0.048 (0.043)\tData 0.003 (0.004)\tLoss 0.0353 (0.0177)\tPrec@1 98.438 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][300/390]\tTime 0.033 (0.043)\tData 0.000 (0.004)\tLoss 0.0172 (0.0177)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][310/390]\tTime 0.037 (0.043)\tData 0.000 (0.004)\tLoss 0.0067 (0.0176)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][320/390]\tTime 0.054 (0.043)\tData 0.023 (0.004)\tLoss 0.0078 (0.0175)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][330/390]\tTime 0.037 (0.043)\tData 0.006 (0.004)\tLoss 0.0246 (0.0177)\tPrec@1 99.219 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][340/390]\tTime 0.040 (0.043)\tData 0.005 (0.004)\tLoss 0.0134 (0.0175)\tPrec@1 99.219 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][350/390]\tTime 0.037 (0.043)\tData 0.005 (0.004)\tLoss 0.0139 (0.0174)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][360/390]\tTime 0.037 (0.043)\tData 0.013 (0.004)\tLoss 0.0355 (0.0175)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][370/390]\tTime 0.035 (0.043)\tData 0.002 (0.005)\tLoss 0.0205 (0.0176)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][380/390]\tTime 0.048 (0.043)\tData 0.002 (0.005)\tLoss 0.0083 (0.0175)\tPrec@1 100.000 (99.532)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [282][389/390]\tTime 0.017 (0.043)\tData 0.000 (0.004)\tLoss 0.0101 (0.0174)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [282][0/79]\tTime 0.237 (0.237)\tData 0.217 (0.217)\tLoss 0.2793 (0.2793)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [282][10/79]\tTime 0.059 (0.043)\tData 0.052 (0.030)\tLoss 0.2709 (0.3697)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [282][20/79]\tTime 0.020 (0.035)\tData 0.000 (0.024)\tLoss 0.5408 (0.4095)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [282][30/79]\tTime 0.033 (0.033)\tData 0.027 (0.022)\tLoss 0.0906 (0.3941)\tPrec@1 97.656 (92.036)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [282][40/79]\tTime 0.016 (0.031)\tData 0.000 (0.020)\tLoss 0.2451 (0.3971)\tPrec@1 91.406 (91.940)\tPrec@5 99.219 (99.486)\t\n",
            "EVALUATING - Epoch: [282][50/79]\tTime 0.005 (0.031)\tData 0.000 (0.020)\tLoss 0.4418 (0.3904)\tPrec@1 89.844 (91.866)\tPrec@5 100.000 (99.586)\t\n",
            "EVALUATING - Epoch: [282][60/79]\tTime 0.018 (0.030)\tData 0.002 (0.019)\tLoss 0.6297 (0.3957)\tPrec@1 92.188 (91.803)\tPrec@5 100.000 (99.616)\t\n",
            "EVALUATING - Epoch: [282][70/79]\tTime 0.015 (0.029)\tData 0.000 (0.018)\tLoss 0.4064 (0.3883)\tPrec@1 89.062 (91.747)\tPrec@5 100.000 (99.659)\t\n",
            "EVALUATING - Epoch: [282][78/79]\tTime 0.002 (0.028)\tData 0.000 (0.017)\tLoss 0.2720 (0.3854)\tPrec@1 93.750 (91.760)\tPrec@5 100.000 (99.660)\t\n",
            "\n",
            "Results - Epoch: 283\n",
            "Training Loss 0.0174 \tTraining Prec@1 99.535 \tTraining Prec@5 100.000 \tValidation Loss 0.3854 \tValidation Prec@1 91.760 \tValidation Prec@5 99.660 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 284\n",
            "\n",
            "TRAINING - Epoch: [283][0/390]\tTime 0.323 (0.323)\tData 0.275 (0.275)\tLoss 0.0191 (0.0191)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][10/390]\tTime 0.045 (0.067)\tData 0.001 (0.027)\tLoss 0.0053 (0.0135)\tPrec@1 100.000 (99.716)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][20/390]\tTime 0.052 (0.056)\tData 0.022 (0.016)\tLoss 0.0440 (0.0169)\tPrec@1 98.438 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][30/390]\tTime 0.049 (0.052)\tData 0.010 (0.013)\tLoss 0.0030 (0.0170)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][40/390]\tTime 0.045 (0.049)\tData 0.000 (0.010)\tLoss 0.0134 (0.0166)\tPrec@1 100.000 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][50/390]\tTime 0.035 (0.048)\tData 0.002 (0.009)\tLoss 0.0100 (0.0161)\tPrec@1 100.000 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][60/390]\tTime 0.033 (0.047)\tData 0.000 (0.008)\tLoss 0.0101 (0.0170)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][70/390]\tTime 0.045 (0.046)\tData 0.010 (0.007)\tLoss 0.0285 (0.0181)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][80/390]\tTime 0.049 (0.046)\tData 0.013 (0.007)\tLoss 0.0062 (0.0175)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][90/390]\tTime 0.029 (0.046)\tData 0.001 (0.007)\tLoss 0.0044 (0.0174)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][100/390]\tTime 0.041 (0.046)\tData 0.004 (0.007)\tLoss 0.0096 (0.0168)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][110/390]\tTime 0.054 (0.046)\tData 0.002 (0.006)\tLoss 0.0114 (0.0172)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][120/390]\tTime 0.047 (0.046)\tData 0.000 (0.006)\tLoss 0.0160 (0.0175)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][130/390]\tTime 0.050 (0.046)\tData 0.004 (0.006)\tLoss 0.0132 (0.0171)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][140/390]\tTime 0.044 (0.046)\tData 0.003 (0.005)\tLoss 0.0432 (0.0176)\tPrec@1 99.219 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][150/390]\tTime 0.072 (0.046)\tData 0.011 (0.006)\tLoss 0.0165 (0.0173)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][160/390]\tTime 0.038 (0.046)\tData 0.012 (0.005)\tLoss 0.0145 (0.0173)\tPrec@1 99.219 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][170/390]\tTime 0.036 (0.046)\tData 0.000 (0.005)\tLoss 0.0268 (0.0173)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][180/390]\tTime 0.039 (0.046)\tData 0.000 (0.005)\tLoss 0.0095 (0.0177)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][190/390]\tTime 0.046 (0.045)\tData 0.004 (0.005)\tLoss 0.0101 (0.0177)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][200/390]\tTime 0.032 (0.045)\tData 0.000 (0.005)\tLoss 0.0208 (0.0179)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][210/390]\tTime 0.060 (0.045)\tData 0.010 (0.005)\tLoss 0.0200 (0.0179)\tPrec@1 99.219 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][220/390]\tTime 0.035 (0.045)\tData 0.001 (0.006)\tLoss 0.0058 (0.0180)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][230/390]\tTime 0.032 (0.045)\tData 0.000 (0.005)\tLoss 0.0186 (0.0179)\tPrec@1 99.219 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][240/390]\tTime 0.048 (0.045)\tData 0.018 (0.005)\tLoss 0.0161 (0.0178)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][250/390]\tTime 0.059 (0.045)\tData 0.007 (0.006)\tLoss 0.0131 (0.0178)\tPrec@1 99.219 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][260/390]\tTime 0.037 (0.044)\tData 0.009 (0.006)\tLoss 0.0337 (0.0180)\tPrec@1 99.219 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][270/390]\tTime 0.041 (0.044)\tData 0.000 (0.006)\tLoss 0.0340 (0.0179)\tPrec@1 99.219 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][280/390]\tTime 0.055 (0.044)\tData 0.033 (0.006)\tLoss 0.0223 (0.0179)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][290/390]\tTime 0.045 (0.044)\tData 0.015 (0.006)\tLoss 0.0260 (0.0177)\tPrec@1 99.219 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][300/390]\tTime 0.041 (0.044)\tData 0.005 (0.006)\tLoss 0.0223 (0.0175)\tPrec@1 99.219 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][310/390]\tTime 0.044 (0.044)\tData 0.001 (0.006)\tLoss 0.0124 (0.0177)\tPrec@1 99.219 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][320/390]\tTime 0.047 (0.044)\tData 0.010 (0.006)\tLoss 0.0293 (0.0176)\tPrec@1 99.219 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][330/390]\tTime 0.038 (0.044)\tData 0.006 (0.006)\tLoss 0.0066 (0.0176)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][340/390]\tTime 0.034 (0.044)\tData 0.000 (0.006)\tLoss 0.0135 (0.0177)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][350/390]\tTime 0.045 (0.044)\tData 0.003 (0.006)\tLoss 0.0257 (0.0176)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][360/390]\tTime 0.060 (0.044)\tData 0.002 (0.005)\tLoss 0.0148 (0.0175)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][370/390]\tTime 0.037 (0.044)\tData 0.005 (0.005)\tLoss 0.0250 (0.0175)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][380/390]\tTime 0.039 (0.044)\tData 0.003 (0.005)\tLoss 0.0203 (0.0177)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [283][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0299 (0.0176)\tPrec@1 99.219 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [283][0/79]\tTime 0.173 (0.173)\tData 0.159 (0.159)\tLoss 0.2870 (0.2870)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [283][10/79]\tTime 0.021 (0.044)\tData 0.006 (0.033)\tLoss 0.2605 (0.3703)\tPrec@1 91.406 (92.116)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [283][20/79]\tTime 0.015 (0.034)\tData 0.005 (0.023)\tLoss 0.5159 (0.4095)\tPrec@1 89.844 (91.518)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [283][30/79]\tTime 0.085 (0.035)\tData 0.078 (0.023)\tLoss 0.0944 (0.3968)\tPrec@1 97.656 (91.885)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [283][40/79]\tTime 0.014 (0.032)\tData 0.000 (0.020)\tLoss 0.2568 (0.3979)\tPrec@1 90.625 (91.864)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [283][50/79]\tTime 0.057 (0.031)\tData 0.051 (0.020)\tLoss 0.4621 (0.3917)\tPrec@1 90.625 (91.881)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [283][60/79]\tTime 0.024 (0.031)\tData 0.005 (0.018)\tLoss 0.6393 (0.3960)\tPrec@1 92.969 (91.778)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [283][70/79]\tTime 0.051 (0.031)\tData 0.045 (0.018)\tLoss 0.3897 (0.3879)\tPrec@1 89.844 (91.714)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [283][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2526 (0.3846)\tPrec@1 93.750 (91.740)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 284\n",
            "Training Loss 0.0176 \tTraining Prec@1 99.523 \tTraining Prec@5 100.000 \tValidation Loss 0.3846 \tValidation Prec@1 91.740 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 285\n",
            "\n",
            "TRAINING - Epoch: [284][0/390]\tTime 0.318 (0.318)\tData 0.279 (0.279)\tLoss 0.0168 (0.0168)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][10/390]\tTime 0.047 (0.069)\tData 0.002 (0.028)\tLoss 0.0037 (0.0105)\tPrec@1 100.000 (99.929)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][20/390]\tTime 0.035 (0.057)\tData 0.004 (0.015)\tLoss 0.0358 (0.0146)\tPrec@1 99.219 (99.777)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][30/390]\tTime 0.032 (0.051)\tData 0.000 (0.012)\tLoss 0.0117 (0.0173)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][40/390]\tTime 0.046 (0.049)\tData 0.003 (0.010)\tLoss 0.0083 (0.0172)\tPrec@1 100.000 (99.638)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][50/390]\tTime 0.050 (0.048)\tData 0.004 (0.008)\tLoss 0.0190 (0.0165)\tPrec@1 100.000 (99.663)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][60/390]\tTime 0.032 (0.047)\tData 0.000 (0.007)\tLoss 0.0110 (0.0159)\tPrec@1 100.000 (99.705)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][70/390]\tTime 0.036 (0.047)\tData 0.000 (0.007)\tLoss 0.0245 (0.0166)\tPrec@1 98.438 (99.659)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][80/390]\tTime 0.032 (0.046)\tData 0.000 (0.006)\tLoss 0.0167 (0.0166)\tPrec@1 99.219 (99.633)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][90/390]\tTime 0.043 (0.046)\tData 0.006 (0.006)\tLoss 0.0167 (0.0163)\tPrec@1 99.219 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][100/390]\tTime 0.045 (0.046)\tData 0.002 (0.006)\tLoss 0.0210 (0.0170)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][110/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0119 (0.0169)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][120/390]\tTime 0.039 (0.045)\tData 0.000 (0.005)\tLoss 0.0060 (0.0167)\tPrec@1 100.000 (99.593)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][130/390]\tTime 0.043 (0.045)\tData 0.002 (0.005)\tLoss 0.0145 (0.0166)\tPrec@1 99.219 (99.612)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][140/390]\tTime 0.045 (0.045)\tData 0.003 (0.005)\tLoss 0.0217 (0.0171)\tPrec@1 99.219 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][150/390]\tTime 0.044 (0.044)\tData 0.000 (0.005)\tLoss 0.0092 (0.0168)\tPrec@1 100.000 (99.607)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][160/390]\tTime 0.060 (0.045)\tData 0.015 (0.005)\tLoss 0.0111 (0.0169)\tPrec@1 100.000 (99.602)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][170/390]\tTime 0.033 (0.045)\tData 0.005 (0.005)\tLoss 0.0133 (0.0168)\tPrec@1 100.000 (99.603)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][180/390]\tTime 0.046 (0.045)\tData 0.005 (0.005)\tLoss 0.0179 (0.0168)\tPrec@1 99.219 (99.599)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][190/390]\tTime 0.038 (0.045)\tData 0.000 (0.005)\tLoss 0.0250 (0.0167)\tPrec@1 99.219 (99.595)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][200/390]\tTime 0.034 (0.044)\tData 0.004 (0.005)\tLoss 0.0085 (0.0165)\tPrec@1 100.000 (99.607)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][210/390]\tTime 0.044 (0.044)\tData 0.005 (0.005)\tLoss 0.0077 (0.0165)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][220/390]\tTime 0.052 (0.044)\tData 0.007 (0.004)\tLoss 0.0387 (0.0165)\tPrec@1 99.219 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][230/390]\tTime 0.046 (0.044)\tData 0.013 (0.004)\tLoss 0.0068 (0.0163)\tPrec@1 100.000 (99.604)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [284][240/390]\tTime 0.045 (0.044)\tData 0.005 (0.004)\tLoss 0.0126 (0.0164)\tPrec@1 100.000 (99.614)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [284][250/390]\tTime 0.031 (0.044)\tData 0.000 (0.004)\tLoss 0.0311 (0.0165)\tPrec@1 99.219 (99.605)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [284][260/390]\tTime 0.059 (0.044)\tData 0.002 (0.004)\tLoss 0.0260 (0.0165)\tPrec@1 99.219 (99.602)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [284][270/390]\tTime 0.047 (0.044)\tData 0.019 (0.004)\tLoss 0.0176 (0.0165)\tPrec@1 99.219 (99.591)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [284][280/390]\tTime 0.021 (0.044)\tData 0.000 (0.005)\tLoss 0.0110 (0.0166)\tPrec@1 100.000 (99.580)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [284][290/390]\tTime 0.038 (0.044)\tData 0.009 (0.005)\tLoss 0.0068 (0.0168)\tPrec@1 100.000 (99.573)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [284][300/390]\tTime 0.040 (0.044)\tData 0.005 (0.005)\tLoss 0.0044 (0.0170)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [284][310/390]\tTime 0.035 (0.044)\tData 0.005 (0.005)\tLoss 0.0538 (0.0171)\tPrec@1 97.656 (99.548)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [284][320/390]\tTime 0.042 (0.044)\tData 0.000 (0.005)\tLoss 0.0158 (0.0171)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [284][330/390]\tTime 0.032 (0.044)\tData 0.005 (0.005)\tLoss 0.0104 (0.0171)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [284][340/390]\tTime 0.051 (0.044)\tData 0.011 (0.005)\tLoss 0.0314 (0.0171)\tPrec@1 98.438 (99.551)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [284][350/390]\tTime 0.040 (0.044)\tData 0.000 (0.005)\tLoss 0.0096 (0.0171)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [284][360/390]\tTime 0.029 (0.044)\tData 0.002 (0.005)\tLoss 0.0139 (0.0170)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [284][370/390]\tTime 0.029 (0.044)\tData 0.000 (0.005)\tLoss 0.0284 (0.0170)\tPrec@1 99.219 (99.551)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [284][380/390]\tTime 0.036 (0.044)\tData 0.012 (0.005)\tLoss 0.0222 (0.0171)\tPrec@1 99.219 (99.547)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [284][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.005)\tLoss 0.0072 (0.0173)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [284][0/79]\tTime 0.188 (0.188)\tData 0.175 (0.175)\tLoss 0.2860 (0.2860)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [284][10/79]\tTime 0.018 (0.042)\tData 0.005 (0.033)\tLoss 0.2419 (0.3673)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [284][20/79]\tTime 0.024 (0.036)\tData 0.017 (0.024)\tLoss 0.5339 (0.4098)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [284][30/79]\tTime 0.018 (0.034)\tData 0.012 (0.023)\tLoss 0.0971 (0.3976)\tPrec@1 97.656 (91.986)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [284][40/79]\tTime 0.023 (0.032)\tData 0.013 (0.020)\tLoss 0.2441 (0.3987)\tPrec@1 89.844 (91.921)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [284][50/79]\tTime 0.016 (0.031)\tData 0.011 (0.020)\tLoss 0.4450 (0.3920)\tPrec@1 90.625 (91.881)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [284][60/79]\tTime 0.046 (0.031)\tData 0.040 (0.020)\tLoss 0.6461 (0.3970)\tPrec@1 93.750 (91.765)\tPrec@5 100.000 (99.705)\t\n",
            "EVALUATING - Epoch: [284][70/79]\tTime 0.021 (0.030)\tData 0.000 (0.019)\tLoss 0.3993 (0.3897)\tPrec@1 89.062 (91.703)\tPrec@5 100.000 (99.725)\t\n",
            "EVALUATING - Epoch: [284][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.019)\tLoss 0.2775 (0.3869)\tPrec@1 93.750 (91.710)\tPrec@5 100.000 (99.730)\t\n",
            "\n",
            "Results - Epoch: 285\n",
            "Training Loss 0.0173 \tTraining Prec@1 99.539 \tTraining Prec@5 99.998 \tValidation Loss 0.3869 \tValidation Prec@1 91.710 \tValidation Prec@5 99.730 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 286\n",
            "\n",
            "TRAINING - Epoch: [285][0/390]\tTime 0.334 (0.334)\tData 0.281 (0.281)\tLoss 0.0403 (0.0403)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][10/390]\tTime 0.045 (0.071)\tData 0.004 (0.028)\tLoss 0.0162 (0.0183)\tPrec@1 99.219 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][20/390]\tTime 0.037 (0.056)\tData 0.000 (0.016)\tLoss 0.0042 (0.0163)\tPrec@1 100.000 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][30/390]\tTime 0.032 (0.052)\tData 0.000 (0.012)\tLoss 0.0089 (0.0165)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][40/390]\tTime 0.040 (0.050)\tData 0.000 (0.009)\tLoss 0.0177 (0.0175)\tPrec@1 100.000 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][50/390]\tTime 0.053 (0.048)\tData 0.005 (0.008)\tLoss 0.0229 (0.0177)\tPrec@1 99.219 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][60/390]\tTime 0.050 (0.048)\tData 0.004 (0.007)\tLoss 0.0122 (0.0172)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][70/390]\tTime 0.038 (0.048)\tData 0.004 (0.007)\tLoss 0.0162 (0.0167)\tPrec@1 100.000 (99.604)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][80/390]\tTime 0.041 (0.046)\tData 0.006 (0.007)\tLoss 0.0208 (0.0172)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][90/390]\tTime 0.031 (0.046)\tData 0.000 (0.006)\tLoss 0.0106 (0.0170)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][100/390]\tTime 0.034 (0.046)\tData 0.000 (0.006)\tLoss 0.0091 (0.0170)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][110/390]\tTime 0.050 (0.046)\tData 0.002 (0.005)\tLoss 0.0394 (0.0172)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [285][120/390]\tTime 0.035 (0.045)\tData 0.002 (0.005)\tLoss 0.0115 (0.0180)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [285][130/390]\tTime 0.036 (0.045)\tData 0.000 (0.005)\tLoss 0.0106 (0.0182)\tPrec@1 100.000 (99.487)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [285][140/390]\tTime 0.051 (0.045)\tData 0.000 (0.005)\tLoss 0.0174 (0.0181)\tPrec@1 99.219 (99.490)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [285][150/390]\tTime 0.041 (0.044)\tData 0.005 (0.005)\tLoss 0.0086 (0.0178)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [285][160/390]\tTime 0.046 (0.045)\tData 0.000 (0.005)\tLoss 0.0168 (0.0174)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [285][170/390]\tTime 0.052 (0.045)\tData 0.000 (0.005)\tLoss 0.0095 (0.0178)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [285][180/390]\tTime 0.032 (0.044)\tData 0.000 (0.005)\tLoss 0.0104 (0.0180)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [285][190/390]\tTime 0.035 (0.044)\tData 0.000 (0.005)\tLoss 0.0190 (0.0180)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [285][200/390]\tTime 0.030 (0.044)\tData 0.001 (0.005)\tLoss 0.0103 (0.0179)\tPrec@1 100.000 (99.506)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [285][210/390]\tTime 0.043 (0.044)\tData 0.002 (0.005)\tLoss 0.0086 (0.0178)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [285][220/390]\tTime 0.038 (0.044)\tData 0.000 (0.004)\tLoss 0.0148 (0.0175)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [285][230/390]\tTime 0.044 (0.044)\tData 0.000 (0.004)\tLoss 0.0616 (0.0175)\tPrec@1 97.656 (99.516)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [285][240/390]\tTime 0.031 (0.044)\tData 0.000 (0.004)\tLoss 0.0371 (0.0174)\tPrec@1 97.656 (99.514)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [285][250/390]\tTime 0.037 (0.044)\tData 0.000 (0.004)\tLoss 0.0135 (0.0171)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [285][260/390]\tTime 0.054 (0.044)\tData 0.002 (0.005)\tLoss 0.0079 (0.0171)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [285][270/390]\tTime 0.045 (0.044)\tData 0.000 (0.005)\tLoss 0.0217 (0.0172)\tPrec@1 99.219 (99.527)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [285][280/390]\tTime 0.032 (0.044)\tData 0.000 (0.005)\tLoss 0.0263 (0.0173)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [285][290/390]\tTime 0.041 (0.043)\tData 0.005 (0.004)\tLoss 0.0123 (0.0173)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [285][300/390]\tTime 0.039 (0.043)\tData 0.005 (0.004)\tLoss 0.0201 (0.0172)\tPrec@1 100.000 (99.515)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [285][310/390]\tTime 0.043 (0.043)\tData 0.007 (0.004)\tLoss 0.0096 (0.0173)\tPrec@1 100.000 (99.515)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [285][320/390]\tTime 0.041 (0.043)\tData 0.000 (0.004)\tLoss 0.0176 (0.0174)\tPrec@1 99.219 (99.513)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [285][330/390]\tTime 0.047 (0.043)\tData 0.007 (0.004)\tLoss 0.0231 (0.0176)\tPrec@1 99.219 (99.507)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [285][340/390]\tTime 0.041 (0.043)\tData 0.005 (0.004)\tLoss 0.0123 (0.0175)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [285][350/390]\tTime 0.039 (0.043)\tData 0.000 (0.004)\tLoss 0.0095 (0.0174)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [285][360/390]\tTime 0.034 (0.043)\tData 0.001 (0.004)\tLoss 0.0262 (0.0173)\tPrec@1 99.219 (99.515)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [285][370/390]\tTime 0.046 (0.043)\tData 0.000 (0.004)\tLoss 0.0040 (0.0173)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [285][380/390]\tTime 0.056 (0.043)\tData 0.014 (0.004)\tLoss 0.0078 (0.0172)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [285][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.004)\tLoss 0.0040 (0.0172)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [285][0/79]\tTime 0.171 (0.171)\tData 0.163 (0.163)\tLoss 0.2863 (0.2863)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [285][10/79]\tTime 0.022 (0.041)\tData 0.012 (0.029)\tLoss 0.2568 (0.3679)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [285][20/79]\tTime 0.032 (0.034)\tData 0.027 (0.024)\tLoss 0.5193 (0.4067)\tPrec@1 89.844 (91.443)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [285][30/79]\tTime 0.021 (0.032)\tData 0.003 (0.021)\tLoss 0.1038 (0.3951)\tPrec@1 97.656 (91.860)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [285][40/79]\tTime 0.026 (0.032)\tData 0.008 (0.020)\tLoss 0.2482 (0.3969)\tPrec@1 89.844 (91.825)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [285][50/79]\tTime 0.025 (0.030)\tData 0.015 (0.018)\tLoss 0.4320 (0.3898)\tPrec@1 91.406 (91.835)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [285][60/79]\tTime 0.015 (0.030)\tData 0.000 (0.018)\tLoss 0.6352 (0.3948)\tPrec@1 92.969 (91.714)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [285][70/79]\tTime 0.011 (0.029)\tData 0.000 (0.018)\tLoss 0.3881 (0.3870)\tPrec@1 89.844 (91.681)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [285][78/79]\tTime 0.003 (0.027)\tData 0.000 (0.017)\tLoss 0.2353 (0.3838)\tPrec@1 93.750 (91.670)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 286\n",
            "Training Loss 0.0172 \tTraining Prec@1 99.513 \tTraining Prec@5 99.998 \tValidation Loss 0.3838 \tValidation Prec@1 91.670 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 287\n",
            "\n",
            "TRAINING - Epoch: [286][0/390]\tTime 0.212 (0.212)\tData 0.178 (0.178)\tLoss 0.0061 (0.0061)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][10/390]\tTime 0.055 (0.069)\tData 0.008 (0.032)\tLoss 0.0087 (0.0152)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][20/390]\tTime 0.045 (0.056)\tData 0.000 (0.017)\tLoss 0.0105 (0.0151)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][30/390]\tTime 0.042 (0.051)\tData 0.005 (0.013)\tLoss 0.0018 (0.0155)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][40/390]\tTime 0.038 (0.050)\tData 0.003 (0.011)\tLoss 0.0070 (0.0148)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][50/390]\tTime 0.043 (0.048)\tData 0.005 (0.010)\tLoss 0.0177 (0.0144)\tPrec@1 99.219 (99.632)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][60/390]\tTime 0.030 (0.047)\tData 0.000 (0.008)\tLoss 0.0242 (0.0155)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][70/390]\tTime 0.051 (0.046)\tData 0.000 (0.008)\tLoss 0.0347 (0.0166)\tPrec@1 99.219 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][80/390]\tTime 0.027 (0.045)\tData 0.000 (0.007)\tLoss 0.0098 (0.0160)\tPrec@1 100.000 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][90/390]\tTime 0.028 (0.045)\tData 0.000 (0.007)\tLoss 0.0086 (0.0161)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][100/390]\tTime 0.061 (0.045)\tData 0.000 (0.006)\tLoss 0.0086 (0.0164)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][110/390]\tTime 0.041 (0.045)\tData 0.000 (0.006)\tLoss 0.0135 (0.0164)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][120/390]\tTime 0.036 (0.044)\tData 0.000 (0.006)\tLoss 0.0227 (0.0165)\tPrec@1 99.219 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][130/390]\tTime 0.050 (0.044)\tData 0.000 (0.005)\tLoss 0.0242 (0.0164)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][140/390]\tTime 0.070 (0.044)\tData 0.032 (0.005)\tLoss 0.0132 (0.0165)\tPrec@1 100.000 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][150/390]\tTime 0.043 (0.044)\tData 0.001 (0.006)\tLoss 0.0192 (0.0162)\tPrec@1 99.219 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][160/390]\tTime 0.036 (0.044)\tData 0.001 (0.005)\tLoss 0.0092 (0.0162)\tPrec@1 100.000 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][170/390]\tTime 0.055 (0.044)\tData 0.000 (0.005)\tLoss 0.0062 (0.0161)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][180/390]\tTime 0.051 (0.044)\tData 0.002 (0.005)\tLoss 0.0301 (0.0163)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][190/390]\tTime 0.046 (0.044)\tData 0.001 (0.005)\tLoss 0.0198 (0.0162)\tPrec@1 99.219 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][200/390]\tTime 0.039 (0.044)\tData 0.005 (0.005)\tLoss 0.0145 (0.0160)\tPrec@1 99.219 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][210/390]\tTime 0.042 (0.044)\tData 0.006 (0.005)\tLoss 0.0108 (0.0163)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][220/390]\tTime 0.038 (0.044)\tData 0.001 (0.005)\tLoss 0.0141 (0.0164)\tPrec@1 99.219 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][230/390]\tTime 0.032 (0.044)\tData 0.000 (0.005)\tLoss 0.0168 (0.0164)\tPrec@1 99.219 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][240/390]\tTime 0.026 (0.044)\tData 0.000 (0.005)\tLoss 0.0332 (0.0164)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][250/390]\tTime 0.034 (0.044)\tData 0.005 (0.005)\tLoss 0.0081 (0.0165)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][260/390]\tTime 0.039 (0.044)\tData 0.001 (0.005)\tLoss 0.0110 (0.0164)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][270/390]\tTime 0.058 (0.044)\tData 0.002 (0.004)\tLoss 0.0099 (0.0163)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][280/390]\tTime 0.043 (0.044)\tData 0.000 (0.004)\tLoss 0.0084 (0.0164)\tPrec@1 99.219 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][290/390]\tTime 0.057 (0.044)\tData 0.011 (0.004)\tLoss 0.0156 (0.0165)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][300/390]\tTime 0.045 (0.044)\tData 0.000 (0.004)\tLoss 0.0136 (0.0168)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][310/390]\tTime 0.041 (0.044)\tData 0.002 (0.004)\tLoss 0.0606 (0.0170)\tPrec@1 99.219 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][320/390]\tTime 0.046 (0.044)\tData 0.000 (0.004)\tLoss 0.0120 (0.0170)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][330/390]\tTime 0.050 (0.044)\tData 0.008 (0.004)\tLoss 0.0275 (0.0170)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][340/390]\tTime 0.052 (0.044)\tData 0.007 (0.004)\tLoss 0.0062 (0.0169)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][350/390]\tTime 0.041 (0.044)\tData 0.001 (0.004)\tLoss 0.0229 (0.0169)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][360/390]\tTime 0.035 (0.044)\tData 0.007 (0.004)\tLoss 0.0165 (0.0170)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [286][370/390]\tTime 0.035 (0.044)\tData 0.003 (0.004)\tLoss 0.0330 (0.0172)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [286][380/390]\tTime 0.035 (0.044)\tData 0.007 (0.004)\tLoss 0.0207 (0.0172)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [286][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.004)\tLoss 0.0289 (0.0173)\tPrec@1 98.438 (99.513)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [286][0/79]\tTime 0.246 (0.246)\tData 0.229 (0.229)\tLoss 0.2923 (0.2923)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [286][10/79]\tTime 0.079 (0.048)\tData 0.071 (0.031)\tLoss 0.2485 (0.3685)\tPrec@1 91.406 (92.401)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [286][20/79]\tTime 0.009 (0.038)\tData 0.000 (0.023)\tLoss 0.5392 (0.4094)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [286][30/79]\tTime 0.030 (0.034)\tData 0.024 (0.020)\tLoss 0.1073 (0.3972)\tPrec@1 97.656 (92.087)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [286][40/79]\tTime 0.018 (0.032)\tData 0.005 (0.019)\tLoss 0.2417 (0.3987)\tPrec@1 90.625 (91.921)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [286][50/79]\tTime 0.032 (0.031)\tData 0.026 (0.018)\tLoss 0.4287 (0.3912)\tPrec@1 89.844 (91.850)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [286][60/79]\tTime 0.041 (0.031)\tData 0.001 (0.018)\tLoss 0.6329 (0.3961)\tPrec@1 92.188 (91.765)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [286][70/79]\tTime 0.044 (0.031)\tData 0.039 (0.018)\tLoss 0.4112 (0.3891)\tPrec@1 89.062 (91.736)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [286][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.016)\tLoss 0.2655 (0.3866)\tPrec@1 93.750 (91.800)\tPrec@5 100.000 (99.720)\t\n",
            "\n",
            "Results - Epoch: 287\n",
            "Training Loss 0.0173 \tTraining Prec@1 99.513 \tTraining Prec@5 99.998 \tValidation Loss 0.3866 \tValidation Prec@1 91.800 \tValidation Prec@5 99.720 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 288\n",
            "\n",
            "TRAINING - Epoch: [287][0/390]\tTime 0.284 (0.284)\tData 0.242 (0.242)\tLoss 0.0061 (0.0061)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [287][10/390]\tTime 0.033 (0.065)\tData 0.005 (0.028)\tLoss 0.0107 (0.0130)\tPrec@1 100.000 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [287][20/390]\tTime 0.049 (0.054)\tData 0.021 (0.016)\tLoss 0.0175 (0.0145)\tPrec@1 99.219 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [287][30/390]\tTime 0.042 (0.050)\tData 0.003 (0.013)\tLoss 0.0223 (0.0168)\tPrec@1 99.219 (99.521)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [287][40/390]\tTime 0.059 (0.050)\tData 0.028 (0.012)\tLoss 0.0072 (0.0167)\tPrec@1 100.000 (99.581)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [287][50/390]\tTime 0.041 (0.048)\tData 0.002 (0.010)\tLoss 0.0145 (0.0174)\tPrec@1 100.000 (99.479)\tPrec@5 100.000 (99.985)\t\n",
            "TRAINING - Epoch: [287][60/390]\tTime 0.051 (0.047)\tData 0.001 (0.009)\tLoss 0.0133 (0.0168)\tPrec@1 99.219 (99.501)\tPrec@5 100.000 (99.987)\t\n",
            "TRAINING - Epoch: [287][70/390]\tTime 0.042 (0.046)\tData 0.002 (0.008)\tLoss 0.0095 (0.0177)\tPrec@1 100.000 (99.450)\tPrec@5 100.000 (99.989)\t\n",
            "TRAINING - Epoch: [287][80/390]\tTime 0.055 (0.046)\tData 0.017 (0.008)\tLoss 0.0087 (0.0179)\tPrec@1 100.000 (99.431)\tPrec@5 100.000 (99.990)\t\n",
            "TRAINING - Epoch: [287][90/390]\tTime 0.033 (0.046)\tData 0.000 (0.008)\tLoss 0.0089 (0.0175)\tPrec@1 100.000 (99.442)\tPrec@5 100.000 (99.991)\t\n",
            "TRAINING - Epoch: [287][100/390]\tTime 0.056 (0.045)\tData 0.020 (0.008)\tLoss 0.0150 (0.0169)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (99.992)\t\n",
            "TRAINING - Epoch: [287][110/390]\tTime 0.050 (0.045)\tData 0.005 (0.008)\tLoss 0.0089 (0.0170)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (99.993)\t\n",
            "TRAINING - Epoch: [287][120/390]\tTime 0.032 (0.045)\tData 0.001 (0.008)\tLoss 0.0165 (0.0172)\tPrec@1 99.219 (99.471)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [287][130/390]\tTime 0.043 (0.045)\tData 0.005 (0.007)\tLoss 0.0151 (0.0173)\tPrec@1 100.000 (99.475)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [287][140/390]\tTime 0.039 (0.045)\tData 0.003 (0.007)\tLoss 0.0069 (0.0173)\tPrec@1 100.000 (99.474)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [287][150/390]\tTime 0.043 (0.044)\tData 0.004 (0.007)\tLoss 0.0262 (0.0171)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [287][160/390]\tTime 0.044 (0.044)\tData 0.008 (0.007)\tLoss 0.0105 (0.0171)\tPrec@1 100.000 (99.500)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [287][170/390]\tTime 0.027 (0.044)\tData 0.000 (0.007)\tLoss 0.0167 (0.0168)\tPrec@1 99.219 (99.511)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [287][180/390]\tTime 0.052 (0.044)\tData 0.000 (0.006)\tLoss 0.0274 (0.0172)\tPrec@1 99.219 (99.495)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [287][190/390]\tTime 0.052 (0.044)\tData 0.000 (0.006)\tLoss 0.0124 (0.0172)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [287][200/390]\tTime 0.051 (0.044)\tData 0.001 (0.006)\tLoss 0.0065 (0.0172)\tPrec@1 100.000 (99.491)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [287][210/390]\tTime 0.040 (0.044)\tData 0.004 (0.006)\tLoss 0.0267 (0.0172)\tPrec@1 99.219 (99.493)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [287][220/390]\tTime 0.040 (0.044)\tData 0.007 (0.006)\tLoss 0.0043 (0.0171)\tPrec@1 100.000 (99.498)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [287][230/390]\tTime 0.036 (0.044)\tData 0.001 (0.006)\tLoss 0.0254 (0.0169)\tPrec@1 99.219 (99.499)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [287][240/390]\tTime 0.038 (0.044)\tData 0.012 (0.006)\tLoss 0.0212 (0.0171)\tPrec@1 100.000 (99.498)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [287][250/390]\tTime 0.025 (0.043)\tData 0.000 (0.006)\tLoss 0.0123 (0.0172)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [287][260/390]\tTime 0.043 (0.043)\tData 0.006 (0.006)\tLoss 0.0175 (0.0170)\tPrec@1 100.000 (99.500)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [287][270/390]\tTime 0.041 (0.043)\tData 0.005 (0.006)\tLoss 0.0139 (0.0173)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [287][280/390]\tTime 0.041 (0.043)\tData 0.007 (0.006)\tLoss 0.0088 (0.0172)\tPrec@1 100.000 (99.488)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [287][290/390]\tTime 0.044 (0.043)\tData 0.000 (0.006)\tLoss 0.0166 (0.0171)\tPrec@1 99.219 (99.495)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [287][300/390]\tTime 0.046 (0.043)\tData 0.001 (0.006)\tLoss 0.0109 (0.0171)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [287][310/390]\tTime 0.030 (0.043)\tData 0.003 (0.006)\tLoss 0.0240 (0.0172)\tPrec@1 99.219 (99.490)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [287][320/390]\tTime 0.043 (0.043)\tData 0.001 (0.006)\tLoss 0.0144 (0.0171)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [287][330/390]\tTime 0.042 (0.043)\tData 0.000 (0.006)\tLoss 0.0064 (0.0170)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [287][340/390]\tTime 0.046 (0.043)\tData 0.003 (0.006)\tLoss 0.0054 (0.0170)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [287][350/390]\tTime 0.040 (0.043)\tData 0.000 (0.006)\tLoss 0.0162 (0.0170)\tPrec@1 99.219 (99.501)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [287][360/390]\tTime 0.048 (0.043)\tData 0.000 (0.006)\tLoss 0.0054 (0.0170)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [287][370/390]\tTime 0.054 (0.043)\tData 0.005 (0.006)\tLoss 0.0126 (0.0170)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [287][380/390]\tTime 0.044 (0.043)\tData 0.004 (0.006)\tLoss 0.0175 (0.0170)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [287][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.006)\tLoss 0.0094 (0.0170)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [287][0/79]\tTime 0.182 (0.182)\tData 0.165 (0.165)\tLoss 0.2957 (0.2957)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [287][10/79]\tTime 0.019 (0.046)\tData 0.001 (0.031)\tLoss 0.2607 (0.3726)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.716)\t\n",
            "EVALUATING - Epoch: [287][20/79]\tTime 0.020 (0.039)\tData 0.001 (0.023)\tLoss 0.5361 (0.4120)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [287][30/79]\tTime 0.045 (0.037)\tData 0.039 (0.023)\tLoss 0.0971 (0.3982)\tPrec@1 97.656 (92.036)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [287][40/79]\tTime 0.019 (0.035)\tData 0.004 (0.022)\tLoss 0.2634 (0.3999)\tPrec@1 90.625 (91.902)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [287][50/79]\tTime 0.075 (0.033)\tData 0.070 (0.020)\tLoss 0.4404 (0.3929)\tPrec@1 89.844 (91.835)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [287][60/79]\tTime 0.016 (0.031)\tData 0.000 (0.018)\tLoss 0.6507 (0.3976)\tPrec@1 92.969 (91.752)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [287][70/79]\tTime 0.062 (0.031)\tData 0.056 (0.018)\tLoss 0.4011 (0.3897)\tPrec@1 89.844 (91.692)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [287][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2527 (0.3867)\tPrec@1 93.750 (91.670)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 288\n",
            "Training Loss 0.0170 \tTraining Prec@1 99.511 \tTraining Prec@5 99.998 \tValidation Loss 0.3867 \tValidation Prec@1 91.670 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 289\n",
            "\n",
            "TRAINING - Epoch: [288][0/390]\tTime 0.331 (0.331)\tData 0.277 (0.277)\tLoss 0.0147 (0.0147)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][10/390]\tTime 0.042 (0.070)\tData 0.005 (0.029)\tLoss 0.0231 (0.0185)\tPrec@1 99.219 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][20/390]\tTime 0.045 (0.058)\tData 0.009 (0.017)\tLoss 0.0149 (0.0197)\tPrec@1 100.000 (99.442)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][30/390]\tTime 0.034 (0.052)\tData 0.004 (0.013)\tLoss 0.0114 (0.0186)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][40/390]\tTime 0.036 (0.051)\tData 0.000 (0.010)\tLoss 0.0191 (0.0179)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][50/390]\tTime 0.046 (0.049)\tData 0.005 (0.009)\tLoss 0.0338 (0.0178)\tPrec@1 97.656 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][60/390]\tTime 0.040 (0.048)\tData 0.000 (0.008)\tLoss 0.0146 (0.0176)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][70/390]\tTime 0.038 (0.047)\tData 0.005 (0.007)\tLoss 0.0486 (0.0181)\tPrec@1 98.438 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][80/390]\tTime 0.045 (0.046)\tData 0.001 (0.007)\tLoss 0.0127 (0.0175)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][90/390]\tTime 0.034 (0.046)\tData 0.005 (0.006)\tLoss 0.0197 (0.0177)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][100/390]\tTime 0.038 (0.045)\tData 0.003 (0.006)\tLoss 0.0081 (0.0173)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][110/390]\tTime 0.034 (0.045)\tData 0.004 (0.006)\tLoss 0.0065 (0.0170)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][120/390]\tTime 0.064 (0.045)\tData 0.000 (0.006)\tLoss 0.0333 (0.0175)\tPrec@1 98.438 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][130/390]\tTime 0.042 (0.046)\tData 0.007 (0.006)\tLoss 0.0070 (0.0176)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][140/390]\tTime 0.044 (0.046)\tData 0.001 (0.006)\tLoss 0.0154 (0.0173)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][150/390]\tTime 0.036 (0.046)\tData 0.002 (0.006)\tLoss 0.0115 (0.0176)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][160/390]\tTime 0.048 (0.045)\tData 0.001 (0.006)\tLoss 0.0078 (0.0179)\tPrec@1 100.000 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][170/390]\tTime 0.054 (0.045)\tData 0.006 (0.005)\tLoss 0.0386 (0.0178)\tPrec@1 98.438 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][180/390]\tTime 0.043 (0.045)\tData 0.006 (0.005)\tLoss 0.0179 (0.0180)\tPrec@1 100.000 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][190/390]\tTime 0.030 (0.045)\tData 0.001 (0.005)\tLoss 0.0110 (0.0179)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][200/390]\tTime 0.030 (0.045)\tData 0.005 (0.005)\tLoss 0.0127 (0.0179)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][210/390]\tTime 0.045 (0.045)\tData 0.000 (0.005)\tLoss 0.0156 (0.0177)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][220/390]\tTime 0.041 (0.045)\tData 0.001 (0.005)\tLoss 0.0094 (0.0177)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][230/390]\tTime 0.032 (0.045)\tData 0.001 (0.005)\tLoss 0.0096 (0.0176)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][240/390]\tTime 0.033 (0.045)\tData 0.000 (0.005)\tLoss 0.0198 (0.0176)\tPrec@1 99.219 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][250/390]\tTime 0.037 (0.045)\tData 0.002 (0.005)\tLoss 0.0038 (0.0177)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][260/390]\tTime 0.052 (0.045)\tData 0.012 (0.005)\tLoss 0.0036 (0.0177)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][270/390]\tTime 0.040 (0.044)\tData 0.000 (0.005)\tLoss 0.0041 (0.0178)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][280/390]\tTime 0.051 (0.044)\tData 0.000 (0.005)\tLoss 0.0142 (0.0178)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][290/390]\tTime 0.033 (0.044)\tData 0.002 (0.005)\tLoss 0.0159 (0.0178)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][300/390]\tTime 0.045 (0.044)\tData 0.010 (0.005)\tLoss 0.0113 (0.0178)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][310/390]\tTime 0.056 (0.044)\tData 0.006 (0.005)\tLoss 0.0065 (0.0178)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][320/390]\tTime 0.037 (0.044)\tData 0.010 (0.005)\tLoss 0.0206 (0.0179)\tPrec@1 98.438 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][330/390]\tTime 0.043 (0.044)\tData 0.000 (0.005)\tLoss 0.0172 (0.0179)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][340/390]\tTime 0.041 (0.044)\tData 0.001 (0.005)\tLoss 0.0167 (0.0180)\tPrec@1 99.219 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][350/390]\tTime 0.043 (0.044)\tData 0.000 (0.005)\tLoss 0.0267 (0.0181)\tPrec@1 99.219 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][360/390]\tTime 0.043 (0.044)\tData 0.004 (0.004)\tLoss 0.0072 (0.0181)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][370/390]\tTime 0.045 (0.044)\tData 0.003 (0.004)\tLoss 0.0171 (0.0180)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][380/390]\tTime 0.030 (0.044)\tData 0.004 (0.004)\tLoss 0.0056 (0.0179)\tPrec@1 100.000 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [288][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.004)\tLoss 0.0335 (0.0179)\tPrec@1 98.438 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [288][0/79]\tTime 0.230 (0.230)\tData 0.217 (0.217)\tLoss 0.2882 (0.2882)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [288][10/79]\tTime 0.021 (0.042)\tData 0.008 (0.030)\tLoss 0.2682 (0.3736)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [288][20/79]\tTime 0.024 (0.034)\tData 0.018 (0.023)\tLoss 0.5120 (0.4099)\tPrec@1 89.844 (91.592)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [288][30/79]\tTime 0.019 (0.033)\tData 0.005 (0.022)\tLoss 0.1044 (0.3975)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [288][40/79]\tTime 0.009 (0.031)\tData 0.000 (0.019)\tLoss 0.2534 (0.3998)\tPrec@1 90.625 (91.921)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [288][50/79]\tTime 0.015 (0.030)\tData 0.000 (0.019)\tLoss 0.4379 (0.3926)\tPrec@1 90.625 (91.805)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [288][60/79]\tTime 0.014 (0.029)\tData 0.004 (0.018)\tLoss 0.6466 (0.3975)\tPrec@1 92.969 (91.701)\tPrec@5 99.219 (99.629)\t\n",
            "EVALUATING - Epoch: [288][70/79]\tTime 0.017 (0.030)\tData 0.000 (0.018)\tLoss 0.3939 (0.3893)\tPrec@1 89.062 (91.670)\tPrec@5 100.000 (99.670)\t\n",
            "EVALUATING - Epoch: [288][78/79]\tTime 0.003 (0.028)\tData 0.000 (0.017)\tLoss 0.2090 (0.3863)\tPrec@1 93.750 (91.680)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 289\n",
            "Training Loss 0.0179 \tTraining Prec@1 99.503 \tTraining Prec@5 100.000 \tValidation Loss 0.3863 \tValidation Prec@1 91.680 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 290\n",
            "\n",
            "TRAINING - Epoch: [289][0/390]\tTime 0.272 (0.272)\tData 0.208 (0.208)\tLoss 0.0090 (0.0090)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][10/390]\tTime 0.046 (0.067)\tData 0.002 (0.026)\tLoss 0.0158 (0.0137)\tPrec@1 99.219 (99.787)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][20/390]\tTime 0.044 (0.056)\tData 0.006 (0.017)\tLoss 0.0345 (0.0167)\tPrec@1 98.438 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][30/390]\tTime 0.033 (0.052)\tData 0.000 (0.012)\tLoss 0.0170 (0.0170)\tPrec@1 99.219 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][40/390]\tTime 0.045 (0.050)\tData 0.006 (0.010)\tLoss 0.0117 (0.0177)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][50/390]\tTime 0.051 (0.050)\tData 0.004 (0.010)\tLoss 0.0308 (0.0170)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][60/390]\tTime 0.045 (0.049)\tData 0.005 (0.009)\tLoss 0.0037 (0.0165)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][70/390]\tTime 0.048 (0.049)\tData 0.007 (0.008)\tLoss 0.0262 (0.0168)\tPrec@1 99.219 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][80/390]\tTime 0.047 (0.049)\tData 0.001 (0.007)\tLoss 0.0123 (0.0172)\tPrec@1 99.219 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][90/390]\tTime 0.039 (0.049)\tData 0.005 (0.007)\tLoss 0.0063 (0.0170)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][100/390]\tTime 0.036 (0.048)\tData 0.000 (0.007)\tLoss 0.0260 (0.0172)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][110/390]\tTime 0.040 (0.048)\tData 0.004 (0.006)\tLoss 0.0069 (0.0168)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][120/390]\tTime 0.047 (0.048)\tData 0.006 (0.006)\tLoss 0.0228 (0.0168)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][130/390]\tTime 0.039 (0.047)\tData 0.000 (0.006)\tLoss 0.0070 (0.0167)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][140/390]\tTime 0.046 (0.047)\tData 0.000 (0.006)\tLoss 0.0077 (0.0169)\tPrec@1 100.000 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][150/390]\tTime 0.045 (0.046)\tData 0.000 (0.005)\tLoss 0.0088 (0.0168)\tPrec@1 100.000 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][160/390]\tTime 0.041 (0.046)\tData 0.000 (0.005)\tLoss 0.0063 (0.0166)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][170/390]\tTime 0.049 (0.046)\tData 0.010 (0.005)\tLoss 0.0036 (0.0165)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][180/390]\tTime 0.043 (0.046)\tData 0.001 (0.005)\tLoss 0.0090 (0.0166)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][190/390]\tTime 0.040 (0.046)\tData 0.000 (0.005)\tLoss 0.0079 (0.0164)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][200/390]\tTime 0.038 (0.046)\tData 0.000 (0.005)\tLoss 0.0324 (0.0165)\tPrec@1 98.438 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][210/390]\tTime 0.041 (0.045)\tData 0.001 (0.005)\tLoss 0.0222 (0.0165)\tPrec@1 98.438 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][220/390]\tTime 0.041 (0.046)\tData 0.005 (0.005)\tLoss 0.0268 (0.0168)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][230/390]\tTime 0.055 (0.045)\tData 0.005 (0.005)\tLoss 0.0162 (0.0167)\tPrec@1 99.219 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][240/390]\tTime 0.033 (0.045)\tData 0.005 (0.005)\tLoss 0.0068 (0.0167)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][250/390]\tTime 0.047 (0.045)\tData 0.000 (0.005)\tLoss 0.0167 (0.0168)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][260/390]\tTime 0.054 (0.045)\tData 0.000 (0.005)\tLoss 0.0087 (0.0167)\tPrec@1 100.000 (99.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][270/390]\tTime 0.050 (0.045)\tData 0.001 (0.005)\tLoss 0.0104 (0.0170)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][280/390]\tTime 0.032 (0.045)\tData 0.000 (0.005)\tLoss 0.0509 (0.0171)\tPrec@1 99.219 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][290/390]\tTime 0.032 (0.045)\tData 0.002 (0.005)\tLoss 0.0064 (0.0172)\tPrec@1 100.000 (99.485)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][300/390]\tTime 0.040 (0.045)\tData 0.009 (0.005)\tLoss 0.0062 (0.0174)\tPrec@1 100.000 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][310/390]\tTime 0.055 (0.045)\tData 0.005 (0.005)\tLoss 0.0113 (0.0176)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][320/390]\tTime 0.052 (0.045)\tData 0.000 (0.005)\tLoss 0.0179 (0.0175)\tPrec@1 99.219 (99.474)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][330/390]\tTime 0.063 (0.045)\tData 0.028 (0.005)\tLoss 0.0233 (0.0175)\tPrec@1 99.219 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][340/390]\tTime 0.040 (0.045)\tData 0.004 (0.005)\tLoss 0.0190 (0.0176)\tPrec@1 100.000 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][350/390]\tTime 0.068 (0.045)\tData 0.039 (0.005)\tLoss 0.0245 (0.0179)\tPrec@1 100.000 (99.461)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][360/390]\tTime 0.036 (0.045)\tData 0.000 (0.005)\tLoss 0.0118 (0.0178)\tPrec@1 100.000 (99.461)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][370/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0061 (0.0178)\tPrec@1 100.000 (99.461)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][380/390]\tTime 0.039 (0.045)\tData 0.000 (0.005)\tLoss 0.0133 (0.0179)\tPrec@1 100.000 (99.459)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [289][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0107 (0.0178)\tPrec@1 100.000 (99.463)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [289][0/79]\tTime 0.210 (0.210)\tData 0.190 (0.190)\tLoss 0.2750 (0.2750)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [289][10/79]\tTime 0.025 (0.046)\tData 0.015 (0.032)\tLoss 0.2770 (0.3766)\tPrec@1 91.406 (92.045)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [289][20/79]\tTime 0.019 (0.037)\tData 0.000 (0.025)\tLoss 0.5170 (0.4129)\tPrec@1 90.625 (91.667)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [289][30/79]\tTime 0.060 (0.035)\tData 0.049 (0.024)\tLoss 0.0911 (0.3986)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [289][40/79]\tTime 0.024 (0.032)\tData 0.000 (0.021)\tLoss 0.2412 (0.4017)\tPrec@1 91.406 (91.921)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [289][50/79]\tTime 0.039 (0.031)\tData 0.033 (0.020)\tLoss 0.4591 (0.3951)\tPrec@1 91.406 (91.835)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [289][60/79]\tTime 0.021 (0.030)\tData 0.003 (0.019)\tLoss 0.6475 (0.4003)\tPrec@1 92.969 (91.726)\tPrec@5 100.000 (99.629)\t\n",
            "EVALUATING - Epoch: [289][70/79]\tTime 0.028 (0.030)\tData 0.001 (0.019)\tLoss 0.3961 (0.3919)\tPrec@1 89.062 (91.703)\tPrec@5 100.000 (99.670)\t\n",
            "EVALUATING - Epoch: [289][78/79]\tTime 0.003 (0.028)\tData 0.000 (0.018)\tLoss 0.2512 (0.3888)\tPrec@1 93.750 (91.720)\tPrec@5 100.000 (99.670)\t\n",
            "\n",
            "Results - Epoch: 290\n",
            "Training Loss 0.0178 \tTraining Prec@1 99.463 \tTraining Prec@5 100.000 \tValidation Loss 0.3888 \tValidation Prec@1 91.720 \tValidation Prec@5 99.670 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 291\n",
            "\n",
            "TRAINING - Epoch: [290][0/390]\tTime 0.243 (0.243)\tData 0.185 (0.185)\tLoss 0.0031 (0.0031)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][10/390]\tTime 0.045 (0.073)\tData 0.000 (0.027)\tLoss 0.0243 (0.0132)\tPrec@1 100.000 (99.787)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][20/390]\tTime 0.032 (0.058)\tData 0.001 (0.015)\tLoss 0.0026 (0.0146)\tPrec@1 100.000 (99.702)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][30/390]\tTime 0.037 (0.053)\tData 0.007 (0.011)\tLoss 0.0317 (0.0159)\tPrec@1 98.438 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][40/390]\tTime 0.047 (0.051)\tData 0.000 (0.010)\tLoss 0.0126 (0.0158)\tPrec@1 99.219 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][50/390]\tTime 0.035 (0.049)\tData 0.000 (0.008)\tLoss 0.0134 (0.0157)\tPrec@1 100.000 (99.617)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][60/390]\tTime 0.059 (0.047)\tData 0.005 (0.007)\tLoss 0.0353 (0.0156)\tPrec@1 99.219 (99.603)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][70/390]\tTime 0.033 (0.046)\tData 0.000 (0.007)\tLoss 0.0184 (0.0163)\tPrec@1 99.219 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][80/390]\tTime 0.047 (0.046)\tData 0.000 (0.007)\tLoss 0.0124 (0.0162)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][90/390]\tTime 0.083 (0.046)\tData 0.052 (0.007)\tLoss 0.0055 (0.0162)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][100/390]\tTime 0.047 (0.046)\tData 0.010 (0.008)\tLoss 0.0141 (0.0163)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][110/390]\tTime 0.097 (0.046)\tData 0.056 (0.008)\tLoss 0.0062 (0.0168)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][120/390]\tTime 0.034 (0.046)\tData 0.000 (0.008)\tLoss 0.0379 (0.0173)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][130/390]\tTime 0.041 (0.046)\tData 0.000 (0.007)\tLoss 0.0099 (0.0174)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][140/390]\tTime 0.056 (0.046)\tData 0.002 (0.007)\tLoss 0.0093 (0.0178)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][150/390]\tTime 0.036 (0.045)\tData 0.002 (0.007)\tLoss 0.0385 (0.0181)\tPrec@1 98.438 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][160/390]\tTime 0.040 (0.045)\tData 0.003 (0.007)\tLoss 0.0110 (0.0179)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][170/390]\tTime 0.050 (0.045)\tData 0.004 (0.006)\tLoss 0.0834 (0.0182)\tPrec@1 96.875 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][180/390]\tTime 0.050 (0.045)\tData 0.000 (0.006)\tLoss 0.0080 (0.0181)\tPrec@1 100.000 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][190/390]\tTime 0.047 (0.045)\tData 0.003 (0.006)\tLoss 0.0079 (0.0179)\tPrec@1 100.000 (99.485)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][200/390]\tTime 0.064 (0.045)\tData 0.000 (0.006)\tLoss 0.0182 (0.0178)\tPrec@1 100.000 (99.487)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][210/390]\tTime 0.052 (0.045)\tData 0.002 (0.006)\tLoss 0.0268 (0.0179)\tPrec@1 98.438 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][220/390]\tTime 0.031 (0.045)\tData 0.005 (0.006)\tLoss 0.0087 (0.0177)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][230/390]\tTime 0.051 (0.045)\tData 0.009 (0.006)\tLoss 0.0152 (0.0181)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][240/390]\tTime 0.049 (0.045)\tData 0.013 (0.006)\tLoss 0.0258 (0.0181)\tPrec@1 99.219 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][250/390]\tTime 0.040 (0.045)\tData 0.004 (0.006)\tLoss 0.0211 (0.0180)\tPrec@1 99.219 (99.477)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][260/390]\tTime 0.050 (0.045)\tData 0.003 (0.006)\tLoss 0.0291 (0.0182)\tPrec@1 99.219 (99.482)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][270/390]\tTime 0.044 (0.045)\tData 0.010 (0.005)\tLoss 0.0311 (0.0182)\tPrec@1 98.438 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][280/390]\tTime 0.075 (0.045)\tData 0.044 (0.005)\tLoss 0.0334 (0.0182)\tPrec@1 97.656 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][290/390]\tTime 0.034 (0.044)\tData 0.004 (0.005)\tLoss 0.0108 (0.0182)\tPrec@1 100.000 (99.482)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][300/390]\tTime 0.044 (0.044)\tData 0.005 (0.005)\tLoss 0.0073 (0.0182)\tPrec@1 100.000 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][310/390]\tTime 0.046 (0.044)\tData 0.008 (0.005)\tLoss 0.0093 (0.0181)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][320/390]\tTime 0.050 (0.044)\tData 0.005 (0.005)\tLoss 0.0316 (0.0182)\tPrec@1 98.438 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][330/390]\tTime 0.032 (0.044)\tData 0.000 (0.005)\tLoss 0.0203 (0.0182)\tPrec@1 99.219 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][340/390]\tTime 0.051 (0.044)\tData 0.001 (0.005)\tLoss 0.0029 (0.0180)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][350/390]\tTime 0.035 (0.044)\tData 0.001 (0.005)\tLoss 0.0051 (0.0180)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][360/390]\tTime 0.055 (0.044)\tData 0.018 (0.005)\tLoss 0.0099 (0.0180)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][370/390]\tTime 0.041 (0.044)\tData 0.006 (0.005)\tLoss 0.0231 (0.0180)\tPrec@1 99.219 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][380/390]\tTime 0.055 (0.044)\tData 0.032 (0.005)\tLoss 0.0083 (0.0180)\tPrec@1 100.000 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [290][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0218 (0.0181)\tPrec@1 99.219 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [290][0/79]\tTime 0.256 (0.256)\tData 0.240 (0.240)\tLoss 0.2913 (0.2913)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [290][10/79]\tTime 0.017 (0.045)\tData 0.002 (0.031)\tLoss 0.2581 (0.3720)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [290][20/79]\tTime 0.058 (0.037)\tData 0.052 (0.024)\tLoss 0.5212 (0.4103)\tPrec@1 89.844 (91.667)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [290][30/79]\tTime 0.021 (0.035)\tData 0.005 (0.022)\tLoss 0.0969 (0.3976)\tPrec@1 97.656 (91.935)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [290][40/79]\tTime 0.040 (0.033)\tData 0.034 (0.021)\tLoss 0.2459 (0.3983)\tPrec@1 89.844 (91.883)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [290][50/79]\tTime 0.010 (0.032)\tData 0.000 (0.019)\tLoss 0.4326 (0.3911)\tPrec@1 90.625 (91.820)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [290][60/79]\tTime 0.076 (0.032)\tData 0.068 (0.020)\tLoss 0.6433 (0.3956)\tPrec@1 92.969 (91.726)\tPrec@5 100.000 (99.667)\t\n",
            "EVALUATING - Epoch: [290][70/79]\tTime 0.016 (0.032)\tData 0.000 (0.019)\tLoss 0.3984 (0.3877)\tPrec@1 89.844 (91.692)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [290][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.017)\tLoss 0.2556 (0.3851)\tPrec@1 93.750 (91.680)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 291\n",
            "Training Loss 0.0181 \tTraining Prec@1 99.497 \tTraining Prec@5 100.000 \tValidation Loss 0.3851 \tValidation Prec@1 91.680 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 292\n",
            "\n",
            "TRAINING - Epoch: [291][0/390]\tTime 0.335 (0.335)\tData 0.291 (0.291)\tLoss 0.0105 (0.0105)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][10/390]\tTime 0.044 (0.071)\tData 0.001 (0.030)\tLoss 0.0165 (0.0171)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][20/390]\tTime 0.068 (0.058)\tData 0.034 (0.020)\tLoss 0.0121 (0.0155)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][30/390]\tTime 0.043 (0.055)\tData 0.000 (0.014)\tLoss 0.0214 (0.0149)\tPrec@1 99.219 (99.647)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][40/390]\tTime 0.034 (0.052)\tData 0.000 (0.012)\tLoss 0.0039 (0.0157)\tPrec@1 100.000 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][50/390]\tTime 0.054 (0.051)\tData 0.012 (0.010)\tLoss 0.0067 (0.0156)\tPrec@1 100.000 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][60/390]\tTime 0.037 (0.049)\tData 0.011 (0.009)\tLoss 0.0375 (0.0158)\tPrec@1 97.656 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][70/390]\tTime 0.028 (0.048)\tData 0.000 (0.008)\tLoss 0.0086 (0.0165)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][80/390]\tTime 0.056 (0.048)\tData 0.030 (0.009)\tLoss 0.0119 (0.0161)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][90/390]\tTime 0.038 (0.048)\tData 0.000 (0.009)\tLoss 0.0474 (0.0164)\tPrec@1 98.438 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][100/390]\tTime 0.054 (0.047)\tData 0.015 (0.009)\tLoss 0.0089 (0.0161)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][110/390]\tTime 0.038 (0.047)\tData 0.009 (0.009)\tLoss 0.0100 (0.0157)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][120/390]\tTime 0.038 (0.047)\tData 0.008 (0.009)\tLoss 0.0112 (0.0161)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][130/390]\tTime 0.050 (0.047)\tData 0.003 (0.009)\tLoss 0.0225 (0.0161)\tPrec@1 99.219 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][140/390]\tTime 0.041 (0.047)\tData 0.004 (0.008)\tLoss 0.0352 (0.0164)\tPrec@1 98.438 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][150/390]\tTime 0.033 (0.047)\tData 0.002 (0.008)\tLoss 0.0130 (0.0166)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][160/390]\tTime 0.031 (0.046)\tData 0.000 (0.008)\tLoss 0.0078 (0.0165)\tPrec@1 100.000 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][170/390]\tTime 0.044 (0.046)\tData 0.011 (0.008)\tLoss 0.0096 (0.0169)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][180/390]\tTime 0.045 (0.046)\tData 0.005 (0.008)\tLoss 0.0090 (0.0171)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][190/390]\tTime 0.056 (0.046)\tData 0.003 (0.008)\tLoss 0.0079 (0.0169)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][200/390]\tTime 0.050 (0.046)\tData 0.012 (0.007)\tLoss 0.0184 (0.0168)\tPrec@1 99.219 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][210/390]\tTime 0.055 (0.046)\tData 0.000 (0.007)\tLoss 0.0241 (0.0169)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][220/390]\tTime 0.045 (0.046)\tData 0.008 (0.007)\tLoss 0.0298 (0.0168)\tPrec@1 99.219 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][230/390]\tTime 0.058 (0.046)\tData 0.005 (0.007)\tLoss 0.0090 (0.0166)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][240/390]\tTime 0.047 (0.046)\tData 0.007 (0.007)\tLoss 0.0098 (0.0165)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][250/390]\tTime 0.072 (0.046)\tData 0.043 (0.007)\tLoss 0.0539 (0.0167)\tPrec@1 97.656 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][260/390]\tTime 0.054 (0.046)\tData 0.007 (0.007)\tLoss 0.0075 (0.0167)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][270/390]\tTime 0.048 (0.046)\tData 0.005 (0.007)\tLoss 0.0085 (0.0166)\tPrec@1 100.000 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][280/390]\tTime 0.054 (0.046)\tData 0.006 (0.007)\tLoss 0.0468 (0.0167)\tPrec@1 97.656 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][290/390]\tTime 0.035 (0.046)\tData 0.002 (0.007)\tLoss 0.0139 (0.0167)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][300/390]\tTime 0.046 (0.046)\tData 0.000 (0.007)\tLoss 0.0123 (0.0172)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][310/390]\tTime 0.045 (0.046)\tData 0.003 (0.007)\tLoss 0.0133 (0.0170)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][320/390]\tTime 0.051 (0.046)\tData 0.011 (0.006)\tLoss 0.0302 (0.0172)\tPrec@1 98.438 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][330/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0216 (0.0172)\tPrec@1 99.219 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][340/390]\tTime 0.047 (0.046)\tData 0.005 (0.006)\tLoss 0.0059 (0.0171)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][350/390]\tTime 0.039 (0.046)\tData 0.005 (0.006)\tLoss 0.0079 (0.0170)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][360/390]\tTime 0.035 (0.046)\tData 0.005 (0.006)\tLoss 0.0132 (0.0169)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][370/390]\tTime 0.034 (0.046)\tData 0.000 (0.006)\tLoss 0.0118 (0.0168)\tPrec@1 99.219 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][380/390]\tTime 0.041 (0.046)\tData 0.001 (0.006)\tLoss 0.0096 (0.0167)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [291][389/390]\tTime 0.020 (0.046)\tData 0.002 (0.006)\tLoss 0.0051 (0.0168)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [291][0/79]\tTime 0.198 (0.198)\tData 0.189 (0.189)\tLoss 0.2905 (0.2905)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [291][10/79]\tTime 0.014 (0.048)\tData 0.000 (0.037)\tLoss 0.2579 (0.3741)\tPrec@1 91.406 (92.045)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [291][20/79]\tTime 0.013 (0.040)\tData 0.000 (0.028)\tLoss 0.5280 (0.4128)\tPrec@1 89.844 (91.518)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [291][30/79]\tTime 0.015 (0.037)\tData 0.005 (0.025)\tLoss 0.0942 (0.3982)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [291][40/79]\tTime 0.042 (0.034)\tData 0.010 (0.022)\tLoss 0.2516 (0.3989)\tPrec@1 89.844 (91.825)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [291][50/79]\tTime 0.017 (0.032)\tData 0.005 (0.020)\tLoss 0.4409 (0.3922)\tPrec@1 90.625 (91.805)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [291][60/79]\tTime 0.017 (0.031)\tData 0.005 (0.019)\tLoss 0.6414 (0.3967)\tPrec@1 92.188 (91.726)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [291][70/79]\tTime 0.032 (0.031)\tData 0.018 (0.018)\tLoss 0.4087 (0.3891)\tPrec@1 89.844 (91.670)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [291][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2700 (0.3864)\tPrec@1 93.750 (91.680)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 292\n",
            "Training Loss 0.0168 \tTraining Prec@1 99.563 \tTraining Prec@5 100.000 \tValidation Loss 0.3864 \tValidation Prec@1 91.680 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 293\n",
            "\n",
            "TRAINING - Epoch: [292][0/390]\tTime 0.335 (0.335)\tData 0.279 (0.279)\tLoss 0.0267 (0.0267)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][10/390]\tTime 0.040 (0.071)\tData 0.000 (0.029)\tLoss 0.0056 (0.0187)\tPrec@1 100.000 (99.361)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][20/390]\tTime 0.033 (0.057)\tData 0.000 (0.017)\tLoss 0.0235 (0.0210)\tPrec@1 98.438 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][30/390]\tTime 0.049 (0.053)\tData 0.000 (0.012)\tLoss 0.0119 (0.0181)\tPrec@1 99.219 (99.420)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][40/390]\tTime 0.042 (0.050)\tData 0.005 (0.010)\tLoss 0.0130 (0.0168)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][50/390]\tTime 0.055 (0.050)\tData 0.005 (0.009)\tLoss 0.0092 (0.0168)\tPrec@1 99.219 (99.449)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][60/390]\tTime 0.046 (0.049)\tData 0.006 (0.008)\tLoss 0.0144 (0.0167)\tPrec@1 100.000 (99.462)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][70/390]\tTime 0.061 (0.049)\tData 0.002 (0.008)\tLoss 0.0241 (0.0166)\tPrec@1 99.219 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][80/390]\tTime 0.056 (0.048)\tData 0.004 (0.008)\tLoss 0.0157 (0.0164)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][90/390]\tTime 0.047 (0.047)\tData 0.003 (0.007)\tLoss 0.0133 (0.0167)\tPrec@1 99.219 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][100/390]\tTime 0.029 (0.047)\tData 0.000 (0.007)\tLoss 0.0414 (0.0165)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][110/390]\tTime 0.034 (0.047)\tData 0.005 (0.007)\tLoss 0.0126 (0.0167)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][120/390]\tTime 0.035 (0.047)\tData 0.005 (0.007)\tLoss 0.0147 (0.0164)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][130/390]\tTime 0.054 (0.047)\tData 0.000 (0.007)\tLoss 0.0215 (0.0162)\tPrec@1 99.219 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][140/390]\tTime 0.042 (0.047)\tData 0.005 (0.007)\tLoss 0.0259 (0.0165)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][150/390]\tTime 0.050 (0.046)\tData 0.000 (0.006)\tLoss 0.0313 (0.0170)\tPrec@1 98.438 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][160/390]\tTime 0.042 (0.046)\tData 0.000 (0.006)\tLoss 0.0107 (0.0169)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][170/390]\tTime 0.031 (0.046)\tData 0.004 (0.006)\tLoss 0.0053 (0.0166)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][180/390]\tTime 0.036 (0.046)\tData 0.000 (0.006)\tLoss 0.0198 (0.0166)\tPrec@1 99.219 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][190/390]\tTime 0.040 (0.046)\tData 0.005 (0.006)\tLoss 0.0043 (0.0164)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][200/390]\tTime 0.045 (0.046)\tData 0.006 (0.006)\tLoss 0.0078 (0.0162)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][210/390]\tTime 0.075 (0.046)\tData 0.043 (0.006)\tLoss 0.0385 (0.0162)\tPrec@1 98.438 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][220/390]\tTime 0.040 (0.045)\tData 0.005 (0.006)\tLoss 0.0081 (0.0163)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][230/390]\tTime 0.037 (0.045)\tData 0.001 (0.006)\tLoss 0.0066 (0.0165)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][240/390]\tTime 0.039 (0.045)\tData 0.003 (0.006)\tLoss 0.0059 (0.0167)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][250/390]\tTime 0.038 (0.045)\tData 0.005 (0.006)\tLoss 0.0027 (0.0167)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][260/390]\tTime 0.043 (0.045)\tData 0.003 (0.006)\tLoss 0.0176 (0.0166)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][270/390]\tTime 0.057 (0.045)\tData 0.019 (0.006)\tLoss 0.0174 (0.0167)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][280/390]\tTime 0.040 (0.045)\tData 0.004 (0.006)\tLoss 0.0172 (0.0166)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][290/390]\tTime 0.043 (0.045)\tData 0.003 (0.006)\tLoss 0.0056 (0.0166)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][300/390]\tTime 0.033 (0.045)\tData 0.005 (0.006)\tLoss 0.0042 (0.0165)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][310/390]\tTime 0.038 (0.045)\tData 0.005 (0.006)\tLoss 0.0092 (0.0166)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][320/390]\tTime 0.037 (0.045)\tData 0.000 (0.006)\tLoss 0.0329 (0.0166)\tPrec@1 98.438 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][330/390]\tTime 0.041 (0.045)\tData 0.005 (0.006)\tLoss 0.0123 (0.0164)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][340/390]\tTime 0.038 (0.045)\tData 0.007 (0.006)\tLoss 0.0120 (0.0163)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][350/390]\tTime 0.046 (0.045)\tData 0.005 (0.006)\tLoss 0.0061 (0.0162)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][360/390]\tTime 0.041 (0.045)\tData 0.000 (0.006)\tLoss 0.0094 (0.0164)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][370/390]\tTime 0.038 (0.044)\tData 0.007 (0.006)\tLoss 0.0298 (0.0163)\tPrec@1 99.219 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][380/390]\tTime 0.043 (0.044)\tData 0.000 (0.006)\tLoss 0.0258 (0.0163)\tPrec@1 99.219 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [292][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.006)\tLoss 0.0200 (0.0165)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [292][0/79]\tTime 0.249 (0.249)\tData 0.228 (0.228)\tLoss 0.2915 (0.2915)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [292][10/79]\tTime 0.022 (0.044)\tData 0.000 (0.031)\tLoss 0.2533 (0.3709)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [292][20/79]\tTime 0.013 (0.037)\tData 0.000 (0.024)\tLoss 0.5262 (0.4112)\tPrec@1 89.844 (91.741)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [292][30/79]\tTime 0.018 (0.035)\tData 0.001 (0.022)\tLoss 0.1013 (0.3985)\tPrec@1 97.656 (92.011)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [292][40/79]\tTime 0.013 (0.033)\tData 0.002 (0.019)\tLoss 0.2399 (0.3989)\tPrec@1 91.406 (91.978)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [292][50/79]\tTime 0.017 (0.033)\tData 0.001 (0.019)\tLoss 0.4340 (0.3921)\tPrec@1 90.625 (91.835)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [292][60/79]\tTime 0.016 (0.031)\tData 0.000 (0.018)\tLoss 0.6447 (0.3969)\tPrec@1 92.969 (91.752)\tPrec@5 100.000 (99.667)\t\n",
            "EVALUATING - Epoch: [292][70/79]\tTime 0.017 (0.031)\tData 0.006 (0.018)\tLoss 0.3951 (0.3889)\tPrec@1 89.844 (91.725)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [292][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2530 (0.3863)\tPrec@1 93.750 (91.730)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 293\n",
            "Training Loss 0.0165 \tTraining Prec@1 99.565 \tTraining Prec@5 100.000 \tValidation Loss 0.3863 \tValidation Prec@1 91.730 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 294\n",
            "\n",
            "TRAINING - Epoch: [293][0/390]\tTime 0.316 (0.316)\tData 0.262 (0.262)\tLoss 0.0169 (0.0169)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][10/390]\tTime 0.043 (0.067)\tData 0.000 (0.026)\tLoss 0.0080 (0.0191)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][20/390]\tTime 0.040 (0.055)\tData 0.001 (0.014)\tLoss 0.0195 (0.0178)\tPrec@1 98.438 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][30/390]\tTime 0.054 (0.051)\tData 0.001 (0.010)\tLoss 0.0348 (0.0195)\tPrec@1 99.219 (99.446)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][40/390]\tTime 0.043 (0.049)\tData 0.008 (0.009)\tLoss 0.0152 (0.0190)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][50/390]\tTime 0.038 (0.049)\tData 0.000 (0.008)\tLoss 0.0078 (0.0188)\tPrec@1 100.000 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][60/390]\tTime 0.043 (0.048)\tData 0.003 (0.008)\tLoss 0.0467 (0.0182)\tPrec@1 98.438 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][70/390]\tTime 0.034 (0.048)\tData 0.005 (0.008)\tLoss 0.0210 (0.0185)\tPrec@1 99.219 (99.461)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][80/390]\tTime 0.050 (0.047)\tData 0.021 (0.008)\tLoss 0.0198 (0.0178)\tPrec@1 99.219 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][90/390]\tTime 0.044 (0.047)\tData 0.001 (0.007)\tLoss 0.0333 (0.0184)\tPrec@1 98.438 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][100/390]\tTime 0.054 (0.046)\tData 0.004 (0.007)\tLoss 0.0228 (0.0189)\tPrec@1 99.219 (99.451)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][110/390]\tTime 0.036 (0.047)\tData 0.000 (0.006)\tLoss 0.0265 (0.0185)\tPrec@1 99.219 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][120/390]\tTime 0.035 (0.046)\tData 0.002 (0.007)\tLoss 0.0152 (0.0182)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][130/390]\tTime 0.054 (0.047)\tData 0.002 (0.007)\tLoss 0.0070 (0.0185)\tPrec@1 100.000 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][140/390]\tTime 0.061 (0.047)\tData 0.011 (0.007)\tLoss 0.0193 (0.0184)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][150/390]\tTime 0.045 (0.046)\tData 0.009 (0.007)\tLoss 0.0289 (0.0185)\tPrec@1 98.438 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][160/390]\tTime 0.035 (0.046)\tData 0.000 (0.007)\tLoss 0.0109 (0.0184)\tPrec@1 99.219 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][170/390]\tTime 0.028 (0.046)\tData 0.000 (0.007)\tLoss 0.0267 (0.0182)\tPrec@1 98.438 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][180/390]\tTime 0.045 (0.046)\tData 0.009 (0.006)\tLoss 0.0125 (0.0182)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][190/390]\tTime 0.030 (0.046)\tData 0.000 (0.006)\tLoss 0.0225 (0.0182)\tPrec@1 100.000 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][200/390]\tTime 0.045 (0.046)\tData 0.000 (0.006)\tLoss 0.0065 (0.0179)\tPrec@1 100.000 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][210/390]\tTime 0.046 (0.046)\tData 0.000 (0.006)\tLoss 0.0261 (0.0176)\tPrec@1 98.438 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][220/390]\tTime 0.038 (0.046)\tData 0.000 (0.006)\tLoss 0.0057 (0.0174)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][230/390]\tTime 0.041 (0.045)\tData 0.006 (0.006)\tLoss 0.0187 (0.0174)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][240/390]\tTime 0.045 (0.045)\tData 0.009 (0.006)\tLoss 0.0251 (0.0173)\tPrec@1 99.219 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][250/390]\tTime 0.043 (0.045)\tData 0.002 (0.006)\tLoss 0.0108 (0.0171)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][260/390]\tTime 0.040 (0.045)\tData 0.000 (0.006)\tLoss 0.0110 (0.0172)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][270/390]\tTime 0.049 (0.045)\tData 0.002 (0.005)\tLoss 0.0230 (0.0174)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][280/390]\tTime 0.048 (0.045)\tData 0.012 (0.005)\tLoss 0.0195 (0.0176)\tPrec@1 99.219 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][290/390]\tTime 0.043 (0.045)\tData 0.005 (0.005)\tLoss 0.0249 (0.0174)\tPrec@1 99.219 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][300/390]\tTime 0.030 (0.045)\tData 0.000 (0.005)\tLoss 0.0253 (0.0174)\tPrec@1 98.438 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][310/390]\tTime 0.036 (0.045)\tData 0.000 (0.005)\tLoss 0.0107 (0.0173)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][320/390]\tTime 0.036 (0.045)\tData 0.000 (0.005)\tLoss 0.0109 (0.0173)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][330/390]\tTime 0.043 (0.045)\tData 0.002 (0.005)\tLoss 0.0220 (0.0174)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][340/390]\tTime 0.042 (0.045)\tData 0.001 (0.005)\tLoss 0.0078 (0.0172)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][350/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0144 (0.0171)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][360/390]\tTime 0.047 (0.044)\tData 0.004 (0.005)\tLoss 0.0083 (0.0170)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][370/390]\tTime 0.043 (0.044)\tData 0.007 (0.005)\tLoss 0.0059 (0.0171)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][380/390]\tTime 0.042 (0.044)\tData 0.002 (0.005)\tLoss 0.0152 (0.0172)\tPrec@1 99.219 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [293][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0283 (0.0172)\tPrec@1 98.438 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [293][0/79]\tTime 0.287 (0.287)\tData 0.271 (0.271)\tLoss 0.2854 (0.2854)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [293][10/79]\tTime 0.015 (0.044)\tData 0.005 (0.030)\tLoss 0.2556 (0.3716)\tPrec@1 91.406 (92.401)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [293][20/79]\tTime 0.023 (0.036)\tData 0.009 (0.022)\tLoss 0.5228 (0.4125)\tPrec@1 89.844 (91.555)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [293][30/79]\tTime 0.020 (0.035)\tData 0.005 (0.022)\tLoss 0.1038 (0.3998)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [293][40/79]\tTime 0.016 (0.033)\tData 0.000 (0.019)\tLoss 0.2358 (0.4020)\tPrec@1 90.625 (91.845)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [293][50/79]\tTime 0.038 (0.032)\tData 0.006 (0.018)\tLoss 0.4493 (0.3944)\tPrec@1 89.844 (91.713)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [293][60/79]\tTime 0.017 (0.031)\tData 0.006 (0.017)\tLoss 0.6496 (0.3997)\tPrec@1 92.969 (91.611)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [293][70/79]\tTime 0.024 (0.031)\tData 0.018 (0.017)\tLoss 0.3980 (0.3920)\tPrec@1 89.062 (91.593)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [293][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.016)\tLoss 0.2648 (0.3885)\tPrec@1 93.750 (91.640)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 294\n",
            "Training Loss 0.0172 \tTraining Prec@1 99.541 \tTraining Prec@5 100.000 \tValidation Loss 0.3885 \tValidation Prec@1 91.640 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 295\n",
            "\n",
            "TRAINING - Epoch: [294][0/390]\tTime 0.225 (0.225)\tData 0.181 (0.181)\tLoss 0.0074 (0.0074)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][10/390]\tTime 0.046 (0.069)\tData 0.002 (0.026)\tLoss 0.0291 (0.0218)\tPrec@1 99.219 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][20/390]\tTime 0.033 (0.055)\tData 0.000 (0.016)\tLoss 0.0046 (0.0208)\tPrec@1 100.000 (99.442)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][30/390]\tTime 0.037 (0.052)\tData 0.000 (0.014)\tLoss 0.0146 (0.0192)\tPrec@1 100.000 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][40/390]\tTime 0.037 (0.049)\tData 0.005 (0.012)\tLoss 0.0213 (0.0180)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][50/390]\tTime 0.037 (0.049)\tData 0.002 (0.011)\tLoss 0.0195 (0.0184)\tPrec@1 98.438 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][60/390]\tTime 0.050 (0.048)\tData 0.007 (0.010)\tLoss 0.0108 (0.0190)\tPrec@1 100.000 (99.449)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][70/390]\tTime 0.043 (0.047)\tData 0.000 (0.010)\tLoss 0.0141 (0.0184)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][80/390]\tTime 0.048 (0.047)\tData 0.003 (0.009)\tLoss 0.0148 (0.0183)\tPrec@1 100.000 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][90/390]\tTime 0.061 (0.046)\tData 0.000 (0.008)\tLoss 0.0103 (0.0180)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][100/390]\tTime 0.054 (0.046)\tData 0.014 (0.008)\tLoss 0.0036 (0.0176)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][110/390]\tTime 0.041 (0.046)\tData 0.007 (0.008)\tLoss 0.0094 (0.0169)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][120/390]\tTime 0.032 (0.045)\tData 0.001 (0.007)\tLoss 0.0188 (0.0171)\tPrec@1 99.219 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][130/390]\tTime 0.037 (0.045)\tData 0.005 (0.007)\tLoss 0.0115 (0.0172)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][140/390]\tTime 0.046 (0.045)\tData 0.004 (0.007)\tLoss 0.0074 (0.0175)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][150/390]\tTime 0.049 (0.045)\tData 0.000 (0.006)\tLoss 0.0370 (0.0175)\tPrec@1 98.438 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][160/390]\tTime 0.048 (0.045)\tData 0.007 (0.006)\tLoss 0.0354 (0.0177)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][170/390]\tTime 0.045 (0.045)\tData 0.000 (0.006)\tLoss 0.0160 (0.0177)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][180/390]\tTime 0.053 (0.045)\tData 0.002 (0.006)\tLoss 0.0113 (0.0179)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][190/390]\tTime 0.041 (0.045)\tData 0.001 (0.006)\tLoss 0.0261 (0.0178)\tPrec@1 98.438 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][200/390]\tTime 0.042 (0.045)\tData 0.000 (0.006)\tLoss 0.0029 (0.0177)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][210/390]\tTime 0.047 (0.045)\tData 0.005 (0.006)\tLoss 0.0216 (0.0178)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][220/390]\tTime 0.034 (0.045)\tData 0.000 (0.006)\tLoss 0.0246 (0.0180)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][230/390]\tTime 0.051 (0.045)\tData 0.000 (0.006)\tLoss 0.0086 (0.0179)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][240/390]\tTime 0.044 (0.045)\tData 0.003 (0.005)\tLoss 0.0220 (0.0178)\tPrec@1 99.219 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][250/390]\tTime 0.035 (0.045)\tData 0.000 (0.005)\tLoss 0.0148 (0.0179)\tPrec@1 99.219 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][260/390]\tTime 0.056 (0.045)\tData 0.001 (0.005)\tLoss 0.0382 (0.0181)\tPrec@1 97.656 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][270/390]\tTime 0.061 (0.045)\tData 0.012 (0.005)\tLoss 0.0578 (0.0183)\tPrec@1 97.656 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][280/390]\tTime 0.027 (0.045)\tData 0.000 (0.005)\tLoss 0.0093 (0.0183)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][290/390]\tTime 0.057 (0.045)\tData 0.000 (0.005)\tLoss 0.0387 (0.0183)\tPrec@1 98.438 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][300/390]\tTime 0.044 (0.045)\tData 0.005 (0.005)\tLoss 0.0094 (0.0181)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][310/390]\tTime 0.043 (0.045)\tData 0.007 (0.005)\tLoss 0.0129 (0.0179)\tPrec@1 99.219 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][320/390]\tTime 0.042 (0.045)\tData 0.003 (0.005)\tLoss 0.0128 (0.0180)\tPrec@1 100.000 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][330/390]\tTime 0.044 (0.045)\tData 0.001 (0.005)\tLoss 0.0141 (0.0179)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][340/390]\tTime 0.050 (0.045)\tData 0.001 (0.005)\tLoss 0.0233 (0.0180)\tPrec@1 99.219 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][350/390]\tTime 0.040 (0.045)\tData 0.000 (0.005)\tLoss 0.0040 (0.0179)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][360/390]\tTime 0.057 (0.045)\tData 0.010 (0.005)\tLoss 0.0183 (0.0180)\tPrec@1 99.219 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][370/390]\tTime 0.037 (0.045)\tData 0.005 (0.005)\tLoss 0.0106 (0.0179)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][380/390]\tTime 0.046 (0.045)\tData 0.001 (0.005)\tLoss 0.0268 (0.0179)\tPrec@1 100.000 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [294][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0211 (0.0179)\tPrec@1 99.219 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [294][0/79]\tTime 0.200 (0.200)\tData 0.171 (0.171)\tLoss 0.2816 (0.2816)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [294][10/79]\tTime 0.033 (0.050)\tData 0.027 (0.037)\tLoss 0.2652 (0.3678)\tPrec@1 91.406 (92.116)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [294][20/79]\tTime 0.028 (0.041)\tData 0.012 (0.029)\tLoss 0.5195 (0.4087)\tPrec@1 89.844 (91.592)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [294][30/79]\tTime 0.053 (0.037)\tData 0.043 (0.026)\tLoss 0.0973 (0.3949)\tPrec@1 97.656 (91.986)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [294][40/79]\tTime 0.009 (0.036)\tData 0.001 (0.024)\tLoss 0.2390 (0.3972)\tPrec@1 91.406 (91.921)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [294][50/79]\tTime 0.015 (0.034)\tData 0.000 (0.022)\tLoss 0.4539 (0.3910)\tPrec@1 89.844 (91.835)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [294][60/79]\tTime 0.018 (0.034)\tData 0.000 (0.022)\tLoss 0.6431 (0.3965)\tPrec@1 92.969 (91.752)\tPrec@5 100.000 (99.667)\t\n",
            "EVALUATING - Epoch: [294][70/79]\tTime 0.019 (0.033)\tData 0.010 (0.021)\tLoss 0.4065 (0.3890)\tPrec@1 89.844 (91.670)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [294][78/79]\tTime 0.003 (0.032)\tData 0.000 (0.020)\tLoss 0.2738 (0.3858)\tPrec@1 93.750 (91.680)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 295\n",
            "Training Loss 0.0179 \tTraining Prec@1 99.507 \tTraining Prec@5 100.000 \tValidation Loss 0.3858 \tValidation Prec@1 91.680 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 296\n",
            "\n",
            "TRAINING - Epoch: [295][0/390]\tTime 0.322 (0.322)\tData 0.276 (0.276)\tLoss 0.0123 (0.0123)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][10/390]\tTime 0.046 (0.071)\tData 0.004 (0.027)\tLoss 0.0103 (0.0189)\tPrec@1 100.000 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][20/390]\tTime 0.044 (0.058)\tData 0.004 (0.016)\tLoss 0.0017 (0.0166)\tPrec@1 100.000 (99.702)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][30/390]\tTime 0.037 (0.054)\tData 0.002 (0.012)\tLoss 0.0093 (0.0155)\tPrec@1 100.000 (99.672)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][40/390]\tTime 0.043 (0.052)\tData 0.000 (0.010)\tLoss 0.0165 (0.0157)\tPrec@1 99.219 (99.657)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][50/390]\tTime 0.049 (0.051)\tData 0.000 (0.008)\tLoss 0.0076 (0.0152)\tPrec@1 100.000 (99.663)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][60/390]\tTime 0.046 (0.050)\tData 0.002 (0.007)\tLoss 0.0119 (0.0160)\tPrec@1 100.000 (99.603)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][70/390]\tTime 0.045 (0.049)\tData 0.001 (0.007)\tLoss 0.0061 (0.0152)\tPrec@1 100.000 (99.626)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][80/390]\tTime 0.035 (0.048)\tData 0.000 (0.006)\tLoss 0.0247 (0.0156)\tPrec@1 99.219 (99.605)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][90/390]\tTime 0.060 (0.048)\tData 0.029 (0.007)\tLoss 0.0293 (0.0158)\tPrec@1 99.219 (99.614)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][100/390]\tTime 0.051 (0.048)\tData 0.000 (0.006)\tLoss 0.0169 (0.0159)\tPrec@1 99.219 (99.598)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][110/390]\tTime 0.059 (0.047)\tData 0.021 (0.006)\tLoss 0.0106 (0.0160)\tPrec@1 100.000 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][120/390]\tTime 0.052 (0.047)\tData 0.001 (0.006)\tLoss 0.0115 (0.0158)\tPrec@1 100.000 (99.587)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][130/390]\tTime 0.034 (0.047)\tData 0.010 (0.006)\tLoss 0.0130 (0.0160)\tPrec@1 99.219 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][140/390]\tTime 0.042 (0.047)\tData 0.000 (0.006)\tLoss 0.0113 (0.0159)\tPrec@1 100.000 (99.601)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][150/390]\tTime 0.053 (0.048)\tData 0.000 (0.006)\tLoss 0.0210 (0.0157)\tPrec@1 99.219 (99.607)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][160/390]\tTime 0.042 (0.047)\tData 0.011 (0.006)\tLoss 0.0105 (0.0155)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][170/390]\tTime 0.040 (0.047)\tData 0.007 (0.006)\tLoss 0.0325 (0.0155)\tPrec@1 99.219 (99.625)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][180/390]\tTime 0.042 (0.047)\tData 0.000 (0.006)\tLoss 0.0120 (0.0157)\tPrec@1 100.000 (99.620)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][190/390]\tTime 0.030 (0.047)\tData 0.000 (0.006)\tLoss 0.0104 (0.0158)\tPrec@1 100.000 (99.611)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][200/390]\tTime 0.054 (0.047)\tData 0.001 (0.006)\tLoss 0.0110 (0.0161)\tPrec@1 100.000 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][210/390]\tTime 0.031 (0.047)\tData 0.000 (0.005)\tLoss 0.0032 (0.0161)\tPrec@1 100.000 (99.593)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][220/390]\tTime 0.054 (0.047)\tData 0.002 (0.005)\tLoss 0.0109 (0.0163)\tPrec@1 100.000 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][230/390]\tTime 0.037 (0.047)\tData 0.001 (0.005)\tLoss 0.0095 (0.0163)\tPrec@1 100.000 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][240/390]\tTime 0.042 (0.047)\tData 0.000 (0.005)\tLoss 0.0167 (0.0162)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][250/390]\tTime 0.054 (0.046)\tData 0.010 (0.005)\tLoss 0.0161 (0.0163)\tPrec@1 99.219 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][260/390]\tTime 0.056 (0.046)\tData 0.004 (0.005)\tLoss 0.0091 (0.0163)\tPrec@1 100.000 (99.587)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][270/390]\tTime 0.046 (0.046)\tData 0.001 (0.005)\tLoss 0.0118 (0.0162)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][280/390]\tTime 0.046 (0.046)\tData 0.015 (0.005)\tLoss 0.0348 (0.0162)\tPrec@1 99.219 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][290/390]\tTime 0.042 (0.046)\tData 0.001 (0.005)\tLoss 0.0186 (0.0164)\tPrec@1 100.000 (99.589)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][300/390]\tTime 0.040 (0.046)\tData 0.000 (0.005)\tLoss 0.0131 (0.0163)\tPrec@1 99.219 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][310/390]\tTime 0.055 (0.046)\tData 0.005 (0.005)\tLoss 0.0198 (0.0165)\tPrec@1 99.219 (99.580)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][320/390]\tTime 0.035 (0.046)\tData 0.000 (0.005)\tLoss 0.0125 (0.0167)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][330/390]\tTime 0.049 (0.046)\tData 0.001 (0.005)\tLoss 0.0258 (0.0166)\tPrec@1 99.219 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][340/390]\tTime 0.060 (0.046)\tData 0.000 (0.005)\tLoss 0.0062 (0.0166)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][350/390]\tTime 0.040 (0.046)\tData 0.006 (0.005)\tLoss 0.0232 (0.0168)\tPrec@1 98.438 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][360/390]\tTime 0.041 (0.046)\tData 0.000 (0.005)\tLoss 0.0210 (0.0168)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][370/390]\tTime 0.043 (0.046)\tData 0.001 (0.005)\tLoss 0.0161 (0.0167)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][380/390]\tTime 0.042 (0.046)\tData 0.000 (0.005)\tLoss 0.0087 (0.0166)\tPrec@1 100.000 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [295][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.004)\tLoss 0.0059 (0.0166)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [295][0/79]\tTime 0.164 (0.164)\tData 0.152 (0.152)\tLoss 0.2884 (0.2884)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [295][10/79]\tTime 0.016 (0.042)\tData 0.010 (0.032)\tLoss 0.2623 (0.3703)\tPrec@1 91.406 (92.045)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [295][20/79]\tTime 0.014 (0.036)\tData 0.003 (0.025)\tLoss 0.5130 (0.4085)\tPrec@1 90.625 (91.443)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [295][30/79]\tTime 0.020 (0.034)\tData 0.008 (0.023)\tLoss 0.1026 (0.3950)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [295][40/79]\tTime 0.026 (0.033)\tData 0.007 (0.022)\tLoss 0.2448 (0.3975)\tPrec@1 91.406 (91.902)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [295][50/79]\tTime 0.026 (0.033)\tData 0.005 (0.021)\tLoss 0.4335 (0.3900)\tPrec@1 89.844 (91.850)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [295][60/79]\tTime 0.021 (0.032)\tData 0.004 (0.020)\tLoss 0.6487 (0.3956)\tPrec@1 93.750 (91.726)\tPrec@5 100.000 (99.629)\t\n",
            "EVALUATING - Epoch: [295][70/79]\tTime 0.015 (0.031)\tData 0.005 (0.019)\tLoss 0.4028 (0.3879)\tPrec@1 89.844 (91.714)\tPrec@5 100.000 (99.670)\t\n",
            "EVALUATING - Epoch: [295][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2489 (0.3852)\tPrec@1 93.750 (91.760)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 296\n",
            "Training Loss 0.0166 \tTraining Prec@1 99.571 \tTraining Prec@5 100.000 \tValidation Loss 0.3852 \tValidation Prec@1 91.760 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 297\n",
            "\n",
            "TRAINING - Epoch: [296][0/390]\tTime 0.351 (0.351)\tData 0.304 (0.304)\tLoss 0.0142 (0.0142)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][10/390]\tTime 0.048 (0.070)\tData 0.000 (0.032)\tLoss 0.0128 (0.0182)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][20/390]\tTime 0.067 (0.056)\tData 0.025 (0.020)\tLoss 0.0195 (0.0149)\tPrec@1 99.219 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][30/390]\tTime 0.049 (0.052)\tData 0.000 (0.016)\tLoss 0.0128 (0.0145)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][40/390]\tTime 0.050 (0.050)\tData 0.006 (0.013)\tLoss 0.0237 (0.0143)\tPrec@1 99.219 (99.638)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][50/390]\tTime 0.039 (0.049)\tData 0.006 (0.012)\tLoss 0.0114 (0.0148)\tPrec@1 100.000 (99.617)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][60/390]\tTime 0.047 (0.049)\tData 0.008 (0.011)\tLoss 0.0089 (0.0149)\tPrec@1 100.000 (99.641)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][70/390]\tTime 0.049 (0.049)\tData 0.002 (0.010)\tLoss 0.0199 (0.0158)\tPrec@1 100.000 (99.626)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][80/390]\tTime 0.052 (0.048)\tData 0.025 (0.010)\tLoss 0.0061 (0.0158)\tPrec@1 100.000 (99.605)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][90/390]\tTime 0.043 (0.048)\tData 0.006 (0.010)\tLoss 0.0119 (0.0155)\tPrec@1 100.000 (99.614)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][100/390]\tTime 0.041 (0.048)\tData 0.000 (0.009)\tLoss 0.0194 (0.0161)\tPrec@1 99.219 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][110/390]\tTime 0.052 (0.048)\tData 0.004 (0.008)\tLoss 0.0090 (0.0161)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][120/390]\tTime 0.047 (0.048)\tData 0.001 (0.008)\tLoss 0.0187 (0.0159)\tPrec@1 98.438 (99.580)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][130/390]\tTime 0.051 (0.048)\tData 0.007 (0.008)\tLoss 0.0186 (0.0165)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][140/390]\tTime 0.040 (0.047)\tData 0.002 (0.008)\tLoss 0.0211 (0.0161)\tPrec@1 99.219 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][150/390]\tTime 0.044 (0.047)\tData 0.003 (0.007)\tLoss 0.0068 (0.0167)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][160/390]\tTime 0.045 (0.047)\tData 0.005 (0.007)\tLoss 0.0167 (0.0169)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][170/390]\tTime 0.052 (0.047)\tData 0.000 (0.007)\tLoss 0.0164 (0.0170)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][180/390]\tTime 0.045 (0.046)\tData 0.007 (0.007)\tLoss 0.0227 (0.0171)\tPrec@1 98.438 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][190/390]\tTime 0.038 (0.046)\tData 0.002 (0.007)\tLoss 0.0236 (0.0172)\tPrec@1 98.438 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][200/390]\tTime 0.046 (0.046)\tData 0.000 (0.007)\tLoss 0.0140 (0.0169)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][210/390]\tTime 0.042 (0.046)\tData 0.000 (0.007)\tLoss 0.0105 (0.0167)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][220/390]\tTime 0.038 (0.047)\tData 0.003 (0.007)\tLoss 0.0463 (0.0167)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][230/390]\tTime 0.059 (0.047)\tData 0.009 (0.007)\tLoss 0.0105 (0.0167)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][240/390]\tTime 0.044 (0.046)\tData 0.005 (0.006)\tLoss 0.0175 (0.0166)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][250/390]\tTime 0.044 (0.046)\tData 0.004 (0.006)\tLoss 0.0500 (0.0169)\tPrec@1 99.219 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][260/390]\tTime 0.043 (0.046)\tData 0.000 (0.006)\tLoss 0.0153 (0.0170)\tPrec@1 99.219 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][270/390]\tTime 0.055 (0.046)\tData 0.000 (0.006)\tLoss 0.0058 (0.0168)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][280/390]\tTime 0.040 (0.046)\tData 0.001 (0.006)\tLoss 0.0095 (0.0166)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][290/390]\tTime 0.034 (0.046)\tData 0.005 (0.006)\tLoss 0.0064 (0.0166)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][300/390]\tTime 0.033 (0.046)\tData 0.001 (0.006)\tLoss 0.0138 (0.0166)\tPrec@1 99.219 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][310/390]\tTime 0.028 (0.046)\tData 0.000 (0.006)\tLoss 0.0074 (0.0167)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][320/390]\tTime 0.054 (0.046)\tData 0.001 (0.006)\tLoss 0.0118 (0.0168)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][330/390]\tTime 0.042 (0.046)\tData 0.001 (0.006)\tLoss 0.0120 (0.0167)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][340/390]\tTime 0.037 (0.046)\tData 0.006 (0.006)\tLoss 0.0170 (0.0166)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][350/390]\tTime 0.060 (0.046)\tData 0.006 (0.006)\tLoss 0.0066 (0.0165)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][360/390]\tTime 0.047 (0.046)\tData 0.004 (0.006)\tLoss 0.0262 (0.0166)\tPrec@1 98.438 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][370/390]\tTime 0.040 (0.046)\tData 0.002 (0.006)\tLoss 0.0071 (0.0166)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][380/390]\tTime 0.048 (0.046)\tData 0.004 (0.006)\tLoss 0.0085 (0.0166)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [296][389/390]\tTime 0.019 (0.046)\tData 0.000 (0.006)\tLoss 0.0077 (0.0166)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [296][0/79]\tTime 0.283 (0.283)\tData 0.262 (0.262)\tLoss 0.2876 (0.2876)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [296][10/79]\tTime 0.017 (0.048)\tData 0.000 (0.032)\tLoss 0.2689 (0.3694)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [296][20/79]\tTime 0.032 (0.039)\tData 0.004 (0.025)\tLoss 0.5297 (0.4098)\tPrec@1 90.625 (91.778)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [296][30/79]\tTime 0.030 (0.037)\tData 0.010 (0.024)\tLoss 0.0961 (0.3949)\tPrec@1 97.656 (92.162)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [296][40/79]\tTime 0.007 (0.035)\tData 0.000 (0.022)\tLoss 0.2410 (0.3967)\tPrec@1 90.625 (92.016)\tPrec@5 99.219 (99.486)\t\n",
            "EVALUATING - Epoch: [296][50/79]\tTime 0.018 (0.035)\tData 0.004 (0.021)\tLoss 0.4310 (0.3901)\tPrec@1 89.844 (91.927)\tPrec@5 100.000 (99.586)\t\n",
            "EVALUATING - Epoch: [296][60/79]\tTime 0.052 (0.034)\tData 0.045 (0.021)\tLoss 0.6354 (0.3954)\tPrec@1 92.188 (91.829)\tPrec@5 100.000 (99.616)\t\n",
            "EVALUATING - Epoch: [296][70/79]\tTime 0.026 (0.033)\tData 0.005 (0.021)\tLoss 0.4145 (0.3883)\tPrec@1 89.844 (91.780)\tPrec@5 100.000 (99.659)\t\n",
            "EVALUATING - Epoch: [296][78/79]\tTime 0.003 (0.032)\tData 0.000 (0.020)\tLoss 0.2685 (0.3859)\tPrec@1 93.750 (91.760)\tPrec@5 100.000 (99.670)\t\n",
            "\n",
            "Results - Epoch: 297\n",
            "Training Loss 0.0166 \tTraining Prec@1 99.559 \tTraining Prec@5 100.000 \tValidation Loss 0.3859 \tValidation Prec@1 91.760 \tValidation Prec@5 99.670 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 298\n",
            "\n",
            "TRAINING - Epoch: [297][0/390]\tTime 0.322 (0.322)\tData 0.264 (0.264)\tLoss 0.0141 (0.0141)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][10/390]\tTime 0.040 (0.067)\tData 0.000 (0.026)\tLoss 0.0109 (0.0158)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][20/390]\tTime 0.058 (0.056)\tData 0.008 (0.015)\tLoss 0.0237 (0.0166)\tPrec@1 98.438 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][30/390]\tTime 0.048 (0.054)\tData 0.003 (0.012)\tLoss 0.0515 (0.0179)\tPrec@1 96.875 (99.420)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][40/390]\tTime 0.043 (0.051)\tData 0.002 (0.010)\tLoss 0.0158 (0.0181)\tPrec@1 100.000 (99.447)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][50/390]\tTime 0.057 (0.049)\tData 0.017 (0.009)\tLoss 0.0519 (0.0187)\tPrec@1 98.438 (99.449)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][60/390]\tTime 0.040 (0.050)\tData 0.000 (0.008)\tLoss 0.0095 (0.0175)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][70/390]\tTime 0.091 (0.049)\tData 0.047 (0.009)\tLoss 0.0051 (0.0168)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][80/390]\tTime 0.033 (0.048)\tData 0.005 (0.009)\tLoss 0.0201 (0.0168)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][90/390]\tTime 0.049 (0.049)\tData 0.005 (0.008)\tLoss 0.0117 (0.0167)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][100/390]\tTime 0.047 (0.048)\tData 0.000 (0.008)\tLoss 0.0055 (0.0163)\tPrec@1 100.000 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][110/390]\tTime 0.044 (0.048)\tData 0.004 (0.007)\tLoss 0.0255 (0.0168)\tPrec@1 99.219 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][120/390]\tTime 0.041 (0.047)\tData 0.004 (0.007)\tLoss 0.0292 (0.0170)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][130/390]\tTime 0.047 (0.047)\tData 0.006 (0.007)\tLoss 0.0092 (0.0168)\tPrec@1 100.000 (99.589)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][140/390]\tTime 0.037 (0.047)\tData 0.005 (0.006)\tLoss 0.0124 (0.0165)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][150/390]\tTime 0.036 (0.046)\tData 0.007 (0.006)\tLoss 0.0144 (0.0164)\tPrec@1 99.219 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][160/390]\tTime 0.053 (0.046)\tData 0.000 (0.006)\tLoss 0.0121 (0.0164)\tPrec@1 100.000 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][170/390]\tTime 0.053 (0.046)\tData 0.001 (0.006)\tLoss 0.0248 (0.0166)\tPrec@1 98.438 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][180/390]\tTime 0.043 (0.046)\tData 0.001 (0.006)\tLoss 0.0069 (0.0168)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][190/390]\tTime 0.053 (0.047)\tData 0.000 (0.006)\tLoss 0.0087 (0.0171)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][200/390]\tTime 0.028 (0.046)\tData 0.000 (0.006)\tLoss 0.0225 (0.0175)\tPrec@1 99.219 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][210/390]\tTime 0.050 (0.046)\tData 0.004 (0.006)\tLoss 0.0142 (0.0174)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][220/390]\tTime 0.041 (0.046)\tData 0.008 (0.006)\tLoss 0.0172 (0.0174)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][230/390]\tTime 0.030 (0.046)\tData 0.000 (0.006)\tLoss 0.0068 (0.0172)\tPrec@1 100.000 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][240/390]\tTime 0.047 (0.046)\tData 0.017 (0.006)\tLoss 0.0066 (0.0171)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][250/390]\tTime 0.056 (0.046)\tData 0.009 (0.006)\tLoss 0.0113 (0.0169)\tPrec@1 100.000 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][260/390]\tTime 0.044 (0.046)\tData 0.000 (0.006)\tLoss 0.0154 (0.0169)\tPrec@1 99.219 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][270/390]\tTime 0.043 (0.046)\tData 0.000 (0.006)\tLoss 0.0154 (0.0166)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][280/390]\tTime 0.033 (0.046)\tData 0.000 (0.006)\tLoss 0.0166 (0.0168)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][290/390]\tTime 0.035 (0.046)\tData 0.005 (0.006)\tLoss 0.0307 (0.0168)\tPrec@1 98.438 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][300/390]\tTime 0.027 (0.046)\tData 0.000 (0.006)\tLoss 0.0067 (0.0167)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][310/390]\tTime 0.030 (0.045)\tData 0.000 (0.006)\tLoss 0.0133 (0.0166)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][320/390]\tTime 0.051 (0.046)\tData 0.002 (0.006)\tLoss 0.0117 (0.0167)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][330/390]\tTime 0.051 (0.045)\tData 0.005 (0.006)\tLoss 0.0194 (0.0167)\tPrec@1 99.219 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][340/390]\tTime 0.033 (0.045)\tData 0.001 (0.006)\tLoss 0.0123 (0.0167)\tPrec@1 99.219 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][350/390]\tTime 0.046 (0.045)\tData 0.008 (0.006)\tLoss 0.0143 (0.0169)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][360/390]\tTime 0.061 (0.046)\tData 0.004 (0.006)\tLoss 0.0093 (0.0170)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][370/390]\tTime 0.040 (0.046)\tData 0.004 (0.005)\tLoss 0.0104 (0.0170)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][380/390]\tTime 0.042 (0.046)\tData 0.005 (0.005)\tLoss 0.0057 (0.0169)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [297][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0115 (0.0170)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [297][0/79]\tTime 0.223 (0.223)\tData 0.210 (0.210)\tLoss 0.2741 (0.2741)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [297][10/79]\tTime 0.053 (0.048)\tData 0.046 (0.036)\tLoss 0.2540 (0.3659)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [297][20/79]\tTime 0.011 (0.039)\tData 0.000 (0.026)\tLoss 0.5283 (0.4060)\tPrec@1 90.625 (91.741)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [297][30/79]\tTime 0.049 (0.035)\tData 0.043 (0.023)\tLoss 0.0980 (0.3940)\tPrec@1 97.656 (92.061)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [297][40/79]\tTime 0.023 (0.033)\tData 0.005 (0.021)\tLoss 0.2355 (0.3974)\tPrec@1 92.969 (92.016)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [297][50/79]\tTime 0.046 (0.033)\tData 0.040 (0.021)\tLoss 0.4557 (0.3904)\tPrec@1 89.844 (91.942)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [297][60/79]\tTime 0.019 (0.032)\tData 0.004 (0.020)\tLoss 0.6325 (0.3959)\tPrec@1 92.188 (91.803)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [297][70/79]\tTime 0.062 (0.031)\tData 0.057 (0.019)\tLoss 0.3986 (0.3884)\tPrec@1 89.844 (91.758)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [297][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.018)\tLoss 0.2747 (0.3854)\tPrec@1 93.750 (91.780)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 298\n",
            "Training Loss 0.0170 \tTraining Prec@1 99.517 \tTraining Prec@5 100.000 \tValidation Loss 0.3854 \tValidation Prec@1 91.780 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 299\n",
            "\n",
            "TRAINING - Epoch: [298][0/390]\tTime 0.361 (0.361)\tData 0.298 (0.298)\tLoss 0.0480 (0.0480)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][10/390]\tTime 0.048 (0.069)\tData 0.001 (0.028)\tLoss 0.0098 (0.0147)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][20/390]\tTime 0.054 (0.057)\tData 0.005 (0.016)\tLoss 0.0030 (0.0141)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][30/390]\tTime 0.042 (0.052)\tData 0.001 (0.012)\tLoss 0.0260 (0.0171)\tPrec@1 99.219 (99.395)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][40/390]\tTime 0.041 (0.049)\tData 0.001 (0.009)\tLoss 0.0517 (0.0189)\tPrec@1 98.438 (99.333)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][50/390]\tTime 0.052 (0.049)\tData 0.024 (0.010)\tLoss 0.0043 (0.0187)\tPrec@1 100.000 (99.326)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][60/390]\tTime 0.036 (0.049)\tData 0.000 (0.009)\tLoss 0.0198 (0.0190)\tPrec@1 99.219 (99.360)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][70/390]\tTime 0.051 (0.049)\tData 0.000 (0.010)\tLoss 0.0182 (0.0185)\tPrec@1 100.000 (99.406)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][80/390]\tTime 0.051 (0.048)\tData 0.013 (0.009)\tLoss 0.0159 (0.0189)\tPrec@1 100.000 (99.412)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][90/390]\tTime 0.063 (0.048)\tData 0.032 (0.009)\tLoss 0.0076 (0.0187)\tPrec@1 100.000 (99.433)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][100/390]\tTime 0.050 (0.048)\tData 0.002 (0.008)\tLoss 0.0114 (0.0181)\tPrec@1 100.000 (99.466)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][110/390]\tTime 0.038 (0.047)\tData 0.005 (0.008)\tLoss 0.0376 (0.0186)\tPrec@1 98.438 (99.430)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][120/390]\tTime 0.046 (0.047)\tData 0.000 (0.008)\tLoss 0.0128 (0.0184)\tPrec@1 99.219 (99.425)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][130/390]\tTime 0.046 (0.047)\tData 0.009 (0.007)\tLoss 0.0091 (0.0189)\tPrec@1 100.000 (99.404)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][140/390]\tTime 0.042 (0.046)\tData 0.002 (0.007)\tLoss 0.0067 (0.0187)\tPrec@1 100.000 (99.413)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][150/390]\tTime 0.057 (0.046)\tData 0.000 (0.007)\tLoss 0.0053 (0.0181)\tPrec@1 100.000 (99.446)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][160/390]\tTime 0.058 (0.046)\tData 0.003 (0.007)\tLoss 0.0095 (0.0179)\tPrec@1 100.000 (99.457)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][170/390]\tTime 0.049 (0.046)\tData 0.002 (0.007)\tLoss 0.0159 (0.0179)\tPrec@1 100.000 (99.447)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][180/390]\tTime 0.054 (0.046)\tData 0.005 (0.006)\tLoss 0.0109 (0.0179)\tPrec@1 100.000 (99.456)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][190/390]\tTime 0.048 (0.046)\tData 0.002 (0.006)\tLoss 0.0583 (0.0180)\tPrec@1 99.219 (99.460)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][200/390]\tTime 0.044 (0.046)\tData 0.002 (0.006)\tLoss 0.0180 (0.0177)\tPrec@1 99.219 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][210/390]\tTime 0.037 (0.046)\tData 0.007 (0.006)\tLoss 0.0281 (0.0180)\tPrec@1 99.219 (99.459)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][220/390]\tTime 0.040 (0.046)\tData 0.000 (0.006)\tLoss 0.0152 (0.0180)\tPrec@1 99.219 (99.459)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][230/390]\tTime 0.048 (0.046)\tData 0.000 (0.006)\tLoss 0.0388 (0.0182)\tPrec@1 99.219 (99.462)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][240/390]\tTime 0.047 (0.046)\tData 0.001 (0.006)\tLoss 0.0035 (0.0181)\tPrec@1 100.000 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][250/390]\tTime 0.041 (0.046)\tData 0.013 (0.006)\tLoss 0.0096 (0.0181)\tPrec@1 100.000 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][260/390]\tTime 0.064 (0.046)\tData 0.007 (0.006)\tLoss 0.0190 (0.0181)\tPrec@1 99.219 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][270/390]\tTime 0.030 (0.046)\tData 0.003 (0.006)\tLoss 0.0178 (0.0180)\tPrec@1 99.219 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][280/390]\tTime 0.044 (0.046)\tData 0.000 (0.006)\tLoss 0.0044 (0.0180)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][290/390]\tTime 0.033 (0.046)\tData 0.000 (0.006)\tLoss 0.0325 (0.0179)\tPrec@1 98.438 (99.482)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][300/390]\tTime 0.053 (0.046)\tData 0.014 (0.006)\tLoss 0.0059 (0.0181)\tPrec@1 100.000 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][310/390]\tTime 0.056 (0.046)\tData 0.012 (0.006)\tLoss 0.0121 (0.0181)\tPrec@1 100.000 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][320/390]\tTime 0.038 (0.046)\tData 0.000 (0.005)\tLoss 0.0138 (0.0180)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][330/390]\tTime 0.040 (0.046)\tData 0.003 (0.005)\tLoss 0.0246 (0.0178)\tPrec@1 99.219 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][340/390]\tTime 0.040 (0.046)\tData 0.002 (0.005)\tLoss 0.0300 (0.0177)\tPrec@1 98.438 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][350/390]\tTime 0.048 (0.045)\tData 0.000 (0.005)\tLoss 0.0172 (0.0175)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][360/390]\tTime 0.037 (0.045)\tData 0.003 (0.005)\tLoss 0.0234 (0.0175)\tPrec@1 99.219 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][370/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0138 (0.0174)\tPrec@1 99.219 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][380/390]\tTime 0.037 (0.045)\tData 0.003 (0.005)\tLoss 0.0530 (0.0176)\tPrec@1 97.656 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [298][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0119 (0.0174)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [298][0/79]\tTime 0.195 (0.195)\tData 0.174 (0.174)\tLoss 0.2900 (0.2900)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [298][10/79]\tTime 0.012 (0.047)\tData 0.000 (0.035)\tLoss 0.2584 (0.3689)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [298][20/79]\tTime 0.024 (0.037)\tData 0.003 (0.025)\tLoss 0.5318 (0.4114)\tPrec@1 89.844 (91.555)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [298][30/79]\tTime 0.025 (0.035)\tData 0.005 (0.023)\tLoss 0.1053 (0.3996)\tPrec@1 97.656 (91.860)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [298][40/79]\tTime 0.020 (0.033)\tData 0.005 (0.020)\tLoss 0.2509 (0.4005)\tPrec@1 89.062 (91.806)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [298][50/79]\tTime 0.040 (0.032)\tData 0.032 (0.020)\tLoss 0.4364 (0.3931)\tPrec@1 90.625 (91.743)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [298][60/79]\tTime 0.014 (0.031)\tData 0.004 (0.019)\tLoss 0.6500 (0.3978)\tPrec@1 93.750 (91.662)\tPrec@5 99.219 (99.680)\t\n",
            "EVALUATING - Epoch: [298][70/79]\tTime 0.015 (0.031)\tData 0.002 (0.019)\tLoss 0.3923 (0.3897)\tPrec@1 89.844 (91.604)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [298][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.018)\tLoss 0.2317 (0.3865)\tPrec@1 93.750 (91.630)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 299\n",
            "Training Loss 0.0174 \tTraining Prec@1 99.499 \tTraining Prec@5 100.000 \tValidation Loss 0.3865 \tValidation Prec@1 91.630 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 300\n",
            "\n",
            "TRAINING - Epoch: [299][0/390]\tTime 0.257 (0.257)\tData 0.203 (0.203)\tLoss 0.0310 (0.0310)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][10/390]\tTime 0.039 (0.068)\tData 0.000 (0.030)\tLoss 0.0456 (0.0218)\tPrec@1 99.219 (99.290)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][20/390]\tTime 0.054 (0.057)\tData 0.003 (0.020)\tLoss 0.0150 (0.0193)\tPrec@1 100.000 (99.405)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][30/390]\tTime 0.032 (0.054)\tData 0.000 (0.016)\tLoss 0.0122 (0.0168)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][40/390]\tTime 0.039 (0.051)\tData 0.004 (0.013)\tLoss 0.0131 (0.0168)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][50/390]\tTime 0.039 (0.051)\tData 0.000 (0.011)\tLoss 0.0136 (0.0162)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][60/390]\tTime 0.043 (0.050)\tData 0.000 (0.010)\tLoss 0.0095 (0.0159)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][70/390]\tTime 0.057 (0.049)\tData 0.010 (0.010)\tLoss 0.0172 (0.0164)\tPrec@1 99.219 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][80/390]\tTime 0.040 (0.048)\tData 0.002 (0.009)\tLoss 0.0069 (0.0159)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][90/390]\tTime 0.039 (0.047)\tData 0.005 (0.009)\tLoss 0.0151 (0.0159)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][100/390]\tTime 0.045 (0.048)\tData 0.003 (0.008)\tLoss 0.0384 (0.0163)\tPrec@1 97.656 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][110/390]\tTime 0.047 (0.047)\tData 0.001 (0.008)\tLoss 0.0066 (0.0159)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][120/390]\tTime 0.038 (0.047)\tData 0.007 (0.008)\tLoss 0.0076 (0.0158)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][130/390]\tTime 0.033 (0.047)\tData 0.000 (0.007)\tLoss 0.0262 (0.0160)\tPrec@1 98.438 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][140/390]\tTime 0.031 (0.046)\tData 0.000 (0.007)\tLoss 0.0183 (0.0165)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][150/390]\tTime 0.036 (0.046)\tData 0.000 (0.007)\tLoss 0.0155 (0.0165)\tPrec@1 99.219 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][160/390]\tTime 0.038 (0.046)\tData 0.006 (0.007)\tLoss 0.0114 (0.0164)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][170/390]\tTime 0.046 (0.046)\tData 0.000 (0.007)\tLoss 0.0185 (0.0166)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][180/390]\tTime 0.037 (0.046)\tData 0.004 (0.007)\tLoss 0.0146 (0.0166)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][190/390]\tTime 0.038 (0.046)\tData 0.000 (0.007)\tLoss 0.0249 (0.0168)\tPrec@1 99.219 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][200/390]\tTime 0.066 (0.046)\tData 0.011 (0.007)\tLoss 0.0458 (0.0169)\tPrec@1 98.438 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][210/390]\tTime 0.038 (0.046)\tData 0.007 (0.007)\tLoss 0.0100 (0.0169)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][220/390]\tTime 0.037 (0.045)\tData 0.001 (0.006)\tLoss 0.0295 (0.0172)\tPrec@1 98.438 (99.487)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][230/390]\tTime 0.049 (0.045)\tData 0.003 (0.006)\tLoss 0.0217 (0.0172)\tPrec@1 99.219 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][240/390]\tTime 0.033 (0.046)\tData 0.000 (0.006)\tLoss 0.0263 (0.0171)\tPrec@1 98.438 (99.485)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][250/390]\tTime 0.048 (0.046)\tData 0.007 (0.006)\tLoss 0.0181 (0.0174)\tPrec@1 99.219 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][260/390]\tTime 0.049 (0.046)\tData 0.000 (0.006)\tLoss 0.0075 (0.0172)\tPrec@1 100.000 (99.485)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][270/390]\tTime 0.049 (0.046)\tData 0.002 (0.006)\tLoss 0.0054 (0.0171)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][280/390]\tTime 0.044 (0.046)\tData 0.000 (0.006)\tLoss 0.0142 (0.0171)\tPrec@1 100.000 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][290/390]\tTime 0.029 (0.046)\tData 0.005 (0.006)\tLoss 0.0053 (0.0171)\tPrec@1 100.000 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][300/390]\tTime 0.022 (0.045)\tData 0.000 (0.006)\tLoss 0.0229 (0.0173)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][310/390]\tTime 0.034 (0.045)\tData 0.002 (0.006)\tLoss 0.0096 (0.0174)\tPrec@1 100.000 (99.485)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][320/390]\tTime 0.036 (0.045)\tData 0.000 (0.006)\tLoss 0.0106 (0.0173)\tPrec@1 100.000 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][330/390]\tTime 0.052 (0.045)\tData 0.014 (0.006)\tLoss 0.0130 (0.0172)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][340/390]\tTime 0.060 (0.046)\tData 0.009 (0.006)\tLoss 0.0291 (0.0173)\tPrec@1 99.219 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][350/390]\tTime 0.044 (0.046)\tData 0.004 (0.006)\tLoss 0.0463 (0.0174)\tPrec@1 97.656 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][360/390]\tTime 0.050 (0.046)\tData 0.002 (0.006)\tLoss 0.0205 (0.0174)\tPrec@1 99.219 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][370/390]\tTime 0.057 (0.046)\tData 0.007 (0.006)\tLoss 0.0025 (0.0174)\tPrec@1 100.000 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][380/390]\tTime 0.045 (0.046)\tData 0.000 (0.006)\tLoss 0.0075 (0.0173)\tPrec@1 100.000 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [299][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.006)\tLoss 0.0081 (0.0173)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [299][0/79]\tTime 0.256 (0.256)\tData 0.241 (0.241)\tLoss 0.2874 (0.2874)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [299][10/79]\tTime 0.020 (0.045)\tData 0.004 (0.033)\tLoss 0.2642 (0.3734)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [299][20/79]\tTime 0.038 (0.037)\tData 0.032 (0.025)\tLoss 0.5274 (0.4111)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [299][30/79]\tTime 0.030 (0.034)\tData 0.005 (0.022)\tLoss 0.0934 (0.3972)\tPrec@1 97.656 (92.036)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [299][40/79]\tTime 0.062 (0.033)\tData 0.042 (0.022)\tLoss 0.2437 (0.3993)\tPrec@1 89.844 (91.978)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [299][50/79]\tTime 0.007 (0.033)\tData 0.001 (0.021)\tLoss 0.4492 (0.3923)\tPrec@1 90.625 (91.866)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [299][60/79]\tTime 0.017 (0.031)\tData 0.000 (0.019)\tLoss 0.6381 (0.3972)\tPrec@1 92.969 (91.790)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [299][70/79]\tTime 0.014 (0.032)\tData 0.001 (0.019)\tLoss 0.4042 (0.3895)\tPrec@1 89.062 (91.725)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [299][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.018)\tLoss 0.2661 (0.3865)\tPrec@1 93.750 (91.720)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 300\n",
            "Training Loss 0.0173 \tTraining Prec@1 99.497 \tTraining Prec@5 100.000 \tValidation Loss 0.3865 \tValidation Prec@1 91.720 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 301\n",
            "\n",
            "TRAINING - Epoch: [300][0/390]\tTime 0.340 (0.340)\tData 0.302 (0.302)\tLoss 0.0090 (0.0090)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][10/390]\tTime 0.040 (0.070)\tData 0.005 (0.031)\tLoss 0.0257 (0.0169)\tPrec@1 99.219 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][20/390]\tTime 0.052 (0.057)\tData 0.005 (0.018)\tLoss 0.0071 (0.0156)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][30/390]\tTime 0.028 (0.053)\tData 0.000 (0.013)\tLoss 0.0316 (0.0170)\tPrec@1 99.219 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][40/390]\tTime 0.044 (0.052)\tData 0.000 (0.011)\tLoss 0.0077 (0.0169)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][50/390]\tTime 0.038 (0.051)\tData 0.000 (0.010)\tLoss 0.0416 (0.0175)\tPrec@1 98.438 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][60/390]\tTime 0.046 (0.049)\tData 0.000 (0.009)\tLoss 0.0133 (0.0171)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][70/390]\tTime 0.052 (0.049)\tData 0.003 (0.008)\tLoss 0.0178 (0.0170)\tPrec@1 99.219 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][80/390]\tTime 0.042 (0.048)\tData 0.000 (0.007)\tLoss 0.0263 (0.0169)\tPrec@1 98.438 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][90/390]\tTime 0.054 (0.048)\tData 0.005 (0.007)\tLoss 0.0052 (0.0169)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][100/390]\tTime 0.046 (0.047)\tData 0.001 (0.007)\tLoss 0.0186 (0.0171)\tPrec@1 99.219 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][110/390]\tTime 0.044 (0.048)\tData 0.000 (0.007)\tLoss 0.0144 (0.0177)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][120/390]\tTime 0.043 (0.048)\tData 0.000 (0.006)\tLoss 0.0218 (0.0180)\tPrec@1 99.219 (99.464)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][130/390]\tTime 0.047 (0.047)\tData 0.005 (0.006)\tLoss 0.0128 (0.0182)\tPrec@1 100.000 (99.463)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][140/390]\tTime 0.043 (0.047)\tData 0.002 (0.006)\tLoss 0.0147 (0.0179)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][150/390]\tTime 0.052 (0.047)\tData 0.005 (0.006)\tLoss 0.0054 (0.0180)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][160/390]\tTime 0.048 (0.047)\tData 0.012 (0.006)\tLoss 0.0120 (0.0176)\tPrec@1 100.000 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][170/390]\tTime 0.035 (0.047)\tData 0.001 (0.006)\tLoss 0.0210 (0.0177)\tPrec@1 98.438 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][180/390]\tTime 0.043 (0.047)\tData 0.002 (0.006)\tLoss 0.0070 (0.0177)\tPrec@1 100.000 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][190/390]\tTime 0.046 (0.046)\tData 0.004 (0.006)\tLoss 0.0068 (0.0174)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][200/390]\tTime 0.036 (0.046)\tData 0.004 (0.006)\tLoss 0.0049 (0.0172)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][210/390]\tTime 0.039 (0.046)\tData 0.004 (0.006)\tLoss 0.0544 (0.0177)\tPrec@1 96.875 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][220/390]\tTime 0.040 (0.046)\tData 0.000 (0.006)\tLoss 0.0159 (0.0179)\tPrec@1 99.219 (99.456)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][230/390]\tTime 0.038 (0.046)\tData 0.001 (0.006)\tLoss 0.0089 (0.0178)\tPrec@1 100.000 (99.469)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][240/390]\tTime 0.040 (0.046)\tData 0.001 (0.006)\tLoss 0.0135 (0.0175)\tPrec@1 100.000 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][250/390]\tTime 0.047 (0.046)\tData 0.014 (0.006)\tLoss 0.0080 (0.0173)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][260/390]\tTime 0.048 (0.046)\tData 0.009 (0.006)\tLoss 0.0086 (0.0174)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][270/390]\tTime 0.047 (0.046)\tData 0.000 (0.006)\tLoss 0.0044 (0.0174)\tPrec@1 100.000 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][280/390]\tTime 0.037 (0.046)\tData 0.010 (0.006)\tLoss 0.0248 (0.0172)\tPrec@1 99.219 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][290/390]\tTime 0.046 (0.046)\tData 0.000 (0.006)\tLoss 0.0098 (0.0174)\tPrec@1 99.219 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][300/390]\tTime 0.041 (0.046)\tData 0.010 (0.006)\tLoss 0.0186 (0.0177)\tPrec@1 99.219 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][310/390]\tTime 0.049 (0.046)\tData 0.016 (0.006)\tLoss 0.0192 (0.0177)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][320/390]\tTime 0.037 (0.046)\tData 0.006 (0.006)\tLoss 0.0096 (0.0177)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][330/390]\tTime 0.037 (0.046)\tData 0.002 (0.006)\tLoss 0.0078 (0.0177)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][340/390]\tTime 0.058 (0.046)\tData 0.003 (0.006)\tLoss 0.0025 (0.0176)\tPrec@1 100.000 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][350/390]\tTime 0.057 (0.046)\tData 0.011 (0.005)\tLoss 0.0339 (0.0178)\tPrec@1 98.438 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][360/390]\tTime 0.041 (0.045)\tData 0.001 (0.005)\tLoss 0.0150 (0.0176)\tPrec@1 99.219 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][370/390]\tTime 0.050 (0.045)\tData 0.009 (0.005)\tLoss 0.0079 (0.0175)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][380/390]\tTime 0.044 (0.045)\tData 0.000 (0.005)\tLoss 0.0181 (0.0176)\tPrec@1 100.000 (99.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [300][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0087 (0.0175)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [300][0/79]\tTime 0.197 (0.197)\tData 0.181 (0.181)\tLoss 0.2875 (0.2875)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [300][10/79]\tTime 0.029 (0.047)\tData 0.022 (0.035)\tLoss 0.2534 (0.3692)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [300][20/79]\tTime 0.046 (0.038)\tData 0.041 (0.028)\tLoss 0.5253 (0.4098)\tPrec@1 89.844 (91.667)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [300][30/79]\tTime 0.021 (0.035)\tData 0.005 (0.025)\tLoss 0.0974 (0.3974)\tPrec@1 97.656 (92.011)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [300][40/79]\tTime 0.050 (0.034)\tData 0.044 (0.024)\tLoss 0.2367 (0.3980)\tPrec@1 91.406 (91.978)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [300][50/79]\tTime 0.036 (0.033)\tData 0.028 (0.023)\tLoss 0.4353 (0.3908)\tPrec@1 90.625 (91.896)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [300][60/79]\tTime 0.021 (0.033)\tData 0.007 (0.022)\tLoss 0.6472 (0.3955)\tPrec@1 92.969 (91.803)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [300][70/79]\tTime 0.059 (0.032)\tData 0.053 (0.021)\tLoss 0.3968 (0.3878)\tPrec@1 89.844 (91.747)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [300][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.019)\tLoss 0.2738 (0.3850)\tPrec@1 93.750 (91.740)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 301\n",
            "Training Loss 0.0175 \tTraining Prec@1 99.499 \tTraining Prec@5 100.000 \tValidation Loss 0.3850 \tValidation Prec@1 91.740 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 302\n",
            "\n",
            "TRAINING - Epoch: [301][0/390]\tTime 0.326 (0.326)\tData 0.266 (0.266)\tLoss 0.0059 (0.0059)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][10/390]\tTime 0.053 (0.069)\tData 0.002 (0.028)\tLoss 0.0091 (0.0143)\tPrec@1 100.000 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][20/390]\tTime 0.042 (0.058)\tData 0.000 (0.016)\tLoss 0.0241 (0.0163)\tPrec@1 99.219 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][30/390]\tTime 0.046 (0.055)\tData 0.001 (0.012)\tLoss 0.0170 (0.0158)\tPrec@1 100.000 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][40/390]\tTime 0.052 (0.053)\tData 0.005 (0.010)\tLoss 0.0245 (0.0147)\tPrec@1 99.219 (99.657)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][50/390]\tTime 0.039 (0.051)\tData 0.001 (0.009)\tLoss 0.0053 (0.0147)\tPrec@1 100.000 (99.694)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][60/390]\tTime 0.041 (0.050)\tData 0.000 (0.007)\tLoss 0.0205 (0.0151)\tPrec@1 99.219 (99.680)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][70/390]\tTime 0.038 (0.049)\tData 0.005 (0.007)\tLoss 0.0264 (0.0156)\tPrec@1 99.219 (99.626)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][80/390]\tTime 0.039 (0.049)\tData 0.005 (0.007)\tLoss 0.0155 (0.0153)\tPrec@1 100.000 (99.643)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][90/390]\tTime 0.039 (0.048)\tData 0.007 (0.006)\tLoss 0.0243 (0.0158)\tPrec@1 99.219 (99.614)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][100/390]\tTime 0.060 (0.048)\tData 0.013 (0.006)\tLoss 0.0092 (0.0159)\tPrec@1 100.000 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][110/390]\tTime 0.041 (0.048)\tData 0.001 (0.006)\tLoss 0.0420 (0.0163)\tPrec@1 98.438 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][120/390]\tTime 0.048 (0.048)\tData 0.000 (0.006)\tLoss 0.0218 (0.0159)\tPrec@1 99.219 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][130/390]\tTime 0.052 (0.048)\tData 0.003 (0.006)\tLoss 0.0199 (0.0158)\tPrec@1 99.219 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][140/390]\tTime 0.056 (0.048)\tData 0.004 (0.006)\tLoss 0.0095 (0.0158)\tPrec@1 100.000 (99.607)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][150/390]\tTime 0.032 (0.047)\tData 0.000 (0.005)\tLoss 0.0128 (0.0161)\tPrec@1 100.000 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][160/390]\tTime 0.053 (0.047)\tData 0.000 (0.005)\tLoss 0.0206 (0.0159)\tPrec@1 100.000 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][170/390]\tTime 0.067 (0.047)\tData 0.026 (0.005)\tLoss 0.0213 (0.0160)\tPrec@1 99.219 (99.593)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][180/390]\tTime 0.054 (0.047)\tData 0.006 (0.005)\tLoss 0.0170 (0.0162)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][190/390]\tTime 0.046 (0.047)\tData 0.000 (0.005)\tLoss 0.0105 (0.0163)\tPrec@1 100.000 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][200/390]\tTime 0.044 (0.047)\tData 0.005 (0.005)\tLoss 0.0394 (0.0163)\tPrec@1 97.656 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][210/390]\tTime 0.035 (0.047)\tData 0.000 (0.005)\tLoss 0.0161 (0.0163)\tPrec@1 99.219 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][220/390]\tTime 0.034 (0.047)\tData 0.002 (0.005)\tLoss 0.0094 (0.0163)\tPrec@1 100.000 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][230/390]\tTime 0.032 (0.047)\tData 0.000 (0.005)\tLoss 0.0095 (0.0165)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][240/390]\tTime 0.051 (0.047)\tData 0.003 (0.005)\tLoss 0.0297 (0.0167)\tPrec@1 98.438 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][250/390]\tTime 0.035 (0.046)\tData 0.006 (0.005)\tLoss 0.0071 (0.0166)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][260/390]\tTime 0.059 (0.047)\tData 0.008 (0.005)\tLoss 0.0077 (0.0165)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][270/390]\tTime 0.051 (0.047)\tData 0.004 (0.005)\tLoss 0.0052 (0.0165)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][280/390]\tTime 0.040 (0.046)\tData 0.010 (0.005)\tLoss 0.0245 (0.0168)\tPrec@1 99.219 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][290/390]\tTime 0.042 (0.046)\tData 0.000 (0.005)\tLoss 0.0529 (0.0171)\tPrec@1 97.656 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][300/390]\tTime 0.032 (0.046)\tData 0.000 (0.005)\tLoss 0.0065 (0.0173)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][310/390]\tTime 0.046 (0.046)\tData 0.003 (0.005)\tLoss 0.0172 (0.0172)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][320/390]\tTime 0.053 (0.046)\tData 0.005 (0.005)\tLoss 0.0072 (0.0173)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][330/390]\tTime 0.047 (0.046)\tData 0.000 (0.005)\tLoss 0.0080 (0.0173)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][340/390]\tTime 0.050 (0.046)\tData 0.001 (0.005)\tLoss 0.0312 (0.0174)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][350/390]\tTime 0.047 (0.046)\tData 0.005 (0.005)\tLoss 0.0076 (0.0174)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][360/390]\tTime 0.047 (0.046)\tData 0.000 (0.005)\tLoss 0.0123 (0.0174)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][370/390]\tTime 0.043 (0.046)\tData 0.004 (0.005)\tLoss 0.0121 (0.0173)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][380/390]\tTime 0.058 (0.046)\tData 0.001 (0.005)\tLoss 0.0133 (0.0172)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [301][389/390]\tTime 0.019 (0.045)\tData 0.000 (0.005)\tLoss 0.0055 (0.0172)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [301][0/79]\tTime 0.241 (0.241)\tData 0.228 (0.228)\tLoss 0.2668 (0.2668)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [301][10/79]\tTime 0.018 (0.044)\tData 0.005 (0.030)\tLoss 0.2761 (0.3721)\tPrec@1 91.406 (92.472)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [301][20/79]\tTime 0.056 (0.039)\tData 0.047 (0.025)\tLoss 0.5224 (0.4092)\tPrec@1 89.844 (91.778)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [301][30/79]\tTime 0.017 (0.034)\tData 0.002 (0.021)\tLoss 0.0925 (0.3958)\tPrec@1 97.656 (92.112)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [301][40/79]\tTime 0.043 (0.033)\tData 0.038 (0.021)\tLoss 0.2434 (0.3985)\tPrec@1 90.625 (91.978)\tPrec@5 99.219 (99.486)\t\n",
            "EVALUATING - Epoch: [301][50/79]\tTime 0.029 (0.031)\tData 0.022 (0.019)\tLoss 0.4371 (0.3913)\tPrec@1 90.625 (91.881)\tPrec@5 100.000 (99.586)\t\n",
            "EVALUATING - Epoch: [301][60/79]\tTime 0.011 (0.031)\tData 0.000 (0.020)\tLoss 0.6282 (0.3964)\tPrec@1 92.969 (91.803)\tPrec@5 100.000 (99.629)\t\n",
            "EVALUATING - Epoch: [301][70/79]\tTime 0.064 (0.032)\tData 0.058 (0.020)\tLoss 0.3843 (0.3884)\tPrec@1 90.625 (91.780)\tPrec@5 100.000 (99.670)\t\n",
            "EVALUATING - Epoch: [301][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.018)\tLoss 0.2409 (0.3856)\tPrec@1 93.750 (91.820)\tPrec@5 100.000 (99.670)\t\n",
            "\n",
            "Results - Epoch: 302\n",
            "Training Loss 0.0172 \tTraining Prec@1 99.537 \tTraining Prec@5 100.000 \tValidation Loss 0.3856 \tValidation Prec@1 91.820 \tValidation Prec@5 99.670 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 303\n",
            "\n",
            "TRAINING - Epoch: [302][0/390]\tTime 0.353 (0.353)\tData 0.304 (0.304)\tLoss 0.0147 (0.0147)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][10/390]\tTime 0.048 (0.075)\tData 0.001 (0.032)\tLoss 0.0096 (0.0133)\tPrec@1 100.000 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][20/390]\tTime 0.045 (0.062)\tData 0.004 (0.018)\tLoss 0.0160 (0.0134)\tPrec@1 99.219 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][30/390]\tTime 0.056 (0.056)\tData 0.001 (0.014)\tLoss 0.0117 (0.0136)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][40/390]\tTime 0.044 (0.053)\tData 0.000 (0.011)\tLoss 0.0143 (0.0147)\tPrec@1 99.219 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][50/390]\tTime 0.049 (0.053)\tData 0.011 (0.010)\tLoss 0.0076 (0.0150)\tPrec@1 100.000 (99.617)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][60/390]\tTime 0.036 (0.050)\tData 0.007 (0.009)\tLoss 0.0222 (0.0145)\tPrec@1 98.438 (99.641)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][70/390]\tTime 0.032 (0.050)\tData 0.001 (0.009)\tLoss 0.0137 (0.0152)\tPrec@1 99.219 (99.604)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][80/390]\tTime 0.035 (0.050)\tData 0.000 (0.008)\tLoss 0.0421 (0.0153)\tPrec@1 98.438 (99.614)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][90/390]\tTime 0.044 (0.049)\tData 0.002 (0.008)\tLoss 0.0070 (0.0156)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][100/390]\tTime 0.050 (0.049)\tData 0.000 (0.008)\tLoss 0.0190 (0.0158)\tPrec@1 99.219 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][110/390]\tTime 0.031 (0.048)\tData 0.000 (0.007)\tLoss 0.0309 (0.0159)\tPrec@1 98.438 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [302][120/390]\tTime 0.038 (0.048)\tData 0.004 (0.007)\tLoss 0.0304 (0.0161)\tPrec@1 99.219 (99.561)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [302][130/390]\tTime 0.031 (0.047)\tData 0.003 (0.007)\tLoss 0.0079 (0.0161)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [302][140/390]\tTime 0.060 (0.047)\tData 0.003 (0.007)\tLoss 0.0204 (0.0162)\tPrec@1 98.438 (99.557)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [302][150/390]\tTime 0.045 (0.047)\tData 0.008 (0.006)\tLoss 0.0097 (0.0160)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [302][160/390]\tTime 0.053 (0.047)\tData 0.001 (0.007)\tLoss 0.0080 (0.0160)\tPrec@1 100.000 (99.568)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [302][170/390]\tTime 0.046 (0.047)\tData 0.005 (0.006)\tLoss 0.0117 (0.0162)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [302][180/390]\tTime 0.044 (0.047)\tData 0.000 (0.006)\tLoss 0.0364 (0.0161)\tPrec@1 98.438 (99.551)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [302][190/390]\tTime 0.046 (0.047)\tData 0.001 (0.006)\tLoss 0.0116 (0.0161)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [302][200/390]\tTime 0.042 (0.047)\tData 0.000 (0.006)\tLoss 0.0209 (0.0159)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [302][210/390]\tTime 0.051 (0.047)\tData 0.000 (0.006)\tLoss 0.0191 (0.0161)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [302][220/390]\tTime 0.066 (0.047)\tData 0.026 (0.006)\tLoss 0.0173 (0.0159)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [302][230/390]\tTime 0.041 (0.046)\tData 0.005 (0.006)\tLoss 0.0071 (0.0159)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [302][240/390]\tTime 0.047 (0.046)\tData 0.006 (0.006)\tLoss 0.0153 (0.0158)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [302][250/390]\tTime 0.041 (0.046)\tData 0.007 (0.005)\tLoss 0.0080 (0.0157)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [302][260/390]\tTime 0.064 (0.046)\tData 0.033 (0.006)\tLoss 0.0079 (0.0155)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [302][270/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0068 (0.0157)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [302][280/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0183 (0.0158)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [302][290/390]\tTime 0.040 (0.046)\tData 0.004 (0.006)\tLoss 0.0058 (0.0158)\tPrec@1 100.000 (99.568)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [302][300/390]\tTime 0.041 (0.046)\tData 0.000 (0.006)\tLoss 0.0217 (0.0160)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [302][310/390]\tTime 0.030 (0.046)\tData 0.000 (0.006)\tLoss 0.0073 (0.0159)\tPrec@1 100.000 (99.573)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [302][320/390]\tTime 0.040 (0.046)\tData 0.005 (0.006)\tLoss 0.0157 (0.0159)\tPrec@1 99.219 (99.574)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [302][330/390]\tTime 0.058 (0.046)\tData 0.007 (0.006)\tLoss 0.0089 (0.0159)\tPrec@1 100.000 (99.580)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [302][340/390]\tTime 0.056 (0.046)\tData 0.019 (0.006)\tLoss 0.0094 (0.0160)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [302][350/390]\tTime 0.058 (0.046)\tData 0.000 (0.006)\tLoss 0.0175 (0.0160)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [302][360/390]\tTime 0.039 (0.046)\tData 0.000 (0.005)\tLoss 0.0066 (0.0161)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [302][370/390]\tTime 0.048 (0.046)\tData 0.011 (0.005)\tLoss 0.0126 (0.0161)\tPrec@1 100.000 (99.573)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [302][380/390]\tTime 0.036 (0.046)\tData 0.001 (0.005)\tLoss 0.0277 (0.0160)\tPrec@1 98.438 (99.576)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [302][389/390]\tTime 0.019 (0.045)\tData 0.000 (0.005)\tLoss 0.0046 (0.0160)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [302][0/79]\tTime 0.176 (0.176)\tData 0.161 (0.161)\tLoss 0.2836 (0.2836)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [302][10/79]\tTime 0.039 (0.048)\tData 0.032 (0.036)\tLoss 0.2571 (0.3677)\tPrec@1 91.406 (92.045)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [302][20/79]\tTime 0.019 (0.036)\tData 0.006 (0.025)\tLoss 0.5297 (0.4143)\tPrec@1 89.844 (91.369)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [302][30/79]\tTime 0.022 (0.035)\tData 0.001 (0.024)\tLoss 0.1031 (0.4001)\tPrec@1 97.656 (91.809)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [302][40/79]\tTime 0.010 (0.033)\tData 0.005 (0.022)\tLoss 0.2341 (0.4012)\tPrec@1 89.844 (91.768)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [302][50/79]\tTime 0.028 (0.032)\tData 0.006 (0.021)\tLoss 0.4508 (0.3940)\tPrec@1 90.625 (91.713)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [302][60/79]\tTime 0.025 (0.031)\tData 0.009 (0.020)\tLoss 0.6497 (0.3989)\tPrec@1 92.188 (91.650)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [302][70/79]\tTime 0.011 (0.030)\tData 0.000 (0.019)\tLoss 0.4100 (0.3916)\tPrec@1 89.062 (91.626)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [302][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2855 (0.3889)\tPrec@1 93.750 (91.640)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 303\n",
            "Training Loss 0.0160 \tTraining Prec@1 99.577 \tTraining Prec@5 99.998 \tValidation Loss 0.3889 \tValidation Prec@1 91.640 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 304\n",
            "\n",
            "TRAINING - Epoch: [303][0/390]\tTime 0.365 (0.365)\tData 0.318 (0.318)\tLoss 0.0291 (0.0291)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][10/390]\tTime 0.035 (0.080)\tData 0.000 (0.031)\tLoss 0.0080 (0.0176)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][20/390]\tTime 0.043 (0.063)\tData 0.005 (0.018)\tLoss 0.0231 (0.0186)\tPrec@1 98.438 (99.293)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][30/390]\tTime 0.048 (0.057)\tData 0.000 (0.014)\tLoss 0.0063 (0.0199)\tPrec@1 100.000 (99.294)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][40/390]\tTime 0.049 (0.055)\tData 0.000 (0.011)\tLoss 0.0144 (0.0198)\tPrec@1 99.219 (99.333)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][50/390]\tTime 0.054 (0.052)\tData 0.003 (0.010)\tLoss 0.0246 (0.0193)\tPrec@1 99.219 (99.341)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][60/390]\tTime 0.050 (0.052)\tData 0.008 (0.009)\tLoss 0.0426 (0.0196)\tPrec@1 99.219 (99.385)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][70/390]\tTime 0.039 (0.051)\tData 0.000 (0.009)\tLoss 0.0121 (0.0194)\tPrec@1 99.219 (99.439)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][80/390]\tTime 0.042 (0.050)\tData 0.000 (0.009)\tLoss 0.0144 (0.0188)\tPrec@1 99.219 (99.460)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][90/390]\tTime 0.037 (0.050)\tData 0.005 (0.008)\tLoss 0.0261 (0.0185)\tPrec@1 98.438 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][100/390]\tTime 0.042 (0.049)\tData 0.002 (0.008)\tLoss 0.0146 (0.0186)\tPrec@1 99.219 (99.474)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][110/390]\tTime 0.052 (0.049)\tData 0.011 (0.008)\tLoss 0.0662 (0.0188)\tPrec@1 97.656 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][120/390]\tTime 0.051 (0.049)\tData 0.000 (0.007)\tLoss 0.0187 (0.0181)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][130/390]\tTime 0.035 (0.048)\tData 0.000 (0.007)\tLoss 0.0084 (0.0182)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][140/390]\tTime 0.056 (0.048)\tData 0.016 (0.007)\tLoss 0.0037 (0.0184)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][150/390]\tTime 0.033 (0.048)\tData 0.005 (0.007)\tLoss 0.0138 (0.0185)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][160/390]\tTime 0.040 (0.048)\tData 0.004 (0.007)\tLoss 0.0110 (0.0186)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][170/390]\tTime 0.042 (0.048)\tData 0.006 (0.006)\tLoss 0.0236 (0.0184)\tPrec@1 98.438 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][180/390]\tTime 0.033 (0.047)\tData 0.000 (0.006)\tLoss 0.0148 (0.0186)\tPrec@1 99.219 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][190/390]\tTime 0.047 (0.047)\tData 0.000 (0.006)\tLoss 0.0093 (0.0185)\tPrec@1 100.000 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][200/390]\tTime 0.039 (0.047)\tData 0.001 (0.006)\tLoss 0.0087 (0.0186)\tPrec@1 100.000 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][210/390]\tTime 0.035 (0.047)\tData 0.000 (0.006)\tLoss 0.0150 (0.0185)\tPrec@1 100.000 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][220/390]\tTime 0.042 (0.047)\tData 0.001 (0.007)\tLoss 0.0104 (0.0184)\tPrec@1 100.000 (99.487)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][230/390]\tTime 0.031 (0.047)\tData 0.007 (0.007)\tLoss 0.0114 (0.0188)\tPrec@1 100.000 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][240/390]\tTime 0.044 (0.047)\tData 0.001 (0.007)\tLoss 0.0325 (0.0187)\tPrec@1 98.438 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][250/390]\tTime 0.034 (0.047)\tData 0.000 (0.006)\tLoss 0.0052 (0.0186)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][260/390]\tTime 0.046 (0.047)\tData 0.000 (0.006)\tLoss 0.0110 (0.0184)\tPrec@1 100.000 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][270/390]\tTime 0.050 (0.047)\tData 0.001 (0.006)\tLoss 0.0157 (0.0184)\tPrec@1 100.000 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][280/390]\tTime 0.047 (0.047)\tData 0.004 (0.006)\tLoss 0.0224 (0.0184)\tPrec@1 99.219 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][290/390]\tTime 0.037 (0.046)\tData 0.004 (0.006)\tLoss 0.0139 (0.0182)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][300/390]\tTime 0.046 (0.046)\tData 0.000 (0.006)\tLoss 0.0107 (0.0181)\tPrec@1 100.000 (99.515)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][310/390]\tTime 0.036 (0.046)\tData 0.000 (0.006)\tLoss 0.0220 (0.0181)\tPrec@1 99.219 (99.515)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][320/390]\tTime 0.049 (0.046)\tData 0.008 (0.006)\tLoss 0.0202 (0.0181)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][330/390]\tTime 0.041 (0.046)\tData 0.005 (0.006)\tLoss 0.0094 (0.0182)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][340/390]\tTime 0.055 (0.046)\tData 0.000 (0.006)\tLoss 0.0040 (0.0179)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][350/390]\tTime 0.055 (0.046)\tData 0.022 (0.006)\tLoss 0.0033 (0.0180)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][360/390]\tTime 0.039 (0.046)\tData 0.000 (0.006)\tLoss 0.0084 (0.0178)\tPrec@1 100.000 (99.515)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][370/390]\tTime 0.038 (0.046)\tData 0.001 (0.006)\tLoss 0.0062 (0.0180)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][380/390]\tTime 0.085 (0.046)\tData 0.042 (0.006)\tLoss 0.0195 (0.0180)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [303][389/390]\tTime 0.018 (0.046)\tData 0.000 (0.006)\tLoss 0.0291 (0.0180)\tPrec@1 97.656 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [303][0/79]\tTime 0.182 (0.182)\tData 0.165 (0.165)\tLoss 0.2841 (0.2841)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [303][10/79]\tTime 0.051 (0.049)\tData 0.044 (0.036)\tLoss 0.2601 (0.3675)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [303][20/79]\tTime 0.020 (0.039)\tData 0.004 (0.027)\tLoss 0.5313 (0.4087)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [303][30/79]\tTime 0.067 (0.037)\tData 0.061 (0.026)\tLoss 0.1023 (0.3968)\tPrec@1 97.656 (91.986)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [303][40/79]\tTime 0.025 (0.035)\tData 0.010 (0.022)\tLoss 0.2514 (0.3993)\tPrec@1 89.062 (91.806)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [303][50/79]\tTime 0.018 (0.034)\tData 0.004 (0.022)\tLoss 0.4300 (0.3922)\tPrec@1 90.625 (91.820)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [303][60/79]\tTime 0.017 (0.033)\tData 0.003 (0.021)\tLoss 0.6424 (0.3977)\tPrec@1 92.969 (91.726)\tPrec@5 100.000 (99.693)\t\n",
            "EVALUATING - Epoch: [303][70/79]\tTime 0.020 (0.034)\tData 0.009 (0.021)\tLoss 0.4009 (0.3908)\tPrec@1 89.062 (91.648)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [303][78/79]\tTime 0.003 (0.031)\tData 0.000 (0.019)\tLoss 0.2657 (0.3879)\tPrec@1 93.750 (91.640)\tPrec@5 100.000 (99.720)\t\n",
            "\n",
            "Results - Epoch: 304\n",
            "Training Loss 0.0180 \tTraining Prec@1 99.513 \tTraining Prec@5 100.000 \tValidation Loss 0.3879 \tValidation Prec@1 91.640 \tValidation Prec@5 99.720 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 305\n",
            "\n",
            "TRAINING - Epoch: [304][0/390]\tTime 0.343 (0.343)\tData 0.296 (0.296)\tLoss 0.0375 (0.0375)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][10/390]\tTime 0.042 (0.070)\tData 0.005 (0.031)\tLoss 0.0092 (0.0118)\tPrec@1 100.000 (99.716)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][20/390]\tTime 0.049 (0.059)\tData 0.000 (0.017)\tLoss 0.0040 (0.0158)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][30/390]\tTime 0.044 (0.053)\tData 0.001 (0.012)\tLoss 0.0043 (0.0167)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][40/390]\tTime 0.051 (0.051)\tData 0.000 (0.010)\tLoss 0.0302 (0.0165)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][50/390]\tTime 0.032 (0.050)\tData 0.003 (0.009)\tLoss 0.0288 (0.0178)\tPrec@1 99.219 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][60/390]\tTime 0.041 (0.049)\tData 0.006 (0.008)\tLoss 0.0113 (0.0181)\tPrec@1 100.000 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][70/390]\tTime 0.048 (0.049)\tData 0.000 (0.008)\tLoss 0.0161 (0.0179)\tPrec@1 99.219 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][80/390]\tTime 0.033 (0.048)\tData 0.001 (0.007)\tLoss 0.0167 (0.0180)\tPrec@1 99.219 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][90/390]\tTime 0.049 (0.047)\tData 0.006 (0.007)\tLoss 0.0168 (0.0187)\tPrec@1 99.219 (99.442)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][100/390]\tTime 0.047 (0.047)\tData 0.000 (0.006)\tLoss 0.0148 (0.0182)\tPrec@1 99.219 (99.466)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][110/390]\tTime 0.068 (0.047)\tData 0.035 (0.006)\tLoss 0.0114 (0.0179)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][120/390]\tTime 0.042 (0.047)\tData 0.005 (0.006)\tLoss 0.0116 (0.0178)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][130/390]\tTime 0.025 (0.046)\tData 0.000 (0.006)\tLoss 0.0137 (0.0180)\tPrec@1 100.000 (99.487)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][140/390]\tTime 0.038 (0.046)\tData 0.000 (0.006)\tLoss 0.0264 (0.0178)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][150/390]\tTime 0.050 (0.046)\tData 0.001 (0.006)\tLoss 0.0295 (0.0181)\tPrec@1 98.438 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][160/390]\tTime 0.063 (0.046)\tData 0.010 (0.006)\tLoss 0.0074 (0.0184)\tPrec@1 100.000 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][170/390]\tTime 0.033 (0.046)\tData 0.000 (0.006)\tLoss 0.0355 (0.0183)\tPrec@1 98.438 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][180/390]\tTime 0.036 (0.046)\tData 0.000 (0.006)\tLoss 0.0252 (0.0181)\tPrec@1 99.219 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][190/390]\tTime 0.067 (0.046)\tData 0.001 (0.005)\tLoss 0.0035 (0.0179)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][200/390]\tTime 0.035 (0.046)\tData 0.000 (0.005)\tLoss 0.0190 (0.0178)\tPrec@1 99.219 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][210/390]\tTime 0.023 (0.046)\tData 0.000 (0.005)\tLoss 0.0141 (0.0181)\tPrec@1 100.000 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][220/390]\tTime 0.036 (0.046)\tData 0.000 (0.005)\tLoss 0.0110 (0.0179)\tPrec@1 100.000 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][230/390]\tTime 0.034 (0.046)\tData 0.003 (0.005)\tLoss 0.0168 (0.0179)\tPrec@1 99.219 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][240/390]\tTime 0.060 (0.046)\tData 0.004 (0.005)\tLoss 0.0106 (0.0176)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][250/390]\tTime 0.032 (0.046)\tData 0.000 (0.005)\tLoss 0.0099 (0.0175)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][260/390]\tTime 0.033 (0.046)\tData 0.003 (0.005)\tLoss 0.0386 (0.0177)\tPrec@1 99.219 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][270/390]\tTime 0.051 (0.046)\tData 0.002 (0.005)\tLoss 0.0343 (0.0178)\tPrec@1 99.219 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][280/390]\tTime 0.040 (0.046)\tData 0.000 (0.005)\tLoss 0.0134 (0.0177)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][290/390]\tTime 0.044 (0.046)\tData 0.011 (0.005)\tLoss 0.0152 (0.0178)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][300/390]\tTime 0.044 (0.046)\tData 0.007 (0.005)\tLoss 0.0277 (0.0177)\tPrec@1 98.438 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][310/390]\tTime 0.052 (0.046)\tData 0.000 (0.005)\tLoss 0.0202 (0.0178)\tPrec@1 99.219 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][320/390]\tTime 0.045 (0.046)\tData 0.000 (0.005)\tLoss 0.0208 (0.0177)\tPrec@1 98.438 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][330/390]\tTime 0.033 (0.046)\tData 0.000 (0.005)\tLoss 0.0132 (0.0176)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][340/390]\tTime 0.041 (0.046)\tData 0.002 (0.005)\tLoss 0.0117 (0.0175)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][350/390]\tTime 0.045 (0.046)\tData 0.005 (0.005)\tLoss 0.0133 (0.0176)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][360/390]\tTime 0.048 (0.046)\tData 0.000 (0.005)\tLoss 0.0194 (0.0176)\tPrec@1 99.219 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][370/390]\tTime 0.054 (0.046)\tData 0.000 (0.005)\tLoss 0.0076 (0.0176)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][380/390]\tTime 0.043 (0.046)\tData 0.006 (0.005)\tLoss 0.0069 (0.0175)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [304][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0058 (0.0175)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [304][0/79]\tTime 0.258 (0.258)\tData 0.233 (0.233)\tLoss 0.2962 (0.2962)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [304][10/79]\tTime 0.012 (0.043)\tData 0.000 (0.029)\tLoss 0.2463 (0.3739)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [304][20/79]\tTime 0.069 (0.038)\tData 0.058 (0.024)\tLoss 0.5261 (0.4137)\tPrec@1 89.844 (91.667)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [304][30/79]\tTime 0.016 (0.035)\tData 0.000 (0.021)\tLoss 0.1027 (0.4016)\tPrec@1 97.656 (92.011)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [304][40/79]\tTime 0.052 (0.033)\tData 0.033 (0.019)\tLoss 0.2366 (0.4013)\tPrec@1 90.625 (91.959)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [304][50/79]\tTime 0.067 (0.032)\tData 0.055 (0.019)\tLoss 0.4272 (0.3935)\tPrec@1 90.625 (91.896)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [304][60/79]\tTime 0.058 (0.031)\tData 0.052 (0.018)\tLoss 0.6466 (0.3982)\tPrec@1 92.969 (91.829)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [304][70/79]\tTime 0.068 (0.031)\tData 0.060 (0.018)\tLoss 0.3998 (0.3909)\tPrec@1 89.844 (91.791)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [304][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.018)\tLoss 0.2577 (0.3882)\tPrec@1 93.750 (91.790)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 305\n",
            "Training Loss 0.0175 \tTraining Prec@1 99.511 \tTraining Prec@5 100.000 \tValidation Loss 0.3882 \tValidation Prec@1 91.790 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 306\n",
            "\n",
            "TRAINING - Epoch: [305][0/390]\tTime 0.325 (0.325)\tData 0.273 (0.273)\tLoss 0.0081 (0.0081)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [305][10/390]\tTime 0.045 (0.070)\tData 0.001 (0.028)\tLoss 0.0087 (0.0205)\tPrec@1 100.000 (99.361)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [305][20/390]\tTime 0.041 (0.059)\tData 0.007 (0.017)\tLoss 0.0042 (0.0170)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [305][30/390]\tTime 0.051 (0.056)\tData 0.006 (0.013)\tLoss 0.0137 (0.0167)\tPrec@1 99.219 (99.572)\tPrec@5 100.000 (99.950)\t\n",
            "TRAINING - Epoch: [305][40/390]\tTime 0.043 (0.054)\tData 0.000 (0.011)\tLoss 0.0107 (0.0159)\tPrec@1 100.000 (99.600)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [305][50/390]\tTime 0.042 (0.052)\tData 0.006 (0.010)\tLoss 0.0393 (0.0164)\tPrec@1 98.438 (99.586)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [305][60/390]\tTime 0.045 (0.050)\tData 0.005 (0.009)\tLoss 0.0324 (0.0173)\tPrec@1 97.656 (99.488)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [305][70/390]\tTime 0.053 (0.050)\tData 0.003 (0.008)\tLoss 0.0242 (0.0164)\tPrec@1 99.219 (99.549)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [305][80/390]\tTime 0.047 (0.050)\tData 0.001 (0.007)\tLoss 0.0117 (0.0165)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [305][90/390]\tTime 0.049 (0.049)\tData 0.002 (0.007)\tLoss 0.0176 (0.0167)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [305][100/390]\tTime 0.048 (0.049)\tData 0.000 (0.006)\tLoss 0.0115 (0.0169)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (99.977)\t\n",
            "TRAINING - Epoch: [305][110/390]\tTime 0.053 (0.049)\tData 0.020 (0.006)\tLoss 0.0094 (0.0164)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (99.979)\t\n",
            "TRAINING - Epoch: [305][120/390]\tTime 0.061 (0.049)\tData 0.004 (0.006)\tLoss 0.0105 (0.0164)\tPrec@1 100.000 (99.593)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [305][130/390]\tTime 0.041 (0.049)\tData 0.000 (0.006)\tLoss 0.0720 (0.0167)\tPrec@1 98.438 (99.594)\tPrec@5 100.000 (99.982)\t\n",
            "TRAINING - Epoch: [305][140/390]\tTime 0.035 (0.049)\tData 0.000 (0.006)\tLoss 0.0289 (0.0171)\tPrec@1 98.438 (99.557)\tPrec@5 100.000 (99.983)\t\n",
            "TRAINING - Epoch: [305][150/390]\tTime 0.033 (0.048)\tData 0.005 (0.006)\tLoss 0.0225 (0.0172)\tPrec@1 99.219 (99.555)\tPrec@5 100.000 (99.984)\t\n",
            "TRAINING - Epoch: [305][160/390]\tTime 0.050 (0.048)\tData 0.000 (0.005)\tLoss 0.0077 (0.0171)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (99.985)\t\n",
            "TRAINING - Epoch: [305][170/390]\tTime 0.043 (0.048)\tData 0.009 (0.005)\tLoss 0.0182 (0.0168)\tPrec@1 99.219 (99.561)\tPrec@5 100.000 (99.986)\t\n",
            "TRAINING - Epoch: [305][180/390]\tTime 0.047 (0.048)\tData 0.011 (0.005)\tLoss 0.0137 (0.0168)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (99.987)\t\n",
            "TRAINING - Epoch: [305][190/390]\tTime 0.037 (0.048)\tData 0.001 (0.005)\tLoss 0.0030 (0.0170)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (99.988)\t\n",
            "TRAINING - Epoch: [305][200/390]\tTime 0.052 (0.048)\tData 0.005 (0.005)\tLoss 0.0174 (0.0172)\tPrec@1 99.219 (99.534)\tPrec@5 100.000 (99.988)\t\n",
            "TRAINING - Epoch: [305][210/390]\tTime 0.036 (0.048)\tData 0.002 (0.005)\tLoss 0.0200 (0.0170)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (99.989)\t\n",
            "TRAINING - Epoch: [305][220/390]\tTime 0.057 (0.048)\tData 0.006 (0.005)\tLoss 0.0098 (0.0170)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (99.989)\t\n",
            "TRAINING - Epoch: [305][230/390]\tTime 0.047 (0.047)\tData 0.017 (0.005)\tLoss 0.0056 (0.0169)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (99.990)\t\n",
            "TRAINING - Epoch: [305][240/390]\tTime 0.046 (0.047)\tData 0.004 (0.005)\tLoss 0.0066 (0.0171)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (99.990)\t\n",
            "TRAINING - Epoch: [305][250/390]\tTime 0.063 (0.047)\tData 0.035 (0.005)\tLoss 0.0151 (0.0169)\tPrec@1 99.219 (99.546)\tPrec@5 100.000 (99.991)\t\n",
            "TRAINING - Epoch: [305][260/390]\tTime 0.039 (0.047)\tData 0.004 (0.005)\tLoss 0.0057 (0.0169)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (99.991)\t\n",
            "TRAINING - Epoch: [305][270/390]\tTime 0.057 (0.047)\tData 0.022 (0.005)\tLoss 0.0089 (0.0168)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (99.991)\t\n",
            "TRAINING - Epoch: [305][280/390]\tTime 0.046 (0.047)\tData 0.010 (0.005)\tLoss 0.0205 (0.0169)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (99.992)\t\n",
            "TRAINING - Epoch: [305][290/390]\tTime 0.050 (0.047)\tData 0.005 (0.005)\tLoss 0.0084 (0.0168)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (99.992)\t\n",
            "TRAINING - Epoch: [305][300/390]\tTime 0.047 (0.047)\tData 0.004 (0.005)\tLoss 0.0078 (0.0167)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (99.992)\t\n",
            "TRAINING - Epoch: [305][310/390]\tTime 0.031 (0.047)\tData 0.003 (0.005)\tLoss 0.0562 (0.0171)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (99.992)\t\n",
            "TRAINING - Epoch: [305][320/390]\tTime 0.058 (0.047)\tData 0.004 (0.005)\tLoss 0.0227 (0.0171)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (99.993)\t\n",
            "TRAINING - Epoch: [305][330/390]\tTime 0.062 (0.047)\tData 0.017 (0.005)\tLoss 0.0159 (0.0172)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (99.993)\t\n",
            "TRAINING - Epoch: [305][340/390]\tTime 0.043 (0.046)\tData 0.001 (0.005)\tLoss 0.0263 (0.0174)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (99.993)\t\n",
            "TRAINING - Epoch: [305][350/390]\tTime 0.052 (0.046)\tData 0.000 (0.005)\tLoss 0.0117 (0.0174)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (99.993)\t\n",
            "TRAINING - Epoch: [305][360/390]\tTime 0.050 (0.046)\tData 0.011 (0.005)\tLoss 0.0124 (0.0175)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [305][370/390]\tTime 0.053 (0.046)\tData 0.005 (0.005)\tLoss 0.0191 (0.0175)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [305][380/390]\tTime 0.042 (0.046)\tData 0.000 (0.005)\tLoss 0.0321 (0.0175)\tPrec@1 99.219 (99.541)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [305][389/390]\tTime 0.018 (0.046)\tData 0.000 (0.005)\tLoss 0.0256 (0.0174)\tPrec@1 98.438 (99.541)\tPrec@5 100.000 (99.994)\t\n",
            "EVALUATING - Epoch: [305][0/79]\tTime 0.260 (0.260)\tData 0.243 (0.243)\tLoss 0.2842 (0.2842)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [305][10/79]\tTime 0.015 (0.046)\tData 0.001 (0.035)\tLoss 0.2663 (0.3694)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [305][20/79]\tTime 0.089 (0.040)\tData 0.082 (0.030)\tLoss 0.5219 (0.4092)\tPrec@1 89.844 (91.629)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [305][30/79]\tTime 0.030 (0.036)\tData 0.003 (0.026)\tLoss 0.0977 (0.3963)\tPrec@1 97.656 (91.986)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [305][40/79]\tTime 0.017 (0.034)\tData 0.000 (0.023)\tLoss 0.2371 (0.3983)\tPrec@1 91.406 (91.921)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [305][50/79]\tTime 0.022 (0.034)\tData 0.006 (0.023)\tLoss 0.4478 (0.3916)\tPrec@1 90.625 (91.850)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [305][60/79]\tTime 0.025 (0.032)\tData 0.005 (0.021)\tLoss 0.6367 (0.3969)\tPrec@1 93.750 (91.778)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [305][70/79]\tTime 0.017 (0.033)\tData 0.006 (0.020)\tLoss 0.3967 (0.3893)\tPrec@1 89.844 (91.725)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [305][78/79]\tTime 0.003 (0.031)\tData 0.000 (0.019)\tLoss 0.2615 (0.3865)\tPrec@1 93.750 (91.720)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 306\n",
            "Training Loss 0.0174 \tTraining Prec@1 99.541 \tTraining Prec@5 99.994 \tValidation Loss 0.3865 \tValidation Prec@1 91.720 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 307\n",
            "\n",
            "TRAINING - Epoch: [306][0/390]\tTime 0.343 (0.343)\tData 0.278 (0.278)\tLoss 0.0249 (0.0249)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][10/390]\tTime 0.034 (0.069)\tData 0.000 (0.026)\tLoss 0.0073 (0.0130)\tPrec@1 100.000 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][20/390]\tTime 0.051 (0.059)\tData 0.015 (0.017)\tLoss 0.0186 (0.0133)\tPrec@1 99.219 (99.740)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][30/390]\tTime 0.048 (0.054)\tData 0.004 (0.013)\tLoss 0.0335 (0.0131)\tPrec@1 99.219 (99.773)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][40/390]\tTime 0.039 (0.052)\tData 0.001 (0.011)\tLoss 0.0119 (0.0153)\tPrec@1 100.000 (99.676)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][50/390]\tTime 0.042 (0.052)\tData 0.004 (0.010)\tLoss 0.0267 (0.0160)\tPrec@1 99.219 (99.617)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][60/390]\tTime 0.051 (0.051)\tData 0.005 (0.009)\tLoss 0.0177 (0.0155)\tPrec@1 99.219 (99.641)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][70/390]\tTime 0.039 (0.050)\tData 0.000 (0.008)\tLoss 0.0549 (0.0158)\tPrec@1 97.656 (99.626)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][80/390]\tTime 0.061 (0.050)\tData 0.004 (0.008)\tLoss 0.0063 (0.0155)\tPrec@1 100.000 (99.633)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][90/390]\tTime 0.055 (0.050)\tData 0.006 (0.007)\tLoss 0.0053 (0.0161)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][100/390]\tTime 0.050 (0.050)\tData 0.010 (0.007)\tLoss 0.0195 (0.0169)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][110/390]\tTime 0.041 (0.050)\tData 0.005 (0.007)\tLoss 0.0204 (0.0171)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][120/390]\tTime 0.055 (0.049)\tData 0.008 (0.007)\tLoss 0.0228 (0.0175)\tPrec@1 99.219 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][130/390]\tTime 0.041 (0.049)\tData 0.006 (0.006)\tLoss 0.0080 (0.0173)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][140/390]\tTime 0.051 (0.049)\tData 0.013 (0.006)\tLoss 0.0146 (0.0174)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][150/390]\tTime 0.044 (0.048)\tData 0.000 (0.006)\tLoss 0.0072 (0.0175)\tPrec@1 100.000 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][160/390]\tTime 0.034 (0.048)\tData 0.005 (0.006)\tLoss 0.0240 (0.0175)\tPrec@1 99.219 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][170/390]\tTime 0.047 (0.048)\tData 0.000 (0.006)\tLoss 0.0207 (0.0174)\tPrec@1 99.219 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][180/390]\tTime 0.036 (0.048)\tData 0.005 (0.006)\tLoss 0.0134 (0.0173)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][190/390]\tTime 0.046 (0.048)\tData 0.004 (0.006)\tLoss 0.0078 (0.0171)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][200/390]\tTime 0.056 (0.047)\tData 0.000 (0.006)\tLoss 0.0083 (0.0171)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][210/390]\tTime 0.057 (0.048)\tData 0.001 (0.006)\tLoss 0.0300 (0.0171)\tPrec@1 98.438 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][220/390]\tTime 0.070 (0.047)\tData 0.011 (0.006)\tLoss 0.0070 (0.0169)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][230/390]\tTime 0.030 (0.047)\tData 0.000 (0.006)\tLoss 0.0118 (0.0170)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][240/390]\tTime 0.054 (0.047)\tData 0.011 (0.006)\tLoss 0.0107 (0.0168)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][250/390]\tTime 0.042 (0.047)\tData 0.001 (0.005)\tLoss 0.0307 (0.0169)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][260/390]\tTime 0.036 (0.047)\tData 0.002 (0.005)\tLoss 0.0247 (0.0167)\tPrec@1 99.219 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][270/390]\tTime 0.048 (0.047)\tData 0.012 (0.005)\tLoss 0.0105 (0.0168)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][280/390]\tTime 0.047 (0.047)\tData 0.000 (0.005)\tLoss 0.0222 (0.0169)\tPrec@1 99.219 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][290/390]\tTime 0.039 (0.047)\tData 0.000 (0.005)\tLoss 0.0053 (0.0168)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][300/390]\tTime 0.045 (0.047)\tData 0.000 (0.005)\tLoss 0.0112 (0.0167)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][310/390]\tTime 0.050 (0.047)\tData 0.003 (0.005)\tLoss 0.0045 (0.0166)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][320/390]\tTime 0.033 (0.046)\tData 0.005 (0.005)\tLoss 0.0231 (0.0165)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][330/390]\tTime 0.038 (0.046)\tData 0.000 (0.005)\tLoss 0.0088 (0.0165)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][340/390]\tTime 0.045 (0.046)\tData 0.002 (0.005)\tLoss 0.0254 (0.0167)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][350/390]\tTime 0.033 (0.046)\tData 0.002 (0.005)\tLoss 0.0086 (0.0165)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][360/390]\tTime 0.034 (0.046)\tData 0.000 (0.005)\tLoss 0.0059 (0.0166)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][370/390]\tTime 0.033 (0.046)\tData 0.002 (0.005)\tLoss 0.0207 (0.0165)\tPrec@1 99.219 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][380/390]\tTime 0.057 (0.046)\tData 0.020 (0.005)\tLoss 0.0056 (0.0163)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [306][389/390]\tTime 0.022 (0.046)\tData 0.000 (0.005)\tLoss 0.0280 (0.0165)\tPrec@1 100.000 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [306][0/79]\tTime 0.279 (0.279)\tData 0.263 (0.263)\tLoss 0.2765 (0.2765)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [306][10/79]\tTime 0.029 (0.046)\tData 0.000 (0.032)\tLoss 0.2705 (0.3729)\tPrec@1 91.406 (92.401)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [306][20/79]\tTime 0.035 (0.038)\tData 0.029 (0.025)\tLoss 0.5279 (0.4102)\tPrec@1 89.844 (91.815)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [306][30/79]\tTime 0.033 (0.034)\tData 0.026 (0.022)\tLoss 0.0896 (0.3969)\tPrec@1 97.656 (92.112)\tPrec@5 100.000 (99.597)\t\n",
            "EVALUATING - Epoch: [306][40/79]\tTime 0.065 (0.033)\tData 0.059 (0.021)\tLoss 0.2288 (0.3986)\tPrec@1 91.406 (92.054)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [306][50/79]\tTime 0.041 (0.032)\tData 0.002 (0.019)\tLoss 0.4468 (0.3915)\tPrec@1 90.625 (92.004)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [306][60/79]\tTime 0.037 (0.032)\tData 0.002 (0.019)\tLoss 0.6250 (0.3970)\tPrec@1 93.750 (91.919)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [306][70/79]\tTime 0.037 (0.031)\tData 0.031 (0.017)\tLoss 0.4093 (0.3892)\tPrec@1 89.844 (91.835)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [306][78/79]\tTime 0.002 (0.029)\tData 0.000 (0.016)\tLoss 0.2661 (0.3864)\tPrec@1 93.750 (91.820)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 307\n",
            "Training Loss 0.0165 \tTraining Prec@1 99.583 \tTraining Prec@5 100.000 \tValidation Loss 0.3864 \tValidation Prec@1 91.820 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 308\n",
            "\n",
            "TRAINING - Epoch: [307][0/390]\tTime 0.286 (0.286)\tData 0.236 (0.236)\tLoss 0.0244 (0.0244)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][10/390]\tTime 0.042 (0.068)\tData 0.004 (0.029)\tLoss 0.0120 (0.0156)\tPrec@1 99.219 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][20/390]\tTime 0.040 (0.056)\tData 0.000 (0.017)\tLoss 0.0049 (0.0144)\tPrec@1 100.000 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][30/390]\tTime 0.038 (0.054)\tData 0.005 (0.015)\tLoss 0.0339 (0.0157)\tPrec@1 99.219 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][40/390]\tTime 0.046 (0.051)\tData 0.002 (0.012)\tLoss 0.0124 (0.0174)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][50/390]\tTime 0.043 (0.049)\tData 0.007 (0.011)\tLoss 0.0068 (0.0177)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][60/390]\tTime 0.036 (0.049)\tData 0.000 (0.009)\tLoss 0.0210 (0.0172)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][70/390]\tTime 0.038 (0.048)\tData 0.001 (0.008)\tLoss 0.0176 (0.0170)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][80/390]\tTime 0.050 (0.048)\tData 0.002 (0.008)\tLoss 0.0361 (0.0183)\tPrec@1 98.438 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][90/390]\tTime 0.073 (0.048)\tData 0.039 (0.009)\tLoss 0.0132 (0.0174)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][100/390]\tTime 0.048 (0.047)\tData 0.007 (0.009)\tLoss 0.0174 (0.0170)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][110/390]\tTime 0.054 (0.047)\tData 0.005 (0.009)\tLoss 0.0110 (0.0165)\tPrec@1 100.000 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][120/390]\tTime 0.040 (0.047)\tData 0.005 (0.008)\tLoss 0.0502 (0.0167)\tPrec@1 97.656 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][130/390]\tTime 0.044 (0.046)\tData 0.009 (0.008)\tLoss 0.0067 (0.0170)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][140/390]\tTime 0.036 (0.046)\tData 0.003 (0.008)\tLoss 0.0215 (0.0175)\tPrec@1 100.000 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][150/390]\tTime 0.039 (0.046)\tData 0.004 (0.007)\tLoss 0.0124 (0.0174)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][160/390]\tTime 0.047 (0.046)\tData 0.002 (0.007)\tLoss 0.0179 (0.0173)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][170/390]\tTime 0.056 (0.046)\tData 0.029 (0.007)\tLoss 0.0286 (0.0173)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][180/390]\tTime 0.047 (0.046)\tData 0.011 (0.007)\tLoss 0.0267 (0.0176)\tPrec@1 99.219 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][190/390]\tTime 0.041 (0.046)\tData 0.003 (0.007)\tLoss 0.0366 (0.0177)\tPrec@1 98.438 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][200/390]\tTime 0.046 (0.046)\tData 0.004 (0.007)\tLoss 0.0184 (0.0175)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][210/390]\tTime 0.051 (0.045)\tData 0.010 (0.007)\tLoss 0.0266 (0.0172)\tPrec@1 98.438 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][220/390]\tTime 0.043 (0.045)\tData 0.001 (0.007)\tLoss 0.0157 (0.0171)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][230/390]\tTime 0.029 (0.045)\tData 0.000 (0.007)\tLoss 0.0300 (0.0170)\tPrec@1 98.438 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][240/390]\tTime 0.042 (0.045)\tData 0.006 (0.006)\tLoss 0.0174 (0.0170)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][250/390]\tTime 0.048 (0.045)\tData 0.003 (0.006)\tLoss 0.0044 (0.0168)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][260/390]\tTime 0.036 (0.045)\tData 0.001 (0.006)\tLoss 0.0274 (0.0167)\tPrec@1 99.219 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][270/390]\tTime 0.033 (0.045)\tData 0.009 (0.006)\tLoss 0.0157 (0.0166)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][280/390]\tTime 0.042 (0.045)\tData 0.001 (0.006)\tLoss 0.0048 (0.0165)\tPrec@1 100.000 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][290/390]\tTime 0.035 (0.045)\tData 0.000 (0.006)\tLoss 0.0199 (0.0166)\tPrec@1 99.219 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][300/390]\tTime 0.039 (0.045)\tData 0.001 (0.006)\tLoss 0.0181 (0.0166)\tPrec@1 99.219 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][310/390]\tTime 0.053 (0.045)\tData 0.005 (0.006)\tLoss 0.0121 (0.0166)\tPrec@1 100.000 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][320/390]\tTime 0.042 (0.045)\tData 0.004 (0.006)\tLoss 0.0376 (0.0164)\tPrec@1 97.656 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][330/390]\tTime 0.057 (0.045)\tData 0.004 (0.006)\tLoss 0.0132 (0.0163)\tPrec@1 100.000 (99.587)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][340/390]\tTime 0.042 (0.045)\tData 0.005 (0.006)\tLoss 0.0073 (0.0162)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][350/390]\tTime 0.082 (0.045)\tData 0.051 (0.006)\tLoss 0.0097 (0.0162)\tPrec@1 99.219 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][360/390]\tTime 0.049 (0.045)\tData 0.014 (0.006)\tLoss 0.0304 (0.0163)\tPrec@1 99.219 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][370/390]\tTime 0.061 (0.045)\tData 0.019 (0.006)\tLoss 0.0240 (0.0162)\tPrec@1 99.219 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][380/390]\tTime 0.045 (0.045)\tData 0.005 (0.006)\tLoss 0.0168 (0.0164)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [307][389/390]\tTime 0.020 (0.045)\tData 0.000 (0.006)\tLoss 0.0054 (0.0163)\tPrec@1 100.000 (99.587)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [307][0/79]\tTime 0.222 (0.222)\tData 0.203 (0.203)\tLoss 0.3012 (0.3012)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [307][10/79]\tTime 0.013 (0.054)\tData 0.007 (0.040)\tLoss 0.2681 (0.3737)\tPrec@1 91.406 (92.116)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [307][20/79]\tTime 0.014 (0.041)\tData 0.000 (0.028)\tLoss 0.5418 (0.4125)\tPrec@1 89.844 (91.481)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [307][30/79]\tTime 0.015 (0.037)\tData 0.005 (0.025)\tLoss 0.0931 (0.3982)\tPrec@1 97.656 (91.860)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [307][40/79]\tTime 0.016 (0.034)\tData 0.005 (0.022)\tLoss 0.2573 (0.3991)\tPrec@1 89.844 (91.787)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [307][50/79]\tTime 0.021 (0.033)\tData 0.004 (0.020)\tLoss 0.4188 (0.3923)\tPrec@1 89.844 (91.789)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [307][60/79]\tTime 0.053 (0.032)\tData 0.046 (0.020)\tLoss 0.6471 (0.3974)\tPrec@1 92.969 (91.726)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [307][70/79]\tTime 0.018 (0.032)\tData 0.000 (0.020)\tLoss 0.4086 (0.3901)\tPrec@1 89.062 (91.681)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [307][78/79]\tTime 0.003 (0.031)\tData 0.000 (0.019)\tLoss 0.2315 (0.3874)\tPrec@1 93.750 (91.670)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 308\n",
            "Training Loss 0.0163 \tTraining Prec@1 99.587 \tTraining Prec@5 100.000 \tValidation Loss 0.3874 \tValidation Prec@1 91.670 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 309\n",
            "\n",
            "TRAINING - Epoch: [308][0/390]\tTime 0.320 (0.320)\tData 0.271 (0.271)\tLoss 0.0129 (0.0129)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][10/390]\tTime 0.052 (0.073)\tData 0.005 (0.029)\tLoss 0.0228 (0.0244)\tPrec@1 98.438 (99.006)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][20/390]\tTime 0.048 (0.060)\tData 0.000 (0.017)\tLoss 0.0164 (0.0197)\tPrec@1 99.219 (99.330)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][30/390]\tTime 0.047 (0.056)\tData 0.001 (0.013)\tLoss 0.0188 (0.0185)\tPrec@1 100.000 (99.420)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][40/390]\tTime 0.042 (0.053)\tData 0.007 (0.010)\tLoss 0.0138 (0.0190)\tPrec@1 100.000 (99.428)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][50/390]\tTime 0.055 (0.051)\tData 0.010 (0.009)\tLoss 0.0083 (0.0193)\tPrec@1 100.000 (99.341)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][60/390]\tTime 0.035 (0.049)\tData 0.008 (0.009)\tLoss 0.0389 (0.0195)\tPrec@1 97.656 (99.334)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][70/390]\tTime 0.033 (0.048)\tData 0.002 (0.008)\tLoss 0.0105 (0.0183)\tPrec@1 99.219 (99.395)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][80/390]\tTime 0.050 (0.048)\tData 0.009 (0.008)\tLoss 0.0177 (0.0180)\tPrec@1 99.219 (99.412)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][90/390]\tTime 0.039 (0.047)\tData 0.003 (0.008)\tLoss 0.0039 (0.0181)\tPrec@1 100.000 (99.416)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][100/390]\tTime 0.051 (0.048)\tData 0.007 (0.008)\tLoss 0.0106 (0.0180)\tPrec@1 100.000 (99.428)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][110/390]\tTime 0.042 (0.047)\tData 0.000 (0.008)\tLoss 0.0043 (0.0184)\tPrec@1 100.000 (99.402)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][120/390]\tTime 0.055 (0.047)\tData 0.000 (0.008)\tLoss 0.0077 (0.0178)\tPrec@1 100.000 (99.445)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][130/390]\tTime 0.045 (0.047)\tData 0.001 (0.008)\tLoss 0.0458 (0.0177)\tPrec@1 98.438 (99.469)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][140/390]\tTime 0.049 (0.047)\tData 0.000 (0.007)\tLoss 0.0044 (0.0176)\tPrec@1 100.000 (99.474)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][150/390]\tTime 0.033 (0.046)\tData 0.004 (0.007)\tLoss 0.0055 (0.0174)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][160/390]\tTime 0.034 (0.046)\tData 0.000 (0.007)\tLoss 0.0192 (0.0176)\tPrec@1 99.219 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][170/390]\tTime 0.046 (0.046)\tData 0.000 (0.007)\tLoss 0.0045 (0.0174)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][180/390]\tTime 0.045 (0.046)\tData 0.005 (0.007)\tLoss 0.0104 (0.0174)\tPrec@1 100.000 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][190/390]\tTime 0.044 (0.046)\tData 0.013 (0.007)\tLoss 0.0136 (0.0172)\tPrec@1 99.219 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][200/390]\tTime 0.041 (0.046)\tData 0.002 (0.007)\tLoss 0.0102 (0.0173)\tPrec@1 99.219 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][210/390]\tTime 0.050 (0.046)\tData 0.005 (0.007)\tLoss 0.0196 (0.0174)\tPrec@1 98.438 (99.485)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][220/390]\tTime 0.033 (0.046)\tData 0.004 (0.007)\tLoss 0.0127 (0.0175)\tPrec@1 100.000 (99.480)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][230/390]\tTime 0.041 (0.046)\tData 0.000 (0.007)\tLoss 0.0315 (0.0175)\tPrec@1 98.438 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][240/390]\tTime 0.049 (0.046)\tData 0.007 (0.007)\tLoss 0.0081 (0.0174)\tPrec@1 100.000 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][250/390]\tTime 0.044 (0.045)\tData 0.007 (0.006)\tLoss 0.0331 (0.0177)\tPrec@1 99.219 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][260/390]\tTime 0.049 (0.045)\tData 0.000 (0.006)\tLoss 0.0059 (0.0175)\tPrec@1 100.000 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][270/390]\tTime 0.038 (0.045)\tData 0.001 (0.006)\tLoss 0.0142 (0.0176)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][280/390]\tTime 0.050 (0.045)\tData 0.000 (0.006)\tLoss 0.0182 (0.0174)\tPrec@1 99.219 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][290/390]\tTime 0.043 (0.045)\tData 0.000 (0.006)\tLoss 0.0173 (0.0173)\tPrec@1 99.219 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][300/390]\tTime 0.048 (0.045)\tData 0.005 (0.006)\tLoss 0.0062 (0.0171)\tPrec@1 100.000 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][310/390]\tTime 0.044 (0.045)\tData 0.007 (0.006)\tLoss 0.0034 (0.0170)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][320/390]\tTime 0.038 (0.045)\tData 0.000 (0.006)\tLoss 0.0258 (0.0173)\tPrec@1 99.219 (99.474)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][330/390]\tTime 0.058 (0.045)\tData 0.009 (0.006)\tLoss 0.0091 (0.0173)\tPrec@1 100.000 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][340/390]\tTime 0.033 (0.045)\tData 0.003 (0.006)\tLoss 0.0108 (0.0172)\tPrec@1 100.000 (99.480)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][350/390]\tTime 0.051 (0.045)\tData 0.000 (0.005)\tLoss 0.0160 (0.0174)\tPrec@1 99.219 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][360/390]\tTime 0.049 (0.045)\tData 0.000 (0.005)\tLoss 0.0059 (0.0175)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [308][370/390]\tTime 0.040 (0.045)\tData 0.009 (0.005)\tLoss 0.0041 (0.0176)\tPrec@1 100.000 (99.484)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [308][380/390]\tTime 0.102 (0.045)\tData 0.077 (0.006)\tLoss 0.0108 (0.0177)\tPrec@1 100.000 (99.481)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [308][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0049 (0.0176)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [308][0/79]\tTime 0.179 (0.179)\tData 0.170 (0.170)\tLoss 0.2854 (0.2854)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [308][10/79]\tTime 0.027 (0.043)\tData 0.000 (0.030)\tLoss 0.2443 (0.3684)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [308][20/79]\tTime 0.016 (0.035)\tData 0.010 (0.023)\tLoss 0.5207 (0.4090)\tPrec@1 89.844 (91.443)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [308][30/79]\tTime 0.016 (0.033)\tData 0.005 (0.022)\tLoss 0.1087 (0.3980)\tPrec@1 97.656 (91.784)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [308][40/79]\tTime 0.018 (0.032)\tData 0.004 (0.021)\tLoss 0.2393 (0.3998)\tPrec@1 90.625 (91.787)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [308][50/79]\tTime 0.027 (0.032)\tData 0.004 (0.021)\tLoss 0.4283 (0.3919)\tPrec@1 90.625 (91.682)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [308][60/79]\tTime 0.026 (0.032)\tData 0.006 (0.020)\tLoss 0.6539 (0.3971)\tPrec@1 92.969 (91.624)\tPrec@5 100.000 (99.667)\t\n",
            "EVALUATING - Epoch: [308][70/79]\tTime 0.011 (0.031)\tData 0.005 (0.019)\tLoss 0.3834 (0.3894)\tPrec@1 89.844 (91.615)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [308][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.019)\tLoss 0.2265 (0.3863)\tPrec@1 93.750 (91.660)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 309\n",
            "Training Loss 0.0176 \tTraining Prec@1 99.483 \tTraining Prec@5 99.998 \tValidation Loss 0.3863 \tValidation Prec@1 91.660 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 310\n",
            "\n",
            "TRAINING - Epoch: [309][0/390]\tTime 0.249 (0.249)\tData 0.182 (0.182)\tLoss 0.0077 (0.0077)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][10/390]\tTime 0.033 (0.068)\tData 0.005 (0.027)\tLoss 0.0330 (0.0116)\tPrec@1 99.219 (99.787)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][20/390]\tTime 0.041 (0.057)\tData 0.000 (0.016)\tLoss 0.0444 (0.0153)\tPrec@1 98.438 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][30/390]\tTime 0.048 (0.053)\tData 0.000 (0.012)\tLoss 0.0134 (0.0174)\tPrec@1 100.000 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][40/390]\tTime 0.051 (0.051)\tData 0.005 (0.010)\tLoss 0.0080 (0.0166)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][50/390]\tTime 0.059 (0.049)\tData 0.007 (0.009)\tLoss 0.0491 (0.0170)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][60/390]\tTime 0.039 (0.049)\tData 0.000 (0.008)\tLoss 0.0149 (0.0167)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][70/390]\tTime 0.055 (0.048)\tData 0.010 (0.008)\tLoss 0.0118 (0.0161)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][80/390]\tTime 0.049 (0.048)\tData 0.000 (0.007)\tLoss 0.0034 (0.0158)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][90/390]\tTime 0.048 (0.047)\tData 0.005 (0.007)\tLoss 0.0658 (0.0162)\tPrec@1 96.875 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][100/390]\tTime 0.051 (0.046)\tData 0.004 (0.006)\tLoss 0.0146 (0.0161)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][110/390]\tTime 0.046 (0.046)\tData 0.001 (0.006)\tLoss 0.0186 (0.0162)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][120/390]\tTime 0.049 (0.046)\tData 0.000 (0.006)\tLoss 0.0079 (0.0162)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][130/390]\tTime 0.041 (0.046)\tData 0.008 (0.006)\tLoss 0.0095 (0.0160)\tPrec@1 100.000 (99.589)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][140/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0124 (0.0163)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][150/390]\tTime 0.044 (0.046)\tData 0.009 (0.005)\tLoss 0.0110 (0.0163)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][160/390]\tTime 0.040 (0.046)\tData 0.002 (0.005)\tLoss 0.0099 (0.0162)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][170/390]\tTime 0.038 (0.046)\tData 0.004 (0.005)\tLoss 0.0079 (0.0162)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][180/390]\tTime 0.073 (0.046)\tData 0.011 (0.005)\tLoss 0.0107 (0.0161)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][190/390]\tTime 0.040 (0.046)\tData 0.001 (0.005)\tLoss 0.0131 (0.0164)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][200/390]\tTime 0.037 (0.046)\tData 0.000 (0.006)\tLoss 0.0195 (0.0163)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][210/390]\tTime 0.037 (0.046)\tData 0.003 (0.005)\tLoss 0.0047 (0.0162)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][220/390]\tTime 0.037 (0.046)\tData 0.000 (0.005)\tLoss 0.0482 (0.0163)\tPrec@1 97.656 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][230/390]\tTime 0.038 (0.046)\tData 0.000 (0.005)\tLoss 0.0207 (0.0162)\tPrec@1 99.219 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][240/390]\tTime 0.058 (0.046)\tData 0.003 (0.005)\tLoss 0.0465 (0.0161)\tPrec@1 98.438 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][250/390]\tTime 0.039 (0.045)\tData 0.006 (0.005)\tLoss 0.0231 (0.0161)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][260/390]\tTime 0.036 (0.045)\tData 0.000 (0.005)\tLoss 0.0177 (0.0161)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][270/390]\tTime 0.045 (0.045)\tData 0.006 (0.005)\tLoss 0.0206 (0.0161)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][280/390]\tTime 0.042 (0.046)\tData 0.006 (0.005)\tLoss 0.0015 (0.0163)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][290/390]\tTime 0.054 (0.046)\tData 0.000 (0.005)\tLoss 0.0045 (0.0163)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][300/390]\tTime 0.038 (0.045)\tData 0.010 (0.005)\tLoss 0.0242 (0.0163)\tPrec@1 99.219 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][310/390]\tTime 0.041 (0.045)\tData 0.007 (0.005)\tLoss 0.0178 (0.0163)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][320/390]\tTime 0.071 (0.045)\tData 0.043 (0.006)\tLoss 0.0070 (0.0163)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][330/390]\tTime 0.047 (0.046)\tData 0.006 (0.006)\tLoss 0.0046 (0.0162)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][340/390]\tTime 0.050 (0.045)\tData 0.000 (0.006)\tLoss 0.0126 (0.0161)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][350/390]\tTime 0.046 (0.045)\tData 0.000 (0.006)\tLoss 0.0099 (0.0160)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][360/390]\tTime 0.050 (0.045)\tData 0.002 (0.005)\tLoss 0.0206 (0.0161)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][370/390]\tTime 0.031 (0.045)\tData 0.004 (0.006)\tLoss 0.0098 (0.0161)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][380/390]\tTime 0.053 (0.045)\tData 0.000 (0.005)\tLoss 0.0069 (0.0161)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [309][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0075 (0.0162)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [309][0/79]\tTime 0.260 (0.260)\tData 0.233 (0.233)\tLoss 0.2843 (0.2843)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [309][10/79]\tTime 0.018 (0.041)\tData 0.003 (0.027)\tLoss 0.2620 (0.3703)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [309][20/79]\tTime 0.026 (0.036)\tData 0.012 (0.023)\tLoss 0.5227 (0.4098)\tPrec@1 90.625 (91.778)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [309][30/79]\tTime 0.025 (0.033)\tData 0.010 (0.022)\tLoss 0.0972 (0.3971)\tPrec@1 97.656 (92.036)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [309][40/79]\tTime 0.066 (0.033)\tData 0.053 (0.022)\tLoss 0.2432 (0.3991)\tPrec@1 90.625 (91.902)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [309][50/79]\tTime 0.017 (0.032)\tData 0.005 (0.020)\tLoss 0.4356 (0.3919)\tPrec@1 89.844 (91.881)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [309][60/79]\tTime 0.067 (0.032)\tData 0.061 (0.021)\tLoss 0.6429 (0.3976)\tPrec@1 92.969 (91.765)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [309][70/79]\tTime 0.026 (0.031)\tData 0.010 (0.019)\tLoss 0.4032 (0.3902)\tPrec@1 89.844 (91.692)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [309][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2503 (0.3873)\tPrec@1 93.750 (91.680)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 310\n",
            "Training Loss 0.0162 \tTraining Prec@1 99.557 \tTraining Prec@5 100.000 \tValidation Loss 0.3873 \tValidation Prec@1 91.680 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 311\n",
            "\n",
            "TRAINING - Epoch: [310][0/390]\tTime 0.404 (0.404)\tData 0.352 (0.352)\tLoss 0.0075 (0.0075)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][10/390]\tTime 0.048 (0.074)\tData 0.008 (0.037)\tLoss 0.0189 (0.0171)\tPrec@1 99.219 (99.361)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][20/390]\tTime 0.051 (0.061)\tData 0.002 (0.021)\tLoss 0.0062 (0.0174)\tPrec@1 100.000 (99.330)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][30/390]\tTime 0.028 (0.056)\tData 0.000 (0.015)\tLoss 0.0116 (0.0167)\tPrec@1 100.000 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][40/390]\tTime 0.055 (0.052)\tData 0.001 (0.012)\tLoss 0.0299 (0.0193)\tPrec@1 99.219 (99.428)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][50/390]\tTime 0.054 (0.050)\tData 0.004 (0.010)\tLoss 0.0041 (0.0190)\tPrec@1 100.000 (99.433)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][60/390]\tTime 0.045 (0.049)\tData 0.003 (0.009)\tLoss 0.0286 (0.0198)\tPrec@1 98.438 (99.372)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][70/390]\tTime 0.033 (0.049)\tData 0.005 (0.009)\tLoss 0.0379 (0.0196)\tPrec@1 99.219 (99.384)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][80/390]\tTime 0.026 (0.048)\tData 0.005 (0.008)\tLoss 0.0151 (0.0195)\tPrec@1 99.219 (99.363)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][90/390]\tTime 0.036 (0.047)\tData 0.000 (0.007)\tLoss 0.0160 (0.0188)\tPrec@1 99.219 (99.408)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][100/390]\tTime 0.046 (0.047)\tData 0.001 (0.007)\tLoss 0.0053 (0.0188)\tPrec@1 100.000 (99.412)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][110/390]\tTime 0.048 (0.046)\tData 0.017 (0.007)\tLoss 0.0093 (0.0184)\tPrec@1 100.000 (99.444)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][120/390]\tTime 0.055 (0.046)\tData 0.005 (0.007)\tLoss 0.0138 (0.0180)\tPrec@1 100.000 (99.464)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][130/390]\tTime 0.053 (0.046)\tData 0.005 (0.007)\tLoss 0.0116 (0.0178)\tPrec@1 100.000 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][140/390]\tTime 0.054 (0.046)\tData 0.000 (0.006)\tLoss 0.0318 (0.0180)\tPrec@1 98.438 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][150/390]\tTime 0.034 (0.046)\tData 0.000 (0.006)\tLoss 0.0291 (0.0181)\tPrec@1 98.438 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][160/390]\tTime 0.027 (0.046)\tData 0.000 (0.006)\tLoss 0.0279 (0.0180)\tPrec@1 99.219 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][170/390]\tTime 0.033 (0.046)\tData 0.005 (0.006)\tLoss 0.0255 (0.0175)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][180/390]\tTime 0.049 (0.046)\tData 0.000 (0.006)\tLoss 0.0333 (0.0184)\tPrec@1 98.438 (99.465)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][190/390]\tTime 0.042 (0.045)\tData 0.000 (0.006)\tLoss 0.0157 (0.0185)\tPrec@1 99.219 (99.444)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][200/390]\tTime 0.035 (0.045)\tData 0.000 (0.006)\tLoss 0.0313 (0.0185)\tPrec@1 98.438 (99.448)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][210/390]\tTime 0.054 (0.045)\tData 0.001 (0.006)\tLoss 0.0032 (0.0184)\tPrec@1 100.000 (99.456)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][220/390]\tTime 0.038 (0.045)\tData 0.004 (0.005)\tLoss 0.0051 (0.0182)\tPrec@1 100.000 (99.466)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][230/390]\tTime 0.044 (0.045)\tData 0.005 (0.005)\tLoss 0.0200 (0.0183)\tPrec@1 99.219 (99.462)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][240/390]\tTime 0.046 (0.045)\tData 0.001 (0.005)\tLoss 0.0055 (0.0182)\tPrec@1 100.000 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][250/390]\tTime 0.046 (0.046)\tData 0.010 (0.005)\tLoss 0.0388 (0.0183)\tPrec@1 97.656 (99.458)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][260/390]\tTime 0.047 (0.046)\tData 0.000 (0.005)\tLoss 0.0148 (0.0183)\tPrec@1 100.000 (99.455)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][270/390]\tTime 0.040 (0.046)\tData 0.008 (0.005)\tLoss 0.0115 (0.0181)\tPrec@1 100.000 (99.464)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][280/390]\tTime 0.058 (0.046)\tData 0.010 (0.005)\tLoss 0.0244 (0.0180)\tPrec@1 99.219 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][290/390]\tTime 0.027 (0.045)\tData 0.000 (0.005)\tLoss 0.0074 (0.0180)\tPrec@1 100.000 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][300/390]\tTime 0.027 (0.045)\tData 0.000 (0.005)\tLoss 0.0175 (0.0181)\tPrec@1 100.000 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][310/390]\tTime 0.043 (0.045)\tData 0.010 (0.005)\tLoss 0.0110 (0.0181)\tPrec@1 100.000 (99.477)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][320/390]\tTime 0.045 (0.045)\tData 0.000 (0.005)\tLoss 0.0184 (0.0181)\tPrec@1 99.219 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][330/390]\tTime 0.038 (0.045)\tData 0.000 (0.005)\tLoss 0.0373 (0.0181)\tPrec@1 98.438 (99.469)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][340/390]\tTime 0.053 (0.045)\tData 0.001 (0.005)\tLoss 0.0135 (0.0181)\tPrec@1 100.000 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][350/390]\tTime 0.041 (0.045)\tData 0.000 (0.005)\tLoss 0.0179 (0.0180)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][360/390]\tTime 0.028 (0.045)\tData 0.000 (0.005)\tLoss 0.0405 (0.0178)\tPrec@1 99.219 (99.487)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][370/390]\tTime 0.040 (0.045)\tData 0.002 (0.005)\tLoss 0.0165 (0.0179)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][380/390]\tTime 0.038 (0.045)\tData 0.000 (0.005)\tLoss 0.0112 (0.0178)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [310][389/390]\tTime 0.021 (0.045)\tData 0.000 (0.005)\tLoss 0.0233 (0.0178)\tPrec@1 99.219 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [310][0/79]\tTime 0.196 (0.196)\tData 0.176 (0.176)\tLoss 0.2907 (0.2907)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [310][10/79]\tTime 0.018 (0.046)\tData 0.006 (0.034)\tLoss 0.2550 (0.3690)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [310][20/79]\tTime 0.017 (0.037)\tData 0.004 (0.025)\tLoss 0.5240 (0.4098)\tPrec@1 89.844 (91.629)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [310][30/79]\tTime 0.022 (0.036)\tData 0.016 (0.025)\tLoss 0.1002 (0.3973)\tPrec@1 97.656 (91.935)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [310][40/79]\tTime 0.019 (0.034)\tData 0.004 (0.023)\tLoss 0.2378 (0.3982)\tPrec@1 92.188 (91.959)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [310][50/79]\tTime 0.056 (0.033)\tData 0.041 (0.021)\tLoss 0.4322 (0.3913)\tPrec@1 89.844 (91.942)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [310][60/79]\tTime 0.018 (0.032)\tData 0.000 (0.020)\tLoss 0.6471 (0.3963)\tPrec@1 92.969 (91.842)\tPrec@5 99.219 (99.680)\t\n",
            "EVALUATING - Epoch: [310][70/79]\tTime 0.065 (0.032)\tData 0.057 (0.020)\tLoss 0.3988 (0.3889)\tPrec@1 89.844 (91.791)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [310][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.019)\tLoss 0.2441 (0.3862)\tPrec@1 93.750 (91.770)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 311\n",
            "Training Loss 0.0178 \tTraining Prec@1 99.497 \tTraining Prec@5 100.000 \tValidation Loss 0.3862 \tValidation Prec@1 91.770 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 312\n",
            "\n",
            "TRAINING - Epoch: [311][0/390]\tTime 0.338 (0.338)\tData 0.279 (0.279)\tLoss 0.0107 (0.0107)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][10/390]\tTime 0.037 (0.068)\tData 0.001 (0.027)\tLoss 0.0163 (0.0124)\tPrec@1 100.000 (99.787)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][20/390]\tTime 0.041 (0.058)\tData 0.004 (0.017)\tLoss 0.0162 (0.0190)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][30/390]\tTime 0.048 (0.054)\tData 0.002 (0.012)\tLoss 0.0271 (0.0197)\tPrec@1 99.219 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][40/390]\tTime 0.029 (0.051)\tData 0.000 (0.010)\tLoss 0.0178 (0.0179)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][50/390]\tTime 0.052 (0.050)\tData 0.001 (0.009)\tLoss 0.0327 (0.0192)\tPrec@1 99.219 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][60/390]\tTime 0.043 (0.050)\tData 0.001 (0.009)\tLoss 0.0087 (0.0188)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][70/390]\tTime 0.049 (0.050)\tData 0.008 (0.008)\tLoss 0.0031 (0.0179)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][80/390]\tTime 0.040 (0.050)\tData 0.000 (0.007)\tLoss 0.0110 (0.0178)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][90/390]\tTime 0.046 (0.049)\tData 0.006 (0.007)\tLoss 0.0245 (0.0180)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][100/390]\tTime 0.046 (0.048)\tData 0.009 (0.007)\tLoss 0.0025 (0.0174)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][110/390]\tTime 0.058 (0.048)\tData 0.001 (0.007)\tLoss 0.0067 (0.0171)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][120/390]\tTime 0.062 (0.048)\tData 0.013 (0.006)\tLoss 0.0275 (0.0169)\tPrec@1 98.438 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][130/390]\tTime 0.049 (0.048)\tData 0.002 (0.006)\tLoss 0.0102 (0.0173)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][140/390]\tTime 0.036 (0.048)\tData 0.001 (0.006)\tLoss 0.0254 (0.0173)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][150/390]\tTime 0.056 (0.047)\tData 0.001 (0.006)\tLoss 0.0124 (0.0170)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][160/390]\tTime 0.027 (0.047)\tData 0.000 (0.006)\tLoss 0.0063 (0.0168)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][170/390]\tTime 0.049 (0.047)\tData 0.001 (0.006)\tLoss 0.0112 (0.0168)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][180/390]\tTime 0.051 (0.047)\tData 0.003 (0.005)\tLoss 0.0025 (0.0170)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][190/390]\tTime 0.052 (0.047)\tData 0.012 (0.006)\tLoss 0.0122 (0.0168)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][200/390]\tTime 0.039 (0.047)\tData 0.000 (0.005)\tLoss 0.0092 (0.0166)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][210/390]\tTime 0.032 (0.047)\tData 0.000 (0.005)\tLoss 0.0256 (0.0170)\tPrec@1 98.438 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][220/390]\tTime 0.051 (0.046)\tData 0.000 (0.005)\tLoss 0.0149 (0.0173)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][230/390]\tTime 0.045 (0.046)\tData 0.000 (0.005)\tLoss 0.0235 (0.0175)\tPrec@1 98.438 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][240/390]\tTime 0.050 (0.046)\tData 0.005 (0.005)\tLoss 0.0453 (0.0176)\tPrec@1 98.438 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][250/390]\tTime 0.046 (0.046)\tData 0.006 (0.005)\tLoss 0.0188 (0.0174)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][260/390]\tTime 0.055 (0.046)\tData 0.004 (0.005)\tLoss 0.0127 (0.0174)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][270/390]\tTime 0.049 (0.046)\tData 0.003 (0.005)\tLoss 0.0035 (0.0174)\tPrec@1 100.000 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][280/390]\tTime 0.037 (0.046)\tData 0.000 (0.005)\tLoss 0.0089 (0.0174)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][290/390]\tTime 0.039 (0.046)\tData 0.000 (0.005)\tLoss 0.0145 (0.0173)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][300/390]\tTime 0.053 (0.046)\tData 0.001 (0.005)\tLoss 0.0123 (0.0173)\tPrec@1 99.219 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][310/390]\tTime 0.042 (0.046)\tData 0.004 (0.005)\tLoss 0.0052 (0.0173)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][320/390]\tTime 0.030 (0.046)\tData 0.005 (0.005)\tLoss 0.0077 (0.0174)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][330/390]\tTime 0.043 (0.046)\tData 0.002 (0.005)\tLoss 0.0131 (0.0174)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][340/390]\tTime 0.036 (0.046)\tData 0.001 (0.005)\tLoss 0.0236 (0.0175)\tPrec@1 98.438 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][350/390]\tTime 0.039 (0.045)\tData 0.000 (0.005)\tLoss 0.0174 (0.0175)\tPrec@1 99.219 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][360/390]\tTime 0.037 (0.045)\tData 0.007 (0.005)\tLoss 0.0191 (0.0175)\tPrec@1 99.219 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][370/390]\tTime 0.037 (0.045)\tData 0.002 (0.005)\tLoss 0.0121 (0.0173)\tPrec@1 99.219 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][380/390]\tTime 0.038 (0.045)\tData 0.006 (0.005)\tLoss 0.0061 (0.0173)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [311][389/390]\tTime 0.020 (0.045)\tData 0.000 (0.005)\tLoss 0.0079 (0.0172)\tPrec@1 100.000 (99.515)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [311][0/79]\tTime 0.292 (0.292)\tData 0.277 (0.277)\tLoss 0.2976 (0.2976)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [311][10/79]\tTime 0.011 (0.045)\tData 0.005 (0.033)\tLoss 0.2547 (0.3714)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [311][20/79]\tTime 0.033 (0.038)\tData 0.027 (0.024)\tLoss 0.5396 (0.4125)\tPrec@1 89.844 (91.518)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [311][30/79]\tTime 0.046 (0.034)\tData 0.040 (0.022)\tLoss 0.0954 (0.4001)\tPrec@1 97.656 (91.835)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [311][40/79]\tTime 0.020 (0.033)\tData 0.010 (0.021)\tLoss 0.2531 (0.4011)\tPrec@1 89.844 (91.845)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [311][50/79]\tTime 0.041 (0.032)\tData 0.035 (0.021)\tLoss 0.4450 (0.3939)\tPrec@1 90.625 (91.820)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [311][60/79]\tTime 0.029 (0.031)\tData 0.000 (0.019)\tLoss 0.6508 (0.3983)\tPrec@1 92.188 (91.752)\tPrec@5 100.000 (99.718)\t\n",
            "EVALUATING - Epoch: [311][70/79]\tTime 0.057 (0.032)\tData 0.052 (0.019)\tLoss 0.4080 (0.3908)\tPrec@1 89.844 (91.670)\tPrec@5 100.000 (99.747)\t\n",
            "EVALUATING - Epoch: [311][78/79]\tTime 0.004 (0.030)\tData 0.000 (0.018)\tLoss 0.2503 (0.3875)\tPrec@1 93.750 (91.690)\tPrec@5 100.000 (99.750)\t\n",
            "\n",
            "Results - Epoch: 312\n",
            "Training Loss 0.0172 \tTraining Prec@1 99.515 \tTraining Prec@5 100.000 \tValidation Loss 0.3875 \tValidation Prec@1 91.690 \tValidation Prec@5 99.750 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 313\n",
            "\n",
            "TRAINING - Epoch: [312][0/390]\tTime 0.344 (0.344)\tData 0.275 (0.275)\tLoss 0.0127 (0.0127)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][10/390]\tTime 0.040 (0.072)\tData 0.000 (0.029)\tLoss 0.0408 (0.0194)\tPrec@1 97.656 (99.290)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][20/390]\tTime 0.047 (0.057)\tData 0.007 (0.017)\tLoss 0.0162 (0.0188)\tPrec@1 99.219 (99.368)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][30/390]\tTime 0.034 (0.052)\tData 0.000 (0.012)\tLoss 0.0058 (0.0166)\tPrec@1 100.000 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][40/390]\tTime 0.036 (0.049)\tData 0.005 (0.010)\tLoss 0.0134 (0.0172)\tPrec@1 100.000 (99.447)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][50/390]\tTime 0.046 (0.048)\tData 0.008 (0.010)\tLoss 0.0141 (0.0170)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][60/390]\tTime 0.053 (0.048)\tData 0.006 (0.009)\tLoss 0.0405 (0.0174)\tPrec@1 98.438 (99.449)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][70/390]\tTime 0.037 (0.048)\tData 0.000 (0.008)\tLoss 0.0115 (0.0167)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][80/390]\tTime 0.030 (0.047)\tData 0.000 (0.008)\tLoss 0.0324 (0.0168)\tPrec@1 98.438 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][90/390]\tTime 0.040 (0.047)\tData 0.005 (0.007)\tLoss 0.0105 (0.0163)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][100/390]\tTime 0.048 (0.047)\tData 0.009 (0.007)\tLoss 0.0246 (0.0166)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][110/390]\tTime 0.047 (0.047)\tData 0.000 (0.007)\tLoss 0.0170 (0.0173)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][120/390]\tTime 0.056 (0.047)\tData 0.002 (0.007)\tLoss 0.0339 (0.0172)\tPrec@1 99.219 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][130/390]\tTime 0.052 (0.047)\tData 0.003 (0.006)\tLoss 0.0390 (0.0173)\tPrec@1 98.438 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][140/390]\tTime 0.044 (0.047)\tData 0.007 (0.006)\tLoss 0.0039 (0.0170)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][150/390]\tTime 0.042 (0.047)\tData 0.007 (0.006)\tLoss 0.0184 (0.0172)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][160/390]\tTime 0.052 (0.046)\tData 0.006 (0.006)\tLoss 0.0175 (0.0173)\tPrec@1 100.000 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][170/390]\tTime 0.034 (0.046)\tData 0.001 (0.006)\tLoss 0.0085 (0.0172)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][180/390]\tTime 0.072 (0.046)\tData 0.045 (0.006)\tLoss 0.0099 (0.0173)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][190/390]\tTime 0.048 (0.046)\tData 0.005 (0.006)\tLoss 0.0118 (0.0173)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][200/390]\tTime 0.052 (0.046)\tData 0.020 (0.006)\tLoss 0.0146 (0.0173)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][210/390]\tTime 0.061 (0.046)\tData 0.001 (0.006)\tLoss 0.0059 (0.0171)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][220/390]\tTime 0.053 (0.046)\tData 0.005 (0.006)\tLoss 0.0072 (0.0172)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][230/390]\tTime 0.041 (0.046)\tData 0.004 (0.006)\tLoss 0.0245 (0.0175)\tPrec@1 99.219 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][240/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0052 (0.0172)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][250/390]\tTime 0.046 (0.046)\tData 0.005 (0.006)\tLoss 0.0264 (0.0171)\tPrec@1 99.219 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][260/390]\tTime 0.035 (0.046)\tData 0.003 (0.006)\tLoss 0.0074 (0.0169)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][270/390]\tTime 0.046 (0.046)\tData 0.002 (0.006)\tLoss 0.0125 (0.0169)\tPrec@1 99.219 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][280/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0136 (0.0170)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][290/390]\tTime 0.036 (0.046)\tData 0.000 (0.006)\tLoss 0.0041 (0.0170)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][300/390]\tTime 0.045 (0.046)\tData 0.000 (0.005)\tLoss 0.0309 (0.0171)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][310/390]\tTime 0.037 (0.046)\tData 0.002 (0.005)\tLoss 0.0099 (0.0170)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][320/390]\tTime 0.040 (0.046)\tData 0.004 (0.005)\tLoss 0.0085 (0.0172)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][330/390]\tTime 0.052 (0.046)\tData 0.001 (0.005)\tLoss 0.0155 (0.0171)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][340/390]\tTime 0.048 (0.046)\tData 0.003 (0.005)\tLoss 0.0042 (0.0170)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][350/390]\tTime 0.046 (0.046)\tData 0.015 (0.005)\tLoss 0.0216 (0.0170)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][360/390]\tTime 0.032 (0.046)\tData 0.000 (0.005)\tLoss 0.0103 (0.0171)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][370/390]\tTime 0.052 (0.046)\tData 0.011 (0.005)\tLoss 0.0057 (0.0169)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][380/390]\tTime 0.044 (0.046)\tData 0.020 (0.005)\tLoss 0.0394 (0.0169)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [312][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0187 (0.0170)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [312][0/79]\tTime 0.258 (0.258)\tData 0.240 (0.240)\tLoss 0.3035 (0.3035)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [312][10/79]\tTime 0.018 (0.048)\tData 0.001 (0.034)\tLoss 0.2688 (0.3699)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [312][20/79]\tTime 0.010 (0.038)\tData 0.002 (0.025)\tLoss 0.5433 (0.4128)\tPrec@1 89.844 (91.518)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [312][30/79]\tTime 0.044 (0.036)\tData 0.017 (0.023)\tLoss 0.0952 (0.3986)\tPrec@1 97.656 (91.809)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [312][40/79]\tTime 0.011 (0.036)\tData 0.002 (0.023)\tLoss 0.2597 (0.3988)\tPrec@1 89.844 (91.787)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [312][50/79]\tTime 0.013 (0.035)\tData 0.006 (0.022)\tLoss 0.4261 (0.3925)\tPrec@1 90.625 (91.774)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [312][60/79]\tTime 0.014 (0.034)\tData 0.002 (0.022)\tLoss 0.6484 (0.3970)\tPrec@1 92.188 (91.688)\tPrec@5 99.219 (99.693)\t\n",
            "EVALUATING - Epoch: [312][70/79]\tTime 0.017 (0.033)\tData 0.006 (0.021)\tLoss 0.4077 (0.3902)\tPrec@1 89.844 (91.626)\tPrec@5 100.000 (99.725)\t\n",
            "EVALUATING - Epoch: [312][78/79]\tTime 0.003 (0.031)\tData 0.000 (0.020)\tLoss 0.2507 (0.3874)\tPrec@1 93.750 (91.680)\tPrec@5 100.000 (99.720)\t\n",
            "\n",
            "Results - Epoch: 313\n",
            "Training Loss 0.0170 \tTraining Prec@1 99.543 \tTraining Prec@5 100.000 \tValidation Loss 0.3874 \tValidation Prec@1 91.680 \tValidation Prec@5 99.720 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 314\n",
            "\n",
            "TRAINING - Epoch: [313][0/390]\tTime 0.348 (0.348)\tData 0.298 (0.298)\tLoss 0.0105 (0.0105)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][10/390]\tTime 0.045 (0.075)\tData 0.002 (0.030)\tLoss 0.0267 (0.0151)\tPrec@1 98.438 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][20/390]\tTime 0.046 (0.063)\tData 0.005 (0.018)\tLoss 0.0201 (0.0144)\tPrec@1 99.219 (99.702)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][30/390]\tTime 0.040 (0.056)\tData 0.000 (0.012)\tLoss 0.0156 (0.0164)\tPrec@1 100.000 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][40/390]\tTime 0.041 (0.054)\tData 0.000 (0.010)\tLoss 0.0116 (0.0164)\tPrec@1 100.000 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][50/390]\tTime 0.060 (0.053)\tData 0.005 (0.009)\tLoss 0.0198 (0.0175)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][60/390]\tTime 0.041 (0.052)\tData 0.005 (0.009)\tLoss 0.0521 (0.0179)\tPrec@1 98.438 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][70/390]\tTime 0.050 (0.052)\tData 0.000 (0.008)\tLoss 0.0129 (0.0178)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][80/390]\tTime 0.049 (0.052)\tData 0.000 (0.008)\tLoss 0.0162 (0.0176)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][90/390]\tTime 0.052 (0.051)\tData 0.002 (0.007)\tLoss 0.0093 (0.0179)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][100/390]\tTime 0.047 (0.051)\tData 0.005 (0.007)\tLoss 0.0126 (0.0180)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][110/390]\tTime 0.046 (0.051)\tData 0.005 (0.006)\tLoss 0.0164 (0.0175)\tPrec@1 99.219 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][120/390]\tTime 0.053 (0.050)\tData 0.001 (0.006)\tLoss 0.0108 (0.0172)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][130/390]\tTime 0.040 (0.050)\tData 0.002 (0.006)\tLoss 0.0224 (0.0173)\tPrec@1 98.438 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][140/390]\tTime 0.049 (0.050)\tData 0.005 (0.006)\tLoss 0.0270 (0.0176)\tPrec@1 99.219 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][150/390]\tTime 0.045 (0.050)\tData 0.000 (0.007)\tLoss 0.0230 (0.0173)\tPrec@1 98.438 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][160/390]\tTime 0.051 (0.050)\tData 0.000 (0.006)\tLoss 0.0085 (0.0174)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][170/390]\tTime 0.048 (0.050)\tData 0.005 (0.006)\tLoss 0.0099 (0.0176)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][180/390]\tTime 0.049 (0.049)\tData 0.000 (0.006)\tLoss 0.0169 (0.0174)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][190/390]\tTime 0.054 (0.049)\tData 0.005 (0.006)\tLoss 0.0047 (0.0171)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][200/390]\tTime 0.044 (0.049)\tData 0.007 (0.006)\tLoss 0.0081 (0.0169)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][210/390]\tTime 0.062 (0.049)\tData 0.016 (0.006)\tLoss 0.0131 (0.0169)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][220/390]\tTime 0.038 (0.049)\tData 0.010 (0.006)\tLoss 0.0165 (0.0169)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][230/390]\tTime 0.045 (0.049)\tData 0.005 (0.006)\tLoss 0.0201 (0.0168)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][240/390]\tTime 0.041 (0.049)\tData 0.001 (0.006)\tLoss 0.0270 (0.0170)\tPrec@1 99.219 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][250/390]\tTime 0.047 (0.049)\tData 0.013 (0.006)\tLoss 0.0366 (0.0169)\tPrec@1 99.219 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][260/390]\tTime 0.054 (0.049)\tData 0.002 (0.006)\tLoss 0.0237 (0.0167)\tPrec@1 99.219 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][270/390]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.0137 (0.0169)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][280/390]\tTime 0.044 (0.049)\tData 0.003 (0.006)\tLoss 0.0066 (0.0169)\tPrec@1 100.000 (99.589)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][290/390]\tTime 0.028 (0.049)\tData 0.000 (0.005)\tLoss 0.0067 (0.0167)\tPrec@1 100.000 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][300/390]\tTime 0.062 (0.049)\tData 0.000 (0.005)\tLoss 0.0194 (0.0166)\tPrec@1 99.219 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][310/390]\tTime 0.035 (0.049)\tData 0.000 (0.005)\tLoss 0.0392 (0.0166)\tPrec@1 98.438 (99.593)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][320/390]\tTime 0.040 (0.048)\tData 0.007 (0.005)\tLoss 0.0147 (0.0166)\tPrec@1 99.219 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][330/390]\tTime 0.060 (0.048)\tData 0.005 (0.005)\tLoss 0.0081 (0.0168)\tPrec@1 100.000 (99.580)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][340/390]\tTime 0.036 (0.048)\tData 0.001 (0.005)\tLoss 0.0137 (0.0169)\tPrec@1 100.000 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][350/390]\tTime 0.037 (0.048)\tData 0.001 (0.005)\tLoss 0.0262 (0.0169)\tPrec@1 99.219 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][360/390]\tTime 0.034 (0.048)\tData 0.006 (0.005)\tLoss 0.0070 (0.0169)\tPrec@1 100.000 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][370/390]\tTime 0.050 (0.048)\tData 0.005 (0.005)\tLoss 0.0076 (0.0168)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][380/390]\tTime 0.047 (0.048)\tData 0.005 (0.005)\tLoss 0.0109 (0.0167)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [313][389/390]\tTime 0.018 (0.048)\tData 0.000 (0.005)\tLoss 0.0071 (0.0167)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [313][0/79]\tTime 0.258 (0.258)\tData 0.237 (0.237)\tLoss 0.2946 (0.2946)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [313][10/79]\tTime 0.086 (0.050)\tData 0.074 (0.037)\tLoss 0.2638 (0.3708)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [313][20/79]\tTime 0.015 (0.039)\tData 0.001 (0.025)\tLoss 0.5411 (0.4114)\tPrec@1 89.844 (91.667)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [313][30/79]\tTime 0.014 (0.035)\tData 0.007 (0.023)\tLoss 0.0965 (0.3976)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [313][40/79]\tTime 0.016 (0.036)\tData 0.003 (0.023)\tLoss 0.2438 (0.3984)\tPrec@1 91.406 (91.845)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [313][50/79]\tTime 0.041 (0.035)\tData 0.007 (0.021)\tLoss 0.4313 (0.3917)\tPrec@1 90.625 (91.805)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [313][60/79]\tTime 0.022 (0.034)\tData 0.005 (0.021)\tLoss 0.6377 (0.3967)\tPrec@1 92.188 (91.714)\tPrec@5 100.000 (99.693)\t\n",
            "EVALUATING - Epoch: [313][70/79]\tTime 0.029 (0.033)\tData 0.013 (0.020)\tLoss 0.4034 (0.3895)\tPrec@1 89.844 (91.659)\tPrec@5 100.000 (99.725)\t\n",
            "EVALUATING - Epoch: [313][78/79]\tTime 0.003 (0.032)\tData 0.000 (0.019)\tLoss 0.2577 (0.3868)\tPrec@1 93.750 (91.680)\tPrec@5 100.000 (99.730)\t\n",
            "\n",
            "Results - Epoch: 314\n",
            "Training Loss 0.0167 \tTraining Prec@1 99.591 \tTraining Prec@5 100.000 \tValidation Loss 0.3868 \tValidation Prec@1 91.680 \tValidation Prec@5 99.730 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 315\n",
            "\n",
            "TRAINING - Epoch: [314][0/390]\tTime 0.268 (0.268)\tData 0.201 (0.201)\tLoss 0.0053 (0.0053)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][10/390]\tTime 0.035 (0.071)\tData 0.000 (0.025)\tLoss 0.0117 (0.0148)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][20/390]\tTime 0.040 (0.059)\tData 0.001 (0.015)\tLoss 0.0146 (0.0145)\tPrec@1 100.000 (99.702)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][30/390]\tTime 0.034 (0.055)\tData 0.005 (0.011)\tLoss 0.0087 (0.0138)\tPrec@1 100.000 (99.748)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][40/390]\tTime 0.046 (0.052)\tData 0.005 (0.010)\tLoss 0.0142 (0.0138)\tPrec@1 100.000 (99.733)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][50/390]\tTime 0.036 (0.051)\tData 0.008 (0.010)\tLoss 0.0072 (0.0140)\tPrec@1 100.000 (99.709)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][60/390]\tTime 0.030 (0.051)\tData 0.001 (0.011)\tLoss 0.0076 (0.0141)\tPrec@1 100.000 (99.693)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][70/390]\tTime 0.040 (0.050)\tData 0.000 (0.011)\tLoss 0.0479 (0.0146)\tPrec@1 99.219 (99.670)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][80/390]\tTime 0.042 (0.049)\tData 0.006 (0.010)\tLoss 0.0164 (0.0143)\tPrec@1 99.219 (99.662)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][90/390]\tTime 0.175 (0.050)\tData 0.142 (0.011)\tLoss 0.0181 (0.0153)\tPrec@1 99.219 (99.605)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][100/390]\tTime 0.049 (0.049)\tData 0.005 (0.011)\tLoss 0.0049 (0.0155)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][110/390]\tTime 0.044 (0.049)\tData 0.000 (0.010)\tLoss 0.0249 (0.0158)\tPrec@1 98.438 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][120/390]\tTime 0.060 (0.048)\tData 0.003 (0.009)\tLoss 0.0139 (0.0159)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][130/390]\tTime 0.044 (0.050)\tData 0.000 (0.010)\tLoss 0.0127 (0.0158)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][140/390]\tTime 0.054 (0.050)\tData 0.002 (0.010)\tLoss 0.0053 (0.0157)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][150/390]\tTime 0.058 (0.050)\tData 0.006 (0.009)\tLoss 0.0137 (0.0156)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][160/390]\tTime 0.041 (0.050)\tData 0.008 (0.010)\tLoss 0.0167 (0.0158)\tPrec@1 100.000 (99.607)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][170/390]\tTime 0.046 (0.050)\tData 0.005 (0.009)\tLoss 0.0062 (0.0158)\tPrec@1 100.000 (99.607)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][180/390]\tTime 0.044 (0.050)\tData 0.014 (0.009)\tLoss 0.0084 (0.0159)\tPrec@1 100.000 (99.599)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][190/390]\tTime 0.045 (0.049)\tData 0.005 (0.009)\tLoss 0.0069 (0.0159)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][200/390]\tTime 0.048 (0.049)\tData 0.000 (0.009)\tLoss 0.0133 (0.0159)\tPrec@1 100.000 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][210/390]\tTime 0.028 (0.049)\tData 0.000 (0.008)\tLoss 0.0082 (0.0159)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][220/390]\tTime 0.051 (0.049)\tData 0.003 (0.008)\tLoss 0.0304 (0.0159)\tPrec@1 98.438 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][230/390]\tTime 0.042 (0.049)\tData 0.000 (0.008)\tLoss 0.0256 (0.0157)\tPrec@1 99.219 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][240/390]\tTime 0.046 (0.049)\tData 0.005 (0.008)\tLoss 0.0247 (0.0158)\tPrec@1 99.219 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][250/390]\tTime 0.040 (0.049)\tData 0.000 (0.008)\tLoss 0.0279 (0.0159)\tPrec@1 99.219 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][260/390]\tTime 0.034 (0.049)\tData 0.000 (0.007)\tLoss 0.0126 (0.0159)\tPrec@1 100.000 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][270/390]\tTime 0.045 (0.049)\tData 0.000 (0.007)\tLoss 0.0138 (0.0158)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][280/390]\tTime 0.056 (0.049)\tData 0.000 (0.007)\tLoss 0.0182 (0.0160)\tPrec@1 99.219 (99.589)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][290/390]\tTime 0.039 (0.049)\tData 0.000 (0.007)\tLoss 0.0152 (0.0161)\tPrec@1 100.000 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][300/390]\tTime 0.072 (0.049)\tData 0.029 (0.007)\tLoss 0.0360 (0.0160)\tPrec@1 99.219 (99.603)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][310/390]\tTime 0.038 (0.048)\tData 0.001 (0.007)\tLoss 0.0127 (0.0161)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][320/390]\tTime 0.044 (0.049)\tData 0.011 (0.007)\tLoss 0.0293 (0.0161)\tPrec@1 99.219 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][330/390]\tTime 0.049 (0.048)\tData 0.000 (0.007)\tLoss 0.0131 (0.0161)\tPrec@1 99.219 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][340/390]\tTime 0.069 (0.048)\tData 0.014 (0.007)\tLoss 0.0090 (0.0160)\tPrec@1 100.000 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][350/390]\tTime 0.042 (0.048)\tData 0.001 (0.007)\tLoss 0.0339 (0.0161)\tPrec@1 99.219 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][360/390]\tTime 0.048 (0.048)\tData 0.000 (0.007)\tLoss 0.0104 (0.0162)\tPrec@1 100.000 (99.593)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][370/390]\tTime 0.054 (0.048)\tData 0.002 (0.007)\tLoss 0.0172 (0.0162)\tPrec@1 99.219 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][380/390]\tTime 0.056 (0.048)\tData 0.009 (0.007)\tLoss 0.0229 (0.0163)\tPrec@1 99.219 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [314][389/390]\tTime 0.018 (0.048)\tData 0.000 (0.007)\tLoss 0.0098 (0.0162)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [314][0/79]\tTime 0.267 (0.267)\tData 0.246 (0.246)\tLoss 0.2913 (0.2913)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [314][10/79]\tTime 0.022 (0.047)\tData 0.010 (0.035)\tLoss 0.2577 (0.3627)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [314][20/79]\tTime 0.029 (0.040)\tData 0.010 (0.025)\tLoss 0.5213 (0.4039)\tPrec@1 89.844 (91.629)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [314][30/79]\tTime 0.012 (0.038)\tData 0.002 (0.024)\tLoss 0.1065 (0.3917)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [314][40/79]\tTime 0.020 (0.037)\tData 0.005 (0.023)\tLoss 0.2321 (0.3928)\tPrec@1 92.188 (91.921)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [314][50/79]\tTime 0.024 (0.035)\tData 0.010 (0.021)\tLoss 0.4213 (0.3854)\tPrec@1 90.625 (91.912)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [314][60/79]\tTime 0.013 (0.035)\tData 0.005 (0.021)\tLoss 0.6332 (0.3901)\tPrec@1 92.188 (91.829)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [314][70/79]\tTime 0.125 (0.036)\tData 0.118 (0.022)\tLoss 0.4028 (0.3827)\tPrec@1 90.625 (91.813)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [314][78/79]\tTime 0.003 (0.033)\tData 0.000 (0.020)\tLoss 0.2532 (0.3800)\tPrec@1 93.750 (91.840)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 315\n",
            "Training Loss 0.0162 \tTraining Prec@1 99.591 \tTraining Prec@5 100.000 \tValidation Loss 0.3800 \tValidation Prec@1 91.840 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 316\n",
            "\n",
            "TRAINING - Epoch: [315][0/390]\tTime 0.343 (0.343)\tData 0.288 (0.288)\tLoss 0.0220 (0.0220)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][10/390]\tTime 0.038 (0.074)\tData 0.000 (0.029)\tLoss 0.0051 (0.0152)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][20/390]\tTime 0.050 (0.062)\tData 0.000 (0.016)\tLoss 0.0208 (0.0168)\tPrec@1 99.219 (99.405)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][30/390]\tTime 0.039 (0.057)\tData 0.000 (0.012)\tLoss 0.0115 (0.0148)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][40/390]\tTime 0.057 (0.054)\tData 0.005 (0.010)\tLoss 0.0061 (0.0161)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][50/390]\tTime 0.031 (0.053)\tData 0.000 (0.008)\tLoss 0.0170 (0.0162)\tPrec@1 99.219 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][60/390]\tTime 0.057 (0.052)\tData 0.001 (0.007)\tLoss 0.0165 (0.0166)\tPrec@1 99.219 (99.462)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][70/390]\tTime 0.052 (0.051)\tData 0.000 (0.007)\tLoss 0.0219 (0.0169)\tPrec@1 99.219 (99.450)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][80/390]\tTime 0.053 (0.051)\tData 0.000 (0.006)\tLoss 0.0136 (0.0166)\tPrec@1 99.219 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][90/390]\tTime 0.049 (0.051)\tData 0.001 (0.006)\tLoss 0.0129 (0.0168)\tPrec@1 100.000 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][100/390]\tTime 0.039 (0.050)\tData 0.005 (0.006)\tLoss 0.0092 (0.0168)\tPrec@1 100.000 (99.474)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][110/390]\tTime 0.034 (0.050)\tData 0.006 (0.006)\tLoss 0.0088 (0.0165)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][120/390]\tTime 0.043 (0.050)\tData 0.000 (0.005)\tLoss 0.0382 (0.0172)\tPrec@1 98.438 (99.458)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][130/390]\tTime 0.045 (0.050)\tData 0.000 (0.005)\tLoss 0.0210 (0.0174)\tPrec@1 99.219 (99.457)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][140/390]\tTime 0.039 (0.050)\tData 0.001 (0.005)\tLoss 0.0073 (0.0172)\tPrec@1 100.000 (99.474)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][150/390]\tTime 0.054 (0.049)\tData 0.005 (0.005)\tLoss 0.0067 (0.0170)\tPrec@1 100.000 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][160/390]\tTime 0.051 (0.049)\tData 0.000 (0.005)\tLoss 0.0169 (0.0170)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][170/390]\tTime 0.049 (0.049)\tData 0.002 (0.005)\tLoss 0.0154 (0.0172)\tPrec@1 99.219 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][180/390]\tTime 0.045 (0.049)\tData 0.001 (0.005)\tLoss 0.0137 (0.0176)\tPrec@1 100.000 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][190/390]\tTime 0.055 (0.049)\tData 0.014 (0.005)\tLoss 0.0169 (0.0178)\tPrec@1 99.219 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][200/390]\tTime 0.040 (0.049)\tData 0.003 (0.005)\tLoss 0.0159 (0.0179)\tPrec@1 100.000 (99.475)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][210/390]\tTime 0.039 (0.049)\tData 0.000 (0.005)\tLoss 0.0211 (0.0179)\tPrec@1 99.219 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][220/390]\tTime 0.070 (0.049)\tData 0.031 (0.005)\tLoss 0.0120 (0.0178)\tPrec@1 100.000 (99.480)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][230/390]\tTime 0.042 (0.049)\tData 0.002 (0.005)\tLoss 0.0053 (0.0177)\tPrec@1 100.000 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][240/390]\tTime 0.037 (0.049)\tData 0.001 (0.005)\tLoss 0.0104 (0.0175)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][250/390]\tTime 0.036 (0.048)\tData 0.001 (0.005)\tLoss 0.0095 (0.0177)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][260/390]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.0188 (0.0179)\tPrec@1 98.438 (99.491)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][270/390]\tTime 0.054 (0.048)\tData 0.007 (0.005)\tLoss 0.0087 (0.0178)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][280/390]\tTime 0.035 (0.048)\tData 0.000 (0.005)\tLoss 0.0091 (0.0176)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][290/390]\tTime 0.050 (0.048)\tData 0.006 (0.005)\tLoss 0.0124 (0.0174)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][300/390]\tTime 0.041 (0.048)\tData 0.000 (0.005)\tLoss 0.0111 (0.0174)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][310/390]\tTime 0.057 (0.048)\tData 0.000 (0.005)\tLoss 0.0075 (0.0172)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][320/390]\tTime 0.040 (0.048)\tData 0.007 (0.005)\tLoss 0.0218 (0.0171)\tPrec@1 99.219 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][330/390]\tTime 0.044 (0.048)\tData 0.005 (0.005)\tLoss 0.0303 (0.0170)\tPrec@1 98.438 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][340/390]\tTime 0.047 (0.048)\tData 0.005 (0.005)\tLoss 0.0192 (0.0171)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][350/390]\tTime 0.039 (0.048)\tData 0.000 (0.005)\tLoss 0.0583 (0.0173)\tPrec@1 98.438 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][360/390]\tTime 0.046 (0.048)\tData 0.004 (0.005)\tLoss 0.0215 (0.0172)\tPrec@1 98.438 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][370/390]\tTime 0.061 (0.048)\tData 0.005 (0.005)\tLoss 0.0151 (0.0172)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][380/390]\tTime 0.054 (0.048)\tData 0.003 (0.005)\tLoss 0.0267 (0.0173)\tPrec@1 99.219 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [315][389/390]\tTime 0.018 (0.048)\tData 0.000 (0.004)\tLoss 0.0256 (0.0173)\tPrec@1 99.219 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [315][0/79]\tTime 0.250 (0.250)\tData 0.231 (0.231)\tLoss 0.2740 (0.2740)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [315][10/79]\tTime 0.019 (0.050)\tData 0.005 (0.038)\tLoss 0.2737 (0.3703)\tPrec@1 91.406 (92.401)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [315][20/79]\tTime 0.023 (0.041)\tData 0.003 (0.027)\tLoss 0.5336 (0.4106)\tPrec@1 89.844 (91.853)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [315][30/79]\tTime 0.031 (0.038)\tData 0.002 (0.023)\tLoss 0.0970 (0.3976)\tPrec@1 97.656 (92.188)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [315][40/79]\tTime 0.016 (0.034)\tData 0.001 (0.020)\tLoss 0.2394 (0.4004)\tPrec@1 90.625 (92.016)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [315][50/79]\tTime 0.016 (0.033)\tData 0.010 (0.018)\tLoss 0.4379 (0.3932)\tPrec@1 89.844 (91.927)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [315][60/79]\tTime 0.012 (0.032)\tData 0.005 (0.019)\tLoss 0.6315 (0.3987)\tPrec@1 92.969 (91.855)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [315][70/79]\tTime 0.019 (0.033)\tData 0.005 (0.020)\tLoss 0.4034 (0.3912)\tPrec@1 89.844 (91.802)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [315][78/79]\tTime 0.003 (0.031)\tData 0.000 (0.018)\tLoss 0.2593 (0.3886)\tPrec@1 93.750 (91.800)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 316\n",
            "Training Loss 0.0173 \tTraining Prec@1 99.517 \tTraining Prec@5 100.000 \tValidation Loss 0.3886 \tValidation Prec@1 91.800 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 317\n",
            "\n",
            "TRAINING - Epoch: [316][0/390]\tTime 0.357 (0.357)\tData 0.312 (0.312)\tLoss 0.0158 (0.0158)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][10/390]\tTime 0.045 (0.071)\tData 0.000 (0.037)\tLoss 0.0221 (0.0138)\tPrec@1 99.219 (99.716)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][20/390]\tTime 0.045 (0.058)\tData 0.005 (0.021)\tLoss 0.0429 (0.0175)\tPrec@1 98.438 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][30/390]\tTime 0.050 (0.053)\tData 0.002 (0.015)\tLoss 0.0301 (0.0173)\tPrec@1 98.438 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][40/390]\tTime 0.044 (0.051)\tData 0.008 (0.012)\tLoss 0.0233 (0.0166)\tPrec@1 99.219 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][50/390]\tTime 0.028 (0.051)\tData 0.000 (0.010)\tLoss 0.0158 (0.0164)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][60/390]\tTime 0.044 (0.049)\tData 0.008 (0.009)\tLoss 0.0105 (0.0163)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][70/390]\tTime 0.040 (0.048)\tData 0.005 (0.008)\tLoss 0.0050 (0.0180)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][80/390]\tTime 0.038 (0.048)\tData 0.000 (0.008)\tLoss 0.0191 (0.0184)\tPrec@1 100.000 (99.450)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][90/390]\tTime 0.043 (0.048)\tData 0.002 (0.007)\tLoss 0.0171 (0.0182)\tPrec@1 99.219 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][100/390]\tTime 0.043 (0.048)\tData 0.003 (0.007)\tLoss 0.0085 (0.0181)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][110/390]\tTime 0.033 (0.047)\tData 0.005 (0.007)\tLoss 0.0071 (0.0177)\tPrec@1 100.000 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][120/390]\tTime 0.046 (0.047)\tData 0.001 (0.006)\tLoss 0.0221 (0.0176)\tPrec@1 99.219 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][130/390]\tTime 0.042 (0.046)\tData 0.003 (0.006)\tLoss 0.0575 (0.0180)\tPrec@1 98.438 (99.481)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][140/390]\tTime 0.043 (0.046)\tData 0.004 (0.006)\tLoss 0.0105 (0.0176)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][150/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0193 (0.0175)\tPrec@1 99.219 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][160/390]\tTime 0.045 (0.046)\tData 0.003 (0.006)\tLoss 0.0105 (0.0170)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][170/390]\tTime 0.051 (0.046)\tData 0.000 (0.006)\tLoss 0.0045 (0.0167)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][180/390]\tTime 0.057 (0.046)\tData 0.003 (0.006)\tLoss 0.0183 (0.0167)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][190/390]\tTime 0.060 (0.046)\tData 0.002 (0.006)\tLoss 0.0148 (0.0166)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][200/390]\tTime 0.044 (0.046)\tData 0.000 (0.005)\tLoss 0.0129 (0.0168)\tPrec@1 99.219 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][210/390]\tTime 0.043 (0.046)\tData 0.004 (0.005)\tLoss 0.0155 (0.0166)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][220/390]\tTime 0.040 (0.046)\tData 0.001 (0.005)\tLoss 0.0103 (0.0167)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][230/390]\tTime 0.038 (0.046)\tData 0.000 (0.005)\tLoss 0.0300 (0.0168)\tPrec@1 97.656 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][240/390]\tTime 0.043 (0.046)\tData 0.000 (0.005)\tLoss 0.0150 (0.0166)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][250/390]\tTime 0.036 (0.046)\tData 0.002 (0.005)\tLoss 0.0134 (0.0166)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][260/390]\tTime 0.034 (0.046)\tData 0.006 (0.005)\tLoss 0.0419 (0.0168)\tPrec@1 96.875 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][270/390]\tTime 0.040 (0.046)\tData 0.000 (0.005)\tLoss 0.0066 (0.0165)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][280/390]\tTime 0.037 (0.045)\tData 0.001 (0.005)\tLoss 0.0082 (0.0166)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][290/390]\tTime 0.039 (0.045)\tData 0.005 (0.005)\tLoss 0.0064 (0.0166)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][300/390]\tTime 0.041 (0.045)\tData 0.006 (0.005)\tLoss 0.0049 (0.0167)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][310/390]\tTime 0.049 (0.045)\tData 0.010 (0.005)\tLoss 0.0044 (0.0167)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][320/390]\tTime 0.052 (0.045)\tData 0.001 (0.005)\tLoss 0.0112 (0.0165)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][330/390]\tTime 0.047 (0.045)\tData 0.005 (0.005)\tLoss 0.0072 (0.0163)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][340/390]\tTime 0.039 (0.045)\tData 0.002 (0.005)\tLoss 0.0132 (0.0163)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][350/390]\tTime 0.046 (0.045)\tData 0.009 (0.005)\tLoss 0.0219 (0.0162)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][360/390]\tTime 0.083 (0.045)\tData 0.049 (0.005)\tLoss 0.0139 (0.0165)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][370/390]\tTime 0.029 (0.045)\tData 0.000 (0.005)\tLoss 0.0119 (0.0164)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][380/390]\tTime 0.056 (0.045)\tData 0.012 (0.005)\tLoss 0.0084 (0.0164)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [316][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0126 (0.0164)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [316][0/79]\tTime 0.259 (0.259)\tData 0.242 (0.242)\tLoss 0.2900 (0.2900)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [316][10/79]\tTime 0.006 (0.044)\tData 0.000 (0.032)\tLoss 0.2595 (0.3670)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [316][20/79]\tTime 0.067 (0.039)\tData 0.061 (0.027)\tLoss 0.5298 (0.4060)\tPrec@1 89.844 (91.667)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [316][30/79]\tTime 0.008 (0.034)\tData 0.000 (0.022)\tLoss 0.0949 (0.3935)\tPrec@1 97.656 (92.011)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [316][40/79]\tTime 0.042 (0.032)\tData 0.037 (0.020)\tLoss 0.2445 (0.3948)\tPrec@1 92.188 (91.997)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [316][50/79]\tTime 0.018 (0.031)\tData 0.001 (0.019)\tLoss 0.4334 (0.3877)\tPrec@1 90.625 (91.973)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [316][60/79]\tTime 0.076 (0.031)\tData 0.070 (0.019)\tLoss 0.6317 (0.3926)\tPrec@1 92.188 (91.867)\tPrec@5 100.000 (99.667)\t\n",
            "EVALUATING - Epoch: [316][70/79]\tTime 0.020 (0.031)\tData 0.010 (0.019)\tLoss 0.4052 (0.3851)\tPrec@1 89.844 (91.791)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [316][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2491 (0.3823)\tPrec@1 93.750 (91.810)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 317\n",
            "Training Loss 0.0164 \tTraining Prec@1 99.555 \tTraining Prec@5 100.000 \tValidation Loss 0.3823 \tValidation Prec@1 91.810 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 318\n",
            "\n",
            "TRAINING - Epoch: [317][0/390]\tTime 0.357 (0.357)\tData 0.309 (0.309)\tLoss 0.0119 (0.0119)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][10/390]\tTime 0.055 (0.071)\tData 0.013 (0.033)\tLoss 0.0371 (0.0176)\tPrec@1 99.219 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][20/390]\tTime 0.063 (0.056)\tData 0.031 (0.021)\tLoss 0.0170 (0.0180)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][30/390]\tTime 0.059 (0.054)\tData 0.012 (0.016)\tLoss 0.0296 (0.0187)\tPrec@1 99.219 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][40/390]\tTime 0.042 (0.052)\tData 0.002 (0.013)\tLoss 0.0177 (0.0194)\tPrec@1 99.219 (99.466)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][50/390]\tTime 0.033 (0.050)\tData 0.005 (0.011)\tLoss 0.0056 (0.0197)\tPrec@1 100.000 (99.433)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][60/390]\tTime 0.049 (0.049)\tData 0.015 (0.010)\tLoss 0.0092 (0.0188)\tPrec@1 100.000 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][70/390]\tTime 0.048 (0.048)\tData 0.005 (0.009)\tLoss 0.0077 (0.0187)\tPrec@1 100.000 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][80/390]\tTime 0.038 (0.048)\tData 0.010 (0.008)\tLoss 0.0144 (0.0187)\tPrec@1 99.219 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][90/390]\tTime 0.044 (0.047)\tData 0.002 (0.008)\tLoss 0.0218 (0.0182)\tPrec@1 99.219 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][100/390]\tTime 0.042 (0.047)\tData 0.011 (0.008)\tLoss 0.0262 (0.0181)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][110/390]\tTime 0.043 (0.047)\tData 0.000 (0.007)\tLoss 0.0643 (0.0180)\tPrec@1 97.656 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][120/390]\tTime 0.040 (0.047)\tData 0.004 (0.007)\tLoss 0.0162 (0.0174)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][130/390]\tTime 0.053 (0.046)\tData 0.005 (0.007)\tLoss 0.0126 (0.0171)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][140/390]\tTime 0.038 (0.046)\tData 0.000 (0.006)\tLoss 0.0043 (0.0171)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][150/390]\tTime 0.050 (0.046)\tData 0.000 (0.006)\tLoss 0.0338 (0.0173)\tPrec@1 99.219 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][160/390]\tTime 0.046 (0.046)\tData 0.000 (0.006)\tLoss 0.0236 (0.0174)\tPrec@1 100.000 (99.515)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][170/390]\tTime 0.041 (0.046)\tData 0.001 (0.006)\tLoss 0.0431 (0.0177)\tPrec@1 97.656 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][180/390]\tTime 0.043 (0.046)\tData 0.005 (0.006)\tLoss 0.0109 (0.0174)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][190/390]\tTime 0.059 (0.046)\tData 0.007 (0.006)\tLoss 0.0210 (0.0177)\tPrec@1 99.219 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][200/390]\tTime 0.048 (0.046)\tData 0.003 (0.005)\tLoss 0.0052 (0.0175)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][210/390]\tTime 0.051 (0.046)\tData 0.006 (0.005)\tLoss 0.0216 (0.0173)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][220/390]\tTime 0.045 (0.046)\tData 0.004 (0.005)\tLoss 0.0036 (0.0171)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][230/390]\tTime 0.036 (0.046)\tData 0.005 (0.005)\tLoss 0.0070 (0.0171)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][240/390]\tTime 0.044 (0.046)\tData 0.000 (0.005)\tLoss 0.0108 (0.0171)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][250/390]\tTime 0.040 (0.045)\tData 0.012 (0.005)\tLoss 0.0075 (0.0170)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][260/390]\tTime 0.030 (0.046)\tData 0.000 (0.005)\tLoss 0.0062 (0.0169)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][270/390]\tTime 0.053 (0.045)\tData 0.021 (0.005)\tLoss 0.0276 (0.0167)\tPrec@1 98.438 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][280/390]\tTime 0.036 (0.045)\tData 0.000 (0.005)\tLoss 0.0110 (0.0170)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][290/390]\tTime 0.041 (0.045)\tData 0.004 (0.005)\tLoss 0.0048 (0.0172)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][300/390]\tTime 0.035 (0.046)\tData 0.000 (0.005)\tLoss 0.0115 (0.0170)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][310/390]\tTime 0.059 (0.046)\tData 0.003 (0.005)\tLoss 0.0179 (0.0170)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][320/390]\tTime 0.048 (0.046)\tData 0.000 (0.006)\tLoss 0.0157 (0.0171)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][330/390]\tTime 0.047 (0.046)\tData 0.009 (0.005)\tLoss 0.0168 (0.0171)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][340/390]\tTime 0.036 (0.046)\tData 0.001 (0.005)\tLoss 0.0148 (0.0173)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][350/390]\tTime 0.043 (0.046)\tData 0.007 (0.005)\tLoss 0.0335 (0.0173)\tPrec@1 98.438 (99.515)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][360/390]\tTime 0.035 (0.045)\tData 0.001 (0.005)\tLoss 0.0245 (0.0173)\tPrec@1 99.219 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][370/390]\tTime 0.049 (0.045)\tData 0.000 (0.005)\tLoss 0.0147 (0.0173)\tPrec@1 99.219 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][380/390]\tTime 0.037 (0.045)\tData 0.004 (0.005)\tLoss 0.0095 (0.0173)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [317][389/390]\tTime 0.019 (0.045)\tData 0.000 (0.005)\tLoss 0.0117 (0.0173)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [317][0/79]\tTime 0.253 (0.253)\tData 0.226 (0.226)\tLoss 0.2935 (0.2935)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [317][10/79]\tTime 0.055 (0.049)\tData 0.049 (0.037)\tLoss 0.2547 (0.3716)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [317][20/79]\tTime 0.053 (0.040)\tData 0.014 (0.027)\tLoss 0.5345 (0.4124)\tPrec@1 89.844 (91.518)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [317][30/79]\tTime 0.034 (0.035)\tData 0.026 (0.022)\tLoss 0.1064 (0.4004)\tPrec@1 97.656 (91.835)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [317][40/79]\tTime 0.023 (0.034)\tData 0.004 (0.020)\tLoss 0.2509 (0.4018)\tPrec@1 89.844 (91.749)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [317][50/79]\tTime 0.009 (0.033)\tData 0.000 (0.020)\tLoss 0.4175 (0.3943)\tPrec@1 89.844 (91.697)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [317][60/79]\tTime 0.020 (0.032)\tData 0.004 (0.019)\tLoss 0.6574 (0.3992)\tPrec@1 92.188 (91.637)\tPrec@5 99.219 (99.680)\t\n",
            "EVALUATING - Epoch: [317][70/79]\tTime 0.023 (0.032)\tData 0.008 (0.018)\tLoss 0.3956 (0.3919)\tPrec@1 89.062 (91.604)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [317][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.017)\tLoss 0.2328 (0.3890)\tPrec@1 93.750 (91.640)\tPrec@5 100.000 (99.720)\t\n",
            "\n",
            "Results - Epoch: 318\n",
            "Training Loss 0.0173 \tTraining Prec@1 99.513 \tTraining Prec@5 100.000 \tValidation Loss 0.3890 \tValidation Prec@1 91.640 \tValidation Prec@5 99.720 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 319\n",
            "\n",
            "TRAINING - Epoch: [318][0/390]\tTime 0.301 (0.301)\tData 0.232 (0.232)\tLoss 0.0155 (0.0155)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][10/390]\tTime 0.039 (0.072)\tData 0.005 (0.026)\tLoss 0.0045 (0.0118)\tPrec@1 100.000 (99.716)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][20/390]\tTime 0.037 (0.057)\tData 0.001 (0.015)\tLoss 0.0353 (0.0147)\tPrec@1 98.438 (99.665)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][30/390]\tTime 0.038 (0.052)\tData 0.002 (0.011)\tLoss 0.0101 (0.0155)\tPrec@1 100.000 (99.672)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][40/390]\tTime 0.042 (0.050)\tData 0.002 (0.008)\tLoss 0.0041 (0.0155)\tPrec@1 100.000 (99.638)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][50/390]\tTime 0.035 (0.048)\tData 0.000 (0.007)\tLoss 0.0090 (0.0163)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][60/390]\tTime 0.046 (0.047)\tData 0.000 (0.007)\tLoss 0.0132 (0.0168)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][70/390]\tTime 0.033 (0.047)\tData 0.005 (0.006)\tLoss 0.0196 (0.0171)\tPrec@1 99.219 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][80/390]\tTime 0.047 (0.047)\tData 0.003 (0.006)\tLoss 0.0048 (0.0167)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][90/390]\tTime 0.044 (0.047)\tData 0.005 (0.006)\tLoss 0.0085 (0.0176)\tPrec@1 100.000 (99.485)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][100/390]\tTime 0.052 (0.047)\tData 0.007 (0.005)\tLoss 0.0087 (0.0171)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][110/390]\tTime 0.038 (0.047)\tData 0.000 (0.005)\tLoss 0.0280 (0.0167)\tPrec@1 99.219 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][120/390]\tTime 0.036 (0.046)\tData 0.000 (0.005)\tLoss 0.0070 (0.0169)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][130/390]\tTime 0.051 (0.046)\tData 0.001 (0.005)\tLoss 0.0117 (0.0170)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][140/390]\tTime 0.037 (0.046)\tData 0.000 (0.005)\tLoss 0.0175 (0.0175)\tPrec@1 99.219 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][150/390]\tTime 0.048 (0.046)\tData 0.008 (0.005)\tLoss 0.0178 (0.0173)\tPrec@1 99.219 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][160/390]\tTime 0.049 (0.046)\tData 0.001 (0.005)\tLoss 0.0403 (0.0175)\tPrec@1 98.438 (99.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][170/390]\tTime 0.031 (0.046)\tData 0.005 (0.005)\tLoss 0.0183 (0.0175)\tPrec@1 98.438 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][180/390]\tTime 0.032 (0.045)\tData 0.000 (0.005)\tLoss 0.0092 (0.0175)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][190/390]\tTime 0.077 (0.045)\tData 0.045 (0.005)\tLoss 0.0086 (0.0173)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][200/390]\tTime 0.046 (0.045)\tData 0.003 (0.005)\tLoss 0.0335 (0.0172)\tPrec@1 98.438 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][210/390]\tTime 0.038 (0.045)\tData 0.000 (0.005)\tLoss 0.0062 (0.0172)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][220/390]\tTime 0.045 (0.045)\tData 0.005 (0.005)\tLoss 0.0110 (0.0172)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][230/390]\tTime 0.033 (0.045)\tData 0.004 (0.005)\tLoss 0.0201 (0.0172)\tPrec@1 98.438 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][240/390]\tTime 0.041 (0.045)\tData 0.007 (0.005)\tLoss 0.0105 (0.0171)\tPrec@1 100.000 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][250/390]\tTime 0.078 (0.045)\tData 0.049 (0.005)\tLoss 0.0268 (0.0172)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][260/390]\tTime 0.045 (0.045)\tData 0.004 (0.005)\tLoss 0.0360 (0.0172)\tPrec@1 98.438 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][270/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0223 (0.0171)\tPrec@1 100.000 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][280/390]\tTime 0.039 (0.045)\tData 0.000 (0.005)\tLoss 0.0338 (0.0170)\tPrec@1 99.219 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][290/390]\tTime 0.041 (0.045)\tData 0.000 (0.005)\tLoss 0.0114 (0.0169)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][300/390]\tTime 0.045 (0.045)\tData 0.003 (0.005)\tLoss 0.0115 (0.0169)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][310/390]\tTime 0.044 (0.045)\tData 0.005 (0.005)\tLoss 0.0032 (0.0168)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][320/390]\tTime 0.055 (0.045)\tData 0.005 (0.005)\tLoss 0.0083 (0.0167)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][330/390]\tTime 0.048 (0.045)\tData 0.006 (0.005)\tLoss 0.0127 (0.0167)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][340/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0249 (0.0167)\tPrec@1 98.438 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][350/390]\tTime 0.039 (0.045)\tData 0.000 (0.005)\tLoss 0.0326 (0.0169)\tPrec@1 98.438 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][360/390]\tTime 0.051 (0.045)\tData 0.008 (0.005)\tLoss 0.0092 (0.0170)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][370/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0090 (0.0171)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][380/390]\tTime 0.035 (0.045)\tData 0.005 (0.005)\tLoss 0.0140 (0.0169)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [318][389/390]\tTime 0.020 (0.045)\tData 0.000 (0.005)\tLoss 0.0090 (0.0169)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [318][0/79]\tTime 0.243 (0.243)\tData 0.231 (0.231)\tLoss 0.2920 (0.2920)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [318][10/79]\tTime 0.017 (0.045)\tData 0.000 (0.033)\tLoss 0.2726 (0.3776)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [318][20/79]\tTime 0.041 (0.036)\tData 0.035 (0.024)\tLoss 0.5048 (0.4119)\tPrec@1 90.625 (91.555)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [318][30/79]\tTime 0.047 (0.033)\tData 0.041 (0.021)\tLoss 0.0998 (0.3981)\tPrec@1 97.656 (91.885)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [318][40/79]\tTime 0.024 (0.032)\tData 0.019 (0.020)\tLoss 0.2379 (0.3986)\tPrec@1 91.406 (91.883)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [318][50/79]\tTime 0.025 (0.031)\tData 0.019 (0.019)\tLoss 0.4338 (0.3911)\tPrec@1 90.625 (91.942)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [318][60/79]\tTime 0.016 (0.030)\tData 0.005 (0.019)\tLoss 0.6460 (0.3965)\tPrec@1 92.969 (91.829)\tPrec@5 99.219 (99.641)\t\n",
            "EVALUATING - Epoch: [318][70/79]\tTime 0.019 (0.030)\tData 0.001 (0.019)\tLoss 0.4050 (0.3887)\tPrec@1 89.844 (91.791)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [318][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2413 (0.3861)\tPrec@1 93.750 (91.810)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 319\n",
            "Training Loss 0.0169 \tTraining Prec@1 99.529 \tTraining Prec@5 100.000 \tValidation Loss 0.3861 \tValidation Prec@1 91.810 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 320\n",
            "\n",
            "TRAINING - Epoch: [319][0/390]\tTime 0.335 (0.335)\tData 0.271 (0.271)\tLoss 0.0253 (0.0253)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][10/390]\tTime 0.049 (0.071)\tData 0.000 (0.027)\tLoss 0.0339 (0.0169)\tPrec@1 99.219 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][20/390]\tTime 0.048 (0.061)\tData 0.005 (0.016)\tLoss 0.0096 (0.0184)\tPrec@1 100.000 (99.442)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][30/390]\tTime 0.044 (0.056)\tData 0.005 (0.012)\tLoss 0.0326 (0.0169)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][40/390]\tTime 0.023 (0.052)\tData 0.000 (0.010)\tLoss 0.0202 (0.0164)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][50/390]\tTime 0.071 (0.050)\tData 0.028 (0.009)\tLoss 0.0144 (0.0169)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][60/390]\tTime 0.042 (0.051)\tData 0.000 (0.008)\tLoss 0.0153 (0.0167)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][70/390]\tTime 0.035 (0.050)\tData 0.006 (0.008)\tLoss 0.0291 (0.0176)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][80/390]\tTime 0.041 (0.049)\tData 0.000 (0.007)\tLoss 0.0258 (0.0173)\tPrec@1 98.438 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][90/390]\tTime 0.047 (0.049)\tData 0.005 (0.007)\tLoss 0.0089 (0.0173)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][100/390]\tTime 0.041 (0.048)\tData 0.005 (0.007)\tLoss 0.0098 (0.0173)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][110/390]\tTime 0.050 (0.048)\tData 0.004 (0.006)\tLoss 0.0071 (0.0167)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][120/390]\tTime 0.030 (0.048)\tData 0.000 (0.006)\tLoss 0.0378 (0.0169)\tPrec@1 98.438 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][130/390]\tTime 0.038 (0.047)\tData 0.002 (0.006)\tLoss 0.0071 (0.0171)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][140/390]\tTime 0.049 (0.047)\tData 0.006 (0.006)\tLoss 0.0079 (0.0173)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][150/390]\tTime 0.035 (0.047)\tData 0.007 (0.006)\tLoss 0.0373 (0.0171)\tPrec@1 98.438 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][160/390]\tTime 0.034 (0.047)\tData 0.000 (0.006)\tLoss 0.0149 (0.0172)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][170/390]\tTime 0.056 (0.047)\tData 0.000 (0.006)\tLoss 0.0084 (0.0172)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][180/390]\tTime 0.038 (0.047)\tData 0.001 (0.006)\tLoss 0.0263 (0.0173)\tPrec@1 99.219 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][190/390]\tTime 0.040 (0.047)\tData 0.005 (0.006)\tLoss 0.0052 (0.0169)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][200/390]\tTime 0.053 (0.047)\tData 0.022 (0.006)\tLoss 0.0080 (0.0166)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][210/390]\tTime 0.041 (0.046)\tData 0.000 (0.006)\tLoss 0.0196 (0.0165)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][220/390]\tTime 0.039 (0.046)\tData 0.007 (0.006)\tLoss 0.0164 (0.0166)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][230/390]\tTime 0.038 (0.046)\tData 0.005 (0.006)\tLoss 0.0063 (0.0166)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][240/390]\tTime 0.029 (0.046)\tData 0.000 (0.006)\tLoss 0.0298 (0.0168)\tPrec@1 98.438 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][250/390]\tTime 0.047 (0.046)\tData 0.005 (0.005)\tLoss 0.0100 (0.0169)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][260/390]\tTime 0.052 (0.046)\tData 0.005 (0.005)\tLoss 0.0053 (0.0169)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][270/390]\tTime 0.044 (0.046)\tData 0.008 (0.005)\tLoss 0.0257 (0.0170)\tPrec@1 98.438 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][280/390]\tTime 0.042 (0.046)\tData 0.010 (0.005)\tLoss 0.0055 (0.0169)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][290/390]\tTime 0.037 (0.046)\tData 0.003 (0.005)\tLoss 0.0101 (0.0170)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][300/390]\tTime 0.054 (0.045)\tData 0.007 (0.005)\tLoss 0.0047 (0.0169)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][310/390]\tTime 0.048 (0.045)\tData 0.002 (0.005)\tLoss 0.0386 (0.0170)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][320/390]\tTime 0.053 (0.045)\tData 0.016 (0.005)\tLoss 0.0111 (0.0170)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][330/390]\tTime 0.044 (0.045)\tData 0.004 (0.005)\tLoss 0.0206 (0.0171)\tPrec@1 98.438 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][340/390]\tTime 0.048 (0.045)\tData 0.019 (0.005)\tLoss 0.0145 (0.0172)\tPrec@1 99.219 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][350/390]\tTime 0.056 (0.046)\tData 0.000 (0.005)\tLoss 0.0051 (0.0174)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][360/390]\tTime 0.028 (0.046)\tData 0.000 (0.005)\tLoss 0.0328 (0.0174)\tPrec@1 99.219 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][370/390]\tTime 0.036 (0.045)\tData 0.006 (0.005)\tLoss 0.0304 (0.0174)\tPrec@1 98.438 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][380/390]\tTime 0.055 (0.045)\tData 0.000 (0.005)\tLoss 0.0163 (0.0173)\tPrec@1 99.219 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [319][389/390]\tTime 0.021 (0.045)\tData 0.000 (0.005)\tLoss 0.0128 (0.0173)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [319][0/79]\tTime 0.170 (0.170)\tData 0.161 (0.161)\tLoss 0.3006 (0.3006)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [319][10/79]\tTime 0.020 (0.046)\tData 0.000 (0.033)\tLoss 0.2582 (0.3728)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [319][20/79]\tTime 0.019 (0.037)\tData 0.002 (0.023)\tLoss 0.5294 (0.4120)\tPrec@1 89.844 (91.629)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [319][30/79]\tTime 0.016 (0.033)\tData 0.000 (0.020)\tLoss 0.0988 (0.3986)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [319][40/79]\tTime 0.018 (0.032)\tData 0.004 (0.018)\tLoss 0.2431 (0.3981)\tPrec@1 89.844 (91.921)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [319][50/79]\tTime 0.022 (0.032)\tData 0.004 (0.018)\tLoss 0.4290 (0.3910)\tPrec@1 90.625 (91.835)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [319][60/79]\tTime 0.022 (0.031)\tData 0.005 (0.017)\tLoss 0.6402 (0.3952)\tPrec@1 92.969 (91.739)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [319][70/79]\tTime 0.072 (0.030)\tData 0.060 (0.017)\tLoss 0.4055 (0.3878)\tPrec@1 89.844 (91.747)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [319][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.016)\tLoss 0.2546 (0.3852)\tPrec@1 93.750 (91.740)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 320\n",
            "Training Loss 0.0173 \tTraining Prec@1 99.511 \tTraining Prec@5 100.000 \tValidation Loss 0.3852 \tValidation Prec@1 91.740 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 321\n",
            "\n",
            "TRAINING - Epoch: [320][0/390]\tTime 0.360 (0.360)\tData 0.300 (0.300)\tLoss 0.0125 (0.0125)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][10/390]\tTime 0.028 (0.068)\tData 0.000 (0.029)\tLoss 0.0130 (0.0225)\tPrec@1 100.000 (99.290)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][20/390]\tTime 0.056 (0.055)\tData 0.016 (0.017)\tLoss 0.0122 (0.0197)\tPrec@1 100.000 (99.405)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][30/390]\tTime 0.040 (0.051)\tData 0.005 (0.013)\tLoss 0.0195 (0.0185)\tPrec@1 99.219 (99.420)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][40/390]\tTime 0.047 (0.050)\tData 0.006 (0.012)\tLoss 0.0162 (0.0189)\tPrec@1 100.000 (99.409)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][50/390]\tTime 0.048 (0.049)\tData 0.005 (0.010)\tLoss 0.0084 (0.0198)\tPrec@1 100.000 (99.372)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][60/390]\tTime 0.053 (0.048)\tData 0.004 (0.009)\tLoss 0.0042 (0.0194)\tPrec@1 100.000 (99.411)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][70/390]\tTime 0.038 (0.048)\tData 0.003 (0.009)\tLoss 0.0118 (0.0188)\tPrec@1 99.219 (99.406)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][80/390]\tTime 0.054 (0.047)\tData 0.016 (0.008)\tLoss 0.0097 (0.0186)\tPrec@1 99.219 (99.421)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][90/390]\tTime 0.042 (0.047)\tData 0.005 (0.008)\tLoss 0.0126 (0.0186)\tPrec@1 99.219 (99.408)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][100/390]\tTime 0.033 (0.046)\tData 0.000 (0.008)\tLoss 0.0093 (0.0182)\tPrec@1 100.000 (99.412)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][110/390]\tTime 0.043 (0.046)\tData 0.005 (0.007)\tLoss 0.0514 (0.0186)\tPrec@1 97.656 (99.381)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][120/390]\tTime 0.032 (0.046)\tData 0.005 (0.007)\tLoss 0.0161 (0.0187)\tPrec@1 100.000 (99.380)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][130/390]\tTime 0.053 (0.046)\tData 0.000 (0.007)\tLoss 0.0115 (0.0181)\tPrec@1 100.000 (99.410)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][140/390]\tTime 0.048 (0.046)\tData 0.014 (0.007)\tLoss 0.0055 (0.0179)\tPrec@1 100.000 (99.440)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][150/390]\tTime 0.064 (0.046)\tData 0.000 (0.007)\tLoss 0.0152 (0.0178)\tPrec@1 100.000 (99.446)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][160/390]\tTime 0.044 (0.045)\tData 0.000 (0.006)\tLoss 0.0063 (0.0180)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][170/390]\tTime 0.044 (0.045)\tData 0.002 (0.006)\tLoss 0.0108 (0.0181)\tPrec@1 100.000 (99.438)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][180/390]\tTime 0.030 (0.045)\tData 0.000 (0.006)\tLoss 0.0170 (0.0178)\tPrec@1 100.000 (99.456)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][190/390]\tTime 0.046 (0.045)\tData 0.000 (0.006)\tLoss 0.0076 (0.0178)\tPrec@1 100.000 (99.456)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][200/390]\tTime 0.046 (0.045)\tData 0.000 (0.006)\tLoss 0.0180 (0.0177)\tPrec@1 99.219 (99.471)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][210/390]\tTime 0.030 (0.045)\tData 0.000 (0.006)\tLoss 0.0040 (0.0176)\tPrec@1 100.000 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][220/390]\tTime 0.038 (0.045)\tData 0.000 (0.006)\tLoss 0.0068 (0.0179)\tPrec@1 100.000 (99.473)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][230/390]\tTime 0.037 (0.045)\tData 0.000 (0.006)\tLoss 0.0109 (0.0179)\tPrec@1 100.000 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][240/390]\tTime 0.039 (0.045)\tData 0.000 (0.006)\tLoss 0.0099 (0.0180)\tPrec@1 100.000 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][250/390]\tTime 0.056 (0.045)\tData 0.012 (0.006)\tLoss 0.0170 (0.0178)\tPrec@1 100.000 (99.474)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][260/390]\tTime 0.044 (0.045)\tData 0.003 (0.006)\tLoss 0.0265 (0.0179)\tPrec@1 99.219 (99.476)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][270/390]\tTime 0.041 (0.045)\tData 0.005 (0.006)\tLoss 0.0264 (0.0179)\tPrec@1 99.219 (99.478)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][280/390]\tTime 0.038 (0.045)\tData 0.000 (0.006)\tLoss 0.0080 (0.0178)\tPrec@1 100.000 (99.488)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][290/390]\tTime 0.038 (0.045)\tData 0.009 (0.006)\tLoss 0.0151 (0.0175)\tPrec@1 99.219 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][300/390]\tTime 0.048 (0.045)\tData 0.004 (0.006)\tLoss 0.0301 (0.0176)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][310/390]\tTime 0.065 (0.045)\tData 0.010 (0.006)\tLoss 0.0074 (0.0175)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][320/390]\tTime 0.059 (0.045)\tData 0.000 (0.006)\tLoss 0.0101 (0.0173)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][330/390]\tTime 0.052 (0.045)\tData 0.000 (0.005)\tLoss 0.0133 (0.0171)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][340/390]\tTime 0.044 (0.045)\tData 0.001 (0.005)\tLoss 0.0094 (0.0170)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][350/390]\tTime 0.049 (0.045)\tData 0.012 (0.005)\tLoss 0.0093 (0.0171)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][360/390]\tTime 0.042 (0.045)\tData 0.001 (0.005)\tLoss 0.0139 (0.0170)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][370/390]\tTime 0.034 (0.045)\tData 0.007 (0.005)\tLoss 0.0254 (0.0170)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][380/390]\tTime 0.052 (0.045)\tData 0.001 (0.005)\tLoss 0.0138 (0.0170)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [320][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0182 (0.0171)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [320][0/79]\tTime 0.250 (0.250)\tData 0.240 (0.240)\tLoss 0.2896 (0.2896)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [320][10/79]\tTime 0.014 (0.043)\tData 0.000 (0.031)\tLoss 0.2771 (0.3734)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [320][20/79]\tTime 0.056 (0.038)\tData 0.049 (0.025)\tLoss 0.5463 (0.4122)\tPrec@1 90.625 (91.667)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [320][30/79]\tTime 0.017 (0.033)\tData 0.003 (0.022)\tLoss 0.0949 (0.3985)\tPrec@1 97.656 (91.986)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [320][40/79]\tTime 0.049 (0.032)\tData 0.043 (0.021)\tLoss 0.2531 (0.4008)\tPrec@1 89.844 (91.825)\tPrec@5 99.219 (99.486)\t\n",
            "EVALUATING - Epoch: [320][50/79]\tTime 0.015 (0.032)\tData 0.000 (0.020)\tLoss 0.4165 (0.3940)\tPrec@1 89.844 (91.743)\tPrec@5 100.000 (99.586)\t\n",
            "EVALUATING - Epoch: [320][60/79]\tTime 0.083 (0.032)\tData 0.077 (0.020)\tLoss 0.6342 (0.3988)\tPrec@1 92.188 (91.675)\tPrec@5 100.000 (99.629)\t\n",
            "EVALUATING - Epoch: [320][70/79]\tTime 0.018 (0.030)\tData 0.000 (0.018)\tLoss 0.4214 (0.3922)\tPrec@1 89.062 (91.703)\tPrec@5 100.000 (99.670)\t\n",
            "EVALUATING - Epoch: [320][78/79]\tTime 0.004 (0.029)\tData 0.000 (0.017)\tLoss 0.2584 (0.3896)\tPrec@1 93.750 (91.730)\tPrec@5 100.000 (99.670)\t\n",
            "\n",
            "Results - Epoch: 321\n",
            "Training Loss 0.0171 \tTraining Prec@1 99.523 \tTraining Prec@5 100.000 \tValidation Loss 0.3896 \tValidation Prec@1 91.730 \tValidation Prec@5 99.670 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 322\n",
            "\n",
            "TRAINING - Epoch: [321][0/390]\tTime 0.234 (0.234)\tData 0.189 (0.189)\tLoss 0.0161 (0.0161)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][10/390]\tTime 0.035 (0.071)\tData 0.001 (0.028)\tLoss 0.0181 (0.0187)\tPrec@1 99.219 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][20/390]\tTime 0.040 (0.057)\tData 0.000 (0.016)\tLoss 0.0083 (0.0168)\tPrec@1 100.000 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][30/390]\tTime 0.038 (0.053)\tData 0.014 (0.013)\tLoss 0.0406 (0.0174)\tPrec@1 97.656 (99.446)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][40/390]\tTime 0.037 (0.050)\tData 0.000 (0.011)\tLoss 0.0062 (0.0172)\tPrec@1 100.000 (99.447)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][50/390]\tTime 0.064 (0.050)\tData 0.028 (0.011)\tLoss 0.0187 (0.0179)\tPrec@1 99.219 (99.403)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][60/390]\tTime 0.052 (0.050)\tData 0.000 (0.010)\tLoss 0.0117 (0.0178)\tPrec@1 100.000 (99.424)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][70/390]\tTime 0.030 (0.049)\tData 0.000 (0.010)\tLoss 0.0135 (0.0179)\tPrec@1 100.000 (99.439)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][80/390]\tTime 0.048 (0.048)\tData 0.005 (0.009)\tLoss 0.0118 (0.0174)\tPrec@1 99.219 (99.450)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][90/390]\tTime 0.039 (0.048)\tData 0.000 (0.008)\tLoss 0.0126 (0.0172)\tPrec@1 100.000 (99.468)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][100/390]\tTime 0.041 (0.047)\tData 0.003 (0.008)\tLoss 0.0235 (0.0179)\tPrec@1 99.219 (99.474)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][110/390]\tTime 0.040 (0.047)\tData 0.000 (0.007)\tLoss 0.0041 (0.0178)\tPrec@1 100.000 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][120/390]\tTime 0.060 (0.047)\tData 0.004 (0.007)\tLoss 0.0072 (0.0172)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][130/390]\tTime 0.036 (0.046)\tData 0.000 (0.007)\tLoss 0.0212 (0.0169)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][140/390]\tTime 0.037 (0.046)\tData 0.004 (0.006)\tLoss 0.0477 (0.0167)\tPrec@1 97.656 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][150/390]\tTime 0.038 (0.046)\tData 0.005 (0.006)\tLoss 0.0152 (0.0170)\tPrec@1 100.000 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][160/390]\tTime 0.046 (0.046)\tData 0.001 (0.006)\tLoss 0.0145 (0.0169)\tPrec@1 99.219 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][170/390]\tTime 0.042 (0.046)\tData 0.000 (0.006)\tLoss 0.0191 (0.0169)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][180/390]\tTime 0.053 (0.046)\tData 0.001 (0.006)\tLoss 0.0303 (0.0167)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][190/390]\tTime 0.046 (0.046)\tData 0.008 (0.006)\tLoss 0.0140 (0.0167)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][200/390]\tTime 0.045 (0.046)\tData 0.006 (0.006)\tLoss 0.0091 (0.0165)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][210/390]\tTime 0.038 (0.046)\tData 0.005 (0.006)\tLoss 0.0180 (0.0165)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][220/390]\tTime 0.051 (0.046)\tData 0.002 (0.006)\tLoss 0.0142 (0.0166)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][230/390]\tTime 0.037 (0.046)\tData 0.001 (0.006)\tLoss 0.0188 (0.0164)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][240/390]\tTime 0.048 (0.046)\tData 0.007 (0.006)\tLoss 0.0120 (0.0168)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][250/390]\tTime 0.046 (0.046)\tData 0.005 (0.006)\tLoss 0.0081 (0.0167)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][260/390]\tTime 0.032 (0.046)\tData 0.005 (0.006)\tLoss 0.0107 (0.0166)\tPrec@1 99.219 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][270/390]\tTime 0.036 (0.046)\tData 0.000 (0.006)\tLoss 0.0179 (0.0169)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][280/390]\tTime 0.051 (0.046)\tData 0.000 (0.005)\tLoss 0.0247 (0.0169)\tPrec@1 99.219 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][290/390]\tTime 0.039 (0.045)\tData 0.006 (0.005)\tLoss 0.0125 (0.0169)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][300/390]\tTime 0.041 (0.045)\tData 0.001 (0.005)\tLoss 0.0052 (0.0168)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][310/390]\tTime 0.040 (0.045)\tData 0.004 (0.005)\tLoss 0.0173 (0.0168)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][320/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0115 (0.0169)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][330/390]\tTime 0.039 (0.045)\tData 0.001 (0.005)\tLoss 0.0065 (0.0167)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][340/390]\tTime 0.043 (0.045)\tData 0.009 (0.005)\tLoss 0.0219 (0.0165)\tPrec@1 98.438 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][350/390]\tTime 0.042 (0.045)\tData 0.004 (0.005)\tLoss 0.0051 (0.0163)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][360/390]\tTime 0.036 (0.045)\tData 0.001 (0.005)\tLoss 0.0162 (0.0165)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][370/390]\tTime 0.061 (0.045)\tData 0.002 (0.005)\tLoss 0.0106 (0.0165)\tPrec@1 100.000 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][380/390]\tTime 0.055 (0.045)\tData 0.006 (0.005)\tLoss 0.0343 (0.0166)\tPrec@1 98.438 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [321][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0263 (0.0166)\tPrec@1 98.438 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [321][0/79]\tTime 0.189 (0.189)\tData 0.180 (0.180)\tLoss 0.2797 (0.2797)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [321][10/79]\tTime 0.065 (0.049)\tData 0.059 (0.036)\tLoss 0.2552 (0.3673)\tPrec@1 91.406 (92.472)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [321][20/79]\tTime 0.011 (0.037)\tData 0.005 (0.027)\tLoss 0.5214 (0.4087)\tPrec@1 89.844 (91.741)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [321][30/79]\tTime 0.034 (0.034)\tData 0.028 (0.025)\tLoss 0.1038 (0.3962)\tPrec@1 97.656 (92.061)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [321][40/79]\tTime 0.021 (0.032)\tData 0.006 (0.022)\tLoss 0.2358 (0.3982)\tPrec@1 90.625 (91.978)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [321][50/79]\tTime 0.058 (0.032)\tData 0.052 (0.022)\tLoss 0.4351 (0.3907)\tPrec@1 90.625 (91.896)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [321][60/79]\tTime 0.024 (0.031)\tData 0.005 (0.020)\tLoss 0.6498 (0.3960)\tPrec@1 93.750 (91.803)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [321][70/79]\tTime 0.086 (0.031)\tData 0.076 (0.020)\tLoss 0.3935 (0.3881)\tPrec@1 90.625 (91.780)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [321][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2602 (0.3852)\tPrec@1 93.750 (91.820)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 322\n",
            "Training Loss 0.0166 \tTraining Prec@1 99.555 \tTraining Prec@5 100.000 \tValidation Loss 0.3852 \tValidation Prec@1 91.820 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 323\n",
            "\n",
            "TRAINING - Epoch: [322][0/390]\tTime 0.344 (0.344)\tData 0.301 (0.301)\tLoss 0.0221 (0.0221)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][10/390]\tTime 0.050 (0.070)\tData 0.005 (0.029)\tLoss 0.0409 (0.0205)\tPrec@1 98.438 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][20/390]\tTime 0.045 (0.058)\tData 0.004 (0.017)\tLoss 0.0088 (0.0183)\tPrec@1 100.000 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][30/390]\tTime 0.047 (0.053)\tData 0.000 (0.013)\tLoss 0.0179 (0.0182)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][40/390]\tTime 0.043 (0.051)\tData 0.000 (0.010)\tLoss 0.0034 (0.0182)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][50/390]\tTime 0.050 (0.049)\tData 0.002 (0.009)\tLoss 0.0091 (0.0193)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][60/390]\tTime 0.039 (0.049)\tData 0.000 (0.008)\tLoss 0.0189 (0.0182)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][70/390]\tTime 0.051 (0.048)\tData 0.020 (0.007)\tLoss 0.0285 (0.0179)\tPrec@1 98.438 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][80/390]\tTime 0.038 (0.047)\tData 0.000 (0.007)\tLoss 0.0114 (0.0175)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][90/390]\tTime 0.062 (0.047)\tData 0.028 (0.007)\tLoss 0.0119 (0.0175)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][100/390]\tTime 0.043 (0.048)\tData 0.000 (0.007)\tLoss 0.0100 (0.0175)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][110/390]\tTime 0.045 (0.047)\tData 0.004 (0.006)\tLoss 0.0155 (0.0177)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][120/390]\tTime 0.041 (0.047)\tData 0.012 (0.006)\tLoss 0.0183 (0.0178)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][130/390]\tTime 0.026 (0.047)\tData 0.000 (0.006)\tLoss 0.0121 (0.0173)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][140/390]\tTime 0.034 (0.047)\tData 0.006 (0.006)\tLoss 0.0147 (0.0170)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][150/390]\tTime 0.048 (0.047)\tData 0.006 (0.006)\tLoss 0.0150 (0.0171)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][160/390]\tTime 0.059 (0.047)\tData 0.005 (0.006)\tLoss 0.0070 (0.0176)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][170/390]\tTime 0.041 (0.047)\tData 0.005 (0.006)\tLoss 0.0174 (0.0174)\tPrec@1 99.219 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][180/390]\tTime 0.052 (0.047)\tData 0.000 (0.006)\tLoss 0.0088 (0.0174)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][190/390]\tTime 0.038 (0.047)\tData 0.002 (0.006)\tLoss 0.0126 (0.0175)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][200/390]\tTime 0.038 (0.047)\tData 0.007 (0.005)\tLoss 0.0213 (0.0175)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][210/390]\tTime 0.053 (0.046)\tData 0.002 (0.005)\tLoss 0.0149 (0.0173)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][220/390]\tTime 0.035 (0.046)\tData 0.001 (0.005)\tLoss 0.0032 (0.0170)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][230/390]\tTime 0.055 (0.046)\tData 0.011 (0.005)\tLoss 0.0175 (0.0171)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][240/390]\tTime 0.033 (0.046)\tData 0.005 (0.005)\tLoss 0.0170 (0.0171)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][250/390]\tTime 0.065 (0.046)\tData 0.005 (0.005)\tLoss 0.0210 (0.0170)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][260/390]\tTime 0.047 (0.046)\tData 0.000 (0.005)\tLoss 0.0136 (0.0168)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][270/390]\tTime 0.039 (0.046)\tData 0.002 (0.005)\tLoss 0.0176 (0.0168)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][280/390]\tTime 0.049 (0.046)\tData 0.000 (0.005)\tLoss 0.0210 (0.0170)\tPrec@1 98.438 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][290/390]\tTime 0.045 (0.046)\tData 0.005 (0.005)\tLoss 0.0242 (0.0169)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][300/390]\tTime 0.035 (0.046)\tData 0.000 (0.005)\tLoss 0.0167 (0.0169)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][310/390]\tTime 0.045 (0.046)\tData 0.000 (0.005)\tLoss 0.0188 (0.0170)\tPrec@1 99.219 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][320/390]\tTime 0.053 (0.046)\tData 0.009 (0.005)\tLoss 0.0115 (0.0171)\tPrec@1 99.219 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][330/390]\tTime 0.037 (0.046)\tData 0.005 (0.005)\tLoss 0.0093 (0.0171)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][340/390]\tTime 0.054 (0.046)\tData 0.018 (0.005)\tLoss 0.0173 (0.0170)\tPrec@1 99.219 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][350/390]\tTime 0.049 (0.046)\tData 0.009 (0.005)\tLoss 0.0191 (0.0171)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][360/390]\tTime 0.038 (0.046)\tData 0.002 (0.005)\tLoss 0.0057 (0.0169)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][370/390]\tTime 0.035 (0.046)\tData 0.000 (0.005)\tLoss 0.0107 (0.0168)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][380/390]\tTime 0.070 (0.046)\tData 0.040 (0.005)\tLoss 0.0219 (0.0168)\tPrec@1 99.219 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [322][389/390]\tTime 0.018 (0.046)\tData 0.000 (0.005)\tLoss 0.0030 (0.0169)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [322][0/79]\tTime 0.179 (0.179)\tData 0.170 (0.170)\tLoss 0.2892 (0.2892)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [322][10/79]\tTime 0.021 (0.048)\tData 0.004 (0.036)\tLoss 0.2436 (0.3660)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [322][20/79]\tTime 0.019 (0.038)\tData 0.007 (0.024)\tLoss 0.5406 (0.4096)\tPrec@1 89.844 (91.555)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [322][30/79]\tTime 0.046 (0.035)\tData 0.001 (0.020)\tLoss 0.1033 (0.3983)\tPrec@1 97.656 (91.885)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [322][40/79]\tTime 0.019 (0.032)\tData 0.013 (0.017)\tLoss 0.2511 (0.3994)\tPrec@1 89.844 (91.768)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [322][50/79]\tTime 0.017 (0.032)\tData 0.003 (0.018)\tLoss 0.4380 (0.3921)\tPrec@1 89.844 (91.789)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [322][60/79]\tTime 0.020 (0.031)\tData 0.001 (0.017)\tLoss 0.6348 (0.3963)\tPrec@1 93.750 (91.726)\tPrec@5 100.000 (99.705)\t\n",
            "EVALUATING - Epoch: [322][70/79]\tTime 0.026 (0.031)\tData 0.009 (0.017)\tLoss 0.3937 (0.3889)\tPrec@1 89.062 (91.648)\tPrec@5 100.000 (99.725)\t\n",
            "EVALUATING - Epoch: [322][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.016)\tLoss 0.2469 (0.3858)\tPrec@1 93.750 (91.690)\tPrec@5 100.000 (99.730)\t\n",
            "\n",
            "Results - Epoch: 323\n",
            "Training Loss 0.0169 \tTraining Prec@1 99.541 \tTraining Prec@5 100.000 \tValidation Loss 0.3858 \tValidation Prec@1 91.690 \tValidation Prec@5 99.730 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 324\n",
            "\n",
            "TRAINING - Epoch: [323][0/390]\tTime 0.224 (0.224)\tData 0.182 (0.182)\tLoss 0.0121 (0.0121)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][10/390]\tTime 0.054 (0.068)\tData 0.011 (0.032)\tLoss 0.0506 (0.0186)\tPrec@1 97.656 (99.290)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][20/390]\tTime 0.046 (0.055)\tData 0.010 (0.019)\tLoss 0.0148 (0.0163)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][30/390]\tTime 0.040 (0.052)\tData 0.001 (0.013)\tLoss 0.0361 (0.0202)\tPrec@1 99.219 (99.320)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][40/390]\tTime 0.055 (0.051)\tData 0.005 (0.011)\tLoss 0.0100 (0.0204)\tPrec@1 100.000 (99.371)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][50/390]\tTime 0.047 (0.050)\tData 0.002 (0.010)\tLoss 0.0037 (0.0203)\tPrec@1 100.000 (99.387)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][60/390]\tTime 0.042 (0.049)\tData 0.010 (0.009)\tLoss 0.0246 (0.0191)\tPrec@1 100.000 (99.449)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][70/390]\tTime 0.039 (0.048)\tData 0.002 (0.008)\tLoss 0.0184 (0.0184)\tPrec@1 99.219 (99.472)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][80/390]\tTime 0.045 (0.048)\tData 0.000 (0.008)\tLoss 0.0043 (0.0188)\tPrec@1 100.000 (99.470)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][90/390]\tTime 0.054 (0.047)\tData 0.001 (0.007)\tLoss 0.0124 (0.0185)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][100/390]\tTime 0.036 (0.047)\tData 0.007 (0.007)\tLoss 0.0071 (0.0183)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][110/390]\tTime 0.049 (0.047)\tData 0.010 (0.007)\tLoss 0.0224 (0.0177)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][120/390]\tTime 0.046 (0.047)\tData 0.005 (0.007)\tLoss 0.0053 (0.0177)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][130/390]\tTime 0.078 (0.047)\tData 0.047 (0.007)\tLoss 0.0087 (0.0176)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][140/390]\tTime 0.032 (0.046)\tData 0.007 (0.007)\tLoss 0.0069 (0.0172)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][150/390]\tTime 0.034 (0.046)\tData 0.002 (0.007)\tLoss 0.0108 (0.0170)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][160/390]\tTime 0.056 (0.046)\tData 0.002 (0.007)\tLoss 0.0261 (0.0171)\tPrec@1 98.438 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][170/390]\tTime 0.058 (0.046)\tData 0.025 (0.007)\tLoss 0.0131 (0.0173)\tPrec@1 99.219 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][180/390]\tTime 0.039 (0.046)\tData 0.000 (0.007)\tLoss 0.0190 (0.0174)\tPrec@1 99.219 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][190/390]\tTime 0.044 (0.046)\tData 0.003 (0.006)\tLoss 0.0119 (0.0175)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][200/390]\tTime 0.036 (0.046)\tData 0.007 (0.006)\tLoss 0.0109 (0.0176)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][210/390]\tTime 0.034 (0.045)\tData 0.002 (0.006)\tLoss 0.0266 (0.0174)\tPrec@1 99.219 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][220/390]\tTime 0.030 (0.045)\tData 0.000 (0.006)\tLoss 0.0306 (0.0176)\tPrec@1 99.219 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][230/390]\tTime 0.041 (0.045)\tData 0.000 (0.006)\tLoss 0.0037 (0.0173)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][240/390]\tTime 0.044 (0.045)\tData 0.002 (0.006)\tLoss 0.0310 (0.0172)\tPrec@1 99.219 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][250/390]\tTime 0.035 (0.045)\tData 0.000 (0.006)\tLoss 0.0087 (0.0172)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][260/390]\tTime 0.049 (0.045)\tData 0.005 (0.006)\tLoss 0.0137 (0.0172)\tPrec@1 99.219 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][270/390]\tTime 0.037 (0.045)\tData 0.006 (0.006)\tLoss 0.0374 (0.0173)\tPrec@1 97.656 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][280/390]\tTime 0.066 (0.045)\tData 0.035 (0.006)\tLoss 0.0118 (0.0173)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][290/390]\tTime 0.044 (0.045)\tData 0.000 (0.006)\tLoss 0.0128 (0.0174)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][300/390]\tTime 0.032 (0.045)\tData 0.000 (0.006)\tLoss 0.0237 (0.0174)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][310/390]\tTime 0.047 (0.045)\tData 0.006 (0.006)\tLoss 0.0232 (0.0173)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][320/390]\tTime 0.063 (0.045)\tData 0.023 (0.006)\tLoss 0.0315 (0.0173)\tPrec@1 99.219 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][330/390]\tTime 0.065 (0.045)\tData 0.009 (0.006)\tLoss 0.0098 (0.0174)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][340/390]\tTime 0.039 (0.045)\tData 0.009 (0.006)\tLoss 0.0187 (0.0174)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][350/390]\tTime 0.047 (0.045)\tData 0.000 (0.006)\tLoss 0.0084 (0.0174)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][360/390]\tTime 0.044 (0.045)\tData 0.001 (0.006)\tLoss 0.0143 (0.0173)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][370/390]\tTime 0.034 (0.045)\tData 0.000 (0.006)\tLoss 0.0122 (0.0172)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][380/390]\tTime 0.049 (0.045)\tData 0.000 (0.006)\tLoss 0.0172 (0.0170)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [323][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0190 (0.0169)\tPrec@1 98.438 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [323][0/79]\tTime 0.190 (0.190)\tData 0.176 (0.176)\tLoss 0.2996 (0.2996)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [323][10/79]\tTime 0.025 (0.045)\tData 0.010 (0.033)\tLoss 0.2609 (0.3710)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.716)\t\n",
            "EVALUATING - Epoch: [323][20/79]\tTime 0.011 (0.036)\tData 0.000 (0.023)\tLoss 0.5450 (0.4133)\tPrec@1 89.844 (91.481)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [323][30/79]\tTime 0.019 (0.036)\tData 0.001 (0.021)\tLoss 0.0966 (0.3989)\tPrec@1 97.656 (91.860)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [323][40/79]\tTime 0.023 (0.033)\tData 0.010 (0.019)\tLoss 0.2641 (0.4000)\tPrec@1 89.844 (91.768)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [323][50/79]\tTime 0.092 (0.034)\tData 0.078 (0.020)\tLoss 0.4185 (0.3929)\tPrec@1 89.844 (91.789)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [323][60/79]\tTime 0.020 (0.033)\tData 0.007 (0.019)\tLoss 0.6494 (0.3973)\tPrec@1 92.188 (91.726)\tPrec@5 99.219 (99.667)\t\n",
            "EVALUATING - Epoch: [323][70/79]\tTime 0.048 (0.033)\tData 0.042 (0.018)\tLoss 0.4110 (0.3905)\tPrec@1 89.062 (91.670)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [323][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.017)\tLoss 0.2531 (0.3878)\tPrec@1 93.750 (91.690)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 324\n",
            "Training Loss 0.0169 \tTraining Prec@1 99.543 \tTraining Prec@5 100.000 \tValidation Loss 0.3878 \tValidation Prec@1 91.690 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 325\n",
            "\n",
            "TRAINING - Epoch: [324][0/390]\tTime 0.232 (0.232)\tData 0.182 (0.182)\tLoss 0.0146 (0.0146)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][10/390]\tTime 0.041 (0.066)\tData 0.001 (0.028)\tLoss 0.0251 (0.0153)\tPrec@1 99.219 (99.716)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][20/390]\tTime 0.043 (0.057)\tData 0.007 (0.019)\tLoss 0.0083 (0.0153)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][30/390]\tTime 0.040 (0.053)\tData 0.000 (0.014)\tLoss 0.0111 (0.0182)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][40/390]\tTime 0.046 (0.051)\tData 0.000 (0.011)\tLoss 0.0078 (0.0174)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][50/390]\tTime 0.041 (0.050)\tData 0.000 (0.010)\tLoss 0.0103 (0.0170)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][60/390]\tTime 0.040 (0.050)\tData 0.000 (0.010)\tLoss 0.0096 (0.0174)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][70/390]\tTime 0.037 (0.049)\tData 0.005 (0.009)\tLoss 0.0088 (0.0175)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][80/390]\tTime 0.040 (0.049)\tData 0.007 (0.008)\tLoss 0.0186 (0.0170)\tPrec@1 99.219 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][90/390]\tTime 0.048 (0.048)\tData 0.008 (0.008)\tLoss 0.0086 (0.0172)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][100/390]\tTime 0.048 (0.048)\tData 0.008 (0.008)\tLoss 0.0112 (0.0168)\tPrec@1 99.219 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][110/390]\tTime 0.044 (0.048)\tData 0.002 (0.007)\tLoss 0.0055 (0.0165)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][120/390]\tTime 0.049 (0.047)\tData 0.005 (0.007)\tLoss 0.0034 (0.0163)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][130/390]\tTime 0.060 (0.047)\tData 0.004 (0.007)\tLoss 0.0028 (0.0163)\tPrec@1 100.000 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][140/390]\tTime 0.045 (0.047)\tData 0.010 (0.007)\tLoss 0.0078 (0.0163)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][150/390]\tTime 0.071 (0.047)\tData 0.017 (0.007)\tLoss 0.0141 (0.0162)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][160/390]\tTime 0.048 (0.047)\tData 0.000 (0.007)\tLoss 0.0155 (0.0162)\tPrec@1 98.438 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][170/390]\tTime 0.051 (0.047)\tData 0.003 (0.007)\tLoss 0.0074 (0.0163)\tPrec@1 100.000 (99.580)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][180/390]\tTime 0.041 (0.047)\tData 0.001 (0.007)\tLoss 0.0374 (0.0164)\tPrec@1 97.656 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][190/390]\tTime 0.036 (0.047)\tData 0.004 (0.006)\tLoss 0.0093 (0.0162)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][200/390]\tTime 0.046 (0.047)\tData 0.010 (0.006)\tLoss 0.0152 (0.0161)\tPrec@1 99.219 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][210/390]\tTime 0.044 (0.047)\tData 0.006 (0.006)\tLoss 0.0241 (0.0164)\tPrec@1 99.219 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][220/390]\tTime 0.033 (0.047)\tData 0.000 (0.006)\tLoss 0.0158 (0.0164)\tPrec@1 99.219 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][230/390]\tTime 0.051 (0.047)\tData 0.008 (0.006)\tLoss 0.0173 (0.0167)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][240/390]\tTime 0.047 (0.047)\tData 0.000 (0.006)\tLoss 0.0129 (0.0164)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][250/390]\tTime 0.043 (0.046)\tData 0.005 (0.006)\tLoss 0.0122 (0.0165)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][260/390]\tTime 0.030 (0.046)\tData 0.001 (0.006)\tLoss 0.0661 (0.0170)\tPrec@1 97.656 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][270/390]\tTime 0.037 (0.046)\tData 0.002 (0.006)\tLoss 0.0062 (0.0169)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][280/390]\tTime 0.039 (0.046)\tData 0.002 (0.005)\tLoss 0.0229 (0.0168)\tPrec@1 99.219 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][290/390]\tTime 0.043 (0.046)\tData 0.000 (0.005)\tLoss 0.0191 (0.0169)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][300/390]\tTime 0.055 (0.046)\tData 0.007 (0.005)\tLoss 0.0026 (0.0167)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][310/390]\tTime 0.052 (0.046)\tData 0.007 (0.005)\tLoss 0.0403 (0.0169)\tPrec@1 98.438 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][320/390]\tTime 0.047 (0.046)\tData 0.004 (0.005)\tLoss 0.0111 (0.0170)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][330/390]\tTime 0.055 (0.046)\tData 0.000 (0.005)\tLoss 0.0182 (0.0170)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][340/390]\tTime 0.050 (0.046)\tData 0.004 (0.005)\tLoss 0.0108 (0.0170)\tPrec@1 99.219 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][350/390]\tTime 0.027 (0.046)\tData 0.000 (0.005)\tLoss 0.0142 (0.0170)\tPrec@1 99.219 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][360/390]\tTime 0.051 (0.046)\tData 0.000 (0.005)\tLoss 0.0343 (0.0171)\tPrec@1 98.438 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][370/390]\tTime 0.036 (0.046)\tData 0.000 (0.005)\tLoss 0.0350 (0.0172)\tPrec@1 97.656 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][380/390]\tTime 0.033 (0.046)\tData 0.005 (0.005)\tLoss 0.0125 (0.0172)\tPrec@1 99.219 (99.532)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [324][389/390]\tTime 0.018 (0.046)\tData 0.000 (0.005)\tLoss 0.0641 (0.0175)\tPrec@1 98.438 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [324][0/79]\tTime 0.299 (0.299)\tData 0.277 (0.277)\tLoss 0.2872 (0.2872)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [324][10/79]\tTime 0.031 (0.049)\tData 0.015 (0.036)\tLoss 0.2724 (0.3746)\tPrec@1 91.406 (92.543)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [324][20/79]\tTime 0.044 (0.041)\tData 0.024 (0.026)\tLoss 0.5413 (0.4122)\tPrec@1 89.844 (91.815)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [324][30/79]\tTime 0.036 (0.037)\tData 0.029 (0.023)\tLoss 0.0990 (0.3986)\tPrec@1 97.656 (92.087)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [324][40/79]\tTime 0.050 (0.036)\tData 0.043 (0.024)\tLoss 0.2514 (0.4008)\tPrec@1 90.625 (91.997)\tPrec@5 99.219 (99.486)\t\n",
            "EVALUATING - Epoch: [324][50/79]\tTime 0.071 (0.035)\tData 0.064 (0.023)\tLoss 0.4115 (0.3934)\tPrec@1 90.625 (91.973)\tPrec@5 100.000 (99.586)\t\n",
            "EVALUATING - Epoch: [324][60/79]\tTime 0.010 (0.034)\tData 0.000 (0.022)\tLoss 0.6404 (0.3987)\tPrec@1 92.969 (91.880)\tPrec@5 100.000 (99.629)\t\n",
            "EVALUATING - Epoch: [324][70/79]\tTime 0.014 (0.033)\tData 0.000 (0.020)\tLoss 0.3993 (0.3914)\tPrec@1 89.062 (91.802)\tPrec@5 100.000 (99.670)\t\n",
            "EVALUATING - Epoch: [324][78/79]\tTime 0.004 (0.031)\tData 0.000 (0.019)\tLoss 0.2426 (0.3888)\tPrec@1 93.750 (91.790)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 325\n",
            "Training Loss 0.0175 \tTraining Prec@1 99.525 \tTraining Prec@5 100.000 \tValidation Loss 0.3888 \tValidation Prec@1 91.790 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 326\n",
            "\n",
            "TRAINING - Epoch: [325][0/390]\tTime 0.296 (0.296)\tData 0.223 (0.223)\tLoss 0.0202 (0.0202)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][10/390]\tTime 0.056 (0.073)\tData 0.009 (0.026)\tLoss 0.0171 (0.0122)\tPrec@1 99.219 (99.787)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][20/390]\tTime 0.044 (0.059)\tData 0.000 (0.014)\tLoss 0.0082 (0.0129)\tPrec@1 100.000 (99.740)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][30/390]\tTime 0.044 (0.057)\tData 0.001 (0.011)\tLoss 0.0080 (0.0146)\tPrec@1 100.000 (99.723)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][40/390]\tTime 0.047 (0.053)\tData 0.005 (0.009)\tLoss 0.0114 (0.0147)\tPrec@1 100.000 (99.695)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][50/390]\tTime 0.049 (0.051)\tData 0.005 (0.008)\tLoss 0.0766 (0.0168)\tPrec@1 97.656 (99.602)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][60/390]\tTime 0.056 (0.051)\tData 0.004 (0.008)\tLoss 0.0179 (0.0161)\tPrec@1 99.219 (99.629)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][70/390]\tTime 0.051 (0.050)\tData 0.001 (0.007)\tLoss 0.0176 (0.0164)\tPrec@1 99.219 (99.615)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][80/390]\tTime 0.042 (0.049)\tData 0.005 (0.007)\tLoss 0.0344 (0.0172)\tPrec@1 99.219 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][90/390]\tTime 0.046 (0.048)\tData 0.000 (0.006)\tLoss 0.0036 (0.0172)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][100/390]\tTime 0.055 (0.048)\tData 0.006 (0.006)\tLoss 0.0094 (0.0176)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][110/390]\tTime 0.044 (0.048)\tData 0.001 (0.006)\tLoss 0.0144 (0.0173)\tPrec@1 100.000 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][120/390]\tTime 0.040 (0.048)\tData 0.000 (0.006)\tLoss 0.0039 (0.0173)\tPrec@1 100.000 (99.580)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][130/390]\tTime 0.052 (0.048)\tData 0.004 (0.006)\tLoss 0.0190 (0.0171)\tPrec@1 100.000 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][140/390]\tTime 0.043 (0.047)\tData 0.003 (0.006)\tLoss 0.0090 (0.0170)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][150/390]\tTime 0.052 (0.047)\tData 0.000 (0.006)\tLoss 0.0116 (0.0170)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][160/390]\tTime 0.038 (0.047)\tData 0.001 (0.006)\tLoss 0.0081 (0.0171)\tPrec@1 100.000 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][170/390]\tTime 0.030 (0.047)\tData 0.003 (0.006)\tLoss 0.0202 (0.0174)\tPrec@1 99.219 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][180/390]\tTime 0.038 (0.046)\tData 0.002 (0.006)\tLoss 0.0184 (0.0175)\tPrec@1 100.000 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][190/390]\tTime 0.035 (0.046)\tData 0.001 (0.006)\tLoss 0.0173 (0.0175)\tPrec@1 99.219 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][200/390]\tTime 0.050 (0.046)\tData 0.000 (0.005)\tLoss 0.0109 (0.0175)\tPrec@1 100.000 (99.580)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][210/390]\tTime 0.051 (0.046)\tData 0.001 (0.005)\tLoss 0.0105 (0.0176)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][220/390]\tTime 0.034 (0.046)\tData 0.000 (0.005)\tLoss 0.0067 (0.0178)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][230/390]\tTime 0.039 (0.046)\tData 0.005 (0.005)\tLoss 0.0229 (0.0177)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][240/390]\tTime 0.028 (0.046)\tData 0.003 (0.005)\tLoss 0.0067 (0.0175)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][250/390]\tTime 0.034 (0.046)\tData 0.000 (0.005)\tLoss 0.0079 (0.0175)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][260/390]\tTime 0.037 (0.046)\tData 0.000 (0.005)\tLoss 0.0303 (0.0175)\tPrec@1 97.656 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][270/390]\tTime 0.033 (0.046)\tData 0.000 (0.005)\tLoss 0.0121 (0.0177)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][280/390]\tTime 0.022 (0.046)\tData 0.000 (0.005)\tLoss 0.0220 (0.0176)\tPrec@1 99.219 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][290/390]\tTime 0.038 (0.046)\tData 0.000 (0.005)\tLoss 0.0328 (0.0176)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][300/390]\tTime 0.035 (0.046)\tData 0.000 (0.005)\tLoss 0.0139 (0.0174)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][310/390]\tTime 0.052 (0.046)\tData 0.001 (0.005)\tLoss 0.0044 (0.0174)\tPrec@1 100.000 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][320/390]\tTime 0.047 (0.046)\tData 0.000 (0.005)\tLoss 0.0166 (0.0176)\tPrec@1 99.219 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][330/390]\tTime 0.057 (0.046)\tData 0.004 (0.005)\tLoss 0.0282 (0.0177)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][340/390]\tTime 0.037 (0.045)\tData 0.005 (0.005)\tLoss 0.0109 (0.0177)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][350/390]\tTime 0.057 (0.046)\tData 0.014 (0.005)\tLoss 0.0087 (0.0178)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][360/390]\tTime 0.065 (0.045)\tData 0.029 (0.005)\tLoss 0.0125 (0.0176)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][370/390]\tTime 0.041 (0.046)\tData 0.004 (0.005)\tLoss 0.0240 (0.0177)\tPrec@1 99.219 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][380/390]\tTime 0.036 (0.045)\tData 0.001 (0.005)\tLoss 0.0148 (0.0178)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [325][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.005)\tLoss 0.0050 (0.0178)\tPrec@1 100.000 (99.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [325][0/79]\tTime 0.237 (0.237)\tData 0.217 (0.217)\tLoss 0.2882 (0.2882)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [325][10/79]\tTime 0.035 (0.045)\tData 0.000 (0.028)\tLoss 0.2736 (0.3711)\tPrec@1 91.406 (92.116)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [325][20/79]\tTime 0.074 (0.038)\tData 0.062 (0.023)\tLoss 0.5297 (0.4092)\tPrec@1 89.844 (91.592)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [325][30/79]\tTime 0.009 (0.033)\tData 0.004 (0.019)\tLoss 0.0949 (0.3960)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [325][40/79]\tTime 0.060 (0.034)\tData 0.049 (0.020)\tLoss 0.2452 (0.3977)\tPrec@1 91.406 (91.959)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [325][50/79]\tTime 0.020 (0.032)\tData 0.005 (0.018)\tLoss 0.4246 (0.3917)\tPrec@1 91.406 (91.881)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [325][60/79]\tTime 0.039 (0.031)\tData 0.033 (0.017)\tLoss 0.6443 (0.3969)\tPrec@1 92.969 (91.829)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [325][70/79]\tTime 0.018 (0.030)\tData 0.000 (0.016)\tLoss 0.4017 (0.3898)\tPrec@1 89.062 (91.736)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [325][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.016)\tLoss 0.2411 (0.3869)\tPrec@1 93.750 (91.730)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 326\n",
            "Training Loss 0.0178 \tTraining Prec@1 99.531 \tTraining Prec@5 100.000 \tValidation Loss 0.3869 \tValidation Prec@1 91.730 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 327\n",
            "\n",
            "TRAINING - Epoch: [326][0/390]\tTime 0.263 (0.263)\tData 0.202 (0.202)\tLoss 0.0125 (0.0125)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][10/390]\tTime 0.048 (0.067)\tData 0.000 (0.026)\tLoss 0.0252 (0.0176)\tPrec@1 99.219 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][20/390]\tTime 0.030 (0.057)\tData 0.000 (0.016)\tLoss 0.0131 (0.0171)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][30/390]\tTime 0.030 (0.052)\tData 0.000 (0.012)\tLoss 0.0235 (0.0174)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][40/390]\tTime 0.048 (0.050)\tData 0.002 (0.012)\tLoss 0.0210 (0.0176)\tPrec@1 99.219 (99.447)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][50/390]\tTime 0.039 (0.049)\tData 0.006 (0.010)\tLoss 0.0202 (0.0164)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][60/390]\tTime 0.040 (0.049)\tData 0.003 (0.010)\tLoss 0.0053 (0.0165)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][70/390]\tTime 0.052 (0.048)\tData 0.005 (0.009)\tLoss 0.0330 (0.0160)\tPrec@1 98.438 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][80/390]\tTime 0.033 (0.048)\tData 0.000 (0.009)\tLoss 0.0077 (0.0156)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][90/390]\tTime 0.039 (0.047)\tData 0.003 (0.008)\tLoss 0.0084 (0.0157)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][100/390]\tTime 0.043 (0.047)\tData 0.005 (0.008)\tLoss 0.0117 (0.0156)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][110/390]\tTime 0.044 (0.047)\tData 0.001 (0.008)\tLoss 0.0037 (0.0152)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][120/390]\tTime 0.031 (0.047)\tData 0.000 (0.007)\tLoss 0.0072 (0.0150)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][130/390]\tTime 0.061 (0.046)\tData 0.003 (0.007)\tLoss 0.0323 (0.0149)\tPrec@1 99.219 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][140/390]\tTime 0.040 (0.046)\tData 0.001 (0.007)\tLoss 0.0140 (0.0149)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][150/390]\tTime 0.058 (0.046)\tData 0.000 (0.007)\tLoss 0.0078 (0.0160)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][160/390]\tTime 0.044 (0.046)\tData 0.001 (0.006)\tLoss 0.0086 (0.0161)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][170/390]\tTime 0.054 (0.046)\tData 0.007 (0.006)\tLoss 0.0097 (0.0160)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][180/390]\tTime 0.043 (0.046)\tData 0.001 (0.006)\tLoss 0.0318 (0.0160)\tPrec@1 99.219 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][190/390]\tTime 0.043 (0.046)\tData 0.000 (0.006)\tLoss 0.0089 (0.0161)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][200/390]\tTime 0.039 (0.046)\tData 0.005 (0.006)\tLoss 0.0137 (0.0163)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][210/390]\tTime 0.042 (0.045)\tData 0.005 (0.006)\tLoss 0.0087 (0.0162)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][220/390]\tTime 0.042 (0.045)\tData 0.000 (0.006)\tLoss 0.0259 (0.0163)\tPrec@1 99.219 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][230/390]\tTime 0.051 (0.045)\tData 0.002 (0.005)\tLoss 0.0151 (0.0164)\tPrec@1 99.219 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][240/390]\tTime 0.029 (0.045)\tData 0.000 (0.005)\tLoss 0.0038 (0.0168)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][250/390]\tTime 0.037 (0.045)\tData 0.006 (0.005)\tLoss 0.0250 (0.0169)\tPrec@1 99.219 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][260/390]\tTime 0.049 (0.045)\tData 0.005 (0.005)\tLoss 0.0322 (0.0172)\tPrec@1 98.438 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][270/390]\tTime 0.034 (0.045)\tData 0.003 (0.005)\tLoss 0.0063 (0.0170)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][280/390]\tTime 0.056 (0.045)\tData 0.008 (0.005)\tLoss 0.0106 (0.0168)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][290/390]\tTime 0.036 (0.045)\tData 0.000 (0.005)\tLoss 0.0221 (0.0169)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][300/390]\tTime 0.052 (0.045)\tData 0.002 (0.005)\tLoss 0.0132 (0.0172)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][310/390]\tTime 0.052 (0.045)\tData 0.000 (0.005)\tLoss 0.0197 (0.0172)\tPrec@1 98.438 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][320/390]\tTime 0.045 (0.045)\tData 0.001 (0.005)\tLoss 0.0045 (0.0174)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][330/390]\tTime 0.039 (0.045)\tData 0.007 (0.005)\tLoss 0.0124 (0.0174)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][340/390]\tTime 0.036 (0.045)\tData 0.004 (0.005)\tLoss 0.0082 (0.0173)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][350/390]\tTime 0.042 (0.045)\tData 0.001 (0.005)\tLoss 0.0232 (0.0175)\tPrec@1 98.438 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][360/390]\tTime 0.035 (0.045)\tData 0.002 (0.005)\tLoss 0.0285 (0.0175)\tPrec@1 99.219 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][370/390]\tTime 0.043 (0.045)\tData 0.006 (0.005)\tLoss 0.0223 (0.0175)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][380/390]\tTime 0.046 (0.045)\tData 0.000 (0.005)\tLoss 0.0287 (0.0175)\tPrec@1 99.219 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [326][389/390]\tTime 0.023 (0.044)\tData 0.000 (0.005)\tLoss 0.0159 (0.0175)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [326][0/79]\tTime 0.254 (0.254)\tData 0.233 (0.233)\tLoss 0.2828 (0.2828)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [326][10/79]\tTime 0.018 (0.045)\tData 0.005 (0.032)\tLoss 0.2528 (0.3664)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [326][20/79]\tTime 0.016 (0.037)\tData 0.000 (0.025)\tLoss 0.5295 (0.4086)\tPrec@1 89.844 (91.481)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [326][30/79]\tTime 0.011 (0.036)\tData 0.001 (0.025)\tLoss 0.1085 (0.3951)\tPrec@1 97.656 (91.935)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [326][40/79]\tTime 0.020 (0.034)\tData 0.001 (0.021)\tLoss 0.2341 (0.3975)\tPrec@1 89.844 (91.883)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [326][50/79]\tTime 0.021 (0.033)\tData 0.000 (0.020)\tLoss 0.4243 (0.3904)\tPrec@1 90.625 (91.743)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [326][60/79]\tTime 0.025 (0.032)\tData 0.000 (0.019)\tLoss 0.6453 (0.3959)\tPrec@1 93.750 (91.675)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [326][70/79]\tTime 0.024 (0.032)\tData 0.008 (0.019)\tLoss 0.3949 (0.3891)\tPrec@1 89.844 (91.659)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [326][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.017)\tLoss 0.2611 (0.3863)\tPrec@1 93.750 (91.690)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 327\n",
            "Training Loss 0.0175 \tTraining Prec@1 99.505 \tTraining Prec@5 100.000 \tValidation Loss 0.3863 \tValidation Prec@1 91.690 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 328\n",
            "\n",
            "TRAINING - Epoch: [327][0/390]\tTime 0.322 (0.322)\tData 0.268 (0.268)\tLoss 0.0343 (0.0343)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][10/390]\tTime 0.037 (0.069)\tData 0.000 (0.032)\tLoss 0.0051 (0.0155)\tPrec@1 100.000 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][20/390]\tTime 0.033 (0.058)\tData 0.000 (0.019)\tLoss 0.0228 (0.0166)\tPrec@1 100.000 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][30/390]\tTime 0.038 (0.053)\tData 0.000 (0.016)\tLoss 0.0117 (0.0161)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][40/390]\tTime 0.040 (0.051)\tData 0.000 (0.013)\tLoss 0.0309 (0.0173)\tPrec@1 99.219 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][50/390]\tTime 0.041 (0.050)\tData 0.007 (0.011)\tLoss 0.0364 (0.0166)\tPrec@1 98.438 (99.602)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][60/390]\tTime 0.040 (0.049)\tData 0.010 (0.010)\tLoss 0.0086 (0.0158)\tPrec@1 100.000 (99.616)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][70/390]\tTime 0.050 (0.048)\tData 0.000 (0.009)\tLoss 0.0054 (0.0159)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][80/390]\tTime 0.050 (0.047)\tData 0.013 (0.008)\tLoss 0.0126 (0.0159)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][90/390]\tTime 0.037 (0.047)\tData 0.005 (0.008)\tLoss 0.0174 (0.0164)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][100/390]\tTime 0.038 (0.047)\tData 0.002 (0.008)\tLoss 0.0076 (0.0161)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][110/390]\tTime 0.064 (0.047)\tData 0.001 (0.008)\tLoss 0.0079 (0.0164)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][120/390]\tTime 0.044 (0.047)\tData 0.002 (0.008)\tLoss 0.0041 (0.0162)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][130/390]\tTime 0.033 (0.047)\tData 0.005 (0.008)\tLoss 0.0171 (0.0158)\tPrec@1 100.000 (99.589)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][140/390]\tTime 0.031 (0.047)\tData 0.000 (0.008)\tLoss 0.0155 (0.0157)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][150/390]\tTime 0.077 (0.047)\tData 0.047 (0.008)\tLoss 0.0357 (0.0156)\tPrec@1 99.219 (99.607)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][160/390]\tTime 0.038 (0.047)\tData 0.000 (0.008)\tLoss 0.0215 (0.0163)\tPrec@1 99.219 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][170/390]\tTime 0.050 (0.046)\tData 0.008 (0.007)\tLoss 0.0215 (0.0165)\tPrec@1 98.438 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][180/390]\tTime 0.053 (0.046)\tData 0.000 (0.007)\tLoss 0.0048 (0.0163)\tPrec@1 100.000 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][190/390]\tTime 0.052 (0.046)\tData 0.029 (0.007)\tLoss 0.0144 (0.0162)\tPrec@1 99.219 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][200/390]\tTime 0.038 (0.046)\tData 0.006 (0.007)\tLoss 0.0129 (0.0163)\tPrec@1 99.219 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][210/390]\tTime 0.040 (0.046)\tData 0.005 (0.007)\tLoss 0.0216 (0.0165)\tPrec@1 99.219 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][220/390]\tTime 0.039 (0.046)\tData 0.000 (0.007)\tLoss 0.0086 (0.0166)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][230/390]\tTime 0.039 (0.046)\tData 0.000 (0.007)\tLoss 0.0138 (0.0167)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][240/390]\tTime 0.046 (0.046)\tData 0.000 (0.007)\tLoss 0.0075 (0.0165)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][250/390]\tTime 0.037 (0.046)\tData 0.001 (0.007)\tLoss 0.0151 (0.0163)\tPrec@1 99.219 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][260/390]\tTime 0.054 (0.046)\tData 0.005 (0.006)\tLoss 0.0091 (0.0163)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][270/390]\tTime 0.038 (0.046)\tData 0.001 (0.006)\tLoss 0.0193 (0.0163)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][280/390]\tTime 0.043 (0.046)\tData 0.004 (0.006)\tLoss 0.0292 (0.0163)\tPrec@1 99.219 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][290/390]\tTime 0.040 (0.046)\tData 0.002 (0.006)\tLoss 0.0065 (0.0161)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][300/390]\tTime 0.035 (0.046)\tData 0.007 (0.006)\tLoss 0.0145 (0.0162)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][310/390]\tTime 0.039 (0.046)\tData 0.004 (0.006)\tLoss 0.0084 (0.0162)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][320/390]\tTime 0.058 (0.046)\tData 0.010 (0.006)\tLoss 0.0194 (0.0162)\tPrec@1 99.219 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][330/390]\tTime 0.040 (0.046)\tData 0.005 (0.006)\tLoss 0.0022 (0.0161)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][340/390]\tTime 0.040 (0.046)\tData 0.000 (0.006)\tLoss 0.0113 (0.0161)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][350/390]\tTime 0.050 (0.046)\tData 0.001 (0.006)\tLoss 0.0290 (0.0162)\tPrec@1 99.219 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][360/390]\tTime 0.037 (0.045)\tData 0.005 (0.006)\tLoss 0.0017 (0.0162)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][370/390]\tTime 0.046 (0.046)\tData 0.003 (0.006)\tLoss 0.0034 (0.0162)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][380/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0114 (0.0163)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [327][389/390]\tTime 0.018 (0.045)\tData 0.000 (0.006)\tLoss 0.0264 (0.0163)\tPrec@1 99.219 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [327][0/79]\tTime 0.192 (0.192)\tData 0.178 (0.178)\tLoss 0.2939 (0.2939)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [327][10/79]\tTime 0.015 (0.045)\tData 0.004 (0.034)\tLoss 0.2555 (0.3751)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [327][20/79]\tTime 0.021 (0.037)\tData 0.000 (0.025)\tLoss 0.5302 (0.4127)\tPrec@1 89.844 (91.592)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [327][30/79]\tTime 0.024 (0.034)\tData 0.003 (0.021)\tLoss 0.1052 (0.4002)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [327][40/79]\tTime 0.021 (0.033)\tData 0.005 (0.020)\tLoss 0.2519 (0.4013)\tPrec@1 90.625 (91.902)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [327][50/79]\tTime 0.012 (0.031)\tData 0.006 (0.019)\tLoss 0.4361 (0.3937)\tPrec@1 89.844 (91.866)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [327][60/79]\tTime 0.016 (0.031)\tData 0.000 (0.019)\tLoss 0.6504 (0.3984)\tPrec@1 92.188 (91.790)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [327][70/79]\tTime 0.027 (0.030)\tData 0.005 (0.018)\tLoss 0.4026 (0.3909)\tPrec@1 89.844 (91.747)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [327][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2475 (0.3880)\tPrec@1 93.750 (91.770)\tPrec@5 100.000 (99.720)\t\n",
            "\n",
            "Results - Epoch: 328\n",
            "Training Loss 0.0163 \tTraining Prec@1 99.561 \tTraining Prec@5 100.000 \tValidation Loss 0.3880 \tValidation Prec@1 91.770 \tValidation Prec@5 99.720 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 329\n",
            "\n",
            "TRAINING - Epoch: [328][0/390]\tTime 0.225 (0.225)\tData 0.183 (0.183)\tLoss 0.0061 (0.0061)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][10/390]\tTime 0.051 (0.073)\tData 0.002 (0.031)\tLoss 0.0231 (0.0124)\tPrec@1 100.000 (99.858)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][20/390]\tTime 0.033 (0.058)\tData 0.004 (0.017)\tLoss 0.0096 (0.0156)\tPrec@1 100.000 (99.702)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][30/390]\tTime 0.028 (0.053)\tData 0.000 (0.013)\tLoss 0.0077 (0.0163)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][40/390]\tTime 0.054 (0.051)\tData 0.003 (0.011)\tLoss 0.0098 (0.0163)\tPrec@1 100.000 (99.619)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][50/390]\tTime 0.029 (0.049)\tData 0.000 (0.010)\tLoss 0.0228 (0.0152)\tPrec@1 99.219 (99.663)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][60/390]\tTime 0.053 (0.048)\tData 0.003 (0.009)\tLoss 0.0105 (0.0157)\tPrec@1 100.000 (99.629)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][70/390]\tTime 0.044 (0.047)\tData 0.005 (0.008)\tLoss 0.0109 (0.0162)\tPrec@1 100.000 (99.615)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][80/390]\tTime 0.033 (0.047)\tData 0.001 (0.008)\tLoss 0.0330 (0.0168)\tPrec@1 99.219 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][90/390]\tTime 0.039 (0.046)\tData 0.000 (0.007)\tLoss 0.0132 (0.0171)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][100/390]\tTime 0.036 (0.046)\tData 0.007 (0.007)\tLoss 0.0164 (0.0169)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][110/390]\tTime 0.052 (0.046)\tData 0.007 (0.007)\tLoss 0.0272 (0.0170)\tPrec@1 99.219 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][120/390]\tTime 0.031 (0.046)\tData 0.001 (0.007)\tLoss 0.0542 (0.0172)\tPrec@1 97.656 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][130/390]\tTime 0.047 (0.046)\tData 0.014 (0.007)\tLoss 0.0135 (0.0180)\tPrec@1 99.219 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][140/390]\tTime 0.040 (0.046)\tData 0.001 (0.007)\tLoss 0.0043 (0.0179)\tPrec@1 100.000 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][150/390]\tTime 0.040 (0.046)\tData 0.006 (0.007)\tLoss 0.0133 (0.0179)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][160/390]\tTime 0.024 (0.046)\tData 0.000 (0.007)\tLoss 0.0080 (0.0176)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][170/390]\tTime 0.047 (0.046)\tData 0.000 (0.007)\tLoss 0.0191 (0.0175)\tPrec@1 98.438 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][180/390]\tTime 0.030 (0.046)\tData 0.003 (0.006)\tLoss 0.0135 (0.0174)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][190/390]\tTime 0.045 (0.045)\tData 0.000 (0.006)\tLoss 0.0169 (0.0171)\tPrec@1 98.438 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][200/390]\tTime 0.044 (0.045)\tData 0.005 (0.006)\tLoss 0.0194 (0.0170)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][210/390]\tTime 0.040 (0.045)\tData 0.000 (0.006)\tLoss 0.0039 (0.0169)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][220/390]\tTime 0.046 (0.045)\tData 0.004 (0.006)\tLoss 0.0055 (0.0169)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][230/390]\tTime 0.041 (0.045)\tData 0.008 (0.006)\tLoss 0.0044 (0.0167)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][240/390]\tTime 0.034 (0.045)\tData 0.004 (0.006)\tLoss 0.0242 (0.0169)\tPrec@1 99.219 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][250/390]\tTime 0.047 (0.045)\tData 0.003 (0.005)\tLoss 0.0107 (0.0169)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][260/390]\tTime 0.043 (0.045)\tData 0.000 (0.005)\tLoss 0.0271 (0.0169)\tPrec@1 98.438 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][270/390]\tTime 0.051 (0.045)\tData 0.001 (0.005)\tLoss 0.0446 (0.0169)\tPrec@1 98.438 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][280/390]\tTime 0.046 (0.045)\tData 0.010 (0.005)\tLoss 0.0223 (0.0168)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][290/390]\tTime 0.026 (0.045)\tData 0.000 (0.005)\tLoss 0.0171 (0.0169)\tPrec@1 99.219 (99.527)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][300/390]\tTime 0.063 (0.045)\tData 0.007 (0.005)\tLoss 0.0131 (0.0168)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][310/390]\tTime 0.048 (0.045)\tData 0.005 (0.005)\tLoss 0.0090 (0.0168)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][320/390]\tTime 0.045 (0.045)\tData 0.001 (0.005)\tLoss 0.0224 (0.0168)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][330/390]\tTime 0.042 (0.044)\tData 0.010 (0.005)\tLoss 0.0106 (0.0168)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][340/390]\tTime 0.056 (0.044)\tData 0.018 (0.005)\tLoss 0.0170 (0.0168)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][350/390]\tTime 0.045 (0.045)\tData 0.001 (0.005)\tLoss 0.0096 (0.0167)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][360/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0059 (0.0166)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][370/390]\tTime 0.036 (0.045)\tData 0.003 (0.005)\tLoss 0.0242 (0.0166)\tPrec@1 99.219 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][380/390]\tTime 0.047 (0.045)\tData 0.005 (0.005)\tLoss 0.0044 (0.0164)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [328][389/390]\tTime 0.022 (0.044)\tData 0.000 (0.005)\tLoss 0.0141 (0.0164)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [328][0/79]\tTime 0.288 (0.288)\tData 0.271 (0.271)\tLoss 0.2796 (0.2796)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [328][10/79]\tTime 0.009 (0.046)\tData 0.003 (0.035)\tLoss 0.2534 (0.3661)\tPrec@1 90.625 (92.116)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [328][20/79]\tTime 0.037 (0.037)\tData 0.032 (0.027)\tLoss 0.5339 (0.4080)\tPrec@1 89.844 (91.518)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [328][30/79]\tTime 0.011 (0.035)\tData 0.002 (0.025)\tLoss 0.0985 (0.3941)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [328][40/79]\tTime 0.053 (0.033)\tData 0.047 (0.024)\tLoss 0.2471 (0.3967)\tPrec@1 91.406 (91.864)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [328][50/79]\tTime 0.020 (0.033)\tData 0.009 (0.023)\tLoss 0.4267 (0.3899)\tPrec@1 89.844 (91.789)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [328][60/79]\tTime 0.020 (0.032)\tData 0.007 (0.022)\tLoss 0.6457 (0.3950)\tPrec@1 92.188 (91.701)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [328][70/79]\tTime 0.019 (0.032)\tData 0.010 (0.022)\tLoss 0.3931 (0.3878)\tPrec@1 89.062 (91.670)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [328][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.020)\tLoss 0.2866 (0.3852)\tPrec@1 93.750 (91.690)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 329\n",
            "Training Loss 0.0164 \tTraining Prec@1 99.545 \tTraining Prec@5 100.000 \tValidation Loss 0.3852 \tValidation Prec@1 91.690 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 330\n",
            "\n",
            "TRAINING - Epoch: [329][0/390]\tTime 0.334 (0.334)\tData 0.288 (0.288)\tLoss 0.0064 (0.0064)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][10/390]\tTime 0.043 (0.073)\tData 0.001 (0.030)\tLoss 0.0170 (0.0144)\tPrec@1 100.000 (99.716)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][20/390]\tTime 0.046 (0.059)\tData 0.003 (0.017)\tLoss 0.0076 (0.0142)\tPrec@1 100.000 (99.702)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][30/390]\tTime 0.037 (0.053)\tData 0.004 (0.013)\tLoss 0.0500 (0.0164)\tPrec@1 99.219 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][40/390]\tTime 0.037 (0.051)\tData 0.005 (0.011)\tLoss 0.0281 (0.0171)\tPrec@1 99.219 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][50/390]\tTime 0.054 (0.049)\tData 0.002 (0.009)\tLoss 0.0145 (0.0162)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][60/390]\tTime 0.032 (0.049)\tData 0.000 (0.009)\tLoss 0.0169 (0.0159)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][70/390]\tTime 0.045 (0.048)\tData 0.008 (0.009)\tLoss 0.0205 (0.0175)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][80/390]\tTime 0.028 (0.048)\tData 0.000 (0.009)\tLoss 0.0020 (0.0174)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][90/390]\tTime 0.036 (0.047)\tData 0.000 (0.008)\tLoss 0.0224 (0.0174)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][100/390]\tTime 0.032 (0.047)\tData 0.000 (0.008)\tLoss 0.0244 (0.0174)\tPrec@1 99.219 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][110/390]\tTime 0.043 (0.047)\tData 0.002 (0.007)\tLoss 0.0211 (0.0173)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][120/390]\tTime 0.042 (0.046)\tData 0.000 (0.007)\tLoss 0.0171 (0.0173)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][130/390]\tTime 0.053 (0.046)\tData 0.011 (0.007)\tLoss 0.0086 (0.0173)\tPrec@1 99.219 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][140/390]\tTime 0.035 (0.046)\tData 0.002 (0.007)\tLoss 0.0136 (0.0169)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][150/390]\tTime 0.034 (0.046)\tData 0.005 (0.006)\tLoss 0.0127 (0.0168)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][160/390]\tTime 0.037 (0.046)\tData 0.000 (0.006)\tLoss 0.0131 (0.0168)\tPrec@1 99.219 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][170/390]\tTime 0.042 (0.046)\tData 0.004 (0.006)\tLoss 0.0035 (0.0167)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][180/390]\tTime 0.060 (0.046)\tData 0.000 (0.006)\tLoss 0.0085 (0.0163)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][190/390]\tTime 0.045 (0.046)\tData 0.000 (0.006)\tLoss 0.0159 (0.0163)\tPrec@1 99.219 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][200/390]\tTime 0.042 (0.046)\tData 0.004 (0.006)\tLoss 0.0105 (0.0163)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][210/390]\tTime 0.033 (0.045)\tData 0.005 (0.006)\tLoss 0.0081 (0.0163)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][220/390]\tTime 0.041 (0.045)\tData 0.005 (0.005)\tLoss 0.0168 (0.0166)\tPrec@1 98.438 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][230/390]\tTime 0.048 (0.045)\tData 0.012 (0.005)\tLoss 0.0085 (0.0164)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][240/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0084 (0.0165)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][250/390]\tTime 0.042 (0.045)\tData 0.012 (0.005)\tLoss 0.0077 (0.0166)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][260/390]\tTime 0.039 (0.045)\tData 0.001 (0.005)\tLoss 0.0115 (0.0169)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][270/390]\tTime 0.040 (0.045)\tData 0.005 (0.005)\tLoss 0.0098 (0.0169)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][280/390]\tTime 0.062 (0.045)\tData 0.009 (0.005)\tLoss 0.0092 (0.0169)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][290/390]\tTime 0.040 (0.045)\tData 0.002 (0.005)\tLoss 0.0433 (0.0171)\tPrec@1 96.875 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][300/390]\tTime 0.051 (0.045)\tData 0.005 (0.005)\tLoss 0.0049 (0.0170)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][310/390]\tTime 0.041 (0.045)\tData 0.000 (0.005)\tLoss 0.0087 (0.0169)\tPrec@1 100.000 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][320/390]\tTime 0.031 (0.045)\tData 0.007 (0.005)\tLoss 0.0111 (0.0168)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][330/390]\tTime 0.037 (0.045)\tData 0.000 (0.005)\tLoss 0.0050 (0.0170)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][340/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0578 (0.0170)\tPrec@1 98.438 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][350/390]\tTime 0.056 (0.045)\tData 0.004 (0.005)\tLoss 0.0186 (0.0171)\tPrec@1 99.219 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][360/390]\tTime 0.054 (0.045)\tData 0.008 (0.005)\tLoss 0.0172 (0.0171)\tPrec@1 99.219 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][370/390]\tTime 0.066 (0.045)\tData 0.012 (0.005)\tLoss 0.0131 (0.0170)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][380/390]\tTime 0.045 (0.045)\tData 0.004 (0.005)\tLoss 0.0132 (0.0170)\tPrec@1 99.219 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [329][389/390]\tTime 0.019 (0.044)\tData 0.000 (0.005)\tLoss 0.0119 (0.0170)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [329][0/79]\tTime 0.177 (0.177)\tData 0.166 (0.166)\tLoss 0.2924 (0.2924)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [329][10/79]\tTime 0.016 (0.045)\tData 0.010 (0.032)\tLoss 0.2601 (0.3674)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [329][20/79]\tTime 0.022 (0.036)\tData 0.001 (0.024)\tLoss 0.5474 (0.4116)\tPrec@1 90.625 (91.629)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [329][30/79]\tTime 0.062 (0.035)\tData 0.055 (0.023)\tLoss 0.0999 (0.3982)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [329][40/79]\tTime 0.020 (0.032)\tData 0.005 (0.021)\tLoss 0.2437 (0.3996)\tPrec@1 89.844 (91.825)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [329][50/79]\tTime 0.064 (0.032)\tData 0.060 (0.020)\tLoss 0.4167 (0.3928)\tPrec@1 89.844 (91.805)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [329][60/79]\tTime 0.020 (0.031)\tData 0.005 (0.019)\tLoss 0.6429 (0.3978)\tPrec@1 92.188 (91.739)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [329][70/79]\tTime 0.063 (0.031)\tData 0.057 (0.019)\tLoss 0.4172 (0.3911)\tPrec@1 89.062 (91.703)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [329][78/79]\tTime 0.002 (0.029)\tData 0.000 (0.017)\tLoss 0.2695 (0.3888)\tPrec@1 93.750 (91.720)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 330\n",
            "Training Loss 0.0170 \tTraining Prec@1 99.505 \tTraining Prec@5 100.000 \tValidation Loss 0.3888 \tValidation Prec@1 91.720 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 331\n",
            "\n",
            "TRAINING - Epoch: [330][0/390]\tTime 0.346 (0.346)\tData 0.299 (0.299)\tLoss 0.0070 (0.0070)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][10/390]\tTime 0.028 (0.070)\tData 0.000 (0.028)\tLoss 0.0098 (0.0163)\tPrec@1 100.000 (99.361)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][20/390]\tTime 0.034 (0.057)\tData 0.004 (0.017)\tLoss 0.0242 (0.0190)\tPrec@1 98.438 (99.368)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][30/390]\tTime 0.030 (0.052)\tData 0.000 (0.015)\tLoss 0.0081 (0.0181)\tPrec@1 100.000 (99.446)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][40/390]\tTime 0.043 (0.050)\tData 0.000 (0.012)\tLoss 0.0119 (0.0173)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][50/390]\tTime 0.057 (0.049)\tData 0.005 (0.010)\tLoss 0.0049 (0.0171)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][60/390]\tTime 0.043 (0.048)\tData 0.000 (0.009)\tLoss 0.0317 (0.0169)\tPrec@1 97.656 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][70/390]\tTime 0.029 (0.047)\tData 0.007 (0.008)\tLoss 0.0224 (0.0162)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][80/390]\tTime 0.042 (0.046)\tData 0.001 (0.008)\tLoss 0.0140 (0.0156)\tPrec@1 99.219 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][90/390]\tTime 0.042 (0.046)\tData 0.002 (0.007)\tLoss 0.0081 (0.0152)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][100/390]\tTime 0.041 (0.046)\tData 0.002 (0.007)\tLoss 0.0101 (0.0154)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][110/390]\tTime 0.034 (0.046)\tData 0.001 (0.007)\tLoss 0.0135 (0.0154)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][120/390]\tTime 0.030 (0.046)\tData 0.000 (0.007)\tLoss 0.0044 (0.0154)\tPrec@1 100.000 (99.587)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][130/390]\tTime 0.050 (0.046)\tData 0.000 (0.006)\tLoss 0.0134 (0.0152)\tPrec@1 100.000 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][140/390]\tTime 0.047 (0.046)\tData 0.005 (0.006)\tLoss 0.0184 (0.0156)\tPrec@1 99.219 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][150/390]\tTime 0.058 (0.046)\tData 0.000 (0.006)\tLoss 0.0248 (0.0159)\tPrec@1 98.438 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][160/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0089 (0.0157)\tPrec@1 100.000 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][170/390]\tTime 0.038 (0.045)\tData 0.013 (0.005)\tLoss 0.0314 (0.0156)\tPrec@1 99.219 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][180/390]\tTime 0.044 (0.045)\tData 0.009 (0.006)\tLoss 0.0517 (0.0161)\tPrec@1 98.438 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][190/390]\tTime 0.046 (0.045)\tData 0.000 (0.006)\tLoss 0.0199 (0.0158)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][200/390]\tTime 0.046 (0.045)\tData 0.005 (0.006)\tLoss 0.0063 (0.0156)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][210/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0093 (0.0156)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][220/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0313 (0.0156)\tPrec@1 97.656 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][230/390]\tTime 0.029 (0.045)\tData 0.000 (0.005)\tLoss 0.0181 (0.0157)\tPrec@1 99.219 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][240/390]\tTime 0.060 (0.045)\tData 0.005 (0.005)\tLoss 0.0175 (0.0156)\tPrec@1 99.219 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][250/390]\tTime 0.056 (0.045)\tData 0.002 (0.005)\tLoss 0.0082 (0.0156)\tPrec@1 100.000 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][260/390]\tTime 0.055 (0.045)\tData 0.006 (0.005)\tLoss 0.0095 (0.0157)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][270/390]\tTime 0.045 (0.045)\tData 0.004 (0.005)\tLoss 0.0149 (0.0159)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][280/390]\tTime 0.031 (0.045)\tData 0.004 (0.005)\tLoss 0.0177 (0.0158)\tPrec@1 100.000 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][290/390]\tTime 0.044 (0.045)\tData 0.005 (0.005)\tLoss 0.0171 (0.0158)\tPrec@1 99.219 (99.589)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][300/390]\tTime 0.038 (0.045)\tData 0.000 (0.005)\tLoss 0.0140 (0.0157)\tPrec@1 100.000 (99.593)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][310/390]\tTime 0.044 (0.045)\tData 0.000 (0.005)\tLoss 0.0157 (0.0158)\tPrec@1 100.000 (99.593)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][320/390]\tTime 0.039 (0.045)\tData 0.006 (0.005)\tLoss 0.0129 (0.0157)\tPrec@1 99.219 (99.589)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][330/390]\tTime 0.047 (0.045)\tData 0.002 (0.005)\tLoss 0.0059 (0.0156)\tPrec@1 100.000 (99.587)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][340/390]\tTime 0.056 (0.045)\tData 0.006 (0.005)\tLoss 0.0088 (0.0155)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][350/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0225 (0.0155)\tPrec@1 100.000 (99.595)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][360/390]\tTime 0.041 (0.045)\tData 0.000 (0.005)\tLoss 0.0240 (0.0157)\tPrec@1 98.438 (99.587)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][370/390]\tTime 0.048 (0.045)\tData 0.003 (0.005)\tLoss 0.0289 (0.0161)\tPrec@1 99.219 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][380/390]\tTime 0.043 (0.045)\tData 0.007 (0.005)\tLoss 0.0101 (0.0161)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [330][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0147 (0.0162)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [330][0/79]\tTime 0.269 (0.269)\tData 0.261 (0.261)\tLoss 0.2919 (0.2919)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [330][10/79]\tTime 0.018 (0.045)\tData 0.000 (0.033)\tLoss 0.2676 (0.3770)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [330][20/79]\tTime 0.064 (0.038)\tData 0.046 (0.026)\tLoss 0.5368 (0.4137)\tPrec@1 89.844 (91.592)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [330][30/79]\tTime 0.017 (0.034)\tData 0.001 (0.021)\tLoss 0.0973 (0.4006)\tPrec@1 97.656 (91.935)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [330][40/79]\tTime 0.024 (0.033)\tData 0.013 (0.021)\tLoss 0.2476 (0.4023)\tPrec@1 91.406 (91.864)\tPrec@5 99.219 (99.486)\t\n",
            "EVALUATING - Epoch: [330][50/79]\tTime 0.018 (0.031)\tData 0.004 (0.019)\tLoss 0.4266 (0.3950)\tPrec@1 91.406 (91.759)\tPrec@5 100.000 (99.586)\t\n",
            "EVALUATING - Epoch: [330][60/79]\tTime 0.050 (0.030)\tData 0.044 (0.018)\tLoss 0.6443 (0.3998)\tPrec@1 92.969 (91.701)\tPrec@5 100.000 (99.629)\t\n",
            "EVALUATING - Epoch: [330][70/79]\tTime 0.015 (0.030)\tData 0.001 (0.018)\tLoss 0.4011 (0.3919)\tPrec@1 88.281 (91.648)\tPrec@5 100.000 (99.670)\t\n",
            "EVALUATING - Epoch: [330][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2320 (0.3891)\tPrec@1 93.750 (91.670)\tPrec@5 100.000 (99.660)\t\n",
            "\n",
            "Results - Epoch: 331\n",
            "Training Loss 0.0162 \tTraining Prec@1 99.563 \tTraining Prec@5 100.000 \tValidation Loss 0.3891 \tValidation Prec@1 91.670 \tValidation Prec@5 99.660 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 332\n",
            "\n",
            "TRAINING - Epoch: [331][0/390]\tTime 0.232 (0.232)\tData 0.191 (0.191)\tLoss 0.0061 (0.0061)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][10/390]\tTime 0.037 (0.070)\tData 0.003 (0.031)\tLoss 0.0112 (0.0133)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][20/390]\tTime 0.042 (0.057)\tData 0.000 (0.017)\tLoss 0.0093 (0.0154)\tPrec@1 100.000 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][30/390]\tTime 0.055 (0.054)\tData 0.005 (0.015)\tLoss 0.0055 (0.0161)\tPrec@1 100.000 (99.446)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][40/390]\tTime 0.043 (0.052)\tData 0.005 (0.012)\tLoss 0.0104 (0.0160)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][50/390]\tTime 0.053 (0.051)\tData 0.001 (0.010)\tLoss 0.0299 (0.0179)\tPrec@1 98.438 (99.387)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][60/390]\tTime 0.038 (0.050)\tData 0.003 (0.009)\tLoss 0.0116 (0.0179)\tPrec@1 100.000 (99.436)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][70/390]\tTime 0.030 (0.049)\tData 0.000 (0.008)\tLoss 0.0101 (0.0177)\tPrec@1 99.219 (99.461)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][80/390]\tTime 0.028 (0.049)\tData 0.004 (0.008)\tLoss 0.0078 (0.0168)\tPrec@1 100.000 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][90/390]\tTime 0.033 (0.048)\tData 0.001 (0.007)\tLoss 0.0151 (0.0166)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][100/390]\tTime 0.046 (0.047)\tData 0.000 (0.007)\tLoss 0.0180 (0.0161)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][110/390]\tTime 0.039 (0.047)\tData 0.000 (0.007)\tLoss 0.0138 (0.0159)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][120/390]\tTime 0.040 (0.046)\tData 0.000 (0.006)\tLoss 0.0356 (0.0160)\tPrec@1 98.438 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][130/390]\tTime 0.039 (0.046)\tData 0.004 (0.006)\tLoss 0.0038 (0.0164)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][140/390]\tTime 0.040 (0.046)\tData 0.000 (0.006)\tLoss 0.0194 (0.0163)\tPrec@1 98.438 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][150/390]\tTime 0.049 (0.046)\tData 0.000 (0.006)\tLoss 0.0079 (0.0162)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][160/390]\tTime 0.047 (0.046)\tData 0.000 (0.005)\tLoss 0.0071 (0.0163)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][170/390]\tTime 0.042 (0.046)\tData 0.007 (0.005)\tLoss 0.0156 (0.0163)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][180/390]\tTime 0.045 (0.046)\tData 0.002 (0.005)\tLoss 0.0098 (0.0162)\tPrec@1 100.000 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][190/390]\tTime 0.051 (0.046)\tData 0.007 (0.005)\tLoss 0.0117 (0.0168)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][200/390]\tTime 0.050 (0.046)\tData 0.005 (0.005)\tLoss 0.0069 (0.0165)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][210/390]\tTime 0.036 (0.046)\tData 0.006 (0.005)\tLoss 0.0064 (0.0166)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][220/390]\tTime 0.061 (0.046)\tData 0.000 (0.005)\tLoss 0.0095 (0.0167)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][230/390]\tTime 0.052 (0.045)\tData 0.007 (0.005)\tLoss 0.0067 (0.0166)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][240/390]\tTime 0.042 (0.045)\tData 0.003 (0.005)\tLoss 0.0160 (0.0165)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][250/390]\tTime 0.040 (0.045)\tData 0.002 (0.005)\tLoss 0.0224 (0.0166)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][260/390]\tTime 0.042 (0.045)\tData 0.007 (0.005)\tLoss 0.0337 (0.0168)\tPrec@1 99.219 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][270/390]\tTime 0.035 (0.045)\tData 0.000 (0.005)\tLoss 0.0140 (0.0168)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][280/390]\tTime 0.035 (0.045)\tData 0.005 (0.005)\tLoss 0.0112 (0.0168)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][290/390]\tTime 0.029 (0.045)\tData 0.000 (0.005)\tLoss 0.0236 (0.0169)\tPrec@1 99.219 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][300/390]\tTime 0.036 (0.045)\tData 0.002 (0.005)\tLoss 0.0107 (0.0169)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][310/390]\tTime 0.049 (0.045)\tData 0.011 (0.005)\tLoss 0.0736 (0.0171)\tPrec@1 97.656 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][320/390]\tTime 0.040 (0.045)\tData 0.003 (0.005)\tLoss 0.0133 (0.0171)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][330/390]\tTime 0.049 (0.045)\tData 0.000 (0.005)\tLoss 0.0266 (0.0170)\tPrec@1 99.219 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][340/390]\tTime 0.052 (0.045)\tData 0.007 (0.005)\tLoss 0.0142 (0.0170)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][350/390]\tTime 0.038 (0.045)\tData 0.003 (0.005)\tLoss 0.0220 (0.0171)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][360/390]\tTime 0.044 (0.045)\tData 0.004 (0.005)\tLoss 0.0136 (0.0170)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][370/390]\tTime 0.041 (0.045)\tData 0.000 (0.005)\tLoss 0.0163 (0.0169)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][380/390]\tTime 0.038 (0.045)\tData 0.005 (0.005)\tLoss 0.0073 (0.0167)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [331][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0199 (0.0166)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [331][0/79]\tTime 0.223 (0.223)\tData 0.214 (0.214)\tLoss 0.2660 (0.2660)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [331][10/79]\tTime 0.013 (0.041)\tData 0.000 (0.033)\tLoss 0.2694 (0.3667)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [331][20/79]\tTime 0.017 (0.034)\tData 0.008 (0.026)\tLoss 0.5342 (0.4094)\tPrec@1 89.844 (91.629)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [331][30/79]\tTime 0.069 (0.033)\tData 0.063 (0.024)\tLoss 0.0992 (0.3977)\tPrec@1 97.656 (91.986)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [331][40/79]\tTime 0.017 (0.031)\tData 0.002 (0.020)\tLoss 0.2339 (0.4013)\tPrec@1 92.188 (91.864)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [331][50/79]\tTime 0.052 (0.031)\tData 0.045 (0.020)\tLoss 0.4430 (0.3949)\tPrec@1 90.625 (91.866)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [331][60/79]\tTime 0.020 (0.030)\tData 0.003 (0.018)\tLoss 0.6384 (0.4004)\tPrec@1 93.750 (91.778)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [331][70/79]\tTime 0.059 (0.030)\tData 0.051 (0.019)\tLoss 0.3848 (0.3925)\tPrec@1 89.844 (91.703)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [331][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2417 (0.3896)\tPrec@1 93.750 (91.740)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 332\n",
            "Training Loss 0.0166 \tTraining Prec@1 99.565 \tTraining Prec@5 100.000 \tValidation Loss 0.3896 \tValidation Prec@1 91.740 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 333\n",
            "\n",
            "TRAINING - Epoch: [332][0/390]\tTime 0.343 (0.343)\tData 0.277 (0.277)\tLoss 0.0127 (0.0127)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][10/390]\tTime 0.033 (0.066)\tData 0.005 (0.029)\tLoss 0.0555 (0.0259)\tPrec@1 98.438 (99.006)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][20/390]\tTime 0.046 (0.055)\tData 0.011 (0.018)\tLoss 0.0085 (0.0222)\tPrec@1 100.000 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][30/390]\tTime 0.036 (0.051)\tData 0.001 (0.014)\tLoss 0.0055 (0.0191)\tPrec@1 100.000 (99.345)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][40/390]\tTime 0.053 (0.049)\tData 0.015 (0.012)\tLoss 0.0257 (0.0194)\tPrec@1 99.219 (99.352)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][50/390]\tTime 0.049 (0.048)\tData 0.008 (0.011)\tLoss 0.0047 (0.0183)\tPrec@1 100.000 (99.418)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][60/390]\tTime 0.052 (0.047)\tData 0.005 (0.010)\tLoss 0.0060 (0.0187)\tPrec@1 100.000 (99.398)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][70/390]\tTime 0.026 (0.046)\tData 0.000 (0.009)\tLoss 0.0161 (0.0180)\tPrec@1 99.219 (99.417)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][80/390]\tTime 0.051 (0.046)\tData 0.001 (0.008)\tLoss 0.0305 (0.0178)\tPrec@1 99.219 (99.421)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][90/390]\tTime 0.046 (0.047)\tData 0.005 (0.008)\tLoss 0.0056 (0.0176)\tPrec@1 100.000 (99.433)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][100/390]\tTime 0.049 (0.047)\tData 0.004 (0.007)\tLoss 0.0078 (0.0174)\tPrec@1 100.000 (99.459)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][110/390]\tTime 0.033 (0.046)\tData 0.000 (0.007)\tLoss 0.0082 (0.0169)\tPrec@1 100.000 (99.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][120/390]\tTime 0.031 (0.046)\tData 0.001 (0.007)\tLoss 0.0076 (0.0165)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][130/390]\tTime 0.055 (0.046)\tData 0.000 (0.007)\tLoss 0.0155 (0.0167)\tPrec@1 99.219 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][140/390]\tTime 0.050 (0.046)\tData 0.010 (0.006)\tLoss 0.0118 (0.0165)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][150/390]\tTime 0.035 (0.045)\tData 0.000 (0.006)\tLoss 0.0034 (0.0166)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][160/390]\tTime 0.032 (0.045)\tData 0.000 (0.006)\tLoss 0.0429 (0.0168)\tPrec@1 97.656 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][170/390]\tTime 0.038 (0.045)\tData 0.000 (0.006)\tLoss 0.0207 (0.0165)\tPrec@1 99.219 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][180/390]\tTime 0.040 (0.045)\tData 0.001 (0.006)\tLoss 0.0062 (0.0164)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][190/390]\tTime 0.031 (0.045)\tData 0.003 (0.006)\tLoss 0.0368 (0.0165)\tPrec@1 98.438 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][200/390]\tTime 0.033 (0.045)\tData 0.000 (0.006)\tLoss 0.0247 (0.0166)\tPrec@1 99.219 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][210/390]\tTime 0.042 (0.045)\tData 0.004 (0.006)\tLoss 0.0175 (0.0166)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][220/390]\tTime 0.039 (0.045)\tData 0.002 (0.006)\tLoss 0.0037 (0.0166)\tPrec@1 100.000 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [332][230/390]\tTime 0.051 (0.045)\tData 0.005 (0.006)\tLoss 0.0096 (0.0167)\tPrec@1 100.000 (99.527)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [332][240/390]\tTime 0.048 (0.045)\tData 0.003 (0.006)\tLoss 0.0120 (0.0166)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [332][250/390]\tTime 0.050 (0.045)\tData 0.000 (0.006)\tLoss 0.0040 (0.0167)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [332][260/390]\tTime 0.042 (0.045)\tData 0.005 (0.005)\tLoss 0.0210 (0.0168)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [332][270/390]\tTime 0.053 (0.045)\tData 0.000 (0.005)\tLoss 0.0103 (0.0168)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [332][280/390]\tTime 0.031 (0.045)\tData 0.000 (0.005)\tLoss 0.0176 (0.0167)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [332][290/390]\tTime 0.042 (0.044)\tData 0.001 (0.005)\tLoss 0.0158 (0.0166)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [332][300/390]\tTime 0.061 (0.044)\tData 0.023 (0.005)\tLoss 0.0089 (0.0167)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [332][310/390]\tTime 0.044 (0.044)\tData 0.001 (0.005)\tLoss 0.0262 (0.0168)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [332][320/390]\tTime 0.044 (0.044)\tData 0.013 (0.006)\tLoss 0.0346 (0.0170)\tPrec@1 98.438 (99.538)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [332][330/390]\tTime 0.036 (0.044)\tData 0.001 (0.006)\tLoss 0.0114 (0.0170)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [332][340/390]\tTime 0.041 (0.044)\tData 0.000 (0.006)\tLoss 0.0106 (0.0169)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [332][350/390]\tTime 0.034 (0.044)\tData 0.000 (0.005)\tLoss 0.0287 (0.0168)\tPrec@1 98.438 (99.550)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [332][360/390]\tTime 0.045 (0.044)\tData 0.010 (0.005)\tLoss 0.0099 (0.0168)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [332][370/390]\tTime 0.046 (0.044)\tData 0.000 (0.005)\tLoss 0.0050 (0.0167)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [332][380/390]\tTime 0.037 (0.044)\tData 0.001 (0.005)\tLoss 0.0246 (0.0168)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [332][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0346 (0.0168)\tPrec@1 98.438 (99.539)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [332][0/79]\tTime 0.170 (0.170)\tData 0.157 (0.157)\tLoss 0.2731 (0.2731)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [332][10/79]\tTime 0.044 (0.045)\tData 0.038 (0.035)\tLoss 0.2591 (0.3668)\tPrec@1 91.406 (92.472)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [332][20/79]\tTime 0.020 (0.037)\tData 0.005 (0.026)\tLoss 0.5248 (0.4063)\tPrec@1 89.844 (91.778)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [332][30/79]\tTime 0.059 (0.035)\tData 0.052 (0.024)\tLoss 0.1016 (0.3955)\tPrec@1 97.656 (92.112)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [332][40/79]\tTime 0.012 (0.033)\tData 0.004 (0.021)\tLoss 0.2294 (0.3974)\tPrec@1 92.969 (91.997)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [332][50/79]\tTime 0.066 (0.032)\tData 0.060 (0.021)\tLoss 0.4406 (0.3905)\tPrec@1 91.406 (91.942)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [332][60/79]\tTime 0.024 (0.031)\tData 0.004 (0.019)\tLoss 0.6305 (0.3955)\tPrec@1 93.750 (91.855)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [332][70/79]\tTime 0.035 (0.031)\tData 0.030 (0.019)\tLoss 0.3808 (0.3873)\tPrec@1 89.844 (91.802)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [332][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2525 (0.3841)\tPrec@1 93.750 (91.780)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 333\n",
            "Training Loss 0.0168 \tTraining Prec@1 99.539 \tTraining Prec@5 99.998 \tValidation Loss 0.3841 \tValidation Prec@1 91.780 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 334\n",
            "\n",
            "TRAINING - Epoch: [333][0/390]\tTime 0.328 (0.328)\tData 0.284 (0.284)\tLoss 0.0077 (0.0077)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][10/390]\tTime 0.046 (0.072)\tData 0.003 (0.028)\tLoss 0.0102 (0.0133)\tPrec@1 100.000 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][20/390]\tTime 0.036 (0.059)\tData 0.007 (0.017)\tLoss 0.0206 (0.0136)\tPrec@1 99.219 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][30/390]\tTime 0.044 (0.052)\tData 0.000 (0.012)\tLoss 0.0278 (0.0136)\tPrec@1 99.219 (99.672)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][40/390]\tTime 0.051 (0.050)\tData 0.010 (0.010)\tLoss 0.0111 (0.0141)\tPrec@1 100.000 (99.676)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][50/390]\tTime 0.035 (0.050)\tData 0.005 (0.009)\tLoss 0.0195 (0.0147)\tPrec@1 100.000 (99.663)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][60/390]\tTime 0.038 (0.048)\tData 0.006 (0.009)\tLoss 0.0067 (0.0147)\tPrec@1 100.000 (99.680)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][70/390]\tTime 0.039 (0.047)\tData 0.005 (0.008)\tLoss 0.0379 (0.0145)\tPrec@1 99.219 (99.692)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][80/390]\tTime 0.034 (0.047)\tData 0.002 (0.007)\tLoss 0.0042 (0.0146)\tPrec@1 100.000 (99.662)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][90/390]\tTime 0.046 (0.046)\tData 0.004 (0.007)\tLoss 0.0083 (0.0147)\tPrec@1 100.000 (99.639)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][100/390]\tTime 0.052 (0.046)\tData 0.003 (0.007)\tLoss 0.0130 (0.0150)\tPrec@1 99.219 (99.613)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][110/390]\tTime 0.048 (0.046)\tData 0.004 (0.007)\tLoss 0.0145 (0.0151)\tPrec@1 100.000 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][120/390]\tTime 0.044 (0.046)\tData 0.004 (0.007)\tLoss 0.0116 (0.0148)\tPrec@1 100.000 (99.619)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][130/390]\tTime 0.035 (0.046)\tData 0.001 (0.006)\tLoss 0.0121 (0.0148)\tPrec@1 100.000 (99.618)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][140/390]\tTime 0.040 (0.046)\tData 0.005 (0.006)\tLoss 0.0104 (0.0146)\tPrec@1 100.000 (99.640)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][150/390]\tTime 0.047 (0.046)\tData 0.005 (0.006)\tLoss 0.0349 (0.0148)\tPrec@1 98.438 (99.638)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][160/390]\tTime 0.060 (0.046)\tData 0.008 (0.006)\tLoss 0.0046 (0.0151)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][170/390]\tTime 0.028 (0.046)\tData 0.000 (0.006)\tLoss 0.0208 (0.0151)\tPrec@1 99.219 (99.625)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][180/390]\tTime 0.040 (0.045)\tData 0.000 (0.006)\tLoss 0.0052 (0.0150)\tPrec@1 100.000 (99.620)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][190/390]\tTime 0.030 (0.045)\tData 0.000 (0.005)\tLoss 0.0028 (0.0151)\tPrec@1 100.000 (99.616)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][200/390]\tTime 0.044 (0.045)\tData 0.004 (0.005)\tLoss 0.0065 (0.0150)\tPrec@1 100.000 (99.619)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][210/390]\tTime 0.104 (0.045)\tData 0.061 (0.005)\tLoss 0.0252 (0.0152)\tPrec@1 98.438 (99.608)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][220/390]\tTime 0.041 (0.045)\tData 0.000 (0.005)\tLoss 0.0255 (0.0156)\tPrec@1 98.438 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][230/390]\tTime 0.048 (0.045)\tData 0.015 (0.005)\tLoss 0.0114 (0.0155)\tPrec@1 100.000 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][240/390]\tTime 0.056 (0.045)\tData 0.002 (0.006)\tLoss 0.0105 (0.0155)\tPrec@1 100.000 (99.592)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][250/390]\tTime 0.045 (0.045)\tData 0.005 (0.005)\tLoss 0.0383 (0.0158)\tPrec@1 98.438 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][260/390]\tTime 0.027 (0.045)\tData 0.000 (0.005)\tLoss 0.0411 (0.0161)\tPrec@1 97.656 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][270/390]\tTime 0.048 (0.045)\tData 0.004 (0.005)\tLoss 0.0239 (0.0162)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][280/390]\tTime 0.044 (0.044)\tData 0.011 (0.005)\tLoss 0.0107 (0.0162)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][290/390]\tTime 0.040 (0.044)\tData 0.001 (0.005)\tLoss 0.0047 (0.0164)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][300/390]\tTime 0.048 (0.045)\tData 0.002 (0.005)\tLoss 0.0173 (0.0165)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][310/390]\tTime 0.046 (0.044)\tData 0.005 (0.005)\tLoss 0.0178 (0.0164)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][320/390]\tTime 0.047 (0.044)\tData 0.010 (0.005)\tLoss 0.0050 (0.0166)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][330/390]\tTime 0.040 (0.044)\tData 0.001 (0.005)\tLoss 0.0112 (0.0166)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][340/390]\tTime 0.042 (0.044)\tData 0.015 (0.005)\tLoss 0.0086 (0.0167)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][350/390]\tTime 0.046 (0.044)\tData 0.005 (0.005)\tLoss 0.0198 (0.0168)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][360/390]\tTime 0.047 (0.044)\tData 0.018 (0.005)\tLoss 0.0107 (0.0166)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][370/390]\tTime 0.042 (0.044)\tData 0.002 (0.005)\tLoss 0.0159 (0.0165)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][380/390]\tTime 0.037 (0.044)\tData 0.000 (0.005)\tLoss 0.0305 (0.0164)\tPrec@1 99.219 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [333][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0107 (0.0163)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [333][0/79]\tTime 0.274 (0.274)\tData 0.254 (0.254)\tLoss 0.2853 (0.2853)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [333][10/79]\tTime 0.019 (0.047)\tData 0.005 (0.034)\tLoss 0.2604 (0.3699)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [333][20/79]\tTime 0.007 (0.040)\tData 0.001 (0.028)\tLoss 0.5186 (0.4101)\tPrec@1 90.625 (91.518)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [333][30/79]\tTime 0.011 (0.037)\tData 0.000 (0.025)\tLoss 0.1009 (0.3976)\tPrec@1 97.656 (91.809)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [333][40/79]\tTime 0.028 (0.036)\tData 0.004 (0.023)\tLoss 0.2333 (0.3980)\tPrec@1 92.188 (91.864)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [333][50/79]\tTime 0.011 (0.033)\tData 0.005 (0.021)\tLoss 0.4213 (0.3910)\tPrec@1 91.406 (91.881)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [333][60/79]\tTime 0.016 (0.032)\tData 0.000 (0.020)\tLoss 0.6562 (0.3964)\tPrec@1 92.969 (91.803)\tPrec@5 99.219 (99.654)\t\n",
            "EVALUATING - Epoch: [333][70/79]\tTime 0.009 (0.031)\tData 0.000 (0.018)\tLoss 0.3836 (0.3884)\tPrec@1 90.625 (91.769)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [333][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.018)\tLoss 0.2617 (0.3855)\tPrec@1 93.750 (91.770)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 334\n",
            "Training Loss 0.0163 \tTraining Prec@1 99.547 \tTraining Prec@5 100.000 \tValidation Loss 0.3855 \tValidation Prec@1 91.770 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 335\n",
            "\n",
            "TRAINING - Epoch: [334][0/390]\tTime 0.234 (0.234)\tData 0.181 (0.181)\tLoss 0.0092 (0.0092)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][10/390]\tTime 0.042 (0.068)\tData 0.000 (0.030)\tLoss 0.0062 (0.0166)\tPrec@1 100.000 (99.716)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][20/390]\tTime 0.038 (0.055)\tData 0.001 (0.019)\tLoss 0.0145 (0.0162)\tPrec@1 99.219 (99.665)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][30/390]\tTime 0.041 (0.052)\tData 0.000 (0.016)\tLoss 0.0070 (0.0155)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][40/390]\tTime 0.032 (0.049)\tData 0.000 (0.013)\tLoss 0.0114 (0.0159)\tPrec@1 100.000 (99.619)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][50/390]\tTime 0.030 (0.048)\tData 0.000 (0.012)\tLoss 0.0041 (0.0146)\tPrec@1 100.000 (99.678)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][60/390]\tTime 0.051 (0.048)\tData 0.008 (0.011)\tLoss 0.0084 (0.0144)\tPrec@1 100.000 (99.667)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][70/390]\tTime 0.056 (0.047)\tData 0.000 (0.010)\tLoss 0.0133 (0.0147)\tPrec@1 99.219 (99.626)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][80/390]\tTime 0.050 (0.047)\tData 0.005 (0.009)\tLoss 0.0203 (0.0157)\tPrec@1 99.219 (99.595)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][90/390]\tTime 0.027 (0.046)\tData 0.000 (0.008)\tLoss 0.0086 (0.0156)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][100/390]\tTime 0.067 (0.046)\tData 0.010 (0.008)\tLoss 0.0099 (0.0154)\tPrec@1 100.000 (99.598)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][110/390]\tTime 0.037 (0.046)\tData 0.005 (0.007)\tLoss 0.0150 (0.0152)\tPrec@1 100.000 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][120/390]\tTime 0.033 (0.046)\tData 0.001 (0.007)\tLoss 0.0143 (0.0153)\tPrec@1 99.219 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][130/390]\tTime 0.029 (0.045)\tData 0.003 (0.007)\tLoss 0.0108 (0.0154)\tPrec@1 100.000 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][140/390]\tTime 0.051 (0.045)\tData 0.002 (0.006)\tLoss 0.0120 (0.0152)\tPrec@1 100.000 (99.607)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][150/390]\tTime 0.038 (0.045)\tData 0.004 (0.006)\tLoss 0.0281 (0.0151)\tPrec@1 99.219 (99.612)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][160/390]\tTime 0.051 (0.045)\tData 0.003 (0.006)\tLoss 0.0617 (0.0157)\tPrec@1 97.656 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][170/390]\tTime 0.034 (0.045)\tData 0.000 (0.006)\tLoss 0.0067 (0.0159)\tPrec@1 100.000 (99.580)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][180/390]\tTime 0.053 (0.045)\tData 0.000 (0.006)\tLoss 0.0178 (0.0160)\tPrec@1 99.219 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][190/390]\tTime 0.047 (0.045)\tData 0.001 (0.006)\tLoss 0.0423 (0.0163)\tPrec@1 98.438 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][200/390]\tTime 0.032 (0.045)\tData 0.000 (0.006)\tLoss 0.0089 (0.0162)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][210/390]\tTime 0.048 (0.045)\tData 0.008 (0.006)\tLoss 0.0265 (0.0163)\tPrec@1 98.438 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][220/390]\tTime 0.039 (0.045)\tData 0.004 (0.006)\tLoss 0.0143 (0.0162)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][230/390]\tTime 0.036 (0.045)\tData 0.000 (0.006)\tLoss 0.0169 (0.0164)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][240/390]\tTime 0.033 (0.045)\tData 0.001 (0.006)\tLoss 0.0110 (0.0165)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][250/390]\tTime 0.030 (0.044)\tData 0.000 (0.005)\tLoss 0.0251 (0.0165)\tPrec@1 99.219 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][260/390]\tTime 0.039 (0.044)\tData 0.000 (0.005)\tLoss 0.0083 (0.0167)\tPrec@1 100.000 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][270/390]\tTime 0.033 (0.044)\tData 0.005 (0.005)\tLoss 0.0253 (0.0166)\tPrec@1 99.219 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][280/390]\tTime 0.034 (0.044)\tData 0.000 (0.005)\tLoss 0.0490 (0.0168)\tPrec@1 98.438 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][290/390]\tTime 0.041 (0.044)\tData 0.005 (0.005)\tLoss 0.0031 (0.0166)\tPrec@1 100.000 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][300/390]\tTime 0.029 (0.044)\tData 0.001 (0.005)\tLoss 0.0063 (0.0167)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][310/390]\tTime 0.035 (0.044)\tData 0.003 (0.005)\tLoss 0.0108 (0.0168)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][320/390]\tTime 0.038 (0.044)\tData 0.007 (0.005)\tLoss 0.0204 (0.0168)\tPrec@1 99.219 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][330/390]\tTime 0.056 (0.044)\tData 0.007 (0.005)\tLoss 0.0107 (0.0167)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][340/390]\tTime 0.052 (0.044)\tData 0.000 (0.005)\tLoss 0.0071 (0.0166)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][350/390]\tTime 0.043 (0.044)\tData 0.006 (0.005)\tLoss 0.0078 (0.0168)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][360/390]\tTime 0.034 (0.044)\tData 0.001 (0.005)\tLoss 0.0312 (0.0170)\tPrec@1 98.438 (99.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][370/390]\tTime 0.037 (0.044)\tData 0.000 (0.005)\tLoss 0.0064 (0.0171)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][380/390]\tTime 0.051 (0.044)\tData 0.007 (0.005)\tLoss 0.0036 (0.0170)\tPrec@1 100.000 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [334][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0268 (0.0171)\tPrec@1 99.219 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [334][0/79]\tTime 0.245 (0.245)\tData 0.227 (0.227)\tLoss 0.2774 (0.2774)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [334][10/79]\tTime 0.013 (0.043)\tData 0.001 (0.029)\tLoss 0.2654 (0.3720)\tPrec@1 91.406 (91.974)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [334][20/79]\tTime 0.068 (0.039)\tData 0.062 (0.026)\tLoss 0.4976 (0.4081)\tPrec@1 90.625 (91.406)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [334][30/79]\tTime 0.013 (0.035)\tData 0.001 (0.021)\tLoss 0.1061 (0.3956)\tPrec@1 97.656 (91.835)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [334][40/79]\tTime 0.011 (0.032)\tData 0.005 (0.019)\tLoss 0.2330 (0.3983)\tPrec@1 91.406 (91.806)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [334][50/79]\tTime 0.018 (0.031)\tData 0.010 (0.019)\tLoss 0.4446 (0.3906)\tPrec@1 91.406 (91.774)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [334][60/79]\tTime 0.010 (0.031)\tData 0.000 (0.019)\tLoss 0.6490 (0.3962)\tPrec@1 93.750 (91.675)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [334][70/79]\tTime 0.034 (0.030)\tData 0.026 (0.019)\tLoss 0.4024 (0.3883)\tPrec@1 89.844 (91.692)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [334][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2764 (0.3854)\tPrec@1 93.750 (91.730)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 335\n",
            "Training Loss 0.0171 \tTraining Prec@1 99.495 \tTraining Prec@5 100.000 \tValidation Loss 0.3854 \tValidation Prec@1 91.730 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 336\n",
            "\n",
            "TRAINING - Epoch: [335][0/390]\tTime 0.274 (0.274)\tData 0.212 (0.212)\tLoss 0.0081 (0.0081)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][10/390]\tTime 0.040 (0.067)\tData 0.000 (0.028)\tLoss 0.0221 (0.0151)\tPrec@1 99.219 (99.787)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][20/390]\tTime 0.040 (0.057)\tData 0.006 (0.017)\tLoss 0.0211 (0.0185)\tPrec@1 99.219 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][30/390]\tTime 0.041 (0.054)\tData 0.000 (0.014)\tLoss 0.0069 (0.0190)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][40/390]\tTime 0.034 (0.052)\tData 0.000 (0.011)\tLoss 0.0165 (0.0195)\tPrec@1 98.438 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][50/390]\tTime 0.045 (0.050)\tData 0.010 (0.010)\tLoss 0.0091 (0.0182)\tPrec@1 100.000 (99.494)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][60/390]\tTime 0.037 (0.049)\tData 0.002 (0.009)\tLoss 0.0046 (0.0171)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][70/390]\tTime 0.037 (0.048)\tData 0.008 (0.009)\tLoss 0.0120 (0.0176)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][80/390]\tTime 0.034 (0.047)\tData 0.005 (0.009)\tLoss 0.0040 (0.0176)\tPrec@1 100.000 (99.489)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][90/390]\tTime 0.047 (0.047)\tData 0.004 (0.008)\tLoss 0.0117 (0.0171)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][100/390]\tTime 0.047 (0.047)\tData 0.005 (0.008)\tLoss 0.0066 (0.0169)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][110/390]\tTime 0.040 (0.046)\tData 0.001 (0.007)\tLoss 0.0104 (0.0171)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][120/390]\tTime 0.037 (0.046)\tData 0.000 (0.007)\tLoss 0.0189 (0.0172)\tPrec@1 99.219 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][130/390]\tTime 0.037 (0.045)\tData 0.001 (0.006)\tLoss 0.0082 (0.0172)\tPrec@1 100.000 (99.487)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][140/390]\tTime 0.048 (0.045)\tData 0.005 (0.006)\tLoss 0.0415 (0.0170)\tPrec@1 99.219 (99.507)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][150/390]\tTime 0.045 (0.045)\tData 0.000 (0.007)\tLoss 0.0296 (0.0172)\tPrec@1 99.219 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][160/390]\tTime 0.042 (0.045)\tData 0.004 (0.006)\tLoss 0.0164 (0.0171)\tPrec@1 99.219 (99.495)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][170/390]\tTime 0.039 (0.045)\tData 0.005 (0.006)\tLoss 0.0112 (0.0173)\tPrec@1 100.000 (99.497)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][180/390]\tTime 0.039 (0.045)\tData 0.003 (0.006)\tLoss 0.0185 (0.0174)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][190/390]\tTime 0.037 (0.045)\tData 0.000 (0.006)\tLoss 0.0226 (0.0173)\tPrec@1 99.219 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][200/390]\tTime 0.036 (0.045)\tData 0.000 (0.006)\tLoss 0.0055 (0.0173)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][210/390]\tTime 0.050 (0.045)\tData 0.005 (0.006)\tLoss 0.0224 (0.0171)\tPrec@1 99.219 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][220/390]\tTime 0.041 (0.045)\tData 0.006 (0.006)\tLoss 0.0149 (0.0172)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][230/390]\tTime 0.048 (0.045)\tData 0.006 (0.006)\tLoss 0.0064 (0.0176)\tPrec@1 100.000 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][240/390]\tTime 0.039 (0.045)\tData 0.001 (0.006)\tLoss 0.0214 (0.0176)\tPrec@1 98.438 (99.504)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][250/390]\tTime 0.054 (0.045)\tData 0.000 (0.006)\tLoss 0.0153 (0.0174)\tPrec@1 100.000 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][260/390]\tTime 0.047 (0.045)\tData 0.004 (0.006)\tLoss 0.0351 (0.0173)\tPrec@1 97.656 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][270/390]\tTime 0.039 (0.045)\tData 0.003 (0.006)\tLoss 0.0181 (0.0172)\tPrec@1 99.219 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][280/390]\tTime 0.046 (0.045)\tData 0.002 (0.006)\tLoss 0.0175 (0.0170)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][290/390]\tTime 0.044 (0.045)\tData 0.001 (0.006)\tLoss 0.0070 (0.0172)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][300/390]\tTime 0.052 (0.045)\tData 0.001 (0.006)\tLoss 0.0108 (0.0171)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][310/390]\tTime 0.043 (0.045)\tData 0.012 (0.006)\tLoss 0.0110 (0.0171)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][320/390]\tTime 0.051 (0.045)\tData 0.001 (0.005)\tLoss 0.0073 (0.0172)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][330/390]\tTime 0.047 (0.045)\tData 0.000 (0.005)\tLoss 0.0103 (0.0171)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][340/390]\tTime 0.057 (0.045)\tData 0.005 (0.005)\tLoss 0.0109 (0.0170)\tPrec@1 99.219 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][350/390]\tTime 0.045 (0.045)\tData 0.016 (0.005)\tLoss 0.0198 (0.0170)\tPrec@1 99.219 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][360/390]\tTime 0.039 (0.045)\tData 0.004 (0.005)\tLoss 0.0043 (0.0171)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][370/390]\tTime 0.040 (0.045)\tData 0.007 (0.005)\tLoss 0.0082 (0.0170)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][380/390]\tTime 0.051 (0.045)\tData 0.000 (0.006)\tLoss 0.0079 (0.0170)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [335][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0022 (0.0171)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [335][0/79]\tTime 0.210 (0.210)\tData 0.183 (0.183)\tLoss 0.2850 (0.2850)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [335][10/79]\tTime 0.045 (0.046)\tData 0.037 (0.035)\tLoss 0.2484 (0.3738)\tPrec@1 91.406 (92.116)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [335][20/79]\tTime 0.023 (0.038)\tData 0.000 (0.025)\tLoss 0.5173 (0.4141)\tPrec@1 90.625 (91.518)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [335][30/79]\tTime 0.049 (0.034)\tData 0.039 (0.021)\tLoss 0.1048 (0.4009)\tPrec@1 97.656 (91.935)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [335][40/79]\tTime 0.020 (0.033)\tData 0.006 (0.020)\tLoss 0.2232 (0.4017)\tPrec@1 91.406 (91.883)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [335][50/79]\tTime 0.029 (0.032)\tData 0.023 (0.020)\tLoss 0.4382 (0.3940)\tPrec@1 91.406 (91.835)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [335][60/79]\tTime 0.020 (0.032)\tData 0.000 (0.019)\tLoss 0.6532 (0.3990)\tPrec@1 92.969 (91.726)\tPrec@5 99.219 (99.641)\t\n",
            "EVALUATING - Epoch: [335][70/79]\tTime 0.021 (0.031)\tData 0.004 (0.018)\tLoss 0.3943 (0.3909)\tPrec@1 89.844 (91.703)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [335][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2762 (0.3883)\tPrec@1 93.750 (91.740)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 336\n",
            "Training Loss 0.0171 \tTraining Prec@1 99.539 \tTraining Prec@5 100.000 \tValidation Loss 0.3883 \tValidation Prec@1 91.740 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 337\n",
            "\n",
            "TRAINING - Epoch: [336][0/390]\tTime 0.319 (0.319)\tData 0.254 (0.254)\tLoss 0.0178 (0.0178)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][10/390]\tTime 0.037 (0.069)\tData 0.009 (0.026)\tLoss 0.0195 (0.0136)\tPrec@1 100.000 (99.716)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][20/390]\tTime 0.062 (0.059)\tData 0.007 (0.016)\tLoss 0.0227 (0.0132)\tPrec@1 99.219 (99.740)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][30/390]\tTime 0.044 (0.053)\tData 0.001 (0.012)\tLoss 0.0075 (0.0136)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][40/390]\tTime 0.052 (0.051)\tData 0.009 (0.010)\tLoss 0.0266 (0.0145)\tPrec@1 99.219 (99.638)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][50/390]\tTime 0.049 (0.048)\tData 0.001 (0.008)\tLoss 0.0259 (0.0164)\tPrec@1 98.438 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][60/390]\tTime 0.049 (0.048)\tData 0.021 (0.007)\tLoss 0.0042 (0.0162)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][70/390]\tTime 0.041 (0.048)\tData 0.003 (0.007)\tLoss 0.0386 (0.0166)\tPrec@1 99.219 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][80/390]\tTime 0.053 (0.047)\tData 0.015 (0.007)\tLoss 0.0214 (0.0171)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][90/390]\tTime 0.059 (0.047)\tData 0.011 (0.007)\tLoss 0.0328 (0.0179)\tPrec@1 98.438 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][100/390]\tTime 0.045 (0.047)\tData 0.010 (0.007)\tLoss 0.0171 (0.0177)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][110/390]\tTime 0.055 (0.046)\tData 0.005 (0.006)\tLoss 0.0499 (0.0182)\tPrec@1 99.219 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][120/390]\tTime 0.028 (0.046)\tData 0.000 (0.006)\tLoss 0.0122 (0.0179)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][130/390]\tTime 0.050 (0.046)\tData 0.009 (0.006)\tLoss 0.0099 (0.0181)\tPrec@1 100.000 (99.511)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][140/390]\tTime 0.051 (0.046)\tData 0.008 (0.006)\tLoss 0.0144 (0.0179)\tPrec@1 100.000 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][150/390]\tTime 0.044 (0.045)\tData 0.011 (0.006)\tLoss 0.0350 (0.0181)\tPrec@1 98.438 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][160/390]\tTime 0.038 (0.045)\tData 0.000 (0.006)\tLoss 0.0075 (0.0178)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][170/390]\tTime 0.043 (0.045)\tData 0.005 (0.006)\tLoss 0.0070 (0.0177)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][180/390]\tTime 0.044 (0.045)\tData 0.002 (0.006)\tLoss 0.0220 (0.0174)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][190/390]\tTime 0.047 (0.045)\tData 0.007 (0.006)\tLoss 0.0146 (0.0172)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][200/390]\tTime 0.039 (0.045)\tData 0.011 (0.006)\tLoss 0.0084 (0.0173)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][210/390]\tTime 0.045 (0.045)\tData 0.001 (0.005)\tLoss 0.0160 (0.0173)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][220/390]\tTime 0.037 (0.045)\tData 0.007 (0.005)\tLoss 0.0056 (0.0172)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][230/390]\tTime 0.038 (0.045)\tData 0.000 (0.005)\tLoss 0.0168 (0.0173)\tPrec@1 99.219 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][240/390]\tTime 0.040 (0.045)\tData 0.006 (0.005)\tLoss 0.0293 (0.0172)\tPrec@1 98.438 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][250/390]\tTime 0.036 (0.045)\tData 0.002 (0.005)\tLoss 0.0181 (0.0173)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][260/390]\tTime 0.044 (0.045)\tData 0.010 (0.005)\tLoss 0.0110 (0.0174)\tPrec@1 99.219 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][270/390]\tTime 0.043 (0.045)\tData 0.005 (0.005)\tLoss 0.0059 (0.0173)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][280/390]\tTime 0.028 (0.044)\tData 0.000 (0.005)\tLoss 0.0569 (0.0173)\tPrec@1 99.219 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][290/390]\tTime 0.035 (0.044)\tData 0.006 (0.005)\tLoss 0.0463 (0.0174)\tPrec@1 98.438 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][300/390]\tTime 0.048 (0.044)\tData 0.008 (0.005)\tLoss 0.0034 (0.0173)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][310/390]\tTime 0.034 (0.044)\tData 0.005 (0.005)\tLoss 0.0173 (0.0171)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][320/390]\tTime 0.049 (0.044)\tData 0.007 (0.005)\tLoss 0.0467 (0.0171)\tPrec@1 98.438 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][330/390]\tTime 0.050 (0.044)\tData 0.000 (0.005)\tLoss 0.0119 (0.0171)\tPrec@1 100.000 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][340/390]\tTime 0.040 (0.044)\tData 0.010 (0.005)\tLoss 0.0148 (0.0171)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][350/390]\tTime 0.032 (0.044)\tData 0.001 (0.005)\tLoss 0.0116 (0.0171)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][360/390]\tTime 0.044 (0.044)\tData 0.000 (0.005)\tLoss 0.0044 (0.0170)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][370/390]\tTime 0.035 (0.044)\tData 0.007 (0.005)\tLoss 0.0193 (0.0170)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][380/390]\tTime 0.035 (0.044)\tData 0.007 (0.005)\tLoss 0.0305 (0.0170)\tPrec@1 98.438 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [336][389/390]\tTime 0.020 (0.044)\tData 0.000 (0.005)\tLoss 0.0107 (0.0168)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [336][0/79]\tTime 0.199 (0.199)\tData 0.183 (0.183)\tLoss 0.2836 (0.2836)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [336][10/79]\tTime 0.021 (0.046)\tData 0.005 (0.033)\tLoss 0.2770 (0.3736)\tPrec@1 91.406 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [336][20/79]\tTime 0.017 (0.036)\tData 0.005 (0.023)\tLoss 0.5304 (0.4104)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [336][30/79]\tTime 0.022 (0.034)\tData 0.010 (0.020)\tLoss 0.0950 (0.3971)\tPrec@1 97.656 (92.036)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [336][40/79]\tTime 0.038 (0.032)\tData 0.033 (0.020)\tLoss 0.2590 (0.3998)\tPrec@1 92.188 (91.921)\tPrec@5 99.219 (99.486)\t\n",
            "EVALUATING - Epoch: [336][50/79]\tTime 0.051 (0.031)\tData 0.041 (0.020)\tLoss 0.4365 (0.3926)\tPrec@1 89.844 (91.789)\tPrec@5 100.000 (99.586)\t\n",
            "EVALUATING - Epoch: [336][60/79]\tTime 0.017 (0.030)\tData 0.003 (0.018)\tLoss 0.6389 (0.3974)\tPrec@1 92.969 (91.739)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [336][70/79]\tTime 0.011 (0.031)\tData 0.005 (0.019)\tLoss 0.3808 (0.3894)\tPrec@1 89.844 (91.659)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [336][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2479 (0.3863)\tPrec@1 93.750 (91.670)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 337\n",
            "Training Loss 0.0168 \tTraining Prec@1 99.557 \tTraining Prec@5 100.000 \tValidation Loss 0.3863 \tValidation Prec@1 91.670 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 338\n",
            "\n",
            "TRAINING - Epoch: [337][0/390]\tTime 0.255 (0.255)\tData 0.189 (0.189)\tLoss 0.0097 (0.0097)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][10/390]\tTime 0.048 (0.069)\tData 0.003 (0.026)\tLoss 0.0143 (0.0153)\tPrec@1 99.219 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][20/390]\tTime 0.045 (0.055)\tData 0.000 (0.015)\tLoss 0.0284 (0.0162)\tPrec@1 98.438 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][30/390]\tTime 0.049 (0.052)\tData 0.001 (0.013)\tLoss 0.0118 (0.0169)\tPrec@1 100.000 (99.420)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][40/390]\tTime 0.038 (0.049)\tData 0.000 (0.011)\tLoss 0.0132 (0.0181)\tPrec@1 99.219 (99.371)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][50/390]\tTime 0.052 (0.049)\tData 0.003 (0.010)\tLoss 0.0065 (0.0174)\tPrec@1 100.000 (99.387)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][60/390]\tTime 0.044 (0.048)\tData 0.000 (0.009)\tLoss 0.0030 (0.0164)\tPrec@1 100.000 (99.449)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][70/390]\tTime 0.030 (0.047)\tData 0.005 (0.009)\tLoss 0.0223 (0.0163)\tPrec@1 99.219 (99.461)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][80/390]\tTime 0.043 (0.047)\tData 0.005 (0.008)\tLoss 0.0168 (0.0161)\tPrec@1 99.219 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][90/390]\tTime 0.044 (0.047)\tData 0.000 (0.008)\tLoss 0.0125 (0.0164)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][100/390]\tTime 0.044 (0.047)\tData 0.003 (0.007)\tLoss 0.0242 (0.0161)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][110/390]\tTime 0.038 (0.047)\tData 0.010 (0.007)\tLoss 0.0130 (0.0171)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][120/390]\tTime 0.034 (0.047)\tData 0.005 (0.007)\tLoss 0.0167 (0.0172)\tPrec@1 99.219 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][130/390]\tTime 0.054 (0.047)\tData 0.010 (0.007)\tLoss 0.0153 (0.0170)\tPrec@1 99.219 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][140/390]\tTime 0.049 (0.047)\tData 0.002 (0.007)\tLoss 0.0189 (0.0171)\tPrec@1 99.219 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][150/390]\tTime 0.054 (0.047)\tData 0.006 (0.006)\tLoss 0.0028 (0.0171)\tPrec@1 100.000 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][160/390]\tTime 0.027 (0.046)\tData 0.000 (0.006)\tLoss 0.0090 (0.0170)\tPrec@1 100.000 (99.490)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][170/390]\tTime 0.034 (0.046)\tData 0.000 (0.006)\tLoss 0.0517 (0.0173)\tPrec@1 98.438 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][180/390]\tTime 0.038 (0.046)\tData 0.004 (0.006)\tLoss 0.0205 (0.0172)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][190/390]\tTime 0.041 (0.046)\tData 0.000 (0.006)\tLoss 0.0070 (0.0175)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][200/390]\tTime 0.046 (0.046)\tData 0.003 (0.006)\tLoss 0.0091 (0.0174)\tPrec@1 100.000 (99.506)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][210/390]\tTime 0.050 (0.045)\tData 0.001 (0.006)\tLoss 0.0137 (0.0171)\tPrec@1 100.000 (99.515)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][220/390]\tTime 0.038 (0.045)\tData 0.001 (0.006)\tLoss 0.0271 (0.0171)\tPrec@1 98.438 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][230/390]\tTime 0.049 (0.045)\tData 0.002 (0.006)\tLoss 0.0071 (0.0172)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][240/390]\tTime 0.043 (0.045)\tData 0.004 (0.006)\tLoss 0.0090 (0.0171)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][250/390]\tTime 0.042 (0.045)\tData 0.005 (0.006)\tLoss 0.0086 (0.0173)\tPrec@1 100.000 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][260/390]\tTime 0.038 (0.045)\tData 0.000 (0.006)\tLoss 0.0109 (0.0172)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][270/390]\tTime 0.027 (0.045)\tData 0.000 (0.006)\tLoss 0.0162 (0.0172)\tPrec@1 99.219 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][280/390]\tTime 0.037 (0.045)\tData 0.002 (0.006)\tLoss 0.0216 (0.0172)\tPrec@1 99.219 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][290/390]\tTime 0.032 (0.045)\tData 0.000 (0.005)\tLoss 0.0118 (0.0171)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][300/390]\tTime 0.041 (0.045)\tData 0.000 (0.005)\tLoss 0.0207 (0.0173)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][310/390]\tTime 0.035 (0.045)\tData 0.006 (0.005)\tLoss 0.0114 (0.0173)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][320/390]\tTime 0.045 (0.045)\tData 0.004 (0.005)\tLoss 0.0130 (0.0172)\tPrec@1 100.000 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][330/390]\tTime 0.057 (0.045)\tData 0.000 (0.005)\tLoss 0.0137 (0.0172)\tPrec@1 100.000 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][340/390]\tTime 0.044 (0.045)\tData 0.006 (0.005)\tLoss 0.0307 (0.0171)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][350/390]\tTime 0.035 (0.045)\tData 0.005 (0.005)\tLoss 0.0090 (0.0171)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][360/390]\tTime 0.041 (0.044)\tData 0.008 (0.005)\tLoss 0.0447 (0.0170)\tPrec@1 98.438 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][370/390]\tTime 0.049 (0.044)\tData 0.005 (0.005)\tLoss 0.0105 (0.0170)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][380/390]\tTime 0.041 (0.044)\tData 0.005 (0.005)\tLoss 0.0116 (0.0169)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [337][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0168 (0.0169)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [337][0/79]\tTime 0.190 (0.190)\tData 0.174 (0.174)\tLoss 0.2913 (0.2913)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [337][10/79]\tTime 0.016 (0.043)\tData 0.000 (0.031)\tLoss 0.2627 (0.3727)\tPrec@1 91.406 (91.974)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [337][20/79]\tTime 0.017 (0.036)\tData 0.005 (0.023)\tLoss 0.5166 (0.4102)\tPrec@1 90.625 (91.518)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [337][30/79]\tTime 0.019 (0.032)\tData 0.005 (0.020)\tLoss 0.1038 (0.3966)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [337][40/79]\tTime 0.034 (0.032)\tData 0.028 (0.019)\tLoss 0.2461 (0.3984)\tPrec@1 91.406 (91.845)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [337][50/79]\tTime 0.086 (0.032)\tData 0.080 (0.019)\tLoss 0.4453 (0.3919)\tPrec@1 90.625 (91.774)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [337][60/79]\tTime 0.018 (0.031)\tData 0.002 (0.018)\tLoss 0.6535 (0.3969)\tPrec@1 92.188 (91.688)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [337][70/79]\tTime 0.062 (0.031)\tData 0.056 (0.018)\tLoss 0.3983 (0.3894)\tPrec@1 89.844 (91.659)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [337][78/79]\tTime 0.002 (0.029)\tData 0.000 (0.016)\tLoss 0.2607 (0.3863)\tPrec@1 93.750 (91.670)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 338\n",
            "Training Loss 0.0169 \tTraining Prec@1 99.547 \tTraining Prec@5 100.000 \tValidation Loss 0.3863 \tValidation Prec@1 91.670 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 339\n",
            "\n",
            "TRAINING - Epoch: [338][0/390]\tTime 0.350 (0.350)\tData 0.299 (0.299)\tLoss 0.0137 (0.0137)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][10/390]\tTime 0.051 (0.072)\tData 0.005 (0.031)\tLoss 0.0315 (0.0141)\tPrec@1 100.000 (99.787)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][20/390]\tTime 0.044 (0.057)\tData 0.000 (0.018)\tLoss 0.0176 (0.0150)\tPrec@1 100.000 (99.702)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][30/390]\tTime 0.053 (0.054)\tData 0.005 (0.014)\tLoss 0.0052 (0.0155)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][40/390]\tTime 0.053 (0.051)\tData 0.002 (0.011)\tLoss 0.0316 (0.0170)\tPrec@1 98.438 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][50/390]\tTime 0.051 (0.049)\tData 0.008 (0.010)\tLoss 0.0050 (0.0153)\tPrec@1 100.000 (99.602)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][60/390]\tTime 0.033 (0.048)\tData 0.004 (0.009)\tLoss 0.0076 (0.0149)\tPrec@1 100.000 (99.641)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][70/390]\tTime 0.048 (0.047)\tData 0.007 (0.008)\tLoss 0.0192 (0.0151)\tPrec@1 99.219 (99.615)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][80/390]\tTime 0.052 (0.047)\tData 0.009 (0.008)\tLoss 0.0025 (0.0152)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][90/390]\tTime 0.051 (0.047)\tData 0.008 (0.008)\tLoss 0.0296 (0.0151)\tPrec@1 98.438 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][100/390]\tTime 0.052 (0.046)\tData 0.003 (0.007)\tLoss 0.0146 (0.0151)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][110/390]\tTime 0.037 (0.046)\tData 0.001 (0.007)\tLoss 0.0289 (0.0152)\tPrec@1 98.438 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][120/390]\tTime 0.039 (0.046)\tData 0.001 (0.007)\tLoss 0.0121 (0.0151)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][130/390]\tTime 0.044 (0.046)\tData 0.002 (0.007)\tLoss 0.0212 (0.0159)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][140/390]\tTime 0.035 (0.046)\tData 0.001 (0.006)\tLoss 0.0246 (0.0159)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][150/390]\tTime 0.048 (0.045)\tData 0.008 (0.006)\tLoss 0.0166 (0.0160)\tPrec@1 99.219 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][160/390]\tTime 0.050 (0.045)\tData 0.006 (0.006)\tLoss 0.0081 (0.0159)\tPrec@1 100.000 (99.534)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][170/390]\tTime 0.038 (0.045)\tData 0.001 (0.006)\tLoss 0.0048 (0.0158)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][180/390]\tTime 0.037 (0.045)\tData 0.001 (0.006)\tLoss 0.0064 (0.0159)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][190/390]\tTime 0.033 (0.045)\tData 0.000 (0.006)\tLoss 0.0089 (0.0162)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][200/390]\tTime 0.039 (0.045)\tData 0.005 (0.005)\tLoss 0.0138 (0.0162)\tPrec@1 98.438 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][210/390]\tTime 0.034 (0.045)\tData 0.006 (0.006)\tLoss 0.0262 (0.0161)\tPrec@1 98.438 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][220/390]\tTime 0.044 (0.045)\tData 0.016 (0.006)\tLoss 0.0227 (0.0164)\tPrec@1 99.219 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][230/390]\tTime 0.042 (0.045)\tData 0.001 (0.006)\tLoss 0.0061 (0.0163)\tPrec@1 100.000 (99.523)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][240/390]\tTime 0.037 (0.045)\tData 0.005 (0.005)\tLoss 0.0164 (0.0162)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][250/390]\tTime 0.037 (0.045)\tData 0.010 (0.005)\tLoss 0.0117 (0.0162)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][260/390]\tTime 0.044 (0.045)\tData 0.000 (0.005)\tLoss 0.0291 (0.0162)\tPrec@1 99.219 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][270/390]\tTime 0.042 (0.045)\tData 0.000 (0.005)\tLoss 0.0300 (0.0163)\tPrec@1 99.219 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][280/390]\tTime 0.045 (0.045)\tData 0.001 (0.005)\tLoss 0.0290 (0.0166)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][290/390]\tTime 0.050 (0.044)\tData 0.004 (0.005)\tLoss 0.0073 (0.0165)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][300/390]\tTime 0.035 (0.044)\tData 0.006 (0.005)\tLoss 0.0109 (0.0164)\tPrec@1 99.219 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][310/390]\tTime 0.051 (0.044)\tData 0.002 (0.005)\tLoss 0.0076 (0.0163)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][320/390]\tTime 0.048 (0.044)\tData 0.002 (0.005)\tLoss 0.0204 (0.0166)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][330/390]\tTime 0.034 (0.044)\tData 0.000 (0.005)\tLoss 0.0146 (0.0166)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][340/390]\tTime 0.038 (0.044)\tData 0.001 (0.005)\tLoss 0.0065 (0.0165)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][350/390]\tTime 0.041 (0.044)\tData 0.005 (0.005)\tLoss 0.0251 (0.0167)\tPrec@1 99.219 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][360/390]\tTime 0.053 (0.044)\tData 0.004 (0.005)\tLoss 0.0199 (0.0168)\tPrec@1 99.219 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][370/390]\tTime 0.044 (0.044)\tData 0.000 (0.005)\tLoss 0.0061 (0.0167)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][380/390]\tTime 0.063 (0.044)\tData 0.008 (0.005)\tLoss 0.0093 (0.0168)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [338][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0068 (0.0166)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [338][0/79]\tTime 0.260 (0.260)\tData 0.242 (0.242)\tLoss 0.2799 (0.2799)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [338][10/79]\tTime 0.031 (0.042)\tData 0.025 (0.031)\tLoss 0.2643 (0.3672)\tPrec@1 90.625 (92.188)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [338][20/79]\tTime 0.047 (0.037)\tData 0.040 (0.025)\tLoss 0.5362 (0.4089)\tPrec@1 89.844 (91.629)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [338][30/79]\tTime 0.045 (0.034)\tData 0.038 (0.023)\tLoss 0.0908 (0.3952)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [338][40/79]\tTime 0.023 (0.032)\tData 0.017 (0.021)\tLoss 0.2438 (0.3973)\tPrec@1 90.625 (91.883)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [338][50/79]\tTime 0.025 (0.031)\tData 0.010 (0.020)\tLoss 0.4484 (0.3907)\tPrec@1 90.625 (91.850)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [338][60/79]\tTime 0.029 (0.031)\tData 0.022 (0.020)\tLoss 0.6402 (0.3952)\tPrec@1 93.750 (91.829)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [338][70/79]\tTime 0.061 (0.030)\tData 0.049 (0.020)\tLoss 0.3885 (0.3874)\tPrec@1 89.844 (91.780)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [338][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2654 (0.3843)\tPrec@1 93.750 (91.790)\tPrec@5 100.000 (99.720)\t\n",
            "\n",
            "Results - Epoch: 339\n",
            "Training Loss 0.0166 \tTraining Prec@1 99.547 \tTraining Prec@5 100.000 \tValidation Loss 0.3843 \tValidation Prec@1 91.790 \tValidation Prec@5 99.720 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 340\n",
            "\n",
            "TRAINING - Epoch: [339][0/390]\tTime 0.353 (0.353)\tData 0.300 (0.300)\tLoss 0.0072 (0.0072)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][10/390]\tTime 0.042 (0.075)\tData 0.000 (0.030)\tLoss 0.0259 (0.0167)\tPrec@1 99.219 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][20/390]\tTime 0.047 (0.059)\tData 0.005 (0.018)\tLoss 0.0259 (0.0147)\tPrec@1 98.438 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][30/390]\tTime 0.038 (0.054)\tData 0.001 (0.013)\tLoss 0.0072 (0.0159)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][40/390]\tTime 0.042 (0.052)\tData 0.000 (0.011)\tLoss 0.0145 (0.0158)\tPrec@1 99.219 (99.619)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][50/390]\tTime 0.031 (0.049)\tData 0.000 (0.009)\tLoss 0.0088 (0.0156)\tPrec@1 100.000 (99.617)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][60/390]\tTime 0.030 (0.048)\tData 0.000 (0.008)\tLoss 0.0198 (0.0149)\tPrec@1 99.219 (99.629)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][70/390]\tTime 0.038 (0.047)\tData 0.010 (0.007)\tLoss 0.0023 (0.0150)\tPrec@1 100.000 (99.637)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][80/390]\tTime 0.041 (0.046)\tData 0.000 (0.007)\tLoss 0.0098 (0.0148)\tPrec@1 100.000 (99.643)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][90/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0396 (0.0147)\tPrec@1 98.438 (99.648)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][100/390]\tTime 0.029 (0.045)\tData 0.005 (0.006)\tLoss 0.0243 (0.0153)\tPrec@1 99.219 (99.621)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][110/390]\tTime 0.041 (0.045)\tData 0.001 (0.006)\tLoss 0.0326 (0.0156)\tPrec@1 98.438 (99.620)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][120/390]\tTime 0.042 (0.045)\tData 0.000 (0.006)\tLoss 0.0059 (0.0156)\tPrec@1 100.000 (99.632)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][130/390]\tTime 0.039 (0.045)\tData 0.007 (0.006)\tLoss 0.0142 (0.0158)\tPrec@1 99.219 (99.630)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][140/390]\tTime 0.049 (0.045)\tData 0.015 (0.006)\tLoss 0.0306 (0.0161)\tPrec@1 99.219 (99.623)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][150/390]\tTime 0.061 (0.045)\tData 0.000 (0.005)\tLoss 0.0133 (0.0159)\tPrec@1 99.219 (99.607)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][160/390]\tTime 0.048 (0.045)\tData 0.001 (0.005)\tLoss 0.0165 (0.0160)\tPrec@1 99.219 (99.607)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][170/390]\tTime 0.048 (0.045)\tData 0.001 (0.005)\tLoss 0.0167 (0.0162)\tPrec@1 99.219 (99.593)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][180/390]\tTime 0.043 (0.045)\tData 0.005 (0.005)\tLoss 0.0278 (0.0164)\tPrec@1 98.438 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][190/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0228 (0.0165)\tPrec@1 99.219 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][200/390]\tTime 0.054 (0.045)\tData 0.014 (0.005)\tLoss 0.0085 (0.0165)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][210/390]\tTime 0.037 (0.045)\tData 0.001 (0.005)\tLoss 0.0159 (0.0165)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][220/390]\tTime 0.050 (0.045)\tData 0.000 (0.005)\tLoss 0.0364 (0.0166)\tPrec@1 98.438 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][230/390]\tTime 0.036 (0.044)\tData 0.002 (0.005)\tLoss 0.0391 (0.0168)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][240/390]\tTime 0.044 (0.044)\tData 0.010 (0.004)\tLoss 0.0138 (0.0166)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][250/390]\tTime 0.034 (0.044)\tData 0.000 (0.004)\tLoss 0.0160 (0.0166)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][260/390]\tTime 0.044 (0.044)\tData 0.000 (0.004)\tLoss 0.0170 (0.0168)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][270/390]\tTime 0.045 (0.044)\tData 0.013 (0.004)\tLoss 0.0050 (0.0167)\tPrec@1 100.000 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][280/390]\tTime 0.043 (0.044)\tData 0.000 (0.004)\tLoss 0.0139 (0.0167)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][290/390]\tTime 0.036 (0.044)\tData 0.000 (0.004)\tLoss 0.0082 (0.0167)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][300/390]\tTime 0.039 (0.044)\tData 0.001 (0.004)\tLoss 0.0027 (0.0166)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][310/390]\tTime 0.037 (0.044)\tData 0.001 (0.004)\tLoss 0.0024 (0.0167)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][320/390]\tTime 0.034 (0.044)\tData 0.000 (0.004)\tLoss 0.0168 (0.0168)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][330/390]\tTime 0.050 (0.044)\tData 0.009 (0.004)\tLoss 0.0444 (0.0168)\tPrec@1 98.438 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][340/390]\tTime 0.050 (0.044)\tData 0.014 (0.004)\tLoss 0.0057 (0.0168)\tPrec@1 100.000 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][350/390]\tTime 0.045 (0.044)\tData 0.002 (0.004)\tLoss 0.0178 (0.0168)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][360/390]\tTime 0.042 (0.044)\tData 0.000 (0.004)\tLoss 0.0162 (0.0168)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][370/390]\tTime 0.044 (0.044)\tData 0.004 (0.004)\tLoss 0.0160 (0.0167)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][380/390]\tTime 0.037 (0.044)\tData 0.004 (0.004)\tLoss 0.0116 (0.0168)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [339][389/390]\tTime 0.017 (0.044)\tData 0.000 (0.004)\tLoss 0.0111 (0.0168)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [339][0/79]\tTime 0.266 (0.266)\tData 0.243 (0.243)\tLoss 0.2806 (0.2806)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [339][10/79]\tTime 0.011 (0.047)\tData 0.000 (0.037)\tLoss 0.2584 (0.3650)\tPrec@1 91.406 (92.116)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [339][20/79]\tTime 0.063 (0.039)\tData 0.057 (0.029)\tLoss 0.5249 (0.4060)\tPrec@1 89.844 (91.555)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [339][30/79]\tTime 0.013 (0.035)\tData 0.007 (0.025)\tLoss 0.1082 (0.3946)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [339][40/79]\tTime 0.038 (0.034)\tData 0.033 (0.024)\tLoss 0.2321 (0.3976)\tPrec@1 92.188 (91.921)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [339][50/79]\tTime 0.019 (0.032)\tData 0.000 (0.022)\tLoss 0.4405 (0.3912)\tPrec@1 89.844 (91.866)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [339][60/79]\tTime 0.064 (0.032)\tData 0.058 (0.021)\tLoss 0.6329 (0.3966)\tPrec@1 93.750 (91.739)\tPrec@5 100.000 (99.680)\t\n",
            "EVALUATING - Epoch: [339][70/79]\tTime 0.025 (0.031)\tData 0.010 (0.020)\tLoss 0.4025 (0.3894)\tPrec@1 90.625 (91.670)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [339][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.019)\tLoss 0.2648 (0.3863)\tPrec@1 93.750 (91.680)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 340\n",
            "Training Loss 0.0168 \tTraining Prec@1 99.563 \tTraining Prec@5 100.000 \tValidation Loss 0.3863 \tValidation Prec@1 91.680 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 341\n",
            "\n",
            "TRAINING - Epoch: [340][0/390]\tTime 0.225 (0.225)\tData 0.182 (0.182)\tLoss 0.0359 (0.0359)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][10/390]\tTime 0.049 (0.067)\tData 0.005 (0.028)\tLoss 0.0228 (0.0189)\tPrec@1 99.219 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][20/390]\tTime 0.062 (0.057)\tData 0.016 (0.017)\tLoss 0.0091 (0.0161)\tPrec@1 100.000 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][30/390]\tTime 0.048 (0.052)\tData 0.005 (0.013)\tLoss 0.0088 (0.0167)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][40/390]\tTime 0.053 (0.050)\tData 0.007 (0.010)\tLoss 0.0332 (0.0170)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][50/390]\tTime 0.041 (0.049)\tData 0.001 (0.009)\tLoss 0.0111 (0.0165)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][60/390]\tTime 0.032 (0.047)\tData 0.001 (0.008)\tLoss 0.0054 (0.0159)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][70/390]\tTime 0.053 (0.047)\tData 0.001 (0.007)\tLoss 0.0059 (0.0163)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][80/390]\tTime 0.036 (0.046)\tData 0.000 (0.006)\tLoss 0.0322 (0.0161)\tPrec@1 98.438 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][90/390]\tTime 0.045 (0.046)\tData 0.001 (0.006)\tLoss 0.0142 (0.0158)\tPrec@1 99.219 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][100/390]\tTime 0.039 (0.046)\tData 0.007 (0.006)\tLoss 0.0203 (0.0161)\tPrec@1 99.219 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][110/390]\tTime 0.035 (0.046)\tData 0.000 (0.006)\tLoss 0.0119 (0.0162)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][120/390]\tTime 0.047 (0.045)\tData 0.007 (0.006)\tLoss 0.0052 (0.0162)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][130/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0167 (0.0161)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][140/390]\tTime 0.053 (0.045)\tData 0.013 (0.005)\tLoss 0.0228 (0.0161)\tPrec@1 98.438 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][150/390]\tTime 0.039 (0.045)\tData 0.001 (0.005)\tLoss 0.0215 (0.0163)\tPrec@1 100.000 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][160/390]\tTime 0.052 (0.045)\tData 0.008 (0.005)\tLoss 0.0299 (0.0162)\tPrec@1 99.219 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][170/390]\tTime 0.021 (0.045)\tData 0.000 (0.005)\tLoss 0.0280 (0.0163)\tPrec@1 99.219 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][180/390]\tTime 0.036 (0.045)\tData 0.002 (0.005)\tLoss 0.0151 (0.0161)\tPrec@1 99.219 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][190/390]\tTime 0.040 (0.045)\tData 0.006 (0.005)\tLoss 0.0245 (0.0161)\tPrec@1 99.219 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][200/390]\tTime 0.058 (0.045)\tData 0.033 (0.005)\tLoss 0.0188 (0.0163)\tPrec@1 100.000 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][210/390]\tTime 0.044 (0.045)\tData 0.002 (0.005)\tLoss 0.0164 (0.0164)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][220/390]\tTime 0.055 (0.045)\tData 0.006 (0.005)\tLoss 0.0274 (0.0165)\tPrec@1 99.219 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][230/390]\tTime 0.056 (0.045)\tData 0.005 (0.005)\tLoss 0.0117 (0.0164)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][240/390]\tTime 0.059 (0.045)\tData 0.012 (0.005)\tLoss 0.0069 (0.0163)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][250/390]\tTime 0.047 (0.045)\tData 0.007 (0.005)\tLoss 0.0157 (0.0164)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][260/390]\tTime 0.040 (0.045)\tData 0.007 (0.005)\tLoss 0.0051 (0.0164)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][270/390]\tTime 0.035 (0.045)\tData 0.001 (0.005)\tLoss 0.0154 (0.0164)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][280/390]\tTime 0.043 (0.045)\tData 0.000 (0.005)\tLoss 0.0135 (0.0162)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][290/390]\tTime 0.036 (0.045)\tData 0.001 (0.005)\tLoss 0.0206 (0.0163)\tPrec@1 98.438 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][300/390]\tTime 0.039 (0.045)\tData 0.000 (0.005)\tLoss 0.0161 (0.0163)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][310/390]\tTime 0.034 (0.045)\tData 0.000 (0.005)\tLoss 0.0628 (0.0164)\tPrec@1 96.875 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][320/390]\tTime 0.050 (0.045)\tData 0.012 (0.005)\tLoss 0.0150 (0.0166)\tPrec@1 99.219 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][330/390]\tTime 0.029 (0.045)\tData 0.005 (0.005)\tLoss 0.0089 (0.0166)\tPrec@1 100.000 (99.549)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][340/390]\tTime 0.041 (0.045)\tData 0.000 (0.005)\tLoss 0.0085 (0.0165)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][350/390]\tTime 0.037 (0.045)\tData 0.000 (0.005)\tLoss 0.0131 (0.0164)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][360/390]\tTime 0.040 (0.045)\tData 0.000 (0.005)\tLoss 0.0064 (0.0164)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][370/390]\tTime 0.044 (0.045)\tData 0.000 (0.005)\tLoss 0.0083 (0.0164)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][380/390]\tTime 0.061 (0.045)\tData 0.003 (0.005)\tLoss 0.0169 (0.0165)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [340][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0117 (0.0164)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [340][0/79]\tTime 0.218 (0.218)\tData 0.205 (0.205)\tLoss 0.2906 (0.2906)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [340][10/79]\tTime 0.017 (0.041)\tData 0.012 (0.028)\tLoss 0.2506 (0.3696)\tPrec@1 91.406 (92.401)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [340][20/79]\tTime 0.012 (0.034)\tData 0.006 (0.023)\tLoss 0.5409 (0.4116)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [340][30/79]\tTime 0.022 (0.032)\tData 0.010 (0.022)\tLoss 0.0978 (0.3988)\tPrec@1 97.656 (92.011)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [340][40/79]\tTime 0.058 (0.032)\tData 0.052 (0.021)\tLoss 0.2381 (0.3999)\tPrec@1 92.188 (91.959)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [340][50/79]\tTime 0.019 (0.030)\tData 0.000 (0.018)\tLoss 0.4322 (0.3927)\tPrec@1 89.844 (91.881)\tPrec@5 100.000 (99.648)\t\n",
            "EVALUATING - Epoch: [340][60/79]\tTime 0.021 (0.030)\tData 0.003 (0.018)\tLoss 0.6411 (0.3973)\tPrec@1 92.188 (91.803)\tPrec@5 100.000 (99.667)\t\n",
            "EVALUATING - Epoch: [340][70/79]\tTime 0.016 (0.029)\tData 0.000 (0.017)\tLoss 0.3948 (0.3898)\tPrec@1 89.062 (91.747)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [340][78/79]\tTime 0.003 (0.028)\tData 0.000 (0.016)\tLoss 0.2641 (0.3873)\tPrec@1 93.750 (91.750)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 341\n",
            "Training Loss 0.0164 \tTraining Prec@1 99.567 \tTraining Prec@5 100.000 \tValidation Loss 0.3873 \tValidation Prec@1 91.750 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 342\n",
            "\n",
            "TRAINING - Epoch: [341][0/390]\tTime 0.218 (0.218)\tData 0.189 (0.189)\tLoss 0.0130 (0.0130)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][10/390]\tTime 0.035 (0.064)\tData 0.001 (0.033)\tLoss 0.0183 (0.0149)\tPrec@1 99.219 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][20/390]\tTime 0.045 (0.054)\tData 0.005 (0.019)\tLoss 0.0731 (0.0156)\tPrec@1 98.438 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][30/390]\tTime 0.042 (0.052)\tData 0.004 (0.016)\tLoss 0.0235 (0.0167)\tPrec@1 99.219 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][40/390]\tTime 0.038 (0.049)\tData 0.004 (0.014)\tLoss 0.0062 (0.0157)\tPrec@1 100.000 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][50/390]\tTime 0.038 (0.049)\tData 0.005 (0.012)\tLoss 0.0263 (0.0162)\tPrec@1 98.438 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][60/390]\tTime 0.021 (0.047)\tData 0.000 (0.011)\tLoss 0.0184 (0.0166)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][70/390]\tTime 0.049 (0.047)\tData 0.005 (0.011)\tLoss 0.0166 (0.0165)\tPrec@1 99.219 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][80/390]\tTime 0.028 (0.046)\tData 0.000 (0.010)\tLoss 0.0097 (0.0160)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][90/390]\tTime 0.044 (0.046)\tData 0.007 (0.009)\tLoss 0.0078 (0.0160)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][100/390]\tTime 0.031 (0.045)\tData 0.005 (0.008)\tLoss 0.0339 (0.0157)\tPrec@1 99.219 (99.613)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][110/390]\tTime 0.048 (0.045)\tData 0.005 (0.008)\tLoss 0.0055 (0.0157)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][120/390]\tTime 0.037 (0.045)\tData 0.004 (0.007)\tLoss 0.0175 (0.0155)\tPrec@1 100.000 (99.626)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][130/390]\tTime 0.042 (0.045)\tData 0.005 (0.007)\tLoss 0.0084 (0.0155)\tPrec@1 100.000 (99.624)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][140/390]\tTime 0.043 (0.045)\tData 0.000 (0.007)\tLoss 0.0071 (0.0153)\tPrec@1 100.000 (99.634)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][150/390]\tTime 0.033 (0.044)\tData 0.000 (0.007)\tLoss 0.0087 (0.0155)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][160/390]\tTime 0.051 (0.044)\tData 0.006 (0.007)\tLoss 0.0233 (0.0157)\tPrec@1 100.000 (99.617)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][170/390]\tTime 0.047 (0.044)\tData 0.008 (0.007)\tLoss 0.0149 (0.0155)\tPrec@1 100.000 (99.635)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][180/390]\tTime 0.061 (0.045)\tData 0.005 (0.007)\tLoss 0.0229 (0.0153)\tPrec@1 99.219 (99.637)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][190/390]\tTime 0.058 (0.045)\tData 0.008 (0.006)\tLoss 0.0113 (0.0156)\tPrec@1 100.000 (99.628)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][200/390]\tTime 0.031 (0.044)\tData 0.000 (0.006)\tLoss 0.0423 (0.0159)\tPrec@1 98.438 (99.611)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][210/390]\tTime 0.024 (0.044)\tData 0.000 (0.006)\tLoss 0.0240 (0.0159)\tPrec@1 99.219 (99.604)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][220/390]\tTime 0.047 (0.044)\tData 0.006 (0.006)\tLoss 0.0228 (0.0158)\tPrec@1 99.219 (99.604)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][230/390]\tTime 0.044 (0.044)\tData 0.001 (0.006)\tLoss 0.0083 (0.0159)\tPrec@1 100.000 (99.601)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][240/390]\tTime 0.052 (0.044)\tData 0.008 (0.006)\tLoss 0.0072 (0.0161)\tPrec@1 100.000 (99.595)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][250/390]\tTime 0.046 (0.044)\tData 0.000 (0.006)\tLoss 0.0610 (0.0164)\tPrec@1 98.438 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][260/390]\tTime 0.037 (0.044)\tData 0.001 (0.006)\tLoss 0.0088 (0.0164)\tPrec@1 100.000 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][270/390]\tTime 0.040 (0.044)\tData 0.003 (0.005)\tLoss 0.0073 (0.0164)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][280/390]\tTime 0.061 (0.044)\tData 0.005 (0.005)\tLoss 0.0521 (0.0165)\tPrec@1 98.438 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][290/390]\tTime 0.048 (0.044)\tData 0.010 (0.005)\tLoss 0.0177 (0.0165)\tPrec@1 99.219 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][300/390]\tTime 0.035 (0.044)\tData 0.000 (0.005)\tLoss 0.0134 (0.0168)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][310/390]\tTime 0.036 (0.044)\tData 0.000 (0.005)\tLoss 0.0099 (0.0168)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][320/390]\tTime 0.042 (0.044)\tData 0.003 (0.005)\tLoss 0.0304 (0.0167)\tPrec@1 98.438 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][330/390]\tTime 0.032 (0.044)\tData 0.002 (0.005)\tLoss 0.0130 (0.0168)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][340/390]\tTime 0.047 (0.044)\tData 0.023 (0.005)\tLoss 0.0137 (0.0168)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][350/390]\tTime 0.032 (0.044)\tData 0.005 (0.005)\tLoss 0.0151 (0.0167)\tPrec@1 99.219 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][360/390]\tTime 0.058 (0.044)\tData 0.028 (0.005)\tLoss 0.0397 (0.0167)\tPrec@1 98.438 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][370/390]\tTime 0.043 (0.044)\tData 0.007 (0.005)\tLoss 0.0104 (0.0167)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][380/390]\tTime 0.078 (0.044)\tData 0.046 (0.005)\tLoss 0.0135 (0.0167)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [341][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.005)\tLoss 0.0230 (0.0167)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [341][0/79]\tTime 0.257 (0.257)\tData 0.241 (0.241)\tLoss 0.2884 (0.2884)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [341][10/79]\tTime 0.014 (0.044)\tData 0.000 (0.032)\tLoss 0.2624 (0.3728)\tPrec@1 91.406 (91.974)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [341][20/79]\tTime 0.066 (0.038)\tData 0.053 (0.026)\tLoss 0.5301 (0.4117)\tPrec@1 90.625 (91.369)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [341][30/79]\tTime 0.022 (0.034)\tData 0.007 (0.022)\tLoss 0.1032 (0.3991)\tPrec@1 97.656 (91.709)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [341][40/79]\tTime 0.069 (0.034)\tData 0.063 (0.021)\tLoss 0.2510 (0.4006)\tPrec@1 91.406 (91.692)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [341][50/79]\tTime 0.022 (0.032)\tData 0.006 (0.019)\tLoss 0.4311 (0.3935)\tPrec@1 91.406 (91.651)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [341][60/79]\tTime 0.042 (0.031)\tData 0.033 (0.018)\tLoss 0.6514 (0.3983)\tPrec@1 92.969 (91.611)\tPrec@5 100.000 (99.667)\t\n",
            "EVALUATING - Epoch: [341][70/79]\tTime 0.015 (0.031)\tData 0.001 (0.018)\tLoss 0.3932 (0.3904)\tPrec@1 89.844 (91.571)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [341][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2318 (0.3873)\tPrec@1 93.750 (91.590)\tPrec@5 100.000 (99.700)\t\n",
            "\n",
            "Results - Epoch: 342\n",
            "Training Loss 0.0167 \tTraining Prec@1 99.565 \tTraining Prec@5 100.000 \tValidation Loss 0.3873 \tValidation Prec@1 91.590 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 343\n",
            "\n",
            "TRAINING - Epoch: [342][0/390]\tTime 0.264 (0.264)\tData 0.216 (0.216)\tLoss 0.0180 (0.0180)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][10/390]\tTime 0.038 (0.066)\tData 0.000 (0.029)\tLoss 0.0115 (0.0182)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][20/390]\tTime 0.037 (0.055)\tData 0.000 (0.020)\tLoss 0.0032 (0.0180)\tPrec@1 100.000 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][30/390]\tTime 0.036 (0.052)\tData 0.001 (0.017)\tLoss 0.0075 (0.0169)\tPrec@1 100.000 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][40/390]\tTime 0.033 (0.050)\tData 0.000 (0.013)\tLoss 0.0163 (0.0172)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][50/390]\tTime 0.035 (0.048)\tData 0.004 (0.012)\tLoss 0.0218 (0.0172)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][60/390]\tTime 0.032 (0.048)\tData 0.000 (0.010)\tLoss 0.0130 (0.0171)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][70/390]\tTime 0.058 (0.047)\tData 0.001 (0.009)\tLoss 0.0102 (0.0174)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][80/390]\tTime 0.031 (0.046)\tData 0.000 (0.008)\tLoss 0.0149 (0.0179)\tPrec@1 99.219 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][90/390]\tTime 0.026 (0.046)\tData 0.000 (0.008)\tLoss 0.0088 (0.0176)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][100/390]\tTime 0.037 (0.045)\tData 0.002 (0.007)\tLoss 0.0171 (0.0177)\tPrec@1 99.219 (99.520)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][110/390]\tTime 0.038 (0.045)\tData 0.005 (0.007)\tLoss 0.0227 (0.0176)\tPrec@1 99.219 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][120/390]\tTime 0.050 (0.046)\tData 0.001 (0.007)\tLoss 0.0155 (0.0180)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][130/390]\tTime 0.052 (0.045)\tData 0.000 (0.007)\tLoss 0.0082 (0.0178)\tPrec@1 100.000 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][140/390]\tTime 0.054 (0.045)\tData 0.002 (0.007)\tLoss 0.0191 (0.0177)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][150/390]\tTime 0.052 (0.045)\tData 0.012 (0.007)\tLoss 0.0018 (0.0177)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][160/390]\tTime 0.044 (0.045)\tData 0.007 (0.006)\tLoss 0.0116 (0.0177)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][170/390]\tTime 0.054 (0.045)\tData 0.010 (0.006)\tLoss 0.0347 (0.0177)\tPrec@1 98.438 (99.502)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][180/390]\tTime 0.034 (0.045)\tData 0.000 (0.006)\tLoss 0.0088 (0.0176)\tPrec@1 100.000 (99.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][190/390]\tTime 0.034 (0.045)\tData 0.000 (0.006)\tLoss 0.0060 (0.0175)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][200/390]\tTime 0.043 (0.045)\tData 0.000 (0.006)\tLoss 0.0367 (0.0176)\tPrec@1 99.219 (99.514)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][210/390]\tTime 0.047 (0.044)\tData 0.000 (0.006)\tLoss 0.0164 (0.0177)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][220/390]\tTime 0.048 (0.044)\tData 0.006 (0.006)\tLoss 0.0256 (0.0176)\tPrec@1 99.219 (99.526)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][230/390]\tTime 0.048 (0.044)\tData 0.005 (0.006)\tLoss 0.0382 (0.0179)\tPrec@1 99.219 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][240/390]\tTime 0.042 (0.044)\tData 0.002 (0.006)\tLoss 0.0208 (0.0179)\tPrec@1 100.000 (99.517)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][250/390]\tTime 0.049 (0.044)\tData 0.003 (0.006)\tLoss 0.0211 (0.0178)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][260/390]\tTime 0.038 (0.044)\tData 0.000 (0.006)\tLoss 0.0370 (0.0179)\tPrec@1 98.438 (99.518)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][270/390]\tTime 0.055 (0.044)\tData 0.010 (0.006)\tLoss 0.0376 (0.0179)\tPrec@1 98.438 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][280/390]\tTime 0.032 (0.044)\tData 0.000 (0.005)\tLoss 0.0173 (0.0178)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][290/390]\tTime 0.046 (0.044)\tData 0.007 (0.005)\tLoss 0.0233 (0.0176)\tPrec@1 99.219 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][300/390]\tTime 0.042 (0.044)\tData 0.000 (0.005)\tLoss 0.0220 (0.0176)\tPrec@1 99.219 (99.522)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][310/390]\tTime 0.037 (0.044)\tData 0.003 (0.005)\tLoss 0.0039 (0.0175)\tPrec@1 100.000 (99.533)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][320/390]\tTime 0.055 (0.044)\tData 0.021 (0.005)\tLoss 0.0168 (0.0174)\tPrec@1 99.219 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][330/390]\tTime 0.051 (0.044)\tData 0.005 (0.006)\tLoss 0.0056 (0.0174)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][340/390]\tTime 0.045 (0.044)\tData 0.002 (0.006)\tLoss 0.0121 (0.0173)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][350/390]\tTime 0.037 (0.044)\tData 0.000 (0.005)\tLoss 0.0036 (0.0173)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][360/390]\tTime 0.051 (0.044)\tData 0.009 (0.006)\tLoss 0.0130 (0.0172)\tPrec@1 99.219 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][370/390]\tTime 0.037 (0.044)\tData 0.002 (0.005)\tLoss 0.0189 (0.0172)\tPrec@1 99.219 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][380/390]\tTime 0.037 (0.044)\tData 0.000 (0.005)\tLoss 0.0125 (0.0171)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [342][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.005)\tLoss 0.0057 (0.0171)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [342][0/79]\tTime 0.227 (0.227)\tData 0.213 (0.213)\tLoss 0.2865 (0.2865)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [342][10/79]\tTime 0.016 (0.040)\tData 0.010 (0.032)\tLoss 0.2707 (0.3707)\tPrec@1 91.406 (92.116)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [342][20/79]\tTime 0.014 (0.033)\tData 0.009 (0.024)\tLoss 0.5249 (0.4072)\tPrec@1 89.844 (91.667)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [342][30/79]\tTime 0.015 (0.031)\tData 0.001 (0.021)\tLoss 0.0938 (0.3935)\tPrec@1 97.656 (92.011)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [342][40/79]\tTime 0.021 (0.030)\tData 0.013 (0.020)\tLoss 0.2420 (0.3954)\tPrec@1 91.406 (91.921)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [342][50/79]\tTime 0.024 (0.030)\tData 0.005 (0.019)\tLoss 0.4352 (0.3886)\tPrec@1 90.625 (91.866)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [342][60/79]\tTime 0.058 (0.029)\tData 0.052 (0.019)\tLoss 0.6321 (0.3935)\tPrec@1 92.188 (91.790)\tPrec@5 100.000 (99.654)\t\n",
            "EVALUATING - Epoch: [342][70/79]\tTime 0.015 (0.029)\tData 0.000 (0.019)\tLoss 0.3982 (0.3864)\tPrec@1 89.844 (91.747)\tPrec@5 100.000 (99.692)\t\n",
            "EVALUATING - Epoch: [342][78/79]\tTime 0.003 (0.027)\tData 0.000 (0.017)\tLoss 0.2730 (0.3835)\tPrec@1 93.750 (91.750)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 343\n",
            "Training Loss 0.0171 \tTraining Prec@1 99.543 \tTraining Prec@5 100.000 \tValidation Loss 0.3835 \tValidation Prec@1 91.750 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 344\n",
            "\n",
            "TRAINING - Epoch: [343][0/390]\tTime 0.209 (0.209)\tData 0.173 (0.173)\tLoss 0.0112 (0.0112)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][10/390]\tTime 0.027 (0.062)\tData 0.000 (0.023)\tLoss 0.0206 (0.0148)\tPrec@1 99.219 (99.858)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][20/390]\tTime 0.037 (0.054)\tData 0.004 (0.017)\tLoss 0.0167 (0.0158)\tPrec@1 99.219 (99.665)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][30/390]\tTime 0.054 (0.050)\tData 0.008 (0.013)\tLoss 0.0033 (0.0149)\tPrec@1 100.000 (99.672)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][40/390]\tTime 0.041 (0.048)\tData 0.005 (0.012)\tLoss 0.0203 (0.0162)\tPrec@1 99.219 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][50/390]\tTime 0.042 (0.047)\tData 0.003 (0.012)\tLoss 0.0105 (0.0166)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][60/390]\tTime 0.035 (0.047)\tData 0.000 (0.010)\tLoss 0.0332 (0.0173)\tPrec@1 98.438 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][70/390]\tTime 0.051 (0.046)\tData 0.001 (0.009)\tLoss 0.0146 (0.0168)\tPrec@1 99.219 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][80/390]\tTime 0.043 (0.045)\tData 0.001 (0.008)\tLoss 0.0089 (0.0164)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][90/390]\tTime 0.038 (0.045)\tData 0.003 (0.008)\tLoss 0.0356 (0.0167)\tPrec@1 98.438 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][100/390]\tTime 0.034 (0.045)\tData 0.004 (0.007)\tLoss 0.0198 (0.0164)\tPrec@1 99.219 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][110/390]\tTime 0.044 (0.045)\tData 0.000 (0.007)\tLoss 0.0274 (0.0169)\tPrec@1 98.438 (99.521)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][120/390]\tTime 0.033 (0.045)\tData 0.000 (0.007)\tLoss 0.0111 (0.0169)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][130/390]\tTime 0.047 (0.045)\tData 0.007 (0.007)\tLoss 0.0092 (0.0165)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][140/390]\tTime 0.047 (0.045)\tData 0.001 (0.007)\tLoss 0.0034 (0.0163)\tPrec@1 100.000 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][150/390]\tTime 0.042 (0.044)\tData 0.000 (0.006)\tLoss 0.0160 (0.0166)\tPrec@1 99.219 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][160/390]\tTime 0.042 (0.044)\tData 0.000 (0.006)\tLoss 0.0078 (0.0162)\tPrec@1 100.000 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][170/390]\tTime 0.050 (0.044)\tData 0.007 (0.006)\tLoss 0.0072 (0.0163)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][180/390]\tTime 0.049 (0.044)\tData 0.004 (0.006)\tLoss 0.0139 (0.0162)\tPrec@1 100.000 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][190/390]\tTime 0.048 (0.044)\tData 0.007 (0.006)\tLoss 0.0227 (0.0162)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][200/390]\tTime 0.051 (0.044)\tData 0.002 (0.006)\tLoss 0.0193 (0.0163)\tPrec@1 99.219 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][210/390]\tTime 0.040 (0.044)\tData 0.000 (0.006)\tLoss 0.0228 (0.0161)\tPrec@1 98.438 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][220/390]\tTime 0.054 (0.044)\tData 0.000 (0.005)\tLoss 0.0253 (0.0159)\tPrec@1 99.219 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][230/390]\tTime 0.048 (0.044)\tData 0.000 (0.005)\tLoss 0.0445 (0.0161)\tPrec@1 98.438 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][240/390]\tTime 0.043 (0.044)\tData 0.003 (0.005)\tLoss 0.0074 (0.0160)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][250/390]\tTime 0.046 (0.044)\tData 0.005 (0.005)\tLoss 0.0099 (0.0160)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][260/390]\tTime 0.038 (0.044)\tData 0.000 (0.005)\tLoss 0.0205 (0.0161)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][270/390]\tTime 0.033 (0.044)\tData 0.002 (0.005)\tLoss 0.0206 (0.0164)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][280/390]\tTime 0.042 (0.044)\tData 0.002 (0.005)\tLoss 0.0063 (0.0162)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][290/390]\tTime 0.064 (0.044)\tData 0.002 (0.005)\tLoss 0.0272 (0.0161)\tPrec@1 98.438 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][300/390]\tTime 0.048 (0.044)\tData 0.000 (0.005)\tLoss 0.0147 (0.0160)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][310/390]\tTime 0.061 (0.044)\tData 0.029 (0.005)\tLoss 0.0163 (0.0161)\tPrec@1 99.219 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][320/390]\tTime 0.048 (0.044)\tData 0.005 (0.005)\tLoss 0.0232 (0.0162)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][330/390]\tTime 0.049 (0.044)\tData 0.001 (0.005)\tLoss 0.0209 (0.0162)\tPrec@1 99.219 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][340/390]\tTime 0.038 (0.043)\tData 0.000 (0.005)\tLoss 0.0066 (0.0164)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][350/390]\tTime 0.041 (0.044)\tData 0.009 (0.005)\tLoss 0.0042 (0.0166)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][360/390]\tTime 0.040 (0.044)\tData 0.003 (0.005)\tLoss 0.0046 (0.0164)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][370/390]\tTime 0.036 (0.043)\tData 0.000 (0.005)\tLoss 0.0445 (0.0164)\tPrec@1 96.875 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][380/390]\tTime 0.050 (0.044)\tData 0.005 (0.005)\tLoss 0.0148 (0.0165)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [343][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.005)\tLoss 0.0099 (0.0163)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [343][0/79]\tTime 0.195 (0.195)\tData 0.184 (0.184)\tLoss 0.2845 (0.2845)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [343][10/79]\tTime 0.057 (0.045)\tData 0.051 (0.034)\tLoss 0.2570 (0.3706)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [343][20/79]\tTime 0.019 (0.037)\tData 0.010 (0.024)\tLoss 0.5280 (0.4113)\tPrec@1 89.844 (91.555)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [343][30/79]\tTime 0.056 (0.036)\tData 0.042 (0.024)\tLoss 0.1033 (0.3993)\tPrec@1 97.656 (91.935)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [343][40/79]\tTime 0.026 (0.033)\tData 0.006 (0.021)\tLoss 0.2367 (0.4018)\tPrec@1 91.406 (91.902)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [343][50/79]\tTime 0.011 (0.033)\tData 0.005 (0.021)\tLoss 0.4367 (0.3945)\tPrec@1 91.406 (91.805)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [343][60/79]\tTime 0.029 (0.032)\tData 0.005 (0.020)\tLoss 0.6471 (0.3998)\tPrec@1 92.969 (91.675)\tPrec@5 99.219 (99.641)\t\n",
            "EVALUATING - Epoch: [343][70/79]\tTime 0.101 (0.032)\tData 0.094 (0.020)\tLoss 0.3860 (0.3919)\tPrec@1 89.844 (91.626)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [343][78/79]\tTime 0.003 (0.030)\tData 0.000 (0.018)\tLoss 0.2490 (0.3887)\tPrec@1 93.750 (91.630)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 344\n",
            "Training Loss 0.0163 \tTraining Prec@1 99.557 \tTraining Prec@5 100.000 \tValidation Loss 0.3887 \tValidation Prec@1 91.630 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 345\n",
            "\n",
            "TRAINING - Epoch: [344][0/390]\tTime 0.255 (0.255)\tData 0.203 (0.203)\tLoss 0.0030 (0.0030)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][10/390]\tTime 0.064 (0.067)\tData 0.035 (0.033)\tLoss 0.0045 (0.0135)\tPrec@1 100.000 (99.787)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][20/390]\tTime 0.057 (0.056)\tData 0.009 (0.022)\tLoss 0.0118 (0.0146)\tPrec@1 100.000 (99.665)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][30/390]\tTime 0.056 (0.052)\tData 0.004 (0.016)\tLoss 0.0401 (0.0168)\tPrec@1 98.438 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][40/390]\tTime 0.040 (0.050)\tData 0.004 (0.012)\tLoss 0.0119 (0.0171)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][50/390]\tTime 0.044 (0.048)\tData 0.005 (0.011)\tLoss 0.0245 (0.0165)\tPrec@1 99.219 (99.525)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][60/390]\tTime 0.041 (0.047)\tData 0.007 (0.009)\tLoss 0.0267 (0.0169)\tPrec@1 99.219 (99.501)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][70/390]\tTime 0.036 (0.046)\tData 0.001 (0.008)\tLoss 0.0079 (0.0169)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][80/390]\tTime 0.065 (0.046)\tData 0.006 (0.008)\tLoss 0.0767 (0.0178)\tPrec@1 97.656 (99.460)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][90/390]\tTime 0.046 (0.046)\tData 0.000 (0.007)\tLoss 0.0080 (0.0177)\tPrec@1 100.000 (99.459)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][100/390]\tTime 0.042 (0.046)\tData 0.009 (0.007)\tLoss 0.0104 (0.0174)\tPrec@1 100.000 (99.482)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][110/390]\tTime 0.041 (0.045)\tData 0.005 (0.007)\tLoss 0.0214 (0.0171)\tPrec@1 99.219 (99.493)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][120/390]\tTime 0.053 (0.045)\tData 0.005 (0.007)\tLoss 0.0084 (0.0171)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][130/390]\tTime 0.038 (0.045)\tData 0.005 (0.007)\tLoss 0.0162 (0.0170)\tPrec@1 99.219 (99.499)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][140/390]\tTime 0.035 (0.045)\tData 0.007 (0.007)\tLoss 0.0087 (0.0167)\tPrec@1 100.000 (99.512)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][150/390]\tTime 0.038 (0.045)\tData 0.000 (0.007)\tLoss 0.0106 (0.0165)\tPrec@1 100.000 (99.524)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][160/390]\tTime 0.042 (0.045)\tData 0.001 (0.007)\tLoss 0.0186 (0.0164)\tPrec@1 99.219 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][170/390]\tTime 0.047 (0.044)\tData 0.001 (0.006)\tLoss 0.0084 (0.0166)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][180/390]\tTime 0.046 (0.045)\tData 0.007 (0.006)\tLoss 0.0105 (0.0168)\tPrec@1 100.000 (99.530)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][190/390]\tTime 0.032 (0.045)\tData 0.001 (0.006)\tLoss 0.0289 (0.0167)\tPrec@1 99.219 (99.538)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][200/390]\tTime 0.040 (0.044)\tData 0.005 (0.006)\tLoss 0.0040 (0.0165)\tPrec@1 100.000 (99.545)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][210/390]\tTime 0.047 (0.044)\tData 0.000 (0.006)\tLoss 0.0163 (0.0165)\tPrec@1 100.000 (99.541)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][220/390]\tTime 0.044 (0.044)\tData 0.009 (0.006)\tLoss 0.0171 (0.0165)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][230/390]\tTime 0.041 (0.044)\tData 0.003 (0.006)\tLoss 0.0140 (0.0162)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][240/390]\tTime 0.041 (0.044)\tData 0.000 (0.006)\tLoss 0.0134 (0.0162)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][250/390]\tTime 0.035 (0.044)\tData 0.001 (0.006)\tLoss 0.0189 (0.0164)\tPrec@1 99.219 (99.555)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][260/390]\tTime 0.049 (0.044)\tData 0.005 (0.006)\tLoss 0.0148 (0.0163)\tPrec@1 99.219 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][270/390]\tTime 0.034 (0.044)\tData 0.001 (0.005)\tLoss 0.0170 (0.0162)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][280/390]\tTime 0.048 (0.044)\tData 0.011 (0.005)\tLoss 0.0171 (0.0162)\tPrec@1 99.219 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][290/390]\tTime 0.035 (0.044)\tData 0.001 (0.005)\tLoss 0.0068 (0.0162)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][300/390]\tTime 0.047 (0.044)\tData 0.000 (0.005)\tLoss 0.0107 (0.0161)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][310/390]\tTime 0.039 (0.044)\tData 0.009 (0.005)\tLoss 0.0074 (0.0160)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][320/390]\tTime 0.041 (0.043)\tData 0.002 (0.005)\tLoss 0.0183 (0.0161)\tPrec@1 99.219 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][330/390]\tTime 0.039 (0.043)\tData 0.007 (0.005)\tLoss 0.0044 (0.0160)\tPrec@1 100.000 (99.568)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][340/390]\tTime 0.050 (0.044)\tData 0.000 (0.005)\tLoss 0.0048 (0.0160)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][350/390]\tTime 0.047 (0.043)\tData 0.000 (0.005)\tLoss 0.0072 (0.0159)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][360/390]\tTime 0.042 (0.043)\tData 0.005 (0.005)\tLoss 0.0176 (0.0160)\tPrec@1 99.219 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][370/390]\tTime 0.036 (0.043)\tData 0.001 (0.005)\tLoss 0.0166 (0.0161)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][380/390]\tTime 0.056 (0.043)\tData 0.017 (0.005)\tLoss 0.0213 (0.0163)\tPrec@1 99.219 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [344][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.005)\tLoss 0.0331 (0.0164)\tPrec@1 99.219 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [344][0/79]\tTime 0.207 (0.207)\tData 0.187 (0.187)\tLoss 0.2814 (0.2814)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [344][10/79]\tTime 0.028 (0.048)\tData 0.013 (0.036)\tLoss 0.2672 (0.3695)\tPrec@1 91.406 (92.472)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [344][20/79]\tTime 0.016 (0.036)\tData 0.000 (0.023)\tLoss 0.5265 (0.4084)\tPrec@1 90.625 (91.890)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [344][30/79]\tTime 0.044 (0.034)\tData 0.038 (0.021)\tLoss 0.0952 (0.3951)\tPrec@1 97.656 (92.188)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [344][40/79]\tTime 0.019 (0.033)\tData 0.008 (0.019)\tLoss 0.2349 (0.3977)\tPrec@1 91.406 (92.054)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [344][50/79]\tTime 0.021 (0.032)\tData 0.010 (0.019)\tLoss 0.4355 (0.3907)\tPrec@1 89.844 (91.988)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [344][60/79]\tTime 0.019 (0.031)\tData 0.000 (0.018)\tLoss 0.6368 (0.3962)\tPrec@1 92.969 (91.867)\tPrec@5 100.000 (99.629)\t\n",
            "EVALUATING - Epoch: [344][70/79]\tTime 0.019 (0.030)\tData 0.001 (0.017)\tLoss 0.4072 (0.3891)\tPrec@1 89.062 (91.802)\tPrec@5 100.000 (99.670)\t\n",
            "EVALUATING - Epoch: [344][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.017)\tLoss 0.2727 (0.3862)\tPrec@1 93.750 (91.810)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 345\n",
            "Training Loss 0.0164 \tTraining Prec@1 99.553 \tTraining Prec@5 100.000 \tValidation Loss 0.3862 \tValidation Prec@1 91.810 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 346\n",
            "\n",
            "TRAINING - Epoch: [345][0/390]\tTime 0.320 (0.320)\tData 0.262 (0.262)\tLoss 0.0119 (0.0119)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][10/390]\tTime 0.045 (0.070)\tData 0.003 (0.028)\tLoss 0.0046 (0.0183)\tPrec@1 100.000 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][20/390]\tTime 0.041 (0.056)\tData 0.000 (0.015)\tLoss 0.0146 (0.0168)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][30/390]\tTime 0.034 (0.052)\tData 0.000 (0.013)\tLoss 0.0079 (0.0168)\tPrec@1 100.000 (99.546)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][40/390]\tTime 0.038 (0.051)\tData 0.002 (0.012)\tLoss 0.0062 (0.0163)\tPrec@1 100.000 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][50/390]\tTime 0.048 (0.049)\tData 0.004 (0.010)\tLoss 0.0214 (0.0166)\tPrec@1 99.219 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][60/390]\tTime 0.039 (0.047)\tData 0.000 (0.009)\tLoss 0.0061 (0.0163)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][70/390]\tTime 0.044 (0.047)\tData 0.004 (0.008)\tLoss 0.0081 (0.0160)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][80/390]\tTime 0.034 (0.046)\tData 0.006 (0.008)\tLoss 0.0132 (0.0161)\tPrec@1 100.000 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][90/390]\tTime 0.038 (0.046)\tData 0.000 (0.008)\tLoss 0.0064 (0.0162)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][100/390]\tTime 0.049 (0.046)\tData 0.004 (0.007)\tLoss 0.0225 (0.0165)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][110/390]\tTime 0.049 (0.046)\tData 0.002 (0.007)\tLoss 0.0082 (0.0162)\tPrec@1 100.000 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][120/390]\tTime 0.037 (0.045)\tData 0.003 (0.006)\tLoss 0.0193 (0.0162)\tPrec@1 100.000 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][130/390]\tTime 0.038 (0.045)\tData 0.005 (0.007)\tLoss 0.0085 (0.0159)\tPrec@1 100.000 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][140/390]\tTime 0.061 (0.045)\tData 0.033 (0.007)\tLoss 0.0579 (0.0160)\tPrec@1 98.438 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][150/390]\tTime 0.047 (0.045)\tData 0.000 (0.006)\tLoss 0.0151 (0.0158)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][160/390]\tTime 0.039 (0.045)\tData 0.004 (0.006)\tLoss 0.0172 (0.0159)\tPrec@1 99.219 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][170/390]\tTime 0.047 (0.045)\tData 0.005 (0.006)\tLoss 0.0117 (0.0155)\tPrec@1 100.000 (99.580)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][180/390]\tTime 0.051 (0.044)\tData 0.001 (0.006)\tLoss 0.0117 (0.0156)\tPrec@1 100.000 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][190/390]\tTime 0.041 (0.044)\tData 0.000 (0.006)\tLoss 0.0466 (0.0161)\tPrec@1 98.438 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][200/390]\tTime 0.034 (0.044)\tData 0.005 (0.006)\tLoss 0.0166 (0.0162)\tPrec@1 99.219 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][210/390]\tTime 0.030 (0.044)\tData 0.001 (0.006)\tLoss 0.0133 (0.0161)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][220/390]\tTime 0.041 (0.044)\tData 0.006 (0.005)\tLoss 0.0097 (0.0162)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][230/390]\tTime 0.044 (0.044)\tData 0.001 (0.005)\tLoss 0.0219 (0.0161)\tPrec@1 98.438 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][240/390]\tTime 0.055 (0.044)\tData 0.004 (0.005)\tLoss 0.0126 (0.0163)\tPrec@1 100.000 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][250/390]\tTime 0.048 (0.044)\tData 0.000 (0.005)\tLoss 0.0428 (0.0163)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][260/390]\tTime 0.043 (0.044)\tData 0.000 (0.005)\tLoss 0.0205 (0.0163)\tPrec@1 99.219 (99.566)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][270/390]\tTime 0.044 (0.044)\tData 0.004 (0.005)\tLoss 0.0100 (0.0162)\tPrec@1 100.000 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][280/390]\tTime 0.046 (0.044)\tData 0.000 (0.005)\tLoss 0.0141 (0.0163)\tPrec@1 99.219 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][290/390]\tTime 0.039 (0.044)\tData 0.002 (0.005)\tLoss 0.0413 (0.0164)\tPrec@1 98.438 (99.560)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][300/390]\tTime 0.040 (0.044)\tData 0.001 (0.005)\tLoss 0.0142 (0.0165)\tPrec@1 100.000 (99.561)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][310/390]\tTime 0.048 (0.044)\tData 0.005 (0.005)\tLoss 0.0113 (0.0164)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][320/390]\tTime 0.043 (0.044)\tData 0.001 (0.005)\tLoss 0.0210 (0.0166)\tPrec@1 99.219 (99.559)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][330/390]\tTime 0.034 (0.044)\tData 0.006 (0.005)\tLoss 0.0144 (0.0164)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][340/390]\tTime 0.046 (0.044)\tData 0.002 (0.005)\tLoss 0.0233 (0.0166)\tPrec@1 99.219 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][350/390]\tTime 0.041 (0.044)\tData 0.005 (0.005)\tLoss 0.0063 (0.0165)\tPrec@1 100.000 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][360/390]\tTime 0.053 (0.044)\tData 0.011 (0.005)\tLoss 0.0205 (0.0165)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][370/390]\tTime 0.027 (0.044)\tData 0.000 (0.005)\tLoss 0.0093 (0.0165)\tPrec@1 100.000 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][380/390]\tTime 0.045 (0.044)\tData 0.007 (0.005)\tLoss 0.0125 (0.0164)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [345][389/390]\tTime 0.017 (0.044)\tData 0.000 (0.005)\tLoss 0.0412 (0.0165)\tPrec@1 98.438 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [345][0/79]\tTime 0.194 (0.194)\tData 0.177 (0.177)\tLoss 0.2814 (0.2814)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [345][10/79]\tTime 0.024 (0.047)\tData 0.018 (0.038)\tLoss 0.2570 (0.3718)\tPrec@1 91.406 (92.259)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [345][20/79]\tTime 0.016 (0.039)\tData 0.002 (0.029)\tLoss 0.5207 (0.4125)\tPrec@1 89.844 (91.629)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [345][30/79]\tTime 0.017 (0.034)\tData 0.000 (0.024)\tLoss 0.1021 (0.4000)\tPrec@1 97.656 (91.986)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [345][40/79]\tTime 0.019 (0.032)\tData 0.002 (0.022)\tLoss 0.2340 (0.4021)\tPrec@1 91.406 (91.921)\tPrec@5 99.219 (99.543)\t\n",
            "EVALUATING - Epoch: [345][50/79]\tTime 0.021 (0.031)\tData 0.001 (0.020)\tLoss 0.4351 (0.3947)\tPrec@1 90.625 (91.820)\tPrec@5 100.000 (99.632)\t\n",
            "EVALUATING - Epoch: [345][60/79]\tTime 0.053 (0.032)\tData 0.046 (0.020)\tLoss 0.6559 (0.4000)\tPrec@1 93.750 (91.701)\tPrec@5 100.000 (99.667)\t\n",
            "EVALUATING - Epoch: [345][70/79]\tTime 0.020 (0.031)\tData 0.005 (0.019)\tLoss 0.3865 (0.3921)\tPrec@1 90.625 (91.692)\tPrec@5 100.000 (99.703)\t\n",
            "EVALUATING - Epoch: [345][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2739 (0.3890)\tPrec@1 93.750 (91.700)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 346\n",
            "Training Loss 0.0165 \tTraining Prec@1 99.551 \tTraining Prec@5 100.000 \tValidation Loss 0.3890 \tValidation Prec@1 91.700 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 347\n",
            "\n",
            "TRAINING - Epoch: [346][0/390]\tTime 0.248 (0.248)\tData 0.204 (0.204)\tLoss 0.0238 (0.0238)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][10/390]\tTime 0.033 (0.065)\tData 0.002 (0.027)\tLoss 0.0206 (0.0167)\tPrec@1 99.219 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][20/390]\tTime 0.046 (0.053)\tData 0.008 (0.018)\tLoss 0.0262 (0.0149)\tPrec@1 98.438 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][30/390]\tTime 0.049 (0.050)\tData 0.014 (0.014)\tLoss 0.0278 (0.0150)\tPrec@1 99.219 (99.572)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][40/390]\tTime 0.041 (0.049)\tData 0.005 (0.012)\tLoss 0.0095 (0.0160)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][50/390]\tTime 0.038 (0.048)\tData 0.000 (0.011)\tLoss 0.0160 (0.0163)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][60/390]\tTime 0.036 (0.047)\tData 0.007 (0.009)\tLoss 0.0160 (0.0163)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][70/390]\tTime 0.046 (0.046)\tData 0.000 (0.009)\tLoss 0.0136 (0.0161)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][80/390]\tTime 0.042 (0.046)\tData 0.003 (0.008)\tLoss 0.0408 (0.0162)\tPrec@1 99.219 (99.556)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][90/390]\tTime 0.031 (0.045)\tData 0.000 (0.007)\tLoss 0.0145 (0.0170)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][100/390]\tTime 0.044 (0.045)\tData 0.000 (0.007)\tLoss 0.0228 (0.0169)\tPrec@1 99.219 (99.528)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][110/390]\tTime 0.036 (0.045)\tData 0.000 (0.006)\tLoss 0.0086 (0.0166)\tPrec@1 100.000 (99.557)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][120/390]\tTime 0.041 (0.045)\tData 0.006 (0.006)\tLoss 0.0099 (0.0165)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][130/390]\tTime 0.052 (0.045)\tData 0.000 (0.006)\tLoss 0.0448 (0.0166)\tPrec@1 97.656 (99.553)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][140/390]\tTime 0.039 (0.045)\tData 0.004 (0.006)\tLoss 0.0128 (0.0166)\tPrec@1 99.219 (99.551)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][150/390]\tTime 0.044 (0.044)\tData 0.007 (0.006)\tLoss 0.0683 (0.0170)\tPrec@1 97.656 (99.540)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][160/390]\tTime 0.033 (0.044)\tData 0.000 (0.006)\tLoss 0.0144 (0.0167)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][170/390]\tTime 0.036 (0.044)\tData 0.004 (0.006)\tLoss 0.0192 (0.0165)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][180/390]\tTime 0.056 (0.044)\tData 0.006 (0.006)\tLoss 0.0350 (0.0166)\tPrec@1 98.438 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][190/390]\tTime 0.037 (0.044)\tData 0.003 (0.005)\tLoss 0.0104 (0.0164)\tPrec@1 100.000 (99.558)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][200/390]\tTime 0.031 (0.044)\tData 0.000 (0.006)\tLoss 0.0258 (0.0164)\tPrec@1 99.219 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][210/390]\tTime 0.043 (0.044)\tData 0.000 (0.005)\tLoss 0.0064 (0.0164)\tPrec@1 100.000 (99.570)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][220/390]\tTime 0.053 (0.044)\tData 0.007 (0.005)\tLoss 0.0041 (0.0164)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][230/390]\tTime 0.048 (0.044)\tData 0.000 (0.005)\tLoss 0.0328 (0.0166)\tPrec@1 99.219 (99.564)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][240/390]\tTime 0.056 (0.044)\tData 0.002 (0.005)\tLoss 0.0096 (0.0165)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][250/390]\tTime 0.040 (0.044)\tData 0.000 (0.005)\tLoss 0.0020 (0.0164)\tPrec@1 100.000 (99.580)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][260/390]\tTime 0.040 (0.044)\tData 0.010 (0.005)\tLoss 0.0039 (0.0162)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][270/390]\tTime 0.038 (0.044)\tData 0.009 (0.005)\tLoss 0.0404 (0.0164)\tPrec@1 98.438 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][280/390]\tTime 0.041 (0.044)\tData 0.003 (0.005)\tLoss 0.0057 (0.0163)\tPrec@1 100.000 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][290/390]\tTime 0.049 (0.044)\tData 0.001 (0.005)\tLoss 0.0212 (0.0164)\tPrec@1 99.219 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][300/390]\tTime 0.046 (0.044)\tData 0.007 (0.005)\tLoss 0.0092 (0.0164)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][310/390]\tTime 0.035 (0.043)\tData 0.000 (0.005)\tLoss 0.0043 (0.0163)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][320/390]\tTime 0.043 (0.043)\tData 0.000 (0.005)\tLoss 0.0068 (0.0162)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][330/390]\tTime 0.039 (0.043)\tData 0.010 (0.005)\tLoss 0.0033 (0.0162)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][340/390]\tTime 0.039 (0.044)\tData 0.002 (0.005)\tLoss 0.0094 (0.0163)\tPrec@1 100.000 (99.569)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][350/390]\tTime 0.054 (0.044)\tData 0.005 (0.005)\tLoss 0.0127 (0.0162)\tPrec@1 99.219 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][360/390]\tTime 0.043 (0.044)\tData 0.002 (0.005)\tLoss 0.0733 (0.0163)\tPrec@1 98.438 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][370/390]\tTime 0.035 (0.044)\tData 0.007 (0.005)\tLoss 0.0154 (0.0162)\tPrec@1 100.000 (99.587)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][380/390]\tTime 0.059 (0.044)\tData 0.001 (0.005)\tLoss 0.0173 (0.0162)\tPrec@1 100.000 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [346][389/390]\tTime 0.018 (0.043)\tData 0.000 (0.005)\tLoss 0.0054 (0.0161)\tPrec@1 100.000 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [346][0/79]\tTime 0.195 (0.195)\tData 0.175 (0.175)\tLoss 0.2918 (0.2918)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [346][10/79]\tTime 0.011 (0.049)\tData 0.005 (0.037)\tLoss 0.2705 (0.3766)\tPrec@1 91.406 (92.401)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [346][20/79]\tTime 0.028 (0.038)\tData 0.005 (0.027)\tLoss 0.5318 (0.4161)\tPrec@1 89.844 (91.629)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [346][30/79]\tTime 0.019 (0.034)\tData 0.002 (0.023)\tLoss 0.0982 (0.4025)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [346][40/79]\tTime 0.012 (0.032)\tData 0.004 (0.021)\tLoss 0.2530 (0.4040)\tPrec@1 89.062 (91.845)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [346][50/79]\tTime 0.019 (0.032)\tData 0.001 (0.020)\tLoss 0.4384 (0.3966)\tPrec@1 90.625 (91.789)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [346][60/79]\tTime 0.035 (0.031)\tData 0.004 (0.019)\tLoss 0.6516 (0.4011)\tPrec@1 92.969 (91.714)\tPrec@5 99.219 (99.641)\t\n",
            "EVALUATING - Epoch: [346][70/79]\tTime 0.019 (0.030)\tData 0.013 (0.019)\tLoss 0.3986 (0.3931)\tPrec@1 89.844 (91.703)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [346][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2366 (0.3899)\tPrec@1 93.750 (91.710)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 347\n",
            "Training Loss 0.0161 \tTraining Prec@1 99.597 \tTraining Prec@5 100.000 \tValidation Loss 0.3899 \tValidation Prec@1 91.710 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 348\n",
            "\n",
            "TRAINING - Epoch: [347][0/390]\tTime 0.229 (0.229)\tData 0.190 (0.190)\tLoss 0.0180 (0.0180)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][10/390]\tTime 0.053 (0.068)\tData 0.005 (0.031)\tLoss 0.0233 (0.0163)\tPrec@1 99.219 (99.574)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][20/390]\tTime 0.042 (0.057)\tData 0.000 (0.018)\tLoss 0.0148 (0.0154)\tPrec@1 100.000 (99.665)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][30/390]\tTime 0.035 (0.052)\tData 0.000 (0.015)\tLoss 0.0432 (0.0167)\tPrec@1 99.219 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][40/390]\tTime 0.042 (0.050)\tData 0.000 (0.012)\tLoss 0.0044 (0.0160)\tPrec@1 100.000 (99.600)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][50/390]\tTime 0.052 (0.049)\tData 0.012 (0.012)\tLoss 0.0172 (0.0164)\tPrec@1 100.000 (99.617)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][60/390]\tTime 0.032 (0.048)\tData 0.000 (0.010)\tLoss 0.0286 (0.0172)\tPrec@1 99.219 (99.590)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][70/390]\tTime 0.039 (0.047)\tData 0.000 (0.009)\tLoss 0.0139 (0.0167)\tPrec@1 100.000 (99.615)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][80/390]\tTime 0.042 (0.047)\tData 0.000 (0.008)\tLoss 0.0093 (0.0166)\tPrec@1 100.000 (99.595)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][90/390]\tTime 0.042 (0.046)\tData 0.003 (0.008)\tLoss 0.0088 (0.0163)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][100/390]\tTime 0.033 (0.045)\tData 0.000 (0.008)\tLoss 0.0140 (0.0161)\tPrec@1 100.000 (99.621)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][110/390]\tTime 0.054 (0.045)\tData 0.003 (0.007)\tLoss 0.0254 (0.0164)\tPrec@1 99.219 (99.599)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][120/390]\tTime 0.038 (0.045)\tData 0.000 (0.007)\tLoss 0.0071 (0.0159)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][130/390]\tTime 0.021 (0.045)\tData 0.000 (0.006)\tLoss 0.0185 (0.0170)\tPrec@1 99.219 (99.565)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][140/390]\tTime 0.053 (0.045)\tData 0.009 (0.006)\tLoss 0.0058 (0.0168)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][150/390]\tTime 0.051 (0.045)\tData 0.002 (0.006)\tLoss 0.0211 (0.0167)\tPrec@1 99.219 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][160/390]\tTime 0.041 (0.045)\tData 0.007 (0.006)\tLoss 0.0020 (0.0167)\tPrec@1 100.000 (99.583)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][170/390]\tTime 0.052 (0.045)\tData 0.000 (0.006)\tLoss 0.0150 (0.0166)\tPrec@1 99.219 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][180/390]\tTime 0.053 (0.045)\tData 0.005 (0.006)\tLoss 0.0053 (0.0164)\tPrec@1 100.000 (99.586)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][190/390]\tTime 0.042 (0.045)\tData 0.013 (0.006)\tLoss 0.0033 (0.0162)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][200/390]\tTime 0.040 (0.045)\tData 0.000 (0.006)\tLoss 0.0046 (0.0162)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][210/390]\tTime 0.059 (0.045)\tData 0.007 (0.006)\tLoss 0.0109 (0.0162)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][220/390]\tTime 0.045 (0.045)\tData 0.009 (0.006)\tLoss 0.0301 (0.0163)\tPrec@1 98.438 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][230/390]\tTime 0.049 (0.045)\tData 0.002 (0.005)\tLoss 0.0139 (0.0161)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][240/390]\tTime 0.054 (0.044)\tData 0.001 (0.005)\tLoss 0.0108 (0.0162)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][250/390]\tTime 0.056 (0.045)\tData 0.002 (0.005)\tLoss 0.0047 (0.0161)\tPrec@1 100.000 (99.589)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][260/390]\tTime 0.045 (0.045)\tData 0.003 (0.005)\tLoss 0.0527 (0.0162)\tPrec@1 98.438 (99.587)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][270/390]\tTime 0.046 (0.044)\tData 0.007 (0.005)\tLoss 0.0199 (0.0164)\tPrec@1 99.219 (99.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][280/390]\tTime 0.045 (0.045)\tData 0.009 (0.005)\tLoss 0.0053 (0.0163)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][290/390]\tTime 0.041 (0.044)\tData 0.005 (0.005)\tLoss 0.0140 (0.0166)\tPrec@1 99.219 (99.552)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][300/390]\tTime 0.035 (0.044)\tData 0.005 (0.005)\tLoss 0.0137 (0.0167)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][310/390]\tTime 0.039 (0.044)\tData 0.010 (0.005)\tLoss 0.0151 (0.0167)\tPrec@1 99.219 (99.550)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][320/390]\tTime 0.052 (0.044)\tData 0.006 (0.005)\tLoss 0.0312 (0.0166)\tPrec@1 98.438 (99.547)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][330/390]\tTime 0.045 (0.044)\tData 0.003 (0.005)\tLoss 0.0308 (0.0168)\tPrec@1 99.219 (99.542)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][340/390]\tTime 0.046 (0.044)\tData 0.002 (0.005)\tLoss 0.0031 (0.0168)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][350/390]\tTime 0.038 (0.044)\tData 0.005 (0.005)\tLoss 0.0347 (0.0169)\tPrec@1 99.219 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][360/390]\tTime 0.052 (0.044)\tData 0.001 (0.005)\tLoss 0.0102 (0.0169)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][370/390]\tTime 0.047 (0.044)\tData 0.010 (0.005)\tLoss 0.0329 (0.0169)\tPrec@1 98.438 (99.535)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][380/390]\tTime 0.046 (0.044)\tData 0.011 (0.005)\tLoss 0.0161 (0.0170)\tPrec@1 99.219 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [347][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0052 (0.0170)\tPrec@1 100.000 (99.537)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [347][0/79]\tTime 0.275 (0.275)\tData 0.264 (0.264)\tLoss 0.2957 (0.2957)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [347][10/79]\tTime 0.015 (0.042)\tData 0.000 (0.032)\tLoss 0.2734 (0.3788)\tPrec@1 90.625 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [347][20/79]\tTime 0.054 (0.037)\tData 0.048 (0.027)\tLoss 0.5276 (0.4153)\tPrec@1 89.844 (91.518)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [347][30/79]\tTime 0.016 (0.035)\tData 0.001 (0.025)\tLoss 0.0997 (0.4018)\tPrec@1 97.656 (91.910)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [347][40/79]\tTime 0.019 (0.032)\tData 0.005 (0.022)\tLoss 0.2483 (0.4028)\tPrec@1 92.188 (91.902)\tPrec@5 99.219 (99.524)\t\n",
            "EVALUATING - Epoch: [347][50/79]\tTime 0.017 (0.031)\tData 0.005 (0.021)\tLoss 0.4295 (0.3954)\tPrec@1 90.625 (91.743)\tPrec@5 100.000 (99.617)\t\n",
            "EVALUATING - Epoch: [347][60/79]\tTime 0.043 (0.030)\tData 0.013 (0.019)\tLoss 0.6522 (0.4002)\tPrec@1 92.969 (91.688)\tPrec@5 99.219 (99.641)\t\n",
            "EVALUATING - Epoch: [347][70/79]\tTime 0.014 (0.030)\tData 0.000 (0.019)\tLoss 0.4072 (0.3922)\tPrec@1 89.844 (91.648)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [347][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2415 (0.3891)\tPrec@1 93.750 (91.690)\tPrec@5 100.000 (99.680)\t\n",
            "\n",
            "Results - Epoch: 348\n",
            "Training Loss 0.0170 \tTraining Prec@1 99.537 \tTraining Prec@5 100.000 \tValidation Loss 0.3891 \tValidation Prec@1 91.690 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 349\n",
            "\n",
            "TRAINING - Epoch: [348][0/390]\tTime 0.233 (0.233)\tData 0.184 (0.184)\tLoss 0.0174 (0.0174)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][10/390]\tTime 0.047 (0.069)\tData 0.003 (0.026)\tLoss 0.0149 (0.0152)\tPrec@1 99.219 (99.645)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][20/390]\tTime 0.046 (0.057)\tData 0.010 (0.017)\tLoss 0.0516 (0.0204)\tPrec@1 98.438 (99.479)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][30/390]\tTime 0.039 (0.053)\tData 0.000 (0.013)\tLoss 0.0099 (0.0181)\tPrec@1 100.000 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][40/390]\tTime 0.045 (0.050)\tData 0.005 (0.011)\tLoss 0.0319 (0.0182)\tPrec@1 99.219 (99.562)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][50/390]\tTime 0.044 (0.049)\tData 0.004 (0.009)\tLoss 0.0103 (0.0186)\tPrec@1 100.000 (99.510)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][60/390]\tTime 0.040 (0.050)\tData 0.001 (0.010)\tLoss 0.0143 (0.0186)\tPrec@1 100.000 (99.539)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][70/390]\tTime 0.039 (0.049)\tData 0.000 (0.009)\tLoss 0.0086 (0.0184)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][80/390]\tTime 0.040 (0.047)\tData 0.005 (0.008)\tLoss 0.0150 (0.0175)\tPrec@1 100.000 (99.614)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][90/390]\tTime 0.196 (0.049)\tData 0.173 (0.010)\tLoss 0.0144 (0.0170)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][100/390]\tTime 0.045 (0.048)\tData 0.002 (0.009)\tLoss 0.0058 (0.0172)\tPrec@1 100.000 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][110/390]\tTime 0.052 (0.047)\tData 0.009 (0.009)\tLoss 0.0098 (0.0172)\tPrec@1 100.000 (99.599)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][120/390]\tTime 0.042 (0.047)\tData 0.000 (0.008)\tLoss 0.0246 (0.0169)\tPrec@1 99.219 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][130/390]\tTime 0.049 (0.047)\tData 0.005 (0.008)\tLoss 0.0080 (0.0169)\tPrec@1 100.000 (99.594)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][140/390]\tTime 0.029 (0.047)\tData 0.001 (0.008)\tLoss 0.0041 (0.0172)\tPrec@1 100.000 (99.579)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][150/390]\tTime 0.045 (0.046)\tData 0.009 (0.008)\tLoss 0.0172 (0.0172)\tPrec@1 99.219 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][160/390]\tTime 0.044 (0.047)\tData 0.021 (0.008)\tLoss 0.0136 (0.0169)\tPrec@1 99.219 (99.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][170/390]\tTime 0.040 (0.047)\tData 0.007 (0.008)\tLoss 0.0194 (0.0170)\tPrec@1 100.000 (99.584)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][180/390]\tTime 0.033 (0.046)\tData 0.006 (0.008)\tLoss 0.0099 (0.0168)\tPrec@1 100.000 (99.581)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][190/390]\tTime 0.038 (0.046)\tData 0.005 (0.008)\tLoss 0.0333 (0.0170)\tPrec@1 99.219 (99.575)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][200/390]\tTime 0.027 (0.046)\tData 0.000 (0.008)\tLoss 0.0066 (0.0169)\tPrec@1 100.000 (99.576)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][210/390]\tTime 0.036 (0.046)\tData 0.000 (0.008)\tLoss 0.0081 (0.0168)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][220/390]\tTime 0.037 (0.046)\tData 0.003 (0.007)\tLoss 0.0097 (0.0165)\tPrec@1 99.219 (99.597)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][230/390]\tTime 0.031 (0.045)\tData 0.000 (0.007)\tLoss 0.0109 (0.0164)\tPrec@1 100.000 (99.601)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][240/390]\tTime 0.039 (0.045)\tData 0.008 (0.007)\tLoss 0.0098 (0.0166)\tPrec@1 100.000 (99.598)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][250/390]\tTime 0.039 (0.045)\tData 0.000 (0.007)\tLoss 0.0156 (0.0164)\tPrec@1 100.000 (99.605)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][260/390]\tTime 0.041 (0.045)\tData 0.013 (0.007)\tLoss 0.0056 (0.0163)\tPrec@1 100.000 (99.611)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][270/390]\tTime 0.055 (0.045)\tData 0.005 (0.007)\tLoss 0.0208 (0.0165)\tPrec@1 98.438 (99.599)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][280/390]\tTime 0.040 (0.045)\tData 0.005 (0.007)\tLoss 0.0200 (0.0164)\tPrec@1 99.219 (99.602)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][290/390]\tTime 0.036 (0.045)\tData 0.000 (0.007)\tLoss 0.0240 (0.0164)\tPrec@1 98.438 (99.603)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][300/390]\tTime 0.059 (0.045)\tData 0.025 (0.007)\tLoss 0.0108 (0.0166)\tPrec@1 100.000 (99.598)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][310/390]\tTime 0.053 (0.045)\tData 0.000 (0.007)\tLoss 0.0152 (0.0165)\tPrec@1 99.219 (99.601)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][320/390]\tTime 0.051 (0.045)\tData 0.018 (0.007)\tLoss 0.0091 (0.0163)\tPrec@1 100.000 (99.608)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][330/390]\tTime 0.047 (0.045)\tData 0.001 (0.007)\tLoss 0.0086 (0.0162)\tPrec@1 100.000 (99.618)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][340/390]\tTime 0.046 (0.045)\tData 0.014 (0.007)\tLoss 0.0122 (0.0162)\tPrec@1 99.219 (99.617)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][350/390]\tTime 0.049 (0.045)\tData 0.003 (0.007)\tLoss 0.0341 (0.0164)\tPrec@1 99.219 (99.615)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][360/390]\tTime 0.055 (0.045)\tData 0.003 (0.007)\tLoss 0.0212 (0.0164)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][370/390]\tTime 0.045 (0.045)\tData 0.000 (0.006)\tLoss 0.0236 (0.0166)\tPrec@1 99.219 (99.606)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][380/390]\tTime 0.030 (0.044)\tData 0.000 (0.006)\tLoss 0.0084 (0.0166)\tPrec@1 100.000 (99.608)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [348][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.006)\tLoss 0.0192 (0.0165)\tPrec@1 99.219 (99.603)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [348][0/79]\tTime 0.242 (0.242)\tData 0.223 (0.223)\tLoss 0.2966 (0.2966)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [348][10/79]\tTime 0.041 (0.047)\tData 0.022 (0.037)\tLoss 0.2487 (0.3677)\tPrec@1 91.406 (92.330)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [348][20/79]\tTime 0.016 (0.036)\tData 0.000 (0.026)\tLoss 0.5459 (0.4128)\tPrec@1 89.844 (91.704)\tPrec@5 98.438 (99.628)\t\n",
            "EVALUATING - Epoch: [348][30/79]\tTime 0.023 (0.038)\tData 0.012 (0.028)\tLoss 0.0954 (0.4008)\tPrec@1 97.656 (91.961)\tPrec@5 100.000 (99.572)\t\n",
            "EVALUATING - Epoch: [348][40/79]\tTime 0.019 (0.034)\tData 0.004 (0.023)\tLoss 0.2516 (0.4010)\tPrec@1 90.625 (91.883)\tPrec@5 99.219 (99.581)\t\n",
            "EVALUATING - Epoch: [348][50/79]\tTime 0.023 (0.033)\tData 0.007 (0.022)\tLoss 0.4366 (0.3945)\tPrec@1 90.625 (91.835)\tPrec@5 100.000 (99.663)\t\n",
            "EVALUATING - Epoch: [348][60/79]\tTime 0.028 (0.033)\tData 0.003 (0.021)\tLoss 0.6492 (0.3984)\tPrec@1 92.188 (91.778)\tPrec@5 99.219 (99.693)\t\n",
            "EVALUATING - Epoch: [348][70/79]\tTime 0.027 (0.034)\tData 0.003 (0.022)\tLoss 0.3973 (0.3910)\tPrec@1 89.062 (91.703)\tPrec@5 100.000 (99.714)\t\n",
            "EVALUATING - Epoch: [348][78/79]\tTime 0.004 (0.032)\tData 0.000 (0.020)\tLoss 0.2647 (0.3878)\tPrec@1 93.750 (91.700)\tPrec@5 100.000 (99.710)\t\n",
            "\n",
            "Results - Epoch: 349\n",
            "Training Loss 0.0165 \tTraining Prec@1 99.603 \tTraining Prec@5 100.000 \tValidation Loss 0.3878 \tValidation Prec@1 91.700 \tValidation Prec@5 99.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 350\n",
            "\n",
            "TRAINING - Epoch: [349][0/390]\tTime 0.295 (0.295)\tData 0.233 (0.233)\tLoss 0.0210 (0.0210)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][10/390]\tTime 0.030 (0.069)\tData 0.000 (0.027)\tLoss 0.0210 (0.0155)\tPrec@1 100.000 (99.716)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][20/390]\tTime 0.048 (0.057)\tData 0.003 (0.017)\tLoss 0.0213 (0.0171)\tPrec@1 99.219 (99.554)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][30/390]\tTime 0.039 (0.053)\tData 0.000 (0.013)\tLoss 0.0320 (0.0176)\tPrec@1 99.219 (99.496)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][40/390]\tTime 0.050 (0.051)\tData 0.014 (0.011)\tLoss 0.0233 (0.0168)\tPrec@1 98.438 (99.486)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][50/390]\tTime 0.041 (0.049)\tData 0.007 (0.010)\tLoss 0.0111 (0.0181)\tPrec@1 100.000 (99.433)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][60/390]\tTime 0.056 (0.048)\tData 0.010 (0.009)\tLoss 0.0177 (0.0187)\tPrec@1 100.000 (99.449)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][70/390]\tTime 0.049 (0.048)\tData 0.012 (0.009)\tLoss 0.0196 (0.0179)\tPrec@1 99.219 (99.483)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][80/390]\tTime 0.034 (0.047)\tData 0.002 (0.009)\tLoss 0.0085 (0.0180)\tPrec@1 100.000 (99.498)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][90/390]\tTime 0.027 (0.047)\tData 0.000 (0.009)\tLoss 0.0196 (0.0182)\tPrec@1 99.219 (99.485)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][100/390]\tTime 0.042 (0.046)\tData 0.010 (0.009)\tLoss 0.0047 (0.0184)\tPrec@1 100.000 (99.474)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][110/390]\tTime 0.070 (0.046)\tData 0.004 (0.009)\tLoss 0.0194 (0.0189)\tPrec@1 99.219 (99.430)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][120/390]\tTime 0.046 (0.046)\tData 0.004 (0.008)\tLoss 0.0088 (0.0188)\tPrec@1 100.000 (99.419)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][130/390]\tTime 0.037 (0.045)\tData 0.001 (0.008)\tLoss 0.0118 (0.0190)\tPrec@1 100.000 (99.416)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][140/390]\tTime 0.039 (0.045)\tData 0.000 (0.007)\tLoss 0.0071 (0.0189)\tPrec@1 100.000 (99.440)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][150/390]\tTime 0.061 (0.045)\tData 0.016 (0.007)\tLoss 0.0471 (0.0191)\tPrec@1 99.219 (99.431)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][160/390]\tTime 0.035 (0.045)\tData 0.007 (0.007)\tLoss 0.0158 (0.0190)\tPrec@1 99.219 (99.432)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][170/390]\tTime 0.040 (0.045)\tData 0.001 (0.007)\tLoss 0.0133 (0.0188)\tPrec@1 100.000 (99.456)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][180/390]\tTime 0.048 (0.045)\tData 0.002 (0.007)\tLoss 0.0170 (0.0188)\tPrec@1 100.000 (99.452)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][190/390]\tTime 0.033 (0.045)\tData 0.000 (0.006)\tLoss 0.0291 (0.0186)\tPrec@1 99.219 (99.460)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][200/390]\tTime 0.043 (0.045)\tData 0.001 (0.006)\tLoss 0.0097 (0.0185)\tPrec@1 99.219 (99.444)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [349][210/390]\tTime 0.046 (0.045)\tData 0.007 (0.006)\tLoss 0.0245 (0.0185)\tPrec@1 99.219 (99.441)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [349][220/390]\tTime 0.039 (0.045)\tData 0.001 (0.006)\tLoss 0.0039 (0.0184)\tPrec@1 100.000 (99.434)\tPrec@5 100.000 (99.996)\t\n",
            "TRAINING - Epoch: [349][230/390]\tTime 0.048 (0.045)\tData 0.004 (0.006)\tLoss 0.0170 (0.0183)\tPrec@1 99.219 (99.435)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [349][240/390]\tTime 0.049 (0.045)\tData 0.012 (0.006)\tLoss 0.0120 (0.0182)\tPrec@1 99.219 (99.446)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [349][250/390]\tTime 0.035 (0.045)\tData 0.000 (0.006)\tLoss 0.0101 (0.0181)\tPrec@1 100.000 (99.452)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [349][260/390]\tTime 0.038 (0.045)\tData 0.006 (0.006)\tLoss 0.0396 (0.0182)\tPrec@1 97.656 (99.452)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [349][270/390]\tTime 0.048 (0.045)\tData 0.009 (0.006)\tLoss 0.0058 (0.0182)\tPrec@1 100.000 (99.449)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [349][280/390]\tTime 0.049 (0.045)\tData 0.005 (0.006)\tLoss 0.0107 (0.0181)\tPrec@1 100.000 (99.455)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [349][290/390]\tTime 0.037 (0.045)\tData 0.001 (0.006)\tLoss 0.0169 (0.0180)\tPrec@1 100.000 (99.463)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [349][300/390]\tTime 0.045 (0.045)\tData 0.006 (0.006)\tLoss 0.0176 (0.0179)\tPrec@1 99.219 (99.458)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [349][310/390]\tTime 0.030 (0.044)\tData 0.001 (0.006)\tLoss 0.0237 (0.0178)\tPrec@1 99.219 (99.460)\tPrec@5 100.000 (99.997)\t\n",
            "TRAINING - Epoch: [349][320/390]\tTime 0.057 (0.044)\tData 0.003 (0.006)\tLoss 0.0196 (0.0179)\tPrec@1 99.219 (99.457)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [349][330/390]\tTime 0.059 (0.045)\tData 0.007 (0.006)\tLoss 0.0123 (0.0177)\tPrec@1 100.000 (99.464)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [349][340/390]\tTime 0.043 (0.044)\tData 0.000 (0.006)\tLoss 0.0063 (0.0174)\tPrec@1 100.000 (99.475)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [349][350/390]\tTime 0.052 (0.044)\tData 0.009 (0.006)\tLoss 0.0228 (0.0176)\tPrec@1 99.219 (99.468)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [349][360/390]\tTime 0.049 (0.045)\tData 0.003 (0.006)\tLoss 0.0126 (0.0175)\tPrec@1 99.219 (99.468)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [349][370/390]\tTime 0.023 (0.045)\tData 0.000 (0.005)\tLoss 0.0131 (0.0174)\tPrec@1 99.219 (99.474)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [349][380/390]\tTime 0.056 (0.044)\tData 0.005 (0.006)\tLoss 0.0090 (0.0173)\tPrec@1 100.000 (99.485)\tPrec@5 100.000 (99.998)\t\n",
            "TRAINING - Epoch: [349][389/390]\tTime 0.018 (0.044)\tData 0.000 (0.005)\tLoss 0.0436 (0.0174)\tPrec@1 98.438 (99.479)\tPrec@5 100.000 (99.998)\t\n",
            "EVALUATING - Epoch: [349][0/79]\tTime 0.194 (0.194)\tData 0.185 (0.185)\tLoss 0.2939 (0.2939)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [349][10/79]\tTime 0.006 (0.045)\tData 0.000 (0.033)\tLoss 0.2706 (0.3743)\tPrec@1 91.406 (92.543)\tPrec@5 100.000 (99.787)\t\n",
            "EVALUATING - Epoch: [349][20/79]\tTime 0.023 (0.038)\tData 0.005 (0.026)\tLoss 0.5349 (0.4099)\tPrec@1 89.844 (91.741)\tPrec@5 98.438 (99.591)\t\n",
            "EVALUATING - Epoch: [349][30/79]\tTime 0.018 (0.035)\tData 0.002 (0.023)\tLoss 0.0972 (0.3959)\tPrec@1 97.656 (92.011)\tPrec@5 100.000 (99.546)\t\n",
            "EVALUATING - Epoch: [349][40/79]\tTime 0.014 (0.032)\tData 0.000 (0.019)\tLoss 0.2505 (0.3970)\tPrec@1 91.406 (91.921)\tPrec@5 99.219 (99.505)\t\n",
            "EVALUATING - Epoch: [349][50/79]\tTime 0.027 (0.032)\tData 0.017 (0.020)\tLoss 0.4084 (0.3898)\tPrec@1 89.844 (91.805)\tPrec@5 100.000 (99.602)\t\n",
            "EVALUATING - Epoch: [349][60/79]\tTime 0.006 (0.031)\tData 0.000 (0.019)\tLoss 0.6388 (0.3948)\tPrec@1 92.188 (91.765)\tPrec@5 100.000 (99.641)\t\n",
            "EVALUATING - Epoch: [349][70/79]\tTime 0.012 (0.031)\tData 0.000 (0.019)\tLoss 0.3916 (0.3875)\tPrec@1 89.844 (91.736)\tPrec@5 100.000 (99.681)\t\n",
            "EVALUATING - Epoch: [349][78/79]\tTime 0.003 (0.029)\tData 0.000 (0.018)\tLoss 0.2294 (0.3847)\tPrec@1 93.750 (91.750)\tPrec@5 100.000 (99.690)\t\n",
            "\n",
            "Results - Epoch: 350\n",
            "Training Loss 0.0174 \tTraining Prec@1 99.479 \tTraining Prec@5 99.998 \tValidation Loss 0.3847 \tValidation Prec@1 91.750 \tValidation Prec@5 99.690 \t\n",
            "\n"
          ]
        }
      ]
    }
  ]
}